{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k00pXj_pKs0G"
      },
      "source": [
        "# Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AG3q2RyIWCSD",
        "outputId": "7bbea9df-b527-4365-c0ea-b99a22cc8410"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.41.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.3.0+cu121)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.30.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.5.40)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "pip install transformers[torch]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxAyx5-NLGNS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from scipy.stats import chi2_contingency\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set the aesthetic style of the plots\n",
        "sns.set_style(\"whitegrid\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PsEDOJxEKu5P"
      },
      "outputs": [],
      "source": [
        "# test_link = 'https://drive.google.com/file/d/1LJPFNBy2Pq4Nuf_rTMZmCYnzJp9ARUD-/view?usp=sharing'\n",
        "# train_link = 'https://drive.google.com/file/d/1VpAX69AkSsfJQxl-GAv-QWMSq8Lm2mLi/view?usp=sharing'\n",
        "# df_train = pd.read_csv(train_link)\n",
        "# df_test = pd.read_csv(test_link)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "raoqW_eTLU9O",
        "outputId": "624b08fe-0d39-4ffd-972b-c3b73dd6f2ca"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-aca231b7-5f1d-4220-b93f-e0fc23b86e63\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-aca231b7-5f1d-4220-b93f-e0fc23b86e63\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving unlabelled_test_data.csv to unlabelled_test_data (1).csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9fZDPYwLkJ7"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv('training_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RD48eKZaMcDC"
      },
      "outputs": [],
      "source": [
        "df_test = pd.read_csv('unlabelled_test_data.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCiUF3R_Xgrv"
      },
      "source": [
        "# Basic models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miFa8vX_Ntj_"
      },
      "source": [
        "**Linear Regression**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWGB2f1sMtD9",
        "outputId": "0d718127-8586-43c9-bfb0-90b535ab8653"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.45\n",
            "Overall Precision: 0.3\n",
            "Overall Recall: 0.31\n",
            "Overall F1-score: 0.3\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          A1       0.49      0.64      0.56       166\n",
            "          A2       0.33      0.30      0.31       158\n",
            "          B1       0.43      0.29      0.35       166\n",
            "          B2       0.46      0.44      0.45       153\n",
            "          C1       0.45      0.46      0.46       152\n",
            "          C2       0.51      0.57      0.54       165\n",
            "\n",
            "    accuracy                           0.45       960\n",
            "   macro avg       0.45      0.45      0.44       960\n",
            "weighted avg       0.45      0.45      0.44       960\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support\n",
        "\n",
        "# Initialize TF-IDF Vectorizer\n",
        "tfidf = TfidfVectorizer(lowercase=True, max_features=10000)\n",
        "\n",
        "# Fit and transform the training data\n",
        "X_train_tfidf = tfidf.fit_transform(df_train['sentence'])\n",
        "\n",
        "# Transform the test data using the same vectorizer\n",
        "X_test_tfidf = tfidf.transform(df_test['sentence'])\n",
        "\n",
        "# Encode the difficulty levels from the training data\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(df_train['difficulty'])\n",
        "\n",
        "# Splitting the training data into train and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_tfidf, y_train_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Display the shapes of the transformed data\n",
        "# print(X_train.shape, X_val.shape, X_test_tfidf.shape)\n",
        "\n",
        "# Initialize and train the logistic regression model\n",
        "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the validation set\n",
        "y_val_pred = log_reg.predict(X_val)\n",
        "\n",
        "# Calculate accuracy on the validation set\n",
        "validation_accuracy = round(accuracy_score(y_val, y_val_pred), 2)\n",
        "print(\"Validation Accuracy:\", validation_accuracy)\n",
        "\n",
        "# Calculate overall precision, recall, and F1-score\n",
        "precision, recall, f1_score, _ = precision_recall_fscore_support(y_val, y_val_pred_dt, average='weighted')\n",
        "\n",
        "print(\"Overall Precision:\", round(precision, 2))\n",
        "print(\"Overall Recall:\", round(recall, 2))\n",
        "print(\"Overall F1-score:\", round(f1_score, 2))\n",
        "print()\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "classification_report_val = classification_report(y_val, y_val_pred, target_names=label_encoder.classes_)\n",
        "print(\"Classification Report:\\n\", classification_report_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouGIC3XWR5YL"
      },
      "source": [
        "For a linear regression it is possible to make a small improvement, but the result is still far from a decent level."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cNhkdDRSJyu",
        "outputId": "0a6d987b-a44f-4be2-9e89-c25c9058cd30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.46\n"
          ]
        }
      ],
      "source": [
        "# Reinitialize the TF-IDF Vectorizer with increased features and including bi-grams and tri-grams\n",
        "tfidf_enhanced = TfidfVectorizer(lowercase=True, max_features=20000, ngram_range=(1, 3))\n",
        "\n",
        "# Fit and transform the training data\n",
        "X_train_tfidf_enhanced = tfidf_enhanced.fit_transform(df_train['sentence'])\n",
        "\n",
        "# Transform the test data using the same enhanced vectorizer\n",
        "X_test_tfidf_enhanced = tfidf_enhanced.transform(df_test['sentence'])\n",
        "\n",
        "# Using the same label encoder as before\n",
        "# Split the enhanced training data into train and validation sets\n",
        "X_train_enhanced, X_val_enhanced, y_train, y_val = train_test_split(X_train_tfidf_enhanced, y_train_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Display the shapes of the transformed data\n",
        "X_train_enhanced.shape, X_val_enhanced.shape, X_test_tfidf_enhanced.shape\n",
        "\n",
        "# Reinitialize and train the logistic regression model with the enhanced features\n",
        "log_reg_enhanced = LogisticRegression(max_iter=1000, random_state=42)\n",
        "log_reg_enhanced.fit(X_train_enhanced, y_train)\n",
        "\n",
        "# Predict on the enhanced validation set\n",
        "y_val_pred_enhanced = log_reg_enhanced.predict(X_val_enhanced)\n",
        "\n",
        "# Calculate accuracy on the enhanced validation set\n",
        "validation_accuracy_enhanced = accuracy_score(y_val, y_val_pred_enhanced)\n",
        "print(\"Accuracy:\", round(validation_accuracy_enhanced, 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApddlZiUN40C"
      },
      "source": [
        "**KNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IT0aTL3sNLXc",
        "outputId": "7f2a4481-2b92-4192-bc1b-94dc5332f8fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy (KNN): 0.33\n",
            "Overall Precision: 0.3\n",
            "Overall Recall: 0.31\n",
            "Overall F1-score: 0.3\n",
            "\n",
            "Classification Report (KNN):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          A1       0.30      0.79      0.43       166\n",
            "          A2       0.24      0.24      0.24       158\n",
            "          B1       0.21      0.11      0.14       166\n",
            "          B2       0.61      0.20      0.30       153\n",
            "          C1       0.40      0.43      0.41       152\n",
            "          C2       0.63      0.22      0.32       165\n",
            "\n",
            "    accuracy                           0.33       960\n",
            "   macro avg       0.40      0.33      0.31       960\n",
            "weighted avg       0.40      0.33      0.31       960\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support\n",
        "\n",
        "# Initialize TF-IDF Vectorizer\n",
        "tfidf = TfidfVectorizer(lowercase=True, max_features=10000)\n",
        "\n",
        "# Fit and transform the training data\n",
        "X_train_tfidf = tfidf.fit_transform(df_train['sentence'])\n",
        "\n",
        "# Transform the test data using the same vectorizer\n",
        "X_test_tfidf = tfidf.transform(df_test['sentence'])\n",
        "\n",
        "# Encode the difficulty levels from the training data\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(df_train['difficulty'])\n",
        "\n",
        "# Splitting the training data into train and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_tfidf, y_train_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Display the shapes of the transformed data\n",
        "# print(X_train.shape, X_val.shape, X_test_tfidf.shape)\n",
        "\n",
        "# Initialize the KNN model with a chosen number of neighbors, let's start with k=5\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# Train the KNN model\n",
        "knn_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the validation set\n",
        "y_val_pred_knn = knn_model.predict(X_val)\n",
        "\n",
        "# Calculate accuracy on the validation set\n",
        "validation_accuracy_knn = round(accuracy_score(y_val, y_val_pred_knn), 2)\n",
        "print(\"Validation Accuracy (KNN):\", validation_accuracy_knn)\n",
        "\n",
        "# Calculate overall precision, recall, and F1-score\n",
        "precision, recall, f1_score, _ = precision_recall_fscore_support(y_val, y_val_pred_dt, average='weighted')\n",
        "\n",
        "print(\"Overall Precision:\", round(precision, 2))\n",
        "print(\"Overall Recall:\", round(recall, 2))\n",
        "print(\"Overall F1-score:\", round(f1_score, 2))\n",
        "print()\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "classification_report_knn = classification_report(y_val, y_val_pred_knn, target_names=label_encoder.classes_)\n",
        "print(\"Classification Report (KNN):\\n\", classification_report_knn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCVwOYrgOYWG"
      },
      "source": [
        "**Decision Tree**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raosSGw0OB35",
        "outputId": "e5a3860e-0403-4410-9455-1339ad4c3385"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy (Decision Tree): 0.31\n",
            "Overall Precision: 0.3\n",
            "Overall Recall: 0.31\n",
            "Overall F1-score: 0.3\n",
            "\n",
            "Classification Report (Decision Tree):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          A1       0.44      0.51      0.47       166\n",
            "          A2       0.23      0.20      0.21       158\n",
            "          B1       0.24      0.22      0.23       166\n",
            "          B2       0.26      0.30      0.28       153\n",
            "          C1       0.32      0.30      0.31       152\n",
            "          C2       0.33      0.30      0.31       165\n",
            "\n",
            "    accuracy                           0.31       960\n",
            "   macro avg       0.30      0.31      0.30       960\n",
            "weighted avg       0.30      0.31      0.30       960\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support\n",
        "\n",
        "# Initialize TF-IDF Vectorizer\n",
        "tfidf = TfidfVectorizer(lowercase=True, max_features=10000)\n",
        "\n",
        "# Fit and transform the training data\n",
        "X_train_tfidf = tfidf.fit_transform(df_train['sentence'])\n",
        "\n",
        "# Transform the test data using the same vectorizer\n",
        "X_test_tfidf = tfidf.transform(df_test['sentence'])\n",
        "\n",
        "# Encode the difficulty levels from the training data\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(df_train['difficulty'])\n",
        "\n",
        "# Splitting the training data into train and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_tfidf, y_train_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Display the shapes of the transformed data\n",
        "# print(X_train.shape, X_val.shape, X_test_tfidf.shape)\n",
        "\n",
        "# Initialize the Decision Tree model\n",
        "decision_tree = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the Decision Tree model\n",
        "decision_tree.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the validation set\n",
        "y_val_pred_dt = decision_tree.predict(X_val)\n",
        "\n",
        "# Calculate accuracy on the validation set\n",
        "validation_accuracy_dt = round(accuracy_score(y_val, y_val_pred_dt), 2)\n",
        "print(\"Validation Accuracy (Decision Tree):\", validation_accuracy_dt)\n",
        "\n",
        "# Calculate overall precision, recall, and F1-score\n",
        "precision, recall, f1_score, _ = precision_recall_fscore_support(y_val, y_val_pred_dt, average='weighted')\n",
        "\n",
        "print(\"Overall Precision:\", round(precision, 2))\n",
        "print(\"Overall Recall:\", round(recall, 2))\n",
        "print(\"Overall F1-score:\", round(f1_score, 2))\n",
        "print()\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "classification_report_dt = classification_report(y_val, y_val_pred_dt, target_names=label_encoder.classes_)\n",
        "print(\"Classification Report (Decision Tree):\\n\", classification_report_dt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehH0b_TYOhL0",
        "outputId": "29466a0a-896b-4047-ed4f-fd3ae65e664b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3840, 10000) (960, 10000) (1200, 10000)\n",
            "Validation Accuracy (Decision Tree): 0.3072916666666667\n",
            "Overall Precision: 0.3025621064733589\n",
            "Overall Recall: 0.3072916666666667\n",
            "Overall F1-score: 0.3037726801388617\n",
            "Classification Report (Decision Tree):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          A1       0.44      0.51      0.47       166\n",
            "          A2       0.23      0.20      0.21       158\n",
            "          B1       0.24      0.22      0.23       166\n",
            "          B2       0.26      0.30      0.28       153\n",
            "          C1       0.32      0.30      0.31       152\n",
            "          C2       0.33      0.30      0.31       165\n",
            "\n",
            "    accuracy                           0.31       960\n",
            "   macro avg       0.30      0.31      0.30       960\n",
            "weighted avg       0.30      0.31      0.30       960\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support\n",
        "\n",
        "# Initialize TF-IDF Vectorizer\n",
        "tfidf = TfidfVectorizer(lowercase=True, max_features=10000)\n",
        "\n",
        "# Fit and transform the training data\n",
        "X_train_tfidf = tfidf.fit_transform(df_train['sentence'])\n",
        "\n",
        "# Transform the test data using the same vectorizer\n",
        "X_test_tfidf = tfidf.transform(df_test['sentence'])\n",
        "\n",
        "# Encode the difficulty levels from the training data\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(df_train['difficulty'])\n",
        "\n",
        "# Splitting the training data into train and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_tfidf, y_train_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Display the shapes of the transformed data\n",
        "# print(X_train.shape, X_val.shape, X_test_tfidf.shape)\n",
        "\n",
        "# Initialize the Decision Tree model\n",
        "decision_tree = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the Decision Tree model\n",
        "decision_tree.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the validation set\n",
        "y_val_pred_dt = decision_tree.predict(X_val)\n",
        "\n",
        "# Calculate accuracy on the validation set\n",
        "validation_accuracy_dt = accuracy_score(y_val, y_val_pred_dt)\n",
        "print(\"Validation Accuracy (Decision Tree):\", validation_accuracy_dt)\n",
        "\n",
        "# Calculate overall precision, recall, and F1-score\n",
        "precision, recall, f1_score, _ = precision_recall_fscore_support(y_val, y_val_pred_dt, average='weighted')\n",
        "\n",
        "print(\"Overall Precision:\", precision)\n",
        "print(\"Overall Recall:\", recall)\n",
        "print(\"Overall F1-score:\", f1_score)\n",
        "\n",
        "# Optional: Detailed classification report\n",
        "classification_report_dt = classification_report(y_val, y_val_pred_dt, target_names=label_encoder.classes_)\n",
        "print(\"Classification Report (Decision Tree):\\n\", classification_report_dt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrUXzPEfQy5A"
      },
      "source": [
        "**Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mRot9LjPHNT",
        "outputId": "0b3ccd8c-1ace-48cd-9849-1115f47891f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy (Random Forest): 0.42\n",
            "Overall Precision: 0.42\n",
            "Overall Recall: 0.42\n",
            "Overall F1-score: 0.4\n",
            "\n",
            "Classification Report (Random Forest):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          A1       0.43      0.73      0.54       166\n",
            "          A2       0.37      0.29      0.33       158\n",
            "          B1       0.41      0.26      0.32       166\n",
            "          B2       0.40      0.44      0.42       153\n",
            "          C1       0.40      0.48      0.43       152\n",
            "          C2       0.53      0.30      0.38       165\n",
            "\n",
            "    accuracy                           0.42       960\n",
            "   macro avg       0.42      0.42      0.40       960\n",
            "weighted avg       0.42      0.42      0.40       960\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support\n",
        "\n",
        "# Initialize TF-IDF Vectorizer\n",
        "tfidf = TfidfVectorizer(lowercase=True, max_features=10000)\n",
        "\n",
        "# Fit and transform the training data\n",
        "X_train_tfidf = tfidf.fit_transform(df_train['sentence'])\n",
        "\n",
        "# Transform the test data using the same vectorizer\n",
        "X_test_tfidf = tfidf.transform(df_test['sentence'])\n",
        "\n",
        "# Encode the difficulty levels from the training data\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(df_train['difficulty'])\n",
        "\n",
        "# Splitting the training data into train and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_tfidf, y_train_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Display the shapes of the transformed data\n",
        "# print(X_train.shape, X_val.shape, X_test_tfidf.shape)\n",
        "\n",
        "# Initialize the Random Forest model\n",
        "random_forest = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Train the Random Forest model\n",
        "random_forest.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the validation set\n",
        "y_val_pred_rf = random_forest.predict(X_val)\n",
        "\n",
        "# Calculate accuracy on the validation set\n",
        "validation_accuracy_rf = accuracy_score(y_val, y_val_pred_rf)\n",
        "print(\"Validation Accuracy (Random Forest):\", round(validation_accuracy_rf, 2))\n",
        "\n",
        "# Calculate overall precision, recall, and F1-score\n",
        "precision, recall, f1_score, _ = precision_recall_fscore_support(y_val, y_val_pred_rf, average='weighted')\n",
        "\n",
        "print(\"Overall Precision:\", round(precision, 2))\n",
        "print(\"Overall Recall:\", round(recall, 2))\n",
        "print(\"Overall F1-score:\", round(f1_score, 2))\n",
        "print()\n",
        "\n",
        "# Optional: Detailed classification report\n",
        "classification_report_rf = classification_report(y_val, y_val_pred_rf, target_names=label_encoder.classes_)\n",
        "print(\"Classification Report (Random Forest):\\n\", classification_report_rf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2SgifwsTOqq"
      },
      "source": [
        "**Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxF_IwxMRGoy",
        "outputId": "51b0dd8e-17de-4073-e9de-b648fc61867f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy (Neural Network): 0.45\n",
            "Overall Precision: 0.45\n",
            "Overall Recall: 0.45\n",
            "Overall F1-score: 0.45\n",
            "\n",
            "Classification Report (Neural Network):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          A1       0.52      0.60      0.56       166\n",
            "          A2       0.33      0.39      0.36       158\n",
            "          B1       0.36      0.29      0.32       166\n",
            "          B2       0.47      0.42      0.44       153\n",
            "          C1       0.46      0.54      0.50       152\n",
            "          C2       0.58      0.47      0.52       165\n",
            "\n",
            "    accuracy                           0.45       960\n",
            "   macro avg       0.45      0.45      0.45       960\n",
            "weighted avg       0.45      0.45      0.45       960\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support\n",
        "\n",
        "# Initialize TF-IDF Vectorizer\n",
        "tfidf = TfidfVectorizer(lowercase=True, max_features=10000)\n",
        "\n",
        "# Fit and transform the training data\n",
        "X_train_tfidf = tfidf.fit_transform(df_train['sentence'])\n",
        "\n",
        "# Transform the test data using the same vectorizer\n",
        "X_test_tfidf = tfidf.transform(df_test['sentence'])\n",
        "\n",
        "# Encode the difficulty levels from the training data\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(df_train['difficulty'])\n",
        "\n",
        "# Splitting the training data into train and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_tfidf, y_train_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Display the shapes of the transformed data\n",
        "# print(X_train.shape, X_val.shape, X_test_tfidf.shape)\n",
        "\n",
        "# Initialize the Neural Network model\n",
        "neural_network = MLPClassifier(random_state=42, max_iter=1000)\n",
        "\n",
        "# Train the Neural Network model\n",
        "neural_network.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the validation set\n",
        "y_val_pred_nn = neural_network.predict(X_val)\n",
        "\n",
        "# Calculate accuracy on the validation set\n",
        "validation_accuracy_nn = accuracy_score(y_val, y_val_pred_nn)\n",
        "print(\"Validation Accuracy (Neural Network):\", round(validation_accuracy_nn, 2))\n",
        "\n",
        "# Calculate overall precision, recall, and F1-score\n",
        "precision, recall, f1_score, _ = precision_recall_fscore_support(y_val, y_val_pred_nn, average='weighted')\n",
        "\n",
        "print(\"Overall Precision:\", round(precision, 2))\n",
        "print(\"Overall Recall:\", round(recall, 2))\n",
        "print(\"Overall F1-score:\", round(f1_score, 2))\n",
        "print()\n",
        "\n",
        "# Optional: Detailed classification report\n",
        "classification_report_nn = classification_report(y_val, y_val_pred_nn, target_names=label_encoder.classes_)\n",
        "print(\"Classification Report (Neural Network):\\n\", classification_report_nn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52YmbbAST2gI"
      },
      "source": [
        "# Advanced model\n",
        "\n",
        "Basic models didn't show good results. To reach a better score, it is crucial to use different embeddings and more advanced techniques. Let's do this!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IJeUUbXlnEn"
      },
      "source": [
        "## NLTK\n",
        "\n",
        "In some models (further) I will use it to generate additional data, that's why I will mention it in advance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8oqmJ74lsB_"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "# -----\n",
        "\n",
        "from nltk.corpus import wordnet\n",
        "import random\n",
        "\n",
        "def synonym_replacement(sentence):\n",
        "    words = sentence.split()\n",
        "    new_sentence = []\n",
        "    for word in words:\n",
        "        synonyms = wordnet.synsets(word, lang='fra')  # Search for French synonyms\n",
        "        if synonyms:\n",
        "            synonym = random.choice(synonyms).lemmas()[0].name()\n",
        "            new_sentence.append(synonym)\n",
        "        else:\n",
        "            new_sentence.append(word)\n",
        "    return ' '.join(new_sentence)\n",
        "\n",
        "# Generate synonyms for each sentence in the training set\n",
        "data = df_train.copy()\n",
        "generated_sentences = [synonym_replacement(sentence) for sentence in data['sentence']]\n",
        "\n",
        "# ----\n",
        "\n",
        "# Create a new DataFrame for generated sentences\n",
        "generated_data = pd.DataFrame({\n",
        "    'sentence': generated_sentences,\n",
        "    'difficulty': data['difficulty']\n",
        "})\n",
        "\n",
        "# Combine with original data\n",
        "combined_data = pd.concat([data, generated_data])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpA918hoV2Z-"
      },
      "source": [
        "## Full Bert\n",
        "\n",
        "As a first advanced model, I decided to use the **\"bert-base-multilingual-cased\"** as this model was pretrained on the top 104 languages with the largest Wikipedia.\n",
        "\n",
        "The best achieved result was **56.2% accuracy**, after that I decided to try to use additional text embeddings and camerbert (french version of Bert). (In the **Appendix**, you can find some of the attempts with different parameters.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537,
          "referenced_widgets": [
            "d1e6f316a1f34d028073cf06e8949ce9",
            "98fe8ebe212b42ec80384c2f8a1b0e48",
            "05e0201913e041a88ea5f55b40c128fa",
            "852743ea279a4c82a04569ee23595852",
            "0cb5a3b80071456e8425ddc5ee152a56"
          ]
        },
        "id": "EaEW53njxAnt",
        "outputId": "c04c63b4-de32-43aa-e21a-15e75e03a214"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1e6f316a1f34d028073cf06e8949ce9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "98fe8ebe212b42ec80384c2f8a1b0e48",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "05e0201913e041a88ea5f55b40c128fa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "852743ea279a4c82a04569ee23595852",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0cb5a3b80071456e8425ddc5ee152a56",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2880' max='2880' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2880/2880 15:10, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.461200</td>\n",
              "      <td>1.246637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.965100</td>\n",
              "      <td>0.995730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.709200</td>\n",
              "      <td>1.068911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.508600</td>\n",
              "      <td>1.403547</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.575\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# Load data\n",
        "training_data = df_train\n",
        "test_data = df_test\n",
        "\n",
        "# Initialize tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "\n",
        "# Tokenization and dataset preparation\n",
        "class FrenchTextDataset(Dataset):\n",
        "    def __init__(self, texts, labels=None, max_length=800):\n",
        "        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=max_length)\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.labels:\n",
        "            item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)\n",
        "\n",
        "# Encoding the labels\n",
        "label_dict = {label: i for i, label in enumerate(training_data['difficulty'].unique())}\n",
        "training_data['encoded_labels'] = training_data['difficulty'].map(label_dict)\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    training_data['sentence'],\n",
        "    training_data['encoded_labels'],\n",
        "    test_size=0.1\n",
        ")\n",
        "\n",
        "# Prepare datasets\n",
        "train_dataset = FrenchTextDataset(train_texts.tolist(), train_labels.tolist())\n",
        "val_dataset = FrenchTextDataset(val_texts.tolist(), val_labels.tolist())\n",
        "\n",
        "# Load pretrained BERT model\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=len(label_dict))\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=4,\n",
        "    per_device_train_batch_size=6,\n",
        "    per_device_eval_batch_size=12,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\"\n",
        ")\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Prediction on validation data for evaluation\n",
        "outputs = trainer.predict(val_dataset)\n",
        "val_preds = np.argmax(outputs.predictions, axis=-1)\n",
        "val_accuracy = accuracy_score(val_labels, val_preds)\n",
        "print(\"Validation Accuracy:\", val_accuracy)\n",
        "\n",
        "# Prepare test data and predict\n",
        "test_dataset = FrenchTextDataset(test_data['sentence'].tolist())\n",
        "test_outputs = trainer.predict(test_dataset)\n",
        "test_preds = np.argmax(test_outputs.predictions, axis=-1)\n",
        "\n",
        "# Convert numeric predictions back to labels\n",
        "inv_label_dict = {v: k for k, v in label_dict.items()}\n",
        "test_difficulties = [inv_label_dict[pred] for pred in test_preds]\n",
        "\n",
        "# Prepare the submission file\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_data['id'],\n",
        "    'difficulty': test_difficulties\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jw5C2P9FX6t6"
      },
      "outputs": [],
      "source": [
        "submission.to_csv('sample_FB_010_001.csv', index=False)\n",
        "from google.colab import files\n",
        "files.download('sample_FB_010_001.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvd7lgWJbWxv"
      },
      "source": [
        "Full Bert with text embeddings (NLTK) - the accuracy is 51.6."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "16e7f1bbb20449bc8677d3bffacc4f70",
            "03df6020b9fb4cfb8a9436b7dd2b7274",
            "7c152e069bba4e0eb1de42faab91d848",
            "d82b07ee90694fdeaacb483f4b534c47",
            "bbd2c4291bc2438e93e4f17a8cfcb37d",
            "33af99d83f994fdda5f1a1241a26c190",
            "ce796738f25343e78d409a021715d663",
            "a23552e5ea7841529d1f39a5ea6c17ee",
            "793e8ee59ae6492599d45eba1a2b3b25",
            "a994f6bbfd7f4d1589cef3933ac6fbf9",
            "5ff17650b7374eeb8c7f70ec1e68cea4",
            "0d997177551741f184ce944fcf635cb7",
            "ee1a1f2d666f463584615388d62b5b90",
            "49d84830dfe140c59b997545490c8135",
            "17b389aa5b7a4d0ab308f270d4325968",
            "733e7d4ca03e42c59a7fe6241c3cc811",
            "a275227406194bf0b472ee05a2b5fb7f",
            "904d8a2592d148ec882d02982a47798e",
            "ff9b14aa8c354f43855cda0f33fe25cf",
            "aa036fb1cb9c4c3a8a6ff99444509de6",
            "5cbb26bf22b04717b1cab9bacea6a431",
            "23c9ce071f7d49bfb177176be045f071",
            "838ea3137ea743aba873e07bb0e33705",
            "25dd612ccbe64b07ab8b7330f73b791b",
            "f2333f78fef54d3c9805ca1f963a9e3c",
            "a4a544b5e9214bb6990e7f40a5050ad1",
            "ea5c65d03f5f4aec9d697aa05c74a609",
            "ed801dc178e0420498e5a715866063b2",
            "715c0adcfc4549c8aa065038575b8634",
            "c9ddddfb44614a66ade3e9daf4860126",
            "73bac6f7c34748749c765e32f8c1ca33",
            "3f3688f0308b441c810734bba50383aa",
            "154748aa7f9d45c5aafdd6758fa31c47",
            "f9df237cc8ee41b0af6a1673dfd1c3cf",
            "64eca053fbad4119ac97e8ab09711b4e",
            "a666ddc5b55c4475a04102b693d81e29",
            "71a3313a543e4e449184f16a367e1191",
            "63e4ba002dcd49eab7bdec55894b9966",
            "376c4f5326684376bd3b818e0e4ec229",
            "fffadb74a2974676ad614a7a26dd11af",
            "e0d0ea71bc2d4cec95fa17d84912174e",
            "ed2e478e462b46dfb343195bb675bf72",
            "2d63d281516c4e81a1c24d652451eca9",
            "4cc9f3ec455a4467b512e5510d274e9b",
            "1130c12930d14c66b030f9ff0638cea6",
            "6c7de9c797d94fd7a8059d272a36a19f",
            "4a3e7f230a9d43d7a1c41bf02e657955",
            "f8b324d5d073416788a43d426fbb303a",
            "2266f232cb1f4be7872c1d0584c04114",
            "c42c474b89d24ccbb3cc3080135fe171",
            "3d5da44d9f024f7a897b3116b630e0e5",
            "76165cb68ebd42ea90d6c7d76e8b4bcf",
            "f13020bc47314a23ae7ae571d5bb3e75",
            "0d89b2e47c01462ca86e6981425db5a6",
            "54986b4cf12e427db5774d6367ac468b"
          ]
        },
        "id": "jFbNAyjDimlw",
        "outputId": "676a7705-69c1-47c2-a3e3-ce5df611a3dc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "16e7f1bbb20449bc8677d3bffacc4f70",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d997177551741f184ce944fcf635cb7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "838ea3137ea743aba873e07bb0e33705",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f9df237cc8ee41b0af6a1673dfd1c3cf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1130c12930d14c66b030f9ff0638cea6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 1.819430  [    0/ 8640]\n",
            "loss: 1.722090  [   80/ 8640]\n",
            "loss: 1.762729  [  160/ 8640]\n",
            "loss: 1.673600  [  240/ 8640]\n",
            "loss: 1.756749  [  320/ 8640]\n",
            "loss: 1.518456  [  400/ 8640]\n",
            "loss: 1.315417  [  480/ 8640]\n",
            "loss: 1.509497  [  560/ 8640]\n",
            "loss: 1.638610  [  640/ 8640]\n",
            "loss: 1.650122  [  720/ 8640]\n",
            "loss: 1.477011  [  800/ 8640]\n",
            "loss: 1.632597  [  880/ 8640]\n",
            "loss: 1.719302  [  960/ 8640]\n",
            "loss: 1.696949  [ 1040/ 8640]\n",
            "loss: 1.752251  [ 1120/ 8640]\n",
            "loss: 1.850098  [ 1200/ 8640]\n",
            "loss: 1.631422  [ 1280/ 8640]\n",
            "loss: 1.672240  [ 1360/ 8640]\n",
            "loss: 0.995170  [ 1440/ 8640]\n",
            "loss: 1.218635  [ 1520/ 8640]\n",
            "loss: 1.418727  [ 1600/ 8640]\n",
            "loss: 1.762184  [ 1680/ 8640]\n",
            "loss: 1.110772  [ 1760/ 8640]\n",
            "loss: 1.609599  [ 1840/ 8640]\n",
            "loss: 1.447784  [ 1920/ 8640]\n",
            "loss: 1.547804  [ 2000/ 8640]\n",
            "loss: 1.585217  [ 2080/ 8640]\n",
            "loss: 1.266198  [ 2160/ 8640]\n",
            "loss: 1.357282  [ 2240/ 8640]\n",
            "loss: 1.036704  [ 2320/ 8640]\n",
            "loss: 1.240535  [ 2400/ 8640]\n",
            "loss: 0.956048  [ 2480/ 8640]\n",
            "loss: 1.327296  [ 2560/ 8640]\n",
            "loss: 1.364064  [ 2640/ 8640]\n",
            "loss: 0.940716  [ 2720/ 8640]\n",
            "loss: 1.543875  [ 2800/ 8640]\n",
            "loss: 1.659404  [ 2880/ 8640]\n",
            "loss: 1.208020  [ 2960/ 8640]\n",
            "loss: 1.674583  [ 3040/ 8640]\n",
            "loss: 1.539540  [ 3120/ 8640]\n",
            "loss: 1.450037  [ 3200/ 8640]\n",
            "loss: 1.001634  [ 3280/ 8640]\n",
            "loss: 1.163105  [ 3360/ 8640]\n",
            "loss: 1.368861  [ 3440/ 8640]\n",
            "loss: 1.435775  [ 3520/ 8640]\n",
            "loss: 1.138355  [ 3600/ 8640]\n",
            "loss: 1.256856  [ 3680/ 8640]\n",
            "loss: 1.777172  [ 3760/ 8640]\n",
            "loss: 1.689323  [ 3840/ 8640]\n",
            "loss: 1.855631  [ 3920/ 8640]\n",
            "loss: 1.317671  [ 4000/ 8640]\n",
            "loss: 1.041698  [ 4080/ 8640]\n",
            "loss: 0.940635  [ 4160/ 8640]\n",
            "loss: 1.025195  [ 4240/ 8640]\n",
            "loss: 1.141366  [ 4320/ 8640]\n",
            "loss: 1.899372  [ 4400/ 8640]\n",
            "loss: 1.589409  [ 4480/ 8640]\n",
            "loss: 1.121916  [ 4560/ 8640]\n",
            "loss: 0.942416  [ 4640/ 8640]\n",
            "loss: 0.874278  [ 4720/ 8640]\n",
            "loss: 0.989039  [ 4800/ 8640]\n",
            "loss: 1.511705  [ 4880/ 8640]\n",
            "loss: 0.948140  [ 4960/ 8640]\n",
            "loss: 0.874584  [ 5040/ 8640]\n",
            "loss: 1.442161  [ 5120/ 8640]\n",
            "loss: 1.021063  [ 5200/ 8640]\n",
            "loss: 1.121115  [ 5280/ 8640]\n",
            "loss: 1.154216  [ 5360/ 8640]\n",
            "loss: 0.890721  [ 5440/ 8640]\n",
            "loss: 1.496791  [ 5520/ 8640]\n",
            "loss: 0.948438  [ 5600/ 8640]\n",
            "loss: 0.912557  [ 5680/ 8640]\n",
            "loss: 1.263762  [ 5760/ 8640]\n",
            "loss: 1.244811  [ 5840/ 8640]\n",
            "loss: 1.041920  [ 5920/ 8640]\n",
            "loss: 1.410091  [ 6000/ 8640]\n",
            "loss: 1.088055  [ 6080/ 8640]\n",
            "loss: 1.047107  [ 6160/ 8640]\n",
            "loss: 1.332224  [ 6240/ 8640]\n",
            "loss: 1.445737  [ 6320/ 8640]\n",
            "loss: 1.020184  [ 6400/ 8640]\n",
            "loss: 1.250592  [ 6480/ 8640]\n",
            "loss: 0.721099  [ 6560/ 8640]\n",
            "loss: 1.428160  [ 6640/ 8640]\n",
            "loss: 0.980514  [ 6720/ 8640]\n",
            "loss: 0.936477  [ 6800/ 8640]\n",
            "loss: 1.587700  [ 6880/ 8640]\n",
            "loss: 1.797162  [ 6960/ 8640]\n",
            "loss: 1.534282  [ 7040/ 8640]\n",
            "loss: 1.094440  [ 7120/ 8640]\n",
            "loss: 1.216544  [ 7200/ 8640]\n",
            "loss: 1.191279  [ 7280/ 8640]\n",
            "loss: 1.049930  [ 7360/ 8640]\n",
            "loss: 0.864064  [ 7440/ 8640]\n",
            "loss: 1.304217  [ 7520/ 8640]\n",
            "loss: 1.030863  [ 7600/ 8640]\n",
            "loss: 0.943134  [ 7680/ 8640]\n",
            "loss: 0.791498  [ 7760/ 8640]\n",
            "loss: 0.997129  [ 7840/ 8640]\n",
            "loss: 1.056806  [ 7920/ 8640]\n",
            "loss: 1.248467  [ 8000/ 8640]\n",
            "loss: 1.264696  [ 8080/ 8640]\n",
            "loss: 0.970931  [ 8160/ 8640]\n",
            "loss: 1.899784  [ 8240/ 8640]\n",
            "loss: 1.323526  [ 8320/ 8640]\n",
            "loss: 1.258261  [ 8400/ 8640]\n",
            "loss: 0.829149  [ 8480/ 8640]\n",
            "loss: 0.849744  [ 8560/ 8640]\n",
            "Training done\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.784758  [    0/ 8640]\n",
            "loss: 0.861279  [   80/ 8640]\n",
            "loss: 1.136924  [  160/ 8640]\n",
            "loss: 1.159676  [  240/ 8640]\n",
            "loss: 0.822534  [  320/ 8640]\n",
            "loss: 0.765327  [  400/ 8640]\n",
            "loss: 1.010893  [  480/ 8640]\n",
            "loss: 1.153218  [  560/ 8640]\n",
            "loss: 0.980285  [  640/ 8640]\n",
            "loss: 0.946770  [  720/ 8640]\n",
            "loss: 0.864828  [  800/ 8640]\n",
            "loss: 0.423303  [  880/ 8640]\n",
            "loss: 0.695417  [  960/ 8640]\n",
            "loss: 0.537860  [ 1040/ 8640]\n",
            "loss: 1.070250  [ 1120/ 8640]\n",
            "loss: 0.758574  [ 1200/ 8640]\n",
            "loss: 0.730330  [ 1280/ 8640]\n",
            "loss: 1.028184  [ 1360/ 8640]\n",
            "loss: 1.004705  [ 1440/ 8640]\n",
            "loss: 1.178225  [ 1520/ 8640]\n",
            "loss: 1.061129  [ 1600/ 8640]\n",
            "loss: 1.321968  [ 1680/ 8640]\n",
            "loss: 0.781497  [ 1760/ 8640]\n",
            "loss: 1.212656  [ 1840/ 8640]\n",
            "loss: 0.879319  [ 1920/ 8640]\n",
            "loss: 0.632136  [ 2000/ 8640]\n",
            "loss: 1.249580  [ 2080/ 8640]\n",
            "loss: 0.969781  [ 2160/ 8640]\n",
            "loss: 1.430537  [ 2240/ 8640]\n",
            "loss: 1.064166  [ 2320/ 8640]\n",
            "loss: 0.675932  [ 2400/ 8640]\n",
            "loss: 0.780073  [ 2480/ 8640]\n",
            "loss: 0.965381  [ 2560/ 8640]\n",
            "loss: 1.294401  [ 2640/ 8640]\n",
            "loss: 1.440105  [ 2720/ 8640]\n",
            "loss: 0.964813  [ 2800/ 8640]\n",
            "loss: 1.711086  [ 2880/ 8640]\n",
            "loss: 0.799306  [ 2960/ 8640]\n",
            "loss: 0.967038  [ 3040/ 8640]\n",
            "loss: 0.742127  [ 3120/ 8640]\n",
            "loss: 0.651954  [ 3200/ 8640]\n",
            "loss: 1.045490  [ 3280/ 8640]\n",
            "loss: 0.480456  [ 3360/ 8640]\n",
            "loss: 1.334743  [ 3440/ 8640]\n",
            "loss: 0.624954  [ 3520/ 8640]\n",
            "loss: 0.857796  [ 3600/ 8640]\n",
            "loss: 1.098387  [ 3680/ 8640]\n",
            "loss: 0.970847  [ 3760/ 8640]\n",
            "loss: 1.359535  [ 3840/ 8640]\n",
            "loss: 0.770970  [ 3920/ 8640]\n",
            "loss: 0.933300  [ 4000/ 8640]\n",
            "loss: 1.622412  [ 4080/ 8640]\n",
            "loss: 1.391270  [ 4160/ 8640]\n",
            "loss: 1.206559  [ 4240/ 8640]\n",
            "loss: 0.727133  [ 4320/ 8640]\n",
            "loss: 0.738116  [ 4400/ 8640]\n",
            "loss: 0.856577  [ 4480/ 8640]\n",
            "loss: 1.300525  [ 4560/ 8640]\n",
            "loss: 0.622433  [ 4640/ 8640]\n",
            "loss: 0.794409  [ 4720/ 8640]\n",
            "loss: 0.948250  [ 4800/ 8640]\n",
            "loss: 0.593466  [ 4880/ 8640]\n",
            "loss: 1.043440  [ 4960/ 8640]\n",
            "loss: 1.121288  [ 5040/ 8640]\n",
            "loss: 1.034926  [ 5120/ 8640]\n",
            "loss: 0.971113  [ 5200/ 8640]\n",
            "loss: 1.048714  [ 5280/ 8640]\n",
            "loss: 1.013849  [ 5360/ 8640]\n",
            "loss: 0.983550  [ 5440/ 8640]\n",
            "loss: 1.118727  [ 5520/ 8640]\n",
            "loss: 0.762803  [ 5600/ 8640]\n",
            "loss: 0.625766  [ 5680/ 8640]\n",
            "loss: 0.999717  [ 5760/ 8640]\n",
            "loss: 0.847135  [ 5840/ 8640]\n",
            "loss: 1.103040  [ 5920/ 8640]\n",
            "loss: 0.807383  [ 6000/ 8640]\n",
            "loss: 0.936462  [ 6080/ 8640]\n",
            "loss: 1.229480  [ 6160/ 8640]\n",
            "loss: 0.618558  [ 6240/ 8640]\n",
            "loss: 0.536012  [ 6320/ 8640]\n",
            "loss: 0.276931  [ 6400/ 8640]\n",
            "loss: 0.475050  [ 6480/ 8640]\n",
            "loss: 0.546199  [ 6560/ 8640]\n",
            "loss: 0.647259  [ 6640/ 8640]\n",
            "loss: 1.227772  [ 6720/ 8640]\n",
            "loss: 0.765461  [ 6800/ 8640]\n",
            "loss: 1.973796  [ 6880/ 8640]\n",
            "loss: 0.538015  [ 6960/ 8640]\n",
            "loss: 1.059164  [ 7040/ 8640]\n",
            "loss: 0.579641  [ 7120/ 8640]\n",
            "loss: 0.918754  [ 7200/ 8640]\n",
            "loss: 0.735216  [ 7280/ 8640]\n",
            "loss: 0.907249  [ 7360/ 8640]\n",
            "loss: 0.586098  [ 7440/ 8640]\n",
            "loss: 1.123079  [ 7520/ 8640]\n",
            "loss: 0.442895  [ 7600/ 8640]\n",
            "loss: 0.714211  [ 7680/ 8640]\n",
            "loss: 0.497414  [ 7760/ 8640]\n",
            "loss: 0.933850  [ 7840/ 8640]\n",
            "loss: 1.366579  [ 7920/ 8640]\n",
            "loss: 1.185633  [ 8000/ 8640]\n",
            "loss: 1.169522  [ 8080/ 8640]\n",
            "loss: 0.792284  [ 8160/ 8640]\n",
            "loss: 1.231341  [ 8240/ 8640]\n",
            "loss: 1.104420  [ 8320/ 8640]\n",
            "loss: 1.274759  [ 8400/ 8640]\n",
            "loss: 0.864468  [ 8480/ 8640]\n",
            "loss: 0.687432  [ 8560/ 8640]\n",
            "Training done\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.385982  [    0/ 8640]\n",
            "loss: 0.480841  [   80/ 8640]\n",
            "loss: 0.662162  [  160/ 8640]\n",
            "loss: 0.896753  [  240/ 8640]\n",
            "loss: 0.344577  [  320/ 8640]\n",
            "loss: 0.356689  [  400/ 8640]\n",
            "loss: 0.371782  [  480/ 8640]\n",
            "loss: 0.342016  [  560/ 8640]\n",
            "loss: 1.030174  [  640/ 8640]\n",
            "loss: 0.555170  [  720/ 8640]\n",
            "loss: 0.699851  [  800/ 8640]\n",
            "loss: 0.786885  [  880/ 8640]\n",
            "loss: 0.213362  [  960/ 8640]\n",
            "loss: 0.638120  [ 1040/ 8640]\n",
            "loss: 0.258068  [ 1120/ 8640]\n",
            "loss: 0.674520  [ 1200/ 8640]\n",
            "loss: 0.761451  [ 1280/ 8640]\n",
            "loss: 0.260064  [ 1360/ 8640]\n",
            "loss: 0.201311  [ 1440/ 8640]\n",
            "loss: 0.361769  [ 1520/ 8640]\n",
            "loss: 0.115059  [ 1600/ 8640]\n",
            "loss: 0.464279  [ 1680/ 8640]\n",
            "loss: 0.428942  [ 1760/ 8640]\n",
            "loss: 0.654563  [ 1840/ 8640]\n",
            "loss: 0.298645  [ 1920/ 8640]\n",
            "loss: 0.733768  [ 2000/ 8640]\n",
            "loss: 0.838843  [ 2080/ 8640]\n",
            "loss: 0.653326  [ 2160/ 8640]\n",
            "loss: 0.591919  [ 2240/ 8640]\n",
            "loss: 0.544369  [ 2320/ 8640]\n",
            "loss: 0.674174  [ 2400/ 8640]\n",
            "loss: 0.598067  [ 2480/ 8640]\n",
            "loss: 0.948835  [ 2560/ 8640]\n",
            "loss: 0.766862  [ 2640/ 8640]\n",
            "loss: 1.201356  [ 2720/ 8640]\n",
            "loss: 1.083419  [ 2800/ 8640]\n",
            "loss: 0.836505  [ 2880/ 8640]\n",
            "loss: 0.357986  [ 2960/ 8640]\n",
            "loss: 0.542560  [ 3040/ 8640]\n",
            "loss: 1.120839  [ 3120/ 8640]\n",
            "loss: 0.231206  [ 3200/ 8640]\n",
            "loss: 1.053639  [ 3280/ 8640]\n",
            "loss: 0.622933  [ 3360/ 8640]\n",
            "loss: 1.285292  [ 3440/ 8640]\n",
            "loss: 0.521199  [ 3520/ 8640]\n",
            "loss: 0.871008  [ 3600/ 8640]\n",
            "loss: 0.714222  [ 3680/ 8640]\n",
            "loss: 0.917759  [ 3760/ 8640]\n",
            "loss: 0.558802  [ 3840/ 8640]\n",
            "loss: 1.304277  [ 3920/ 8640]\n",
            "loss: 1.358364  [ 4000/ 8640]\n",
            "loss: 0.822271  [ 4080/ 8640]\n",
            "loss: 0.904060  [ 4160/ 8640]\n",
            "loss: 0.595176  [ 4240/ 8640]\n",
            "loss: 0.791659  [ 4320/ 8640]\n",
            "loss: 0.592529  [ 4400/ 8640]\n",
            "loss: 0.543350  [ 4480/ 8640]\n",
            "loss: 0.471884  [ 4560/ 8640]\n",
            "loss: 0.652392  [ 4640/ 8640]\n",
            "loss: 0.297140  [ 4720/ 8640]\n",
            "loss: 0.102369  [ 4800/ 8640]\n",
            "loss: 0.288291  [ 4880/ 8640]\n",
            "loss: 0.776996  [ 4960/ 8640]\n",
            "loss: 1.009439  [ 5040/ 8640]\n",
            "loss: 0.283455  [ 5120/ 8640]\n",
            "loss: 0.431217  [ 5200/ 8640]\n",
            "loss: 0.419945  [ 5280/ 8640]\n",
            "loss: 0.772970  [ 5360/ 8640]\n",
            "loss: 0.625230  [ 5440/ 8640]\n",
            "loss: 0.304739  [ 5520/ 8640]\n",
            "loss: 0.279052  [ 5600/ 8640]\n",
            "loss: 0.235238  [ 5680/ 8640]\n",
            "loss: 0.697786  [ 5760/ 8640]\n",
            "loss: 0.524164  [ 5840/ 8640]\n",
            "loss: 0.941438  [ 5920/ 8640]\n",
            "loss: 0.707874  [ 6000/ 8640]\n",
            "loss: 0.799457  [ 6080/ 8640]\n",
            "loss: 0.837534  [ 6160/ 8640]\n",
            "loss: 0.368318  [ 6240/ 8640]\n",
            "loss: 0.502077  [ 6320/ 8640]\n",
            "loss: 0.577586  [ 6400/ 8640]\n",
            "loss: 0.569722  [ 6480/ 8640]\n",
            "loss: 0.348357  [ 6560/ 8640]\n",
            "loss: 0.432865  [ 6640/ 8640]\n",
            "loss: 1.264072  [ 6720/ 8640]\n",
            "loss: 0.414911  [ 6800/ 8640]\n",
            "loss: 1.061196  [ 6880/ 8640]\n",
            "loss: 0.353432  [ 6960/ 8640]\n",
            "loss: 0.799152  [ 7040/ 8640]\n",
            "loss: 0.898280  [ 7120/ 8640]\n",
            "loss: 1.082008  [ 7200/ 8640]\n",
            "loss: 0.549909  [ 7280/ 8640]\n",
            "loss: 0.510180  [ 7360/ 8640]\n",
            "loss: 0.579475  [ 7440/ 8640]\n",
            "loss: 0.705229  [ 7520/ 8640]\n",
            "loss: 0.440440  [ 7600/ 8640]\n",
            "loss: 0.661409  [ 7680/ 8640]\n",
            "loss: 0.593485  [ 7760/ 8640]\n",
            "loss: 0.850200  [ 7840/ 8640]\n",
            "loss: 0.479670  [ 7920/ 8640]\n",
            "loss: 0.277356  [ 8000/ 8640]\n",
            "loss: 0.535233  [ 8080/ 8640]\n",
            "loss: 1.172954  [ 8160/ 8640]\n",
            "loss: 0.767119  [ 8240/ 8640]\n",
            "loss: 0.649657  [ 8320/ 8640]\n",
            "loss: 0.541557  [ 8400/ 8640]\n",
            "loss: 0.227419  [ 8480/ 8640]\n",
            "loss: 0.703255  [ 8560/ 8640]\n",
            "Training done\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.553940  [    0/ 8640]\n",
            "loss: 0.278744  [   80/ 8640]\n",
            "loss: 0.492963  [  160/ 8640]\n",
            "loss: 0.081746  [  240/ 8640]\n",
            "loss: 0.410460  [  320/ 8640]\n",
            "loss: 0.174197  [  400/ 8640]\n",
            "loss: 0.102050  [  480/ 8640]\n",
            "loss: 0.076478  [  560/ 8640]\n",
            "loss: 0.193029  [  640/ 8640]\n",
            "loss: 0.546322  [  720/ 8640]\n",
            "loss: 0.489105  [  800/ 8640]\n",
            "loss: 0.944431  [  880/ 8640]\n",
            "loss: 0.385590  [  960/ 8640]\n",
            "loss: 0.275082  [ 1040/ 8640]\n",
            "loss: 0.356376  [ 1120/ 8640]\n",
            "loss: 0.506442  [ 1200/ 8640]\n",
            "loss: 0.137072  [ 1280/ 8640]\n",
            "loss: 0.156925  [ 1360/ 8640]\n",
            "loss: 0.297913  [ 1440/ 8640]\n",
            "loss: 0.922051  [ 1520/ 8640]\n",
            "loss: 0.498184  [ 1600/ 8640]\n",
            "loss: 0.811183  [ 1680/ 8640]\n",
            "loss: 0.082123  [ 1760/ 8640]\n",
            "loss: 0.151006  [ 1840/ 8640]\n",
            "loss: 0.274722  [ 1920/ 8640]\n",
            "loss: 0.387033  [ 2000/ 8640]\n",
            "loss: 0.468928  [ 2080/ 8640]\n",
            "loss: 0.564990  [ 2160/ 8640]\n",
            "loss: 0.065453  [ 2240/ 8640]\n",
            "loss: 0.175764  [ 2320/ 8640]\n",
            "loss: 0.302349  [ 2400/ 8640]\n",
            "loss: 0.324567  [ 2480/ 8640]\n",
            "loss: 0.248517  [ 2560/ 8640]\n",
            "loss: 0.492449  [ 2640/ 8640]\n",
            "loss: 0.510086  [ 2720/ 8640]\n",
            "loss: 0.069778  [ 2800/ 8640]\n",
            "loss: 0.156537  [ 2880/ 8640]\n",
            "loss: 0.449014  [ 2960/ 8640]\n",
            "loss: 0.016956  [ 3040/ 8640]\n",
            "loss: 0.436502  [ 3120/ 8640]\n",
            "loss: 0.521058  [ 3200/ 8640]\n",
            "loss: 0.760907  [ 3280/ 8640]\n",
            "loss: 0.888071  [ 3360/ 8640]\n",
            "loss: 0.110396  [ 3440/ 8640]\n",
            "loss: 0.231917  [ 3520/ 8640]\n",
            "loss: 0.122098  [ 3600/ 8640]\n",
            "loss: 0.105075  [ 3680/ 8640]\n",
            "loss: 0.053530  [ 3760/ 8640]\n",
            "loss: 0.296547  [ 3840/ 8640]\n",
            "loss: 0.350711  [ 3920/ 8640]\n",
            "loss: 0.503422  [ 4000/ 8640]\n",
            "loss: 0.325971  [ 4080/ 8640]\n",
            "loss: 0.366213  [ 4160/ 8640]\n",
            "loss: 0.349770  [ 4240/ 8640]\n",
            "loss: 1.102941  [ 4320/ 8640]\n",
            "loss: 0.372628  [ 4400/ 8640]\n",
            "loss: 0.554597  [ 4480/ 8640]\n",
            "loss: 0.374894  [ 4560/ 8640]\n",
            "loss: 0.054260  [ 4640/ 8640]\n",
            "loss: 1.064232  [ 4720/ 8640]\n",
            "loss: 0.083419  [ 4800/ 8640]\n",
            "loss: 0.042975  [ 4880/ 8640]\n",
            "loss: 0.169157  [ 4960/ 8640]\n",
            "loss: 0.406871  [ 5040/ 8640]\n",
            "loss: 0.312096  [ 5120/ 8640]\n",
            "loss: 0.498377  [ 5200/ 8640]\n",
            "loss: 0.615578  [ 5280/ 8640]\n",
            "loss: 0.486420  [ 5360/ 8640]\n",
            "loss: 0.541185  [ 5440/ 8640]\n",
            "loss: 0.587949  [ 5520/ 8640]\n",
            "loss: 0.408044  [ 5600/ 8640]\n",
            "loss: 0.140591  [ 5680/ 8640]\n",
            "loss: 0.677813  [ 5760/ 8640]\n",
            "loss: 0.345650  [ 5840/ 8640]\n",
            "loss: 0.792771  [ 5920/ 8640]\n",
            "loss: 0.481004  [ 6000/ 8640]\n",
            "loss: 0.358782  [ 6080/ 8640]\n",
            "loss: 0.068333  [ 6160/ 8640]\n",
            "loss: 0.601558  [ 6240/ 8640]\n",
            "loss: 0.975635  [ 6320/ 8640]\n",
            "loss: 1.181219  [ 6400/ 8640]\n",
            "loss: 0.099533  [ 6480/ 8640]\n",
            "loss: 0.845747  [ 6560/ 8640]\n",
            "loss: 0.913797  [ 6640/ 8640]\n",
            "loss: 0.369431  [ 6720/ 8640]\n",
            "loss: 0.207089  [ 6800/ 8640]\n",
            "loss: 0.203703  [ 6880/ 8640]\n",
            "loss: 0.156574  [ 6960/ 8640]\n",
            "loss: 0.434023  [ 7040/ 8640]\n",
            "loss: 0.208341  [ 7120/ 8640]\n",
            "loss: 0.445272  [ 7200/ 8640]\n",
            "loss: 0.508443  [ 7280/ 8640]\n",
            "loss: 0.089932  [ 7360/ 8640]\n",
            "loss: 0.239788  [ 7440/ 8640]\n",
            "loss: 0.229809  [ 7520/ 8640]\n",
            "loss: 0.272092  [ 7600/ 8640]\n",
            "loss: 0.615127  [ 7680/ 8640]\n",
            "loss: 0.238258  [ 7760/ 8640]\n",
            "loss: 0.174413  [ 7840/ 8640]\n",
            "loss: 0.310313  [ 7920/ 8640]\n",
            "loss: 0.392047  [ 8000/ 8640]\n",
            "loss: 0.174886  [ 8080/ 8640]\n",
            "loss: 0.304332  [ 8160/ 8640]\n",
            "loss: 0.064904  [ 8240/ 8640]\n",
            "loss: 0.247025  [ 8320/ 8640]\n",
            "loss: 0.186489  [ 8400/ 8640]\n",
            "loss: 0.301874  [ 8480/ 8640]\n",
            "loss: 0.493771  [ 8560/ 8640]\n",
            "Training done\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.220869  [    0/ 8640]\n",
            "loss: 0.119642  [   80/ 8640]\n",
            "loss: 0.187111  [  160/ 8640]\n",
            "loss: 0.032703  [  240/ 8640]\n",
            "loss: 0.019164  [  320/ 8640]\n",
            "loss: 0.415839  [  400/ 8640]\n",
            "loss: 0.123066  [  480/ 8640]\n",
            "loss: 0.151264  [  560/ 8640]\n",
            "loss: 0.895786  [  640/ 8640]\n",
            "loss: 0.100260  [  720/ 8640]\n",
            "loss: 0.340958  [  800/ 8640]\n",
            "loss: 0.143220  [  880/ 8640]\n",
            "loss: 0.134673  [  960/ 8640]\n",
            "loss: 0.448737  [ 1040/ 8640]\n",
            "loss: 0.073417  [ 1120/ 8640]\n",
            "loss: 0.211492  [ 1200/ 8640]\n",
            "loss: 0.108733  [ 1280/ 8640]\n",
            "loss: 0.017864  [ 1360/ 8640]\n",
            "loss: 0.053513  [ 1440/ 8640]\n",
            "loss: 0.145273  [ 1520/ 8640]\n",
            "loss: 0.052945  [ 1600/ 8640]\n",
            "loss: 0.259063  [ 1680/ 8640]\n",
            "loss: 0.411014  [ 1760/ 8640]\n",
            "loss: 0.051418  [ 1840/ 8640]\n",
            "loss: 0.267203  [ 1920/ 8640]\n",
            "loss: 0.096520  [ 2000/ 8640]\n",
            "loss: 0.043706  [ 2080/ 8640]\n",
            "loss: 0.101577  [ 2160/ 8640]\n",
            "loss: 0.019024  [ 2240/ 8640]\n",
            "loss: 0.078085  [ 2320/ 8640]\n",
            "loss: 0.573105  [ 2400/ 8640]\n",
            "loss: 0.121590  [ 2480/ 8640]\n",
            "loss: 0.012376  [ 2560/ 8640]\n",
            "loss: 0.091286  [ 2640/ 8640]\n",
            "loss: 0.011087  [ 2720/ 8640]\n",
            "loss: 0.495284  [ 2800/ 8640]\n",
            "loss: 0.209985  [ 2880/ 8640]\n",
            "loss: 0.013147  [ 2960/ 8640]\n",
            "loss: 0.488825  [ 3040/ 8640]\n",
            "loss: 0.693103  [ 3120/ 8640]\n",
            "loss: 0.063964  [ 3200/ 8640]\n",
            "loss: 0.923501  [ 3280/ 8640]\n",
            "loss: 0.048945  [ 3360/ 8640]\n",
            "loss: 0.196847  [ 3440/ 8640]\n",
            "loss: 0.042638  [ 3520/ 8640]\n",
            "loss: 0.026501  [ 3600/ 8640]\n",
            "loss: 0.024023  [ 3680/ 8640]\n",
            "loss: 0.037023  [ 3760/ 8640]\n",
            "loss: 0.093192  [ 3840/ 8640]\n",
            "loss: 0.026490  [ 3920/ 8640]\n",
            "loss: 0.032715  [ 4000/ 8640]\n",
            "loss: 0.113989  [ 4080/ 8640]\n",
            "loss: 0.472415  [ 4160/ 8640]\n",
            "loss: 0.283545  [ 4240/ 8640]\n",
            "loss: 0.029389  [ 4320/ 8640]\n",
            "loss: 0.397450  [ 4400/ 8640]\n",
            "loss: 0.107642  [ 4480/ 8640]\n",
            "loss: 0.085327  [ 4560/ 8640]\n",
            "loss: 0.095022  [ 4640/ 8640]\n",
            "loss: 0.084984  [ 4720/ 8640]\n",
            "loss: 0.033291  [ 4800/ 8640]\n",
            "loss: 0.241839  [ 4880/ 8640]\n",
            "loss: 0.982695  [ 4960/ 8640]\n",
            "loss: 0.145294  [ 5040/ 8640]\n",
            "loss: 0.080012  [ 5120/ 8640]\n",
            "loss: 0.303078  [ 5200/ 8640]\n",
            "loss: 0.533157  [ 5280/ 8640]\n",
            "loss: 0.087954  [ 5360/ 8640]\n",
            "loss: 0.114943  [ 5440/ 8640]\n",
            "loss: 0.315755  [ 5520/ 8640]\n",
            "loss: 0.043458  [ 5600/ 8640]\n",
            "loss: 0.358646  [ 5680/ 8640]\n",
            "loss: 0.181544  [ 5760/ 8640]\n",
            "loss: 0.037638  [ 5840/ 8640]\n",
            "loss: 0.160318  [ 5920/ 8640]\n",
            "loss: 0.042959  [ 6000/ 8640]\n",
            "loss: 0.336683  [ 6080/ 8640]\n",
            "loss: 0.136912  [ 6160/ 8640]\n",
            "loss: 0.326143  [ 6240/ 8640]\n",
            "loss: 0.878093  [ 6320/ 8640]\n",
            "loss: 0.204469  [ 6400/ 8640]\n",
            "loss: 0.044334  [ 6480/ 8640]\n",
            "loss: 0.088481  [ 6560/ 8640]\n",
            "loss: 0.146163  [ 6640/ 8640]\n",
            "loss: 0.170311  [ 6720/ 8640]\n",
            "loss: 0.870784  [ 6800/ 8640]\n",
            "loss: 0.036640  [ 6880/ 8640]\n",
            "loss: 0.387955  [ 6960/ 8640]\n",
            "loss: 0.108171  [ 7040/ 8640]\n",
            "loss: 0.075217  [ 7120/ 8640]\n",
            "loss: 0.167284  [ 7200/ 8640]\n",
            "loss: 0.072974  [ 7280/ 8640]\n",
            "loss: 0.036403  [ 7360/ 8640]\n",
            "loss: 0.034054  [ 7440/ 8640]\n",
            "loss: 0.658714  [ 7520/ 8640]\n",
            "loss: 0.267927  [ 7600/ 8640]\n",
            "loss: 0.123056  [ 7680/ 8640]\n",
            "loss: 0.453071  [ 7760/ 8640]\n",
            "loss: 0.938652  [ 7840/ 8640]\n",
            "loss: 0.021704  [ 7920/ 8640]\n",
            "loss: 0.042646  [ 8000/ 8640]\n",
            "loss: 0.070673  [ 8080/ 8640]\n",
            "loss: 0.244319  [ 8160/ 8640]\n",
            "loss: 0.410794  [ 8240/ 8640]\n",
            "loss: 0.031175  [ 8320/ 8640]\n",
            "loss: 0.070589  [ 8400/ 8640]\n",
            "loss: 0.040345  [ 8480/ 8640]\n",
            "loss: 0.544958  [ 8560/ 8640]\n",
            "Training done\n",
            "Test Accuracy: 70.94%\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_46f0403e-44a8-4c0d-b91d-364476b9ce32\", \"sample_FB_nltk.csv\", 8504)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "from nltk.corpus import wordnet\n",
        "import random\n",
        "\n",
        "def synonym_replacement(sentence):\n",
        "    words = sentence.split()\n",
        "    new_sentence = []\n",
        "    for word in words:\n",
        "        synonyms = wordnet.synsets(word, lang='fra')  # Search for French synonyms\n",
        "        if synonyms:\n",
        "            synonym = random.choice(synonyms).lemmas()[0].name()\n",
        "            new_sentence.append(synonym)\n",
        "        else:\n",
        "            new_sentence.append(word)\n",
        "    return ' '.join(new_sentence)\n",
        "\n",
        "# Generate synonyms for each sentence in the training set\n",
        "data = df_train.copy()\n",
        "generated_sentences = [synonym_replacement(sentence) for sentence in data['sentence']]\n",
        "\n",
        "# Create a new DataFrame for generated sentences\n",
        "generated_data = pd.DataFrame({\n",
        "    'sentence': generated_sentences,\n",
        "    'difficulty': data['difficulty']\n",
        "})\n",
        "\n",
        "# Combine with original data\n",
        "combined_data = pd.concat([data, generated_data])\n",
        "\n",
        "# Load your data\n",
        "data = combined_data\n",
        "sentences = data['sentence'].tolist()\n",
        "difficulties = data['difficulty'].tolist()\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(difficulties)\n",
        "\n",
        "# Load BERT tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "bert_model = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
        "\n",
        "# Tokenize sentences and convert to tensor\n",
        "def tokenize_and_encode(sentences):\n",
        "    return tokenizer(sentences, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
        "\n",
        "# Custom Dataset class\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.encodings = tokenize_and_encode(texts)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: self.encodings[key][idx] for key in self.encodings if key != 'token_type_ids'}, self.labels[idx]\n",
        "\n",
        "# Data preparation\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    sentences, encoded_labels, test_size=0.1, random_state=42, stratify=encoded_labels\n",
        ")\n",
        "\n",
        "train_dataset = TextDataset(X_train, y_train)\n",
        "test_dataset = TextDataset(X_test, y_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# Neural network model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Net, self).__init__()\n",
        "        self.bert = bert_model\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.fc = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.fc(pooled_output)\n",
        "        return logits\n",
        "\n",
        "# Instantiate the model, loss, and optimizer\n",
        "model = Net(len(label_encoder.classes_)).to('cuda')\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
        "\n",
        "# Function to compute accuracy\n",
        "def compute_accuracy(dataloader, model):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            inputs, labels = batch\n",
        "            inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
        "            labels = labels.to('cuda')\n",
        "            outputs = model(**inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "# Training loop\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()  # Set model to training mode\n",
        "    for batch, (inputs, labels) in enumerate(dataloader):\n",
        "        inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
        "        labels = labels.to('cuda')\n",
        "        pred = model(**inputs)\n",
        "        loss = loss_fn(pred, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 10 == 0:\n",
        "            loss, current = loss.item(), batch * len(inputs['input_ids'])\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "# Execute training\n",
        "for epoch in range(5):  # Number of epochs\n",
        "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
        "    train_loop(train_loader, model, criterion, optimizer)\n",
        "    print(\"Training done\")\n",
        "\n",
        "# Test the model\n",
        "accuracy = compute_accuracy(test_loader, model)\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "\n",
        "# Tokenize and encode the test data\n",
        "def tokenize_and_encode(sentences):\n",
        "    return tokenizer(sentences, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
        "\n",
        "# Custom Dataset class for test data\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, texts):\n",
        "        self.encodings = tokenize_and_encode(texts)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings['input_ids'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: self.encodings[key][idx] for key in self.encodings if key != 'token_type_ids'}\n",
        "\n",
        "# Create the dataset and dataloader for df_test\n",
        "test_dataset = TestDataset(df_test['sentence'].tolist())\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# Define the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Generate predictions for df_test\n",
        "model.eval()  # Make sure the model is in evaluation mode\n",
        "all_predictions = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        inputs = {key: value.to(device) for key, value in batch.items()}\n",
        "        outputs = model(**inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "# Convert numeric predictions back to labels\n",
        "predicted_labels = label_encoder.inverse_transform(all_predictions)\n",
        "\n",
        "# Prepare and save the submission file\n",
        "submission_df = pd.DataFrame({\n",
        "    'id': df_test['id'],  # Ensure df_test includes an 'id' column\n",
        "    'difficulty': predicted_labels\n",
        "})\n",
        "\n",
        "submission_df.to_csv('sample_FB_nltk.csv', index=False)\n",
        "from google.colab import files\n",
        "files.download('sample_FB_nltk.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qV1zLW3qeabJ"
      },
      "source": [
        "## Camembert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebdrrDC_eecb"
      },
      "source": [
        "Best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4da21ae806094554ab00622b8bb6a14f",
            "254b91c27a594886bd5ad31e37796d84",
            "a2836ffc602d45558cc6b6a522fae811",
            "4b0f8afb0fd84daba43da18e19d02607",
            "2062736dfb9247f68d20449da0853f23"
          ]
        },
        "id": "yWVBR_COp8ZE",
        "outputId": "b7a804cb-e8f4-4b6a-e40a-496b61399f31"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4da21ae806094554ab00622b8bb6a14f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "254b91c27a594886bd5ad31e37796d84",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/811k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a2836ffc602d45558cc6b6a522fae811",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.40M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4b0f8afb0fd84daba43da18e19d02607",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/508 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2062736dfb9247f68d20449da0853f23",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 1.787679  [    0/ 4320]\n",
            "loss: 1.759201  [   80/ 4320]\n",
            "loss: 1.819446  [  160/ 4320]\n",
            "loss: 1.761045  [  240/ 4320]\n",
            "loss: 1.741475  [  320/ 4320]\n",
            "loss: 1.710012  [  400/ 4320]\n",
            "loss: 1.660189  [  480/ 4320]\n",
            "loss: 1.710840  [  560/ 4320]\n",
            "loss: 1.617915  [  640/ 4320]\n",
            "loss: 1.588448  [  720/ 4320]\n",
            "loss: 1.596875  [  800/ 4320]\n",
            "loss: 1.588375  [  880/ 4320]\n",
            "loss: 1.351236  [  960/ 4320]\n",
            "loss: 1.467402  [ 1040/ 4320]\n",
            "loss: 1.419346  [ 1120/ 4320]\n",
            "loss: 1.554049  [ 1200/ 4320]\n",
            "loss: 1.292367  [ 1280/ 4320]\n",
            "loss: 1.418434  [ 1360/ 4320]\n",
            "loss: 1.454612  [ 1440/ 4320]\n",
            "loss: 1.357249  [ 1520/ 4320]\n",
            "loss: 1.300206  [ 1600/ 4320]\n",
            "loss: 1.395431  [ 1680/ 4320]\n",
            "loss: 1.187509  [ 1760/ 4320]\n",
            "loss: 1.318011  [ 1840/ 4320]\n",
            "loss: 1.257766  [ 1920/ 4320]\n",
            "loss: 1.252184  [ 2000/ 4320]\n",
            "loss: 1.236168  [ 2080/ 4320]\n",
            "loss: 1.301860  [ 2160/ 4320]\n",
            "loss: 1.232212  [ 2240/ 4320]\n",
            "loss: 1.477469  [ 2320/ 4320]\n",
            "loss: 1.347853  [ 2400/ 4320]\n",
            "loss: 1.158014  [ 2480/ 4320]\n",
            "loss: 1.241383  [ 2560/ 4320]\n",
            "loss: 1.246297  [ 2640/ 4320]\n",
            "loss: 1.047443  [ 2720/ 4320]\n",
            "loss: 1.098099  [ 2800/ 4320]\n",
            "loss: 1.190637  [ 2880/ 4320]\n",
            "loss: 1.157602  [ 2960/ 4320]\n",
            "loss: 0.962221  [ 3040/ 4320]\n",
            "loss: 1.053995  [ 3120/ 4320]\n",
            "loss: 1.233137  [ 3200/ 4320]\n",
            "loss: 1.078228  [ 3280/ 4320]\n",
            "loss: 1.022079  [ 3360/ 4320]\n",
            "loss: 1.558273  [ 3440/ 4320]\n",
            "loss: 0.980274  [ 3520/ 4320]\n",
            "loss: 1.606582  [ 3600/ 4320]\n",
            "loss: 1.127896  [ 3680/ 4320]\n",
            "loss: 1.325196  [ 3760/ 4320]\n",
            "loss: 1.200833  [ 3840/ 4320]\n",
            "loss: 1.370970  [ 3920/ 4320]\n",
            "loss: 1.247709  [ 4000/ 4320]\n",
            "loss: 1.265441  [ 4080/ 4320]\n",
            "loss: 1.094648  [ 4160/ 4320]\n",
            "loss: 1.088370  [ 4240/ 4320]\n",
            "Training done\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.828573  [    0/ 4320]\n",
            "loss: 0.976469  [   80/ 4320]\n",
            "loss: 0.936570  [  160/ 4320]\n",
            "loss: 0.989534  [  240/ 4320]\n",
            "loss: 1.078052  [  320/ 4320]\n",
            "loss: 0.920724  [  400/ 4320]\n",
            "loss: 1.001146  [  480/ 4320]\n",
            "loss: 0.829041  [  560/ 4320]\n",
            "loss: 0.796669  [  640/ 4320]\n",
            "loss: 0.806249  [  720/ 4320]\n",
            "loss: 0.666368  [  800/ 4320]\n",
            "loss: 0.974057  [  880/ 4320]\n",
            "loss: 1.025596  [  960/ 4320]\n",
            "loss: 0.997681  [ 1040/ 4320]\n",
            "loss: 1.501285  [ 1120/ 4320]\n",
            "loss: 0.783024  [ 1200/ 4320]\n",
            "loss: 1.140959  [ 1280/ 4320]\n",
            "loss: 0.749858  [ 1360/ 4320]\n",
            "loss: 1.142841  [ 1440/ 4320]\n",
            "loss: 0.792612  [ 1520/ 4320]\n",
            "loss: 1.402417  [ 1600/ 4320]\n",
            "loss: 0.900974  [ 1680/ 4320]\n",
            "loss: 1.102299  [ 1760/ 4320]\n",
            "loss: 0.937508  [ 1840/ 4320]\n",
            "loss: 0.988612  [ 1920/ 4320]\n",
            "loss: 1.177265  [ 2000/ 4320]\n",
            "loss: 0.790963  [ 2080/ 4320]\n",
            "loss: 0.912480  [ 2160/ 4320]\n",
            "loss: 0.857759  [ 2240/ 4320]\n",
            "loss: 0.741514  [ 2320/ 4320]\n",
            "loss: 1.041137  [ 2400/ 4320]\n",
            "loss: 1.123883  [ 2480/ 4320]\n",
            "loss: 1.105181  [ 2560/ 4320]\n",
            "loss: 1.081498  [ 2640/ 4320]\n",
            "loss: 1.068003  [ 2720/ 4320]\n",
            "loss: 0.878668  [ 2800/ 4320]\n",
            "loss: 0.900789  [ 2880/ 4320]\n",
            "loss: 1.281670  [ 2960/ 4320]\n",
            "loss: 1.547070  [ 3040/ 4320]\n",
            "loss: 0.746018  [ 3120/ 4320]\n",
            "loss: 0.551560  [ 3200/ 4320]\n",
            "loss: 0.665937  [ 3280/ 4320]\n",
            "loss: 1.062906  [ 3360/ 4320]\n",
            "loss: 1.136693  [ 3440/ 4320]\n",
            "loss: 0.930480  [ 3520/ 4320]\n",
            "loss: 0.914612  [ 3600/ 4320]\n",
            "loss: 0.967442  [ 3680/ 4320]\n",
            "loss: 0.720267  [ 3760/ 4320]\n",
            "loss: 0.632278  [ 3840/ 4320]\n",
            "loss: 0.784720  [ 3920/ 4320]\n",
            "loss: 0.765993  [ 4000/ 4320]\n",
            "loss: 0.720538  [ 4080/ 4320]\n",
            "loss: 1.815167  [ 4160/ 4320]\n",
            "loss: 1.165029  [ 4240/ 4320]\n",
            "Training done\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.383611  [    0/ 4320]\n",
            "loss: 0.939928  [   80/ 4320]\n",
            "loss: 1.098464  [  160/ 4320]\n",
            "loss: 0.771050  [  240/ 4320]\n",
            "loss: 0.878077  [  320/ 4320]\n",
            "loss: 0.625472  [  400/ 4320]\n",
            "loss: 0.758461  [  480/ 4320]\n",
            "loss: 0.732739  [  560/ 4320]\n",
            "loss: 0.419415  [  640/ 4320]\n",
            "loss: 0.646572  [  720/ 4320]\n",
            "loss: 0.736244  [  800/ 4320]\n",
            "loss: 0.655058  [  880/ 4320]\n",
            "loss: 1.034852  [  960/ 4320]\n",
            "loss: 0.816624  [ 1040/ 4320]\n",
            "loss: 0.595145  [ 1120/ 4320]\n",
            "loss: 0.787770  [ 1200/ 4320]\n",
            "loss: 0.941503  [ 1280/ 4320]\n",
            "loss: 0.823375  [ 1360/ 4320]\n",
            "loss: 1.016142  [ 1440/ 4320]\n",
            "loss: 0.931344  [ 1520/ 4320]\n",
            "loss: 0.576356  [ 1600/ 4320]\n",
            "loss: 0.431536  [ 1680/ 4320]\n",
            "loss: 0.950188  [ 1760/ 4320]\n",
            "loss: 0.730597  [ 1840/ 4320]\n",
            "loss: 0.690086  [ 1920/ 4320]\n",
            "loss: 1.395425  [ 2000/ 4320]\n",
            "loss: 0.531406  [ 2080/ 4320]\n",
            "loss: 0.801374  [ 2160/ 4320]\n",
            "loss: 0.598320  [ 2240/ 4320]\n",
            "loss: 0.577457  [ 2320/ 4320]\n",
            "loss: 0.607749  [ 2400/ 4320]\n",
            "loss: 0.759370  [ 2480/ 4320]\n",
            "loss: 0.765598  [ 2560/ 4320]\n",
            "loss: 0.357233  [ 2640/ 4320]\n",
            "loss: 0.617376  [ 2720/ 4320]\n",
            "loss: 0.630043  [ 2800/ 4320]\n",
            "loss: 0.378729  [ 2880/ 4320]\n",
            "loss: 0.577030  [ 2960/ 4320]\n",
            "loss: 1.172243  [ 3040/ 4320]\n",
            "loss: 0.593450  [ 3120/ 4320]\n",
            "loss: 0.551007  [ 3200/ 4320]\n",
            "loss: 0.838220  [ 3280/ 4320]\n",
            "loss: 0.801081  [ 3360/ 4320]\n",
            "loss: 0.780080  [ 3440/ 4320]\n",
            "loss: 0.411499  [ 3520/ 4320]\n",
            "loss: 0.556015  [ 3600/ 4320]\n",
            "loss: 0.808207  [ 3680/ 4320]\n",
            "loss: 0.859081  [ 3760/ 4320]\n",
            "loss: 0.546770  [ 3840/ 4320]\n",
            "loss: 0.709576  [ 3920/ 4320]\n",
            "loss: 1.264449  [ 4000/ 4320]\n",
            "loss: 0.731420  [ 4080/ 4320]\n",
            "loss: 0.919567  [ 4160/ 4320]\n",
            "loss: 1.234220  [ 4240/ 4320]\n",
            "Training done\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.484359  [    0/ 4320]\n",
            "loss: 0.684367  [   80/ 4320]\n",
            "loss: 0.540669  [  160/ 4320]\n",
            "loss: 0.377822  [  240/ 4320]\n",
            "loss: 0.305433  [  320/ 4320]\n",
            "loss: 0.529981  [  400/ 4320]\n",
            "loss: 0.726104  [  480/ 4320]\n",
            "loss: 0.457070  [  560/ 4320]\n",
            "loss: 0.208715  [  640/ 4320]\n",
            "loss: 0.680658  [  720/ 4320]\n",
            "loss: 0.253302  [  800/ 4320]\n",
            "loss: 0.225643  [  880/ 4320]\n",
            "loss: 1.002388  [  960/ 4320]\n",
            "loss: 0.422022  [ 1040/ 4320]\n",
            "loss: 0.470985  [ 1120/ 4320]\n",
            "loss: 0.564571  [ 1200/ 4320]\n",
            "loss: 0.222177  [ 1280/ 4320]\n",
            "loss: 0.361419  [ 1360/ 4320]\n",
            "loss: 0.425403  [ 1440/ 4320]\n",
            "loss: 0.348594  [ 1520/ 4320]\n",
            "loss: 0.376244  [ 1600/ 4320]\n",
            "loss: 0.235843  [ 1680/ 4320]\n",
            "loss: 0.252124  [ 1760/ 4320]\n",
            "loss: 0.715977  [ 1840/ 4320]\n",
            "loss: 0.729156  [ 1920/ 4320]\n",
            "loss: 0.296342  [ 2000/ 4320]\n",
            "loss: 0.469259  [ 2080/ 4320]\n",
            "loss: 0.774547  [ 2160/ 4320]\n",
            "loss: 0.528751  [ 2240/ 4320]\n",
            "loss: 0.634346  [ 2320/ 4320]\n",
            "loss: 0.297493  [ 2400/ 4320]\n",
            "loss: 0.858099  [ 2480/ 4320]\n",
            "loss: 0.345171  [ 2560/ 4320]\n",
            "loss: 0.461259  [ 2640/ 4320]\n",
            "loss: 0.462333  [ 2720/ 4320]\n",
            "loss: 0.271506  [ 2800/ 4320]\n",
            "loss: 0.788867  [ 2880/ 4320]\n",
            "loss: 0.509592  [ 2960/ 4320]\n",
            "loss: 0.917449  [ 3040/ 4320]\n",
            "loss: 0.590964  [ 3120/ 4320]\n",
            "loss: 1.097758  [ 3200/ 4320]\n",
            "loss: 0.229463  [ 3280/ 4320]\n",
            "loss: 1.005285  [ 3360/ 4320]\n",
            "loss: 0.756736  [ 3440/ 4320]\n",
            "loss: 0.534251  [ 3520/ 4320]\n",
            "loss: 0.604301  [ 3600/ 4320]\n",
            "loss: 0.672471  [ 3680/ 4320]\n",
            "loss: 0.569654  [ 3760/ 4320]\n",
            "loss: 0.457884  [ 3840/ 4320]\n",
            "loss: 0.337060  [ 3920/ 4320]\n",
            "loss: 0.634318  [ 4000/ 4320]\n",
            "loss: 0.800080  [ 4080/ 4320]\n",
            "loss: 0.298950  [ 4160/ 4320]\n",
            "loss: 0.539872  [ 4240/ 4320]\n",
            "Training done\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.537144  [    0/ 4320]\n",
            "loss: 0.272468  [   80/ 4320]\n",
            "loss: 0.558652  [  160/ 4320]\n",
            "loss: 0.531357  [  240/ 4320]\n",
            "loss: 0.566650  [  320/ 4320]\n",
            "loss: 0.825330  [  400/ 4320]\n",
            "loss: 0.157436  [  480/ 4320]\n",
            "loss: 0.337023  [  560/ 4320]\n",
            "loss: 0.193440  [  640/ 4320]\n",
            "loss: 0.256458  [  720/ 4320]\n",
            "loss: 0.176406  [  800/ 4320]\n",
            "loss: 0.180911  [  880/ 4320]\n",
            "loss: 0.772933  [  960/ 4320]\n",
            "loss: 0.495085  [ 1040/ 4320]\n",
            "loss: 0.440540  [ 1120/ 4320]\n",
            "loss: 0.467221  [ 1200/ 4320]\n",
            "loss: 0.732472  [ 1280/ 4320]\n",
            "loss: 0.296307  [ 1360/ 4320]\n",
            "loss: 0.516818  [ 1440/ 4320]\n",
            "loss: 0.221505  [ 1520/ 4320]\n",
            "loss: 0.128549  [ 1600/ 4320]\n",
            "loss: 0.506354  [ 1680/ 4320]\n",
            "loss: 0.373567  [ 1760/ 4320]\n",
            "loss: 0.400815  [ 1840/ 4320]\n",
            "loss: 0.150893  [ 1920/ 4320]\n",
            "loss: 0.350004  [ 2000/ 4320]\n",
            "loss: 0.509507  [ 2080/ 4320]\n",
            "loss: 0.376677  [ 2160/ 4320]\n",
            "loss: 0.199795  [ 2240/ 4320]\n",
            "loss: 0.280707  [ 2320/ 4320]\n",
            "loss: 0.800768  [ 2400/ 4320]\n",
            "loss: 0.357423  [ 2480/ 4320]\n",
            "loss: 0.472218  [ 2560/ 4320]\n",
            "loss: 0.675086  [ 2640/ 4320]\n",
            "loss: 0.212611  [ 2720/ 4320]\n",
            "loss: 0.689073  [ 2800/ 4320]\n",
            "loss: 0.126922  [ 2880/ 4320]\n",
            "loss: 0.241930  [ 2960/ 4320]\n",
            "loss: 0.460367  [ 3040/ 4320]\n",
            "loss: 0.255691  [ 3120/ 4320]\n",
            "loss: 0.750259  [ 3200/ 4320]\n",
            "loss: 0.444201  [ 3280/ 4320]\n",
            "loss: 0.191331  [ 3360/ 4320]\n",
            "loss: 0.846759  [ 3440/ 4320]\n",
            "loss: 0.276035  [ 3520/ 4320]\n",
            "loss: 0.546484  [ 3600/ 4320]\n",
            "loss: 0.649863  [ 3680/ 4320]\n",
            "loss: 0.372718  [ 3760/ 4320]\n",
            "loss: 0.711309  [ 3840/ 4320]\n",
            "loss: 0.210486  [ 3920/ 4320]\n",
            "loss: 0.407928  [ 4000/ 4320]\n",
            "loss: 0.080434  [ 4080/ 4320]\n",
            "loss: 0.187417  [ 4160/ 4320]\n",
            "loss: 0.393609  [ 4240/ 4320]\n",
            "Training done\n",
            "Test Accuracy: 56.25%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import CamembertTokenizer, CamembertModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load your data\n",
        "data = df_train\n",
        "sentences = data['sentence'].tolist()\n",
        "difficulties = data['difficulty'].tolist()\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(difficulties)\n",
        "\n",
        "# Load CamemBERT tokenizer and model\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
        "camembert = CamembertModel.from_pretrained('camembert-base')\n",
        "\n",
        "# Tokenize sentences and convert to tensor\n",
        "def tokenize_and_encode(sentences):\n",
        "    return tokenizer(sentences, padding=True, truncation=True, max_length=800, return_tensors='pt')\n",
        "\n",
        "# Custom Dataset class\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.encodings = tokenize_and_encode(texts)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: self.encodings[key][idx] for key in self.encodings}, self.labels[idx]\n",
        "\n",
        "# Data preparation\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    sentences, encoded_labels, test_size=0.1, random_state=42, stratify=encoded_labels\n",
        ")\n",
        "\n",
        "train_dataset = TextDataset(X_train, y_train)\n",
        "test_dataset = TextDataset(X_test, y_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# Neural network model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Net, self).__init__()\n",
        "        self.camembert = camembert\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.fc = nn.Linear(self.camembert.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        outputs = self.camembert(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.fc(pooled_output)\n",
        "        return logits\n",
        "\n",
        "# Instantiate the model, loss, and optimizer\n",
        "model = Net(len(label_encoder.classes_)).to('cuda')\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
        "\n",
        "# Function to compute accuracy\n",
        "def compute_accuracy(dataloader, model):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            inputs, labels = batch\n",
        "            inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
        "            labels = labels.to('cuda')\n",
        "            outputs = model(**inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "# Training loop\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()  # Set model to training mode\n",
        "    for batch, (inputs, labels) in enumerate(dataloader):\n",
        "        inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
        "        labels = labels.to('cuda')\n",
        "        pred = model(**inputs)\n",
        "        loss = loss_fn(pred, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 10 == 0:\n",
        "            loss, current = loss.item(), batch * len(inputs['input_ids'])\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "# Execute training\n",
        "for epoch in range(5):  # Number of epochs\n",
        "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
        "    train_loop(train_loader, model, criterion, optimizer)\n",
        "    print(\"Training done\")\n",
        "\n",
        "# Test the model\n",
        "accuracy = compute_accuracy(test_loader, model)\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcx6eO58qLg4",
        "outputId": "a16848f5-0c7a-49e3-e42b-70f8190a9b05"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import CamembertTokenizer\n",
        "\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
        "\n",
        "# Tokenize and encode the test data\n",
        "def tokenize_and_encode(sentences):\n",
        "    return tokenizer(sentences, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
        "\n",
        "# Custom Dataset class for test data\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, texts):\n",
        "        self.encodings = tokenize_and_encode(texts)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings['input_ids'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: self.encodings[key][idx] for key in self.encodings}\n",
        "\n",
        "# Create the dataset and dataloader for df_test\n",
        "test_dataset = TestDataset(df_test['sentence'].tolist())\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# Define the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Generate predictions for df_test\n",
        "model.eval()  # Make sure the model is in evaluation mode\n",
        "all_predictions = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        inputs = {key: value.to(device) for key, value in batch.items()}\n",
        "        outputs = model(**inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "# Convert numeric predictions back to labels\n",
        "predicted_labels = label_encoder.inverse_transform(all_predictions)\n",
        "\n",
        "# Prepare and save the submission file\n",
        "submission_df = pd.DataFrame({\n",
        "    'id': df_test['id'],  # Ensure df_test includes an 'id' column\n",
        "    'difficulty': predicted_labels\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5jNEVqKeqKl"
      },
      "outputs": [],
      "source": [
        "submission_df.to_csv('sample_new.csv', index=False)\n",
        "from google.colab import files\n",
        "files.download('sample_new.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOeAhbR1ey2b"
      },
      "source": [
        "Let's try this model with NLTK.\n",
        "\n",
        "*Accuracy of the model below is 0.565*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "Cfan9s_vAK_t",
        "outputId": "3cd786d2-ce23-4624-f9c3-f83afb233923"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 1.780135  [    0/ 8640]\n",
            "loss: 1.755576  [   60/ 8640]\n",
            "loss: 1.822895  [  120/ 8640]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-a423b9e13cd6>\u001b[0m in \u001b[0;36m<cell line: 157>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Number of epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch+1}\\n-------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m     \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training done\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-a423b9e13cd6>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             )\n\u001b[0;32m--> 522\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def synonym_replacement(sentence, n):\n",
        "    words = sentence.split()\n",
        "    new_words = words.copy()\n",
        "    french_stopwords = set(nltk.corpus.stopwords.words('french'))\n",
        "    random_word_list = list(set([word for word in words if word not in french_stopwords]))\n",
        "    random.shuffle(random_word_list)\n",
        "    num_replaced = 0\n",
        "    for random_word in random_word_list:\n",
        "        synonyms = get_synonyms(random_word)\n",
        "        if len(synonyms) > 0:\n",
        "            synonym = random.choice(synonyms)\n",
        "            new_words = [synonym if word == random_word else word for word in new_words]\n",
        "            num_replaced += 1\n",
        "        if num_replaced >= n:  # Only replace up to n words\n",
        "            break\n",
        "    return ' '.join(new_words)\n",
        "\n",
        "def get_synonyms(word):\n",
        "    synonyms = set()\n",
        "    for syn in wordnet.synsets(word, lang='fra'):\n",
        "        for lemma in syn.lemmas(lang='fra'):\n",
        "            synonym = lemma.name().replace(\"_\", \" \").replace(\"-\", \" \").lower()\n",
        "            synonym = \"\".join([char for char in synonym if char.isalnum() or char.isspace()])\n",
        "            synonyms.add(synonym)\n",
        "    if word in synonyms:\n",
        "        synonyms.remove(word)\n",
        "    return list(synonyms)\n",
        "\n",
        "# Generate augmented sentences\n",
        "new_sentences = []\n",
        "new_difficulties = []\n",
        "for _, row in df_train.iterrows():\n",
        "    original_sentence = row['sentence']\n",
        "    difficulty = row['difficulty']\n",
        "    augmented_sentence = synonym_replacement(original_sentence, 2)\n",
        "    new_sentences.append(augmented_sentence)\n",
        "    new_difficulties.append(difficulty)\n",
        "\n",
        "# Create a new DataFrame for the augmented sentences\n",
        "df_augmented = pd.DataFrame({'sentence': new_sentences, 'difficulty': new_difficulties})\n",
        "\n",
        "# Concatenate the original and augmented DataFrames\n",
        "df_combined = pd.concat([df_train, df_augmented], ignore_index=True)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import CamembertTokenizer, CamembertModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load your data\n",
        "data = df_combined\n",
        "sentences = data['sentence'].tolist()\n",
        "difficulties = data['difficulty'].tolist()\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(difficulties)\n",
        "\n",
        "# Load CamemBERT tokenizer and model\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
        "camembert = CamembertModel.from_pretrained('camembert-base')\n",
        "\n",
        "# Tokenize sentences and convert to tensor\n",
        "def tokenize_and_encode(sentences):\n",
        "    return tokenizer(sentences, padding=True, truncation=True, max_length=600, return_tensors='pt')\n",
        "\n",
        "# Custom Dataset class\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.encodings = tokenize_and_encode(texts)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: self.encodings[key][idx] for key in self.encodings}, self.labels[idx]\n",
        "\n",
        "# Data preparation\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    sentences, encoded_labels, test_size=0.1, random_state=42, stratify=encoded_labels\n",
        ")\n",
        "\n",
        "train_dataset = TextDataset(X_train, y_train)\n",
        "test_dataset = TextDataset(X_test, y_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=6, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=6, shuffle=False)\n",
        "\n",
        "# Neural network model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Net, self).__init__()\n",
        "        self.camembert = camembert\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.fc = nn.Linear(self.camembert.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        outputs = self.camembert(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.fc(pooled_output)\n",
        "        return logits\n",
        "\n",
        "# Instantiate the model, loss, and optimizer\n",
        "model = Net(len(label_encoder.classes_)).to('cpu')\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-5)\n",
        "\n",
        "# Function to compute accuracy\n",
        "def compute_accuracy(dataloader, model):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            inputs, labels = batch\n",
        "            inputs = {key: value.to('cpu') for key, value in inputs.items()}\n",
        "            labels = labels.to('cpu')\n",
        "            outputs = model(**inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "# Training loop\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()  # Set model to training mode\n",
        "    for batch, (inputs, labels) in enumerate(dataloader):\n",
        "        inputs = {key: value.to('cpu') for key, value in inputs.items()}\n",
        "        labels = labels.to('cpu')\n",
        "        pred = model(**inputs)\n",
        "        loss = loss_fn(pred, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 10 == 0:\n",
        "            loss, current = loss.item(), batch * len(inputs['input_ids'])\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "# Execute training\n",
        "for epoch in range(6):  # Number of epochs\n",
        "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
        "    train_loop(train_loader, model, criterion, optimizer)\n",
        "    print(\"Training done\")\n",
        "\n",
        "# Test the model\n",
        "accuracy = compute_accuracy(test_loader, model)\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import CamembertTokenizer\n",
        "\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
        "\n",
        "# Tokenize and encode the test data\n",
        "def tokenize_and_encode(sentences):\n",
        "    return tokenizer(sentences, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
        "\n",
        "# Custom Dataset class for test data\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, texts):\n",
        "        self.encodings = tokenize_and_encode(texts)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings['input_ids'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: self.encodings[key][idx] for key in self.encodings}\n",
        "\n",
        "# Create the dataset and dataloader for df_test\n",
        "test_dataset = TestDataset(df_test['sentence'].tolist())\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# Define the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Generate predictions for df_test\n",
        "model.eval()  # Make sure the model is in evaluation mode\n",
        "all_predictions = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        inputs = {key: value.to(device) for key, value in batch.items()}\n",
        "        outputs = model(**inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "# Convert numeric predictions back to labels\n",
        "predicted_labels = label_encoder.inverse_transform(all_predictions)\n",
        "\n",
        "# Prepare and save the submission file\n",
        "submission_df = pd.DataFrame({\n",
        "    'id': df_test['id'],  # Ensure df_test includes an 'id' column\n",
        "    'difficulty': predicted_labels\n",
        "})\n",
        "\n",
        "submission_df.to_csv('sample_text_add_b6_lr3e5.csv', index=False)\n",
        "from google.colab import files\n",
        "files.download('sample_text_add_b6_lr3e5.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "r4HPzbeh6UWQ",
        "outputId": "41e34016-2aee-476c-8cfa-c937675ecd52"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 1.805159  [    0/ 8640]\n",
            "loss: 1.777842  [   80/ 8640]\n",
            "loss: 1.828654  [  160/ 8640]\n",
            "loss: 1.797761  [  240/ 8640]\n",
            "loss: 1.770976  [  320/ 8640]\n",
            "loss: 1.768090  [  400/ 8640]\n",
            "loss: 1.697596  [  480/ 8640]\n",
            "loss: 1.733081  [  560/ 8640]\n",
            "loss: 1.668509  [  640/ 8640]\n",
            "loss: 1.731325  [  720/ 8640]\n",
            "loss: 1.596237  [  800/ 8640]\n",
            "loss: 1.567631  [  880/ 8640]\n",
            "loss: 1.580948  [  960/ 8640]\n",
            "loss: 1.519274  [ 1040/ 8640]\n",
            "loss: 1.351146  [ 1120/ 8640]\n",
            "loss: 1.587449  [ 1200/ 8640]\n",
            "loss: 1.411421  [ 1280/ 8640]\n",
            "loss: 1.484440  [ 1360/ 8640]\n",
            "loss: 1.437096  [ 1440/ 8640]\n",
            "loss: 1.281033  [ 1520/ 8640]\n",
            "loss: 1.288218  [ 1600/ 8640]\n",
            "loss: 1.440888  [ 1680/ 8640]\n",
            "loss: 1.459860  [ 1760/ 8640]\n",
            "loss: 1.159467  [ 1840/ 8640]\n",
            "loss: 1.386424  [ 1920/ 8640]\n",
            "loss: 1.266188  [ 2000/ 8640]\n",
            "loss: 1.183396  [ 2080/ 8640]\n",
            "loss: 1.232461  [ 2160/ 8640]\n",
            "loss: 1.191609  [ 2240/ 8640]\n",
            "loss: 1.337035  [ 2320/ 8640]\n",
            "loss: 1.490515  [ 2400/ 8640]\n",
            "loss: 1.296418  [ 2480/ 8640]\n",
            "loss: 1.196223  [ 2560/ 8640]\n",
            "loss: 1.191409  [ 2640/ 8640]\n",
            "loss: 1.529652  [ 2720/ 8640]\n",
            "loss: 1.248465  [ 2800/ 8640]\n",
            "loss: 1.323993  [ 2880/ 8640]\n",
            "loss: 1.144643  [ 2960/ 8640]\n",
            "loss: 1.099935  [ 3040/ 8640]\n",
            "loss: 1.281364  [ 3120/ 8640]\n",
            "loss: 1.326690  [ 3200/ 8640]\n",
            "loss: 1.399965  [ 3280/ 8640]\n",
            "loss: 1.094071  [ 3360/ 8640]\n",
            "loss: 1.274364  [ 3440/ 8640]\n",
            "loss: 1.025281  [ 3520/ 8640]\n",
            "loss: 0.982051  [ 3600/ 8640]\n",
            "loss: 0.934087  [ 3680/ 8640]\n",
            "loss: 1.263628  [ 3760/ 8640]\n",
            "loss: 1.102931  [ 3840/ 8640]\n",
            "loss: 1.081809  [ 3920/ 8640]\n",
            "loss: 1.098184  [ 4000/ 8640]\n",
            "loss: 1.072161  [ 4080/ 8640]\n",
            "loss: 1.374037  [ 4160/ 8640]\n",
            "loss: 1.201984  [ 4240/ 8640]\n",
            "loss: 0.961916  [ 4320/ 8640]\n",
            "loss: 1.228384  [ 4400/ 8640]\n",
            "loss: 1.000031  [ 4480/ 8640]\n",
            "loss: 0.916457  [ 4560/ 8640]\n",
            "loss: 1.057076  [ 4640/ 8640]\n",
            "loss: 1.162983  [ 4720/ 8640]\n",
            "loss: 1.272310  [ 4800/ 8640]\n",
            "loss: 0.856366  [ 4880/ 8640]\n",
            "loss: 1.176713  [ 4960/ 8640]\n",
            "loss: 1.172893  [ 5040/ 8640]\n",
            "loss: 1.265058  [ 5120/ 8640]\n",
            "loss: 0.961786  [ 5200/ 8640]\n",
            "loss: 1.281051  [ 5280/ 8640]\n",
            "loss: 0.857048  [ 5360/ 8640]\n",
            "loss: 1.406963  [ 5440/ 8640]\n",
            "loss: 0.888609  [ 5520/ 8640]\n",
            "loss: 0.991157  [ 5600/ 8640]\n",
            "loss: 0.906631  [ 5680/ 8640]\n",
            "loss: 1.260859  [ 5760/ 8640]\n",
            "loss: 0.901331  [ 5840/ 8640]\n",
            "loss: 0.753966  [ 5920/ 8640]\n",
            "loss: 1.316596  [ 6000/ 8640]\n",
            "loss: 1.260721  [ 6080/ 8640]\n",
            "loss: 0.945468  [ 6160/ 8640]\n",
            "loss: 1.532433  [ 6240/ 8640]\n",
            "loss: 1.359779  [ 6320/ 8640]\n",
            "loss: 1.092331  [ 6400/ 8640]\n",
            "loss: 0.834379  [ 6480/ 8640]\n",
            "loss: 1.251111  [ 6560/ 8640]\n",
            "loss: 1.133101  [ 6640/ 8640]\n",
            "loss: 0.733853  [ 6720/ 8640]\n",
            "loss: 1.348089  [ 6800/ 8640]\n",
            "loss: 1.168164  [ 6880/ 8640]\n",
            "loss: 1.387564  [ 6960/ 8640]\n",
            "loss: 1.107297  [ 7040/ 8640]\n",
            "loss: 0.978889  [ 7120/ 8640]\n",
            "loss: 0.585341  [ 7200/ 8640]\n",
            "loss: 1.441545  [ 7280/ 8640]\n",
            "loss: 0.708921  [ 7360/ 8640]\n",
            "loss: 1.455165  [ 7440/ 8640]\n",
            "loss: 0.867360  [ 7520/ 8640]\n",
            "loss: 1.627435  [ 7600/ 8640]\n",
            "loss: 1.536762  [ 7680/ 8640]\n",
            "loss: 1.028444  [ 7760/ 8640]\n",
            "loss: 0.977710  [ 7840/ 8640]\n",
            "loss: 0.842430  [ 7920/ 8640]\n",
            "loss: 1.456379  [ 8000/ 8640]\n",
            "loss: 0.590194  [ 8080/ 8640]\n",
            "loss: 1.277237  [ 8160/ 8640]\n",
            "loss: 1.424112  [ 8240/ 8640]\n",
            "loss: 0.882018  [ 8320/ 8640]\n",
            "loss: 1.046027  [ 8400/ 8640]\n",
            "loss: 1.014026  [ 8480/ 8640]\n",
            "loss: 0.883132  [ 8560/ 8640]\n",
            "Training done\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.928316  [    0/ 8640]\n",
            "loss: 0.748514  [   80/ 8640]\n",
            "loss: 1.095127  [  160/ 8640]\n",
            "loss: 0.942441  [  240/ 8640]\n",
            "loss: 0.856857  [  320/ 8640]\n",
            "loss: 1.038023  [  400/ 8640]\n",
            "loss: 0.676528  [  480/ 8640]\n",
            "loss: 1.071983  [  560/ 8640]\n",
            "loss: 0.860915  [  640/ 8640]\n",
            "loss: 1.607418  [  720/ 8640]\n",
            "loss: 0.910543  [  800/ 8640]\n",
            "loss: 0.732347  [  880/ 8640]\n",
            "loss: 0.622579  [  960/ 8640]\n",
            "loss: 0.687358  [ 1040/ 8640]\n",
            "loss: 0.705193  [ 1120/ 8640]\n",
            "loss: 0.741794  [ 1200/ 8640]\n",
            "loss: 0.552009  [ 1280/ 8640]\n",
            "loss: 0.822469  [ 1360/ 8640]\n",
            "loss: 0.548195  [ 1440/ 8640]\n",
            "loss: 0.754831  [ 1520/ 8640]\n",
            "loss: 1.239803  [ 1600/ 8640]\n",
            "loss: 1.128890  [ 1680/ 8640]\n",
            "loss: 0.925348  [ 1760/ 8640]\n",
            "loss: 1.060019  [ 1840/ 8640]\n",
            "loss: 0.911967  [ 1920/ 8640]\n",
            "loss: 0.558721  [ 2000/ 8640]\n",
            "loss: 1.413109  [ 2080/ 8640]\n",
            "loss: 0.808855  [ 2160/ 8640]\n",
            "loss: 0.994430  [ 2240/ 8640]\n",
            "loss: 0.572763  [ 2320/ 8640]\n",
            "loss: 0.912480  [ 2400/ 8640]\n",
            "loss: 0.684448  [ 2480/ 8640]\n",
            "loss: 0.758404  [ 2560/ 8640]\n",
            "loss: 1.052972  [ 2640/ 8640]\n",
            "loss: 0.710832  [ 2720/ 8640]\n",
            "loss: 0.704618  [ 2800/ 8640]\n",
            "loss: 0.322842  [ 2880/ 8640]\n",
            "loss: 0.631031  [ 2960/ 8640]\n",
            "loss: 0.896634  [ 3040/ 8640]\n",
            "loss: 0.660068  [ 3120/ 8640]\n",
            "loss: 0.757356  [ 3200/ 8640]\n",
            "loss: 0.814442  [ 3280/ 8640]\n",
            "loss: 0.752608  [ 3360/ 8640]\n",
            "loss: 0.704204  [ 3440/ 8640]\n",
            "loss: 0.877888  [ 3520/ 8640]\n",
            "loss: 0.818838  [ 3600/ 8640]\n",
            "loss: 1.175452  [ 3680/ 8640]\n",
            "loss: 1.174426  [ 3760/ 8640]\n",
            "loss: 0.751862  [ 3840/ 8640]\n",
            "loss: 0.559289  [ 3920/ 8640]\n",
            "loss: 1.124755  [ 4000/ 8640]\n",
            "loss: 0.556967  [ 4080/ 8640]\n",
            "loss: 0.643060  [ 4160/ 8640]\n",
            "loss: 0.812673  [ 4240/ 8640]\n",
            "loss: 0.624141  [ 4320/ 8640]\n",
            "loss: 0.480138  [ 4400/ 8640]\n",
            "loss: 0.621212  [ 4480/ 8640]\n",
            "loss: 0.501831  [ 4560/ 8640]\n",
            "loss: 0.579872  [ 4640/ 8640]\n",
            "loss: 0.709333  [ 4720/ 8640]\n",
            "loss: 1.142048  [ 4800/ 8640]\n",
            "loss: 0.588312  [ 4880/ 8640]\n",
            "loss: 1.024658  [ 4960/ 8640]\n",
            "loss: 0.793271  [ 5040/ 8640]\n",
            "loss: 0.657314  [ 5120/ 8640]\n",
            "loss: 0.744893  [ 5200/ 8640]\n",
            "loss: 0.887204  [ 5280/ 8640]\n",
            "loss: 0.617612  [ 5360/ 8640]\n",
            "loss: 0.343112  [ 5440/ 8640]\n",
            "loss: 0.344511  [ 5520/ 8640]\n",
            "loss: 0.957875  [ 5600/ 8640]\n",
            "loss: 0.899914  [ 5680/ 8640]\n",
            "loss: 0.476078  [ 5760/ 8640]\n",
            "loss: 0.643599  [ 5840/ 8640]\n",
            "loss: 0.498033  [ 5920/ 8640]\n",
            "loss: 0.547170  [ 6000/ 8640]\n",
            "loss: 0.703556  [ 6080/ 8640]\n",
            "loss: 0.633657  [ 6160/ 8640]\n",
            "loss: 1.029227  [ 6240/ 8640]\n",
            "loss: 0.500986  [ 6320/ 8640]\n",
            "loss: 0.383156  [ 6400/ 8640]\n",
            "loss: 0.662919  [ 6480/ 8640]\n",
            "loss: 1.077155  [ 6560/ 8640]\n",
            "loss: 0.477145  [ 6640/ 8640]\n",
            "loss: 0.711500  [ 6720/ 8640]\n",
            "loss: 0.764701  [ 6800/ 8640]\n",
            "loss: 0.890671  [ 6880/ 8640]\n",
            "loss: 0.493077  [ 6960/ 8640]\n",
            "loss: 0.916125  [ 7040/ 8640]\n",
            "loss: 0.234882  [ 7120/ 8640]\n",
            "loss: 1.056556  [ 7200/ 8640]\n",
            "loss: 0.710762  [ 7280/ 8640]\n",
            "loss: 0.271759  [ 7360/ 8640]\n",
            "loss: 1.042334  [ 7440/ 8640]\n",
            "loss: 0.358254  [ 7520/ 8640]\n",
            "loss: 0.810830  [ 7600/ 8640]\n",
            "loss: 0.711274  [ 7680/ 8640]\n",
            "loss: 0.852117  [ 7760/ 8640]\n",
            "loss: 0.638242  [ 7840/ 8640]\n",
            "loss: 0.788141  [ 7920/ 8640]\n",
            "loss: 0.975774  [ 8000/ 8640]\n",
            "loss: 0.893901  [ 8080/ 8640]\n",
            "loss: 0.428852  [ 8160/ 8640]\n",
            "loss: 0.506458  [ 8240/ 8640]\n",
            "loss: 0.246043  [ 8320/ 8640]\n",
            "loss: 0.803381  [ 8400/ 8640]\n",
            "loss: 0.974893  [ 8480/ 8640]\n",
            "loss: 0.691469  [ 8560/ 8640]\n",
            "Training done\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.470202  [    0/ 8640]\n",
            "loss: 0.325160  [   80/ 8640]\n",
            "loss: 0.946227  [  160/ 8640]\n",
            "loss: 0.329174  [  240/ 8640]\n",
            "loss: 0.694237  [  320/ 8640]\n",
            "loss: 0.521976  [  400/ 8640]\n",
            "loss: 0.601867  [  480/ 8640]\n",
            "loss: 0.363427  [  560/ 8640]\n",
            "loss: 0.602705  [  640/ 8640]\n",
            "loss: 1.303335  [  720/ 8640]\n",
            "loss: 0.426687  [  800/ 8640]\n",
            "loss: 0.723266  [  880/ 8640]\n",
            "loss: 0.407810  [  960/ 8640]\n",
            "loss: 0.294744  [ 1040/ 8640]\n",
            "loss: 0.556445  [ 1120/ 8640]\n",
            "loss: 1.621987  [ 1200/ 8640]\n",
            "loss: 0.430726  [ 1280/ 8640]\n",
            "loss: 0.679761  [ 1360/ 8640]\n",
            "loss: 0.837375  [ 1440/ 8640]\n",
            "loss: 0.941534  [ 1520/ 8640]\n",
            "loss: 0.356056  [ 1600/ 8640]\n",
            "loss: 0.481403  [ 1680/ 8640]\n",
            "loss: 0.541153  [ 1760/ 8640]\n",
            "loss: 0.440544  [ 1840/ 8640]\n",
            "loss: 0.345106  [ 1920/ 8640]\n",
            "loss: 0.285017  [ 2000/ 8640]\n",
            "loss: 0.463448  [ 2080/ 8640]\n",
            "loss: 0.499995  [ 2160/ 8640]\n",
            "loss: 0.404002  [ 2240/ 8640]\n",
            "loss: 0.180713  [ 2320/ 8640]\n",
            "loss: 0.303144  [ 2400/ 8640]\n",
            "loss: 0.490376  [ 2480/ 8640]\n",
            "loss: 0.297570  [ 2560/ 8640]\n",
            "loss: 0.422270  [ 2640/ 8640]\n",
            "loss: 0.283850  [ 2720/ 8640]\n",
            "loss: 0.568013  [ 2800/ 8640]\n",
            "loss: 0.354557  [ 2880/ 8640]\n",
            "loss: 0.433480  [ 2960/ 8640]\n",
            "loss: 0.393603  [ 3040/ 8640]\n",
            "loss: 0.408375  [ 3120/ 8640]\n",
            "loss: 0.271317  [ 3200/ 8640]\n",
            "loss: 0.249271  [ 3280/ 8640]\n",
            "loss: 0.177745  [ 3360/ 8640]\n",
            "loss: 0.823313  [ 3440/ 8640]\n",
            "loss: 0.325419  [ 3520/ 8640]\n",
            "loss: 0.464506  [ 3600/ 8640]\n",
            "loss: 0.311693  [ 3680/ 8640]\n",
            "loss: 0.320071  [ 3760/ 8640]\n",
            "loss: 0.595475  [ 3840/ 8640]\n",
            "loss: 0.885586  [ 3920/ 8640]\n",
            "loss: 0.376750  [ 4000/ 8640]\n",
            "loss: 0.222463  [ 4080/ 8640]\n",
            "loss: 0.678036  [ 4160/ 8640]\n",
            "loss: 0.221455  [ 4240/ 8640]\n",
            "loss: 0.485542  [ 4320/ 8640]\n",
            "loss: 1.039203  [ 4400/ 8640]\n",
            "loss: 0.412857  [ 4480/ 8640]\n",
            "loss: 0.482945  [ 4560/ 8640]\n",
            "loss: 0.274532  [ 4640/ 8640]\n",
            "loss: 0.522874  [ 4720/ 8640]\n",
            "loss: 0.602172  [ 4800/ 8640]\n",
            "loss: 0.973171  [ 4880/ 8640]\n",
            "loss: 0.443828  [ 4960/ 8640]\n",
            "loss: 0.530300  [ 5040/ 8640]\n",
            "loss: 0.341253  [ 5120/ 8640]\n",
            "loss: 0.426310  [ 5200/ 8640]\n",
            "loss: 0.365367  [ 5280/ 8640]\n",
            "loss: 0.210778  [ 5360/ 8640]\n",
            "loss: 0.758965  [ 5440/ 8640]\n",
            "loss: 1.007736  [ 5520/ 8640]\n",
            "loss: 0.552593  [ 5600/ 8640]\n",
            "loss: 0.499418  [ 5680/ 8640]\n",
            "loss: 0.360862  [ 5760/ 8640]\n",
            "loss: 0.507534  [ 5840/ 8640]\n",
            "loss: 0.539544  [ 5920/ 8640]\n",
            "loss: 0.365752  [ 6000/ 8640]\n",
            "loss: 0.174053  [ 6080/ 8640]\n",
            "loss: 0.384117  [ 6160/ 8640]\n",
            "loss: 0.200382  [ 6240/ 8640]\n",
            "loss: 0.315447  [ 6320/ 8640]\n",
            "loss: 0.180881  [ 6400/ 8640]\n",
            "loss: 0.337695  [ 6480/ 8640]\n",
            "loss: 0.397638  [ 6560/ 8640]\n",
            "loss: 0.397827  [ 6640/ 8640]\n",
            "loss: 0.333535  [ 6720/ 8640]\n",
            "loss: 0.163110  [ 6800/ 8640]\n",
            "loss: 0.179408  [ 6880/ 8640]\n",
            "loss: 0.673358  [ 6960/ 8640]\n",
            "loss: 1.239481  [ 7040/ 8640]\n",
            "loss: 0.137572  [ 7120/ 8640]\n",
            "loss: 0.956067  [ 7200/ 8640]\n",
            "loss: 1.106181  [ 7280/ 8640]\n",
            "loss: 0.425871  [ 7360/ 8640]\n",
            "loss: 0.258610  [ 7440/ 8640]\n",
            "loss: 0.307381  [ 7520/ 8640]\n",
            "loss: 0.177111  [ 7600/ 8640]\n",
            "loss: 0.361654  [ 7680/ 8640]\n",
            "loss: 0.207306  [ 7760/ 8640]\n",
            "loss: 0.558137  [ 7840/ 8640]\n",
            "loss: 0.282116  [ 7920/ 8640]\n",
            "loss: 0.152166  [ 8000/ 8640]\n",
            "loss: 0.322795  [ 8080/ 8640]\n",
            "loss: 0.258187  [ 8160/ 8640]\n",
            "loss: 0.137166  [ 8240/ 8640]\n",
            "loss: 0.269546  [ 8320/ 8640]\n",
            "loss: 1.127235  [ 8400/ 8640]\n",
            "loss: 0.391172  [ 8480/ 8640]\n",
            "loss: 0.247442  [ 8560/ 8640]\n",
            "Training done\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.100290  [    0/ 8640]\n",
            "loss: 0.305443  [   80/ 8640]\n",
            "loss: 1.393554  [  160/ 8640]\n",
            "loss: 0.301812  [  240/ 8640]\n",
            "loss: 0.143250  [  320/ 8640]\n",
            "loss: 0.494648  [  400/ 8640]\n",
            "loss: 0.122624  [  480/ 8640]\n",
            "loss: 0.317163  [  560/ 8640]\n",
            "loss: 0.383618  [  640/ 8640]\n",
            "loss: 0.491101  [  720/ 8640]\n",
            "loss: 0.266756  [  800/ 8640]\n",
            "loss: 0.197863  [  880/ 8640]\n",
            "loss: 0.154662  [  960/ 8640]\n",
            "loss: 0.191622  [ 1040/ 8640]\n",
            "loss: 0.518218  [ 1120/ 8640]\n",
            "loss: 0.945128  [ 1200/ 8640]\n",
            "loss: 0.381012  [ 1280/ 8640]\n",
            "loss: 0.090393  [ 1360/ 8640]\n",
            "loss: 0.174493  [ 1440/ 8640]\n",
            "loss: 0.172245  [ 1520/ 8640]\n",
            "loss: 0.067286  [ 1600/ 8640]\n",
            "loss: 0.366439  [ 1680/ 8640]\n",
            "loss: 0.143127  [ 1760/ 8640]\n",
            "loss: 0.189032  [ 1840/ 8640]\n",
            "loss: 0.126814  [ 1920/ 8640]\n",
            "loss: 0.346754  [ 2000/ 8640]\n",
            "loss: 0.501721  [ 2080/ 8640]\n",
            "loss: 0.053855  [ 2160/ 8640]\n",
            "loss: 0.556686  [ 2240/ 8640]\n",
            "loss: 0.903828  [ 2320/ 8640]\n",
            "loss: 0.101316  [ 2400/ 8640]\n",
            "loss: 0.288686  [ 2480/ 8640]\n",
            "loss: 0.213404  [ 2560/ 8640]\n",
            "loss: 0.093126  [ 2640/ 8640]\n",
            "loss: 0.422683  [ 2720/ 8640]\n",
            "loss: 0.055859  [ 2800/ 8640]\n",
            "loss: 0.096455  [ 2880/ 8640]\n",
            "loss: 0.049930  [ 2960/ 8640]\n",
            "loss: 0.681626  [ 3040/ 8640]\n",
            "loss: 0.049847  [ 3120/ 8640]\n",
            "loss: 0.345368  [ 3200/ 8640]\n",
            "loss: 0.253185  [ 3280/ 8640]\n",
            "loss: 0.076005  [ 3360/ 8640]\n",
            "loss: 0.195451  [ 3440/ 8640]\n",
            "loss: 0.044131  [ 3520/ 8640]\n",
            "loss: 0.261387  [ 3600/ 8640]\n",
            "loss: 0.278600  [ 3680/ 8640]\n",
            "loss: 0.303515  [ 3760/ 8640]\n",
            "loss: 0.369605  [ 3840/ 8640]\n",
            "loss: 0.067365  [ 3920/ 8640]\n",
            "loss: 0.181516  [ 4000/ 8640]\n",
            "loss: 0.130404  [ 4080/ 8640]\n",
            "loss: 0.062173  [ 4160/ 8640]\n",
            "loss: 0.064703  [ 4240/ 8640]\n",
            "loss: 0.991169  [ 4320/ 8640]\n",
            "loss: 0.083554  [ 4400/ 8640]\n",
            "loss: 0.529254  [ 4480/ 8640]\n",
            "loss: 0.337423  [ 4560/ 8640]\n",
            "loss: 0.746014  [ 4640/ 8640]\n",
            "loss: 0.224664  [ 4720/ 8640]\n",
            "loss: 0.120945  [ 4800/ 8640]\n",
            "loss: 0.200401  [ 4880/ 8640]\n",
            "loss: 0.061434  [ 4960/ 8640]\n",
            "loss: 0.129134  [ 5040/ 8640]\n",
            "loss: 0.101290  [ 5120/ 8640]\n",
            "loss: 0.071035  [ 5200/ 8640]\n",
            "loss: 0.999722  [ 5280/ 8640]\n",
            "loss: 0.212514  [ 5360/ 8640]\n",
            "loss: 0.050848  [ 5440/ 8640]\n",
            "loss: 0.195803  [ 5520/ 8640]\n",
            "loss: 0.555871  [ 5600/ 8640]\n",
            "loss: 0.145711  [ 5680/ 8640]\n",
            "loss: 0.129115  [ 5760/ 8640]\n",
            "loss: 0.122417  [ 5840/ 8640]\n",
            "loss: 0.063618  [ 5920/ 8640]\n",
            "loss: 0.096752  [ 6000/ 8640]\n",
            "loss: 0.375782  [ 6080/ 8640]\n",
            "loss: 0.100067  [ 6160/ 8640]\n",
            "loss: 0.070667  [ 6240/ 8640]\n",
            "loss: 0.569019  [ 6320/ 8640]\n",
            "loss: 0.044080  [ 6400/ 8640]\n",
            "loss: 0.037661  [ 6480/ 8640]\n",
            "loss: 0.100971  [ 6560/ 8640]\n",
            "loss: 0.856228  [ 6640/ 8640]\n",
            "loss: 0.084687  [ 6720/ 8640]\n",
            "loss: 0.040790  [ 6800/ 8640]\n",
            "loss: 0.703265  [ 6880/ 8640]\n",
            "loss: 0.080151  [ 6960/ 8640]\n",
            "loss: 0.026489  [ 7040/ 8640]\n",
            "loss: 0.112925  [ 7120/ 8640]\n",
            "loss: 0.287341  [ 7200/ 8640]\n",
            "loss: 0.658437  [ 7280/ 8640]\n",
            "loss: 0.405424  [ 7360/ 8640]\n",
            "loss: 0.063801  [ 7440/ 8640]\n",
            "loss: 0.077412  [ 7520/ 8640]\n",
            "loss: 0.509222  [ 7600/ 8640]\n",
            "loss: 0.076350  [ 7680/ 8640]\n",
            "loss: 0.126087  [ 7760/ 8640]\n",
            "loss: 0.509684  [ 7840/ 8640]\n",
            "loss: 0.136216  [ 7920/ 8640]\n",
            "loss: 0.075626  [ 8000/ 8640]\n",
            "loss: 0.210550  [ 8080/ 8640]\n",
            "loss: 0.164875  [ 8160/ 8640]\n",
            "loss: 0.590886  [ 8240/ 8640]\n",
            "loss: 0.833463  [ 8320/ 8640]\n",
            "loss: 0.082288  [ 8400/ 8640]\n",
            "loss: 0.296106  [ 8480/ 8640]\n",
            "loss: 0.377082  [ 8560/ 8640]\n",
            "Training done\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.069395  [    0/ 8640]\n",
            "loss: 0.065717  [   80/ 8640]\n",
            "loss: 0.073586  [  160/ 8640]\n",
            "loss: 0.131449  [  240/ 8640]\n",
            "loss: 0.130780  [  320/ 8640]\n",
            "loss: 0.122421  [  400/ 8640]\n",
            "loss: 0.118127  [  480/ 8640]\n",
            "loss: 0.109614  [  560/ 8640]\n",
            "loss: 0.035372  [  640/ 8640]\n",
            "loss: 0.067441  [  720/ 8640]\n",
            "loss: 0.067149  [  800/ 8640]\n",
            "loss: 0.195334  [  880/ 8640]\n",
            "loss: 0.044366  [  960/ 8640]\n",
            "loss: 0.771440  [ 1040/ 8640]\n",
            "loss: 0.064540  [ 1120/ 8640]\n",
            "loss: 0.430014  [ 1200/ 8640]\n",
            "loss: 0.045976  [ 1280/ 8640]\n",
            "loss: 0.097387  [ 1360/ 8640]\n",
            "loss: 0.024447  [ 1440/ 8640]\n",
            "loss: 0.019162  [ 1520/ 8640]\n",
            "loss: 0.350068  [ 1600/ 8640]\n",
            "loss: 0.124252  [ 1680/ 8640]\n",
            "loss: 0.075649  [ 1760/ 8640]\n",
            "loss: 0.114154  [ 1840/ 8640]\n",
            "loss: 0.035257  [ 1920/ 8640]\n",
            "loss: 0.083331  [ 2000/ 8640]\n",
            "loss: 0.029396  [ 2080/ 8640]\n",
            "loss: 0.062272  [ 2160/ 8640]\n",
            "loss: 0.063106  [ 2240/ 8640]\n",
            "loss: 0.113783  [ 2320/ 8640]\n",
            "loss: 0.041909  [ 2400/ 8640]\n",
            "loss: 0.022230  [ 2480/ 8640]\n",
            "loss: 0.021695  [ 2560/ 8640]\n",
            "loss: 0.279943  [ 2640/ 8640]\n",
            "loss: 0.365747  [ 2720/ 8640]\n",
            "loss: 0.044074  [ 2800/ 8640]\n",
            "loss: 0.103414  [ 2880/ 8640]\n",
            "loss: 0.019137  [ 2960/ 8640]\n",
            "loss: 0.022946  [ 3040/ 8640]\n",
            "loss: 0.203050  [ 3120/ 8640]\n",
            "loss: 0.017221  [ 3200/ 8640]\n",
            "loss: 0.062104  [ 3280/ 8640]\n",
            "loss: 0.053614  [ 3360/ 8640]\n",
            "loss: 0.061553  [ 3440/ 8640]\n",
            "loss: 0.022389  [ 3520/ 8640]\n",
            "loss: 0.025750  [ 3600/ 8640]\n",
            "loss: 0.044249  [ 3680/ 8640]\n",
            "loss: 0.749627  [ 3760/ 8640]\n",
            "loss: 0.069536  [ 3840/ 8640]\n",
            "loss: 0.043511  [ 3920/ 8640]\n",
            "loss: 0.088763  [ 4000/ 8640]\n",
            "loss: 0.183602  [ 4080/ 8640]\n",
            "loss: 0.709944  [ 4160/ 8640]\n",
            "loss: 0.044916  [ 4240/ 8640]\n",
            "loss: 0.295155  [ 4320/ 8640]\n",
            "loss: 0.119998  [ 4400/ 8640]\n",
            "loss: 0.507672  [ 4480/ 8640]\n",
            "loss: 0.048605  [ 4560/ 8640]\n",
            "loss: 0.033006  [ 4640/ 8640]\n",
            "loss: 0.072031  [ 4720/ 8640]\n",
            "loss: 0.079615  [ 4800/ 8640]\n",
            "loss: 0.153458  [ 4880/ 8640]\n",
            "loss: 0.030167  [ 4960/ 8640]\n",
            "loss: 0.187649  [ 5040/ 8640]\n",
            "loss: 0.669067  [ 5120/ 8640]\n",
            "loss: 0.014531  [ 5200/ 8640]\n",
            "loss: 0.035119  [ 5280/ 8640]\n",
            "loss: 0.026218  [ 5360/ 8640]\n",
            "loss: 0.040677  [ 5440/ 8640]\n",
            "loss: 0.107546  [ 5520/ 8640]\n",
            "loss: 0.254360  [ 5600/ 8640]\n",
            "loss: 0.043452  [ 5680/ 8640]\n",
            "loss: 0.684397  [ 5760/ 8640]\n",
            "loss: 0.023395  [ 5840/ 8640]\n",
            "loss: 0.027259  [ 5920/ 8640]\n",
            "loss: 0.027123  [ 6000/ 8640]\n",
            "loss: 0.026995  [ 6080/ 8640]\n",
            "loss: 0.048193  [ 6160/ 8640]\n",
            "loss: 0.022334  [ 6240/ 8640]\n",
            "loss: 0.041100  [ 6320/ 8640]\n",
            "loss: 0.100818  [ 6400/ 8640]\n",
            "loss: 0.573728  [ 6480/ 8640]\n",
            "loss: 0.797783  [ 6560/ 8640]\n",
            "loss: 0.020558  [ 6640/ 8640]\n",
            "loss: 0.067377  [ 6720/ 8640]\n",
            "loss: 0.251768  [ 6800/ 8640]\n",
            "loss: 0.053430  [ 6880/ 8640]\n",
            "loss: 0.189877  [ 6960/ 8640]\n",
            "loss: 0.031181  [ 7040/ 8640]\n",
            "loss: 0.040336  [ 7120/ 8640]\n",
            "loss: 0.192164  [ 7200/ 8640]\n",
            "loss: 0.026234  [ 7280/ 8640]\n",
            "loss: 0.285845  [ 7360/ 8640]\n",
            "loss: 0.441107  [ 7440/ 8640]\n",
            "loss: 0.133808  [ 7520/ 8640]\n",
            "loss: 0.039832  [ 7600/ 8640]\n",
            "loss: 0.089921  [ 7680/ 8640]\n",
            "loss: 0.042832  [ 7760/ 8640]\n",
            "loss: 0.089798  [ 7840/ 8640]\n",
            "loss: 0.035061  [ 7920/ 8640]\n",
            "loss: 0.802349  [ 8000/ 8640]\n",
            "loss: 0.110572  [ 8080/ 8640]\n",
            "loss: 0.411315  [ 8160/ 8640]\n",
            "loss: 0.276753  [ 8240/ 8640]\n",
            "loss: 0.032702  [ 8320/ 8640]\n",
            "loss: 0.033889  [ 8400/ 8640]\n",
            "loss: 0.027771  [ 8480/ 8640]\n",
            "loss: 0.438078  [ 8560/ 8640]\n",
            "Training done\n",
            "Test Accuracy: 80.94%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_e91f4905-ba4e-4b80-9086-9435141b6a4b\", \"sample_text_add_b8_lr17e4.csv\", 8504)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load your data\n",
        "data = df_combined\n",
        "sentences = data['sentence'].tolist()\n",
        "difficulties = data['difficulty'].tolist()\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(difficulties)\n",
        "\n",
        "# Load CamemBERT tokenizer and model\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
        "camembert = CamembertModel.from_pretrained('camembert-base')\n",
        "\n",
        "# Tokenize sentences and convert to tensor\n",
        "def tokenize_and_encode(sentences):\n",
        "    return tokenizer(sentences, padding=True, truncation=True, max_length=600, return_tensors='pt')\n",
        "\n",
        "# Custom Dataset class\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.encodings = tokenize_and_encode(texts)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: self.encodings[key][idx] for key in self.encodings}, self.labels[idx]\n",
        "\n",
        "# Data preparation\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    sentences, encoded_labels, test_size=0.1, random_state=42, stratify=encoded_labels\n",
        ")\n",
        "\n",
        "train_dataset = TextDataset(X_train, y_train)\n",
        "test_dataset = TextDataset(X_test, y_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# Neural network model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Net, self).__init__()\n",
        "        self.camembert = camembert\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.fc = nn.Linear(self.camembert.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        outputs = self.camembert(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.fc(pooled_output)\n",
        "        return logits\n",
        "\n",
        "# Instantiate the model, loss, and optimizer\n",
        "model = Net(len(label_encoder.classes_)).to('cuda')\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1.7e-5)\n",
        "\n",
        "# Function to compute accuracy\n",
        "def compute_accuracy(dataloader, model):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            inputs, labels = batch\n",
        "            inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
        "            labels = labels.to('cuda')\n",
        "            outputs = model(**inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "# Training loop\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()  # Set model to training mode\n",
        "    for batch, (inputs, labels) in enumerate(dataloader):\n",
        "        inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
        "        labels = labels.to('cuda')\n",
        "        pred = model(**inputs)\n",
        "        loss = loss_fn(pred, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 10 == 0:\n",
        "            loss, current = loss.item(), batch * len(inputs['input_ids'])\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "# Execute training\n",
        "for epoch in range(5):  # Number of epochs\n",
        "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
        "    train_loop(train_loader, model, criterion, optimizer)\n",
        "    print(\"Training done\")\n",
        "\n",
        "# Test the model\n",
        "accuracy = compute_accuracy(test_loader, model)\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import CamembertTokenizer\n",
        "\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
        "\n",
        "# Tokenize and encode the test data\n",
        "def tokenize_and_encode(sentences):\n",
        "    return tokenizer(sentences, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
        "\n",
        "# Custom Dataset class for test data\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, texts):\n",
        "        self.encodings = tokenize_and_encode(texts)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings['input_ids'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: self.encodings[key][idx] for key in self.encodings}\n",
        "\n",
        "# Create the dataset and dataloader for df_test\n",
        "test_dataset = TestDataset(df_test['sentence'].tolist())\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# Define the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Generate predictions for df_test\n",
        "model.eval()  # Make sure the model is in evaluation mode\n",
        "all_predictions = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        inputs = {key: value.to(device) for key, value in batch.items()}\n",
        "        outputs = model(**inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "# Convert numeric predictions back to labels\n",
        "predicted_labels = label_encoder.inverse_transform(all_predictions)\n",
        "\n",
        "# Prepare and save the submission file\n",
        "submission_df = pd.DataFrame({\n",
        "    'id': df_test['id'],  # Ensure df_test includes an 'id' column\n",
        "    'difficulty': predicted_labels\n",
        "})\n",
        "\n",
        "submission_df.to_csv('sample_text_add_b8_lr17e4.csv', index=False)\n",
        "from google.colab import files\n",
        "files.download('sample_text_add_b8_lr17e4.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEvEBoT-_ta5"
      },
      "source": [
        "I also tried models with **lemmatization** (with some success)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0TWoYnI-tp4",
        "outputId": "9c26a634-2790-4c16-a84f-187aa293e19c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.1.1)\n",
            "Collecting fr-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.7.0/fr_core_news_sm-3.7.0-py3-none-any.whl (16.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from fr-core-news-sm==3.7.0) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.1.1)\n",
            "Installing collected packages: fr-core-news-sm\n",
            "Successfully installed fr-core-news-sm-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "# Run this in a cell in your Jupyter notebook or Google Colab\n",
        "!pip install spacy\n",
        "!python -m spacy download fr_core_news_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8IUo983CL-Y"
      },
      "source": [
        "For example, the model below reached 0.573 accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "10941e0e46344cdf8acc3305d493c28a",
            "4712f34a60904cafbe7238897c108c20",
            "00360cac3c1c46038b400fd3cd6366d0",
            "bfc916c39a904d53b1ac0f5c8b872dd8",
            "67d864a1977748ada2e81be160744bf3"
          ]
        },
        "id": "QO81wif7PhJ3",
        "outputId": "b3fd95a4-7454-43cb-d0df-e144949df847"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "10941e0e46344cdf8acc3305d493c28a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4712f34a60904cafbe7238897c108c20",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/811k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "00360cac3c1c46038b400fd3cd6366d0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.40M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bfc916c39a904d53b1ac0f5c8b872dd8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/508 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "67d864a1977748ada2e81be160744bf3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 1.798286  [    0/ 8640]\n",
            "loss: 1.770983  [   80/ 8640]\n",
            "loss: 1.750108  [  160/ 8640]\n",
            "loss: 1.784353  [  240/ 8640]\n",
            "loss: 1.698660  [  320/ 8640]\n",
            "loss: 1.726839  [  400/ 8640]\n",
            "loss: 1.823075  [  480/ 8640]\n",
            "loss: 1.717239  [  560/ 8640]\n",
            "loss: 1.659207  [  640/ 8640]\n",
            "loss: 1.706909  [  720/ 8640]\n",
            "loss: 1.500722  [  800/ 8640]\n",
            "loss: 1.701954  [  880/ 8640]\n",
            "loss: 1.537208  [  960/ 8640]\n",
            "loss: 1.438291  [ 1040/ 8640]\n",
            "loss: 1.469917  [ 1120/ 8640]\n",
            "loss: 1.457222  [ 1200/ 8640]\n",
            "loss: 1.445869  [ 1280/ 8640]\n",
            "loss: 1.332990  [ 1360/ 8640]\n",
            "loss: 1.565134  [ 1440/ 8640]\n",
            "loss: 1.459732  [ 1520/ 8640]\n",
            "loss: 1.741069  [ 1600/ 8640]\n",
            "loss: 1.451294  [ 1680/ 8640]\n",
            "loss: 1.474038  [ 1760/ 8640]\n",
            "loss: 1.466886  [ 1840/ 8640]\n",
            "loss: 1.376761  [ 1920/ 8640]\n",
            "loss: 1.250723  [ 2000/ 8640]\n",
            "loss: 1.261425  [ 2080/ 8640]\n",
            "loss: 1.319154  [ 2160/ 8640]\n",
            "loss: 1.252576  [ 2240/ 8640]\n",
            "loss: 1.299881  [ 2320/ 8640]\n",
            "loss: 1.562539  [ 2400/ 8640]\n",
            "loss: 1.430410  [ 2480/ 8640]\n",
            "loss: 1.424478  [ 2560/ 8640]\n",
            "loss: 1.251067  [ 2640/ 8640]\n",
            "loss: 1.132097  [ 2720/ 8640]\n",
            "loss: 1.351689  [ 2800/ 8640]\n",
            "loss: 1.664661  [ 2880/ 8640]\n",
            "loss: 1.415609  [ 2960/ 8640]\n",
            "loss: 1.228018  [ 3040/ 8640]\n",
            "loss: 1.278190  [ 3120/ 8640]\n",
            "loss: 1.157989  [ 3200/ 8640]\n",
            "loss: 1.421847  [ 3280/ 8640]\n",
            "loss: 1.041276  [ 3360/ 8640]\n",
            "loss: 1.098853  [ 3440/ 8640]\n",
            "loss: 1.152332  [ 3520/ 8640]\n",
            "loss: 1.147382  [ 3600/ 8640]\n",
            "loss: 1.637270  [ 3680/ 8640]\n",
            "loss: 1.260093  [ 3760/ 8640]\n",
            "loss: 1.354885  [ 3840/ 8640]\n",
            "loss: 1.068543  [ 3920/ 8640]\n",
            "loss: 1.207489  [ 4000/ 8640]\n",
            "loss: 1.484230  [ 4080/ 8640]\n",
            "loss: 1.132320  [ 4160/ 8640]\n",
            "loss: 1.361036  [ 4240/ 8640]\n",
            "loss: 1.296668  [ 4320/ 8640]\n",
            "loss: 1.113048  [ 4400/ 8640]\n",
            "loss: 0.830977  [ 4480/ 8640]\n",
            "loss: 0.799361  [ 4560/ 8640]\n",
            "loss: 0.979030  [ 4640/ 8640]\n",
            "loss: 1.172905  [ 4720/ 8640]\n",
            "loss: 1.259695  [ 4800/ 8640]\n",
            "loss: 1.081120  [ 4880/ 8640]\n",
            "loss: 1.000306  [ 4960/ 8640]\n",
            "loss: 1.201571  [ 5040/ 8640]\n",
            "loss: 1.164953  [ 5120/ 8640]\n",
            "loss: 1.181448  [ 5200/ 8640]\n",
            "loss: 1.213327  [ 5280/ 8640]\n",
            "loss: 1.818987  [ 5360/ 8640]\n",
            "loss: 0.900316  [ 5440/ 8640]\n",
            "loss: 0.829789  [ 5520/ 8640]\n",
            "loss: 1.838208  [ 5600/ 8640]\n",
            "loss: 0.988059  [ 5680/ 8640]\n",
            "loss: 1.039887  [ 5760/ 8640]\n",
            "loss: 1.437393  [ 5840/ 8640]\n",
            "loss: 1.257051  [ 5920/ 8640]\n",
            "loss: 1.161951  [ 6000/ 8640]\n",
            "loss: 1.008874  [ 6080/ 8640]\n",
            "loss: 0.950505  [ 6160/ 8640]\n",
            "loss: 1.084838  [ 6240/ 8640]\n",
            "loss: 1.471474  [ 6320/ 8640]\n",
            "loss: 1.117874  [ 6400/ 8640]\n",
            "loss: 1.061348  [ 6480/ 8640]\n",
            "loss: 1.067167  [ 6560/ 8640]\n",
            "loss: 0.921142  [ 6640/ 8640]\n",
            "loss: 1.250928  [ 6720/ 8640]\n",
            "loss: 1.383178  [ 6800/ 8640]\n",
            "loss: 1.313446  [ 6880/ 8640]\n",
            "loss: 1.031351  [ 6960/ 8640]\n",
            "loss: 1.223944  [ 7040/ 8640]\n",
            "loss: 1.095752  [ 7120/ 8640]\n",
            "loss: 1.186816  [ 7200/ 8640]\n",
            "loss: 1.376233  [ 7280/ 8640]\n",
            "loss: 1.243921  [ 7360/ 8640]\n",
            "loss: 0.802597  [ 7440/ 8640]\n",
            "loss: 0.886896  [ 7520/ 8640]\n",
            "loss: 0.926429  [ 7600/ 8640]\n",
            "loss: 1.011672  [ 7680/ 8640]\n",
            "loss: 0.727898  [ 7760/ 8640]\n",
            "loss: 0.954247  [ 7840/ 8640]\n",
            "loss: 0.991139  [ 7920/ 8640]\n",
            "loss: 0.930433  [ 8000/ 8640]\n",
            "loss: 1.410212  [ 8080/ 8640]\n",
            "loss: 1.525689  [ 8160/ 8640]\n",
            "loss: 1.144833  [ 8240/ 8640]\n",
            "loss: 1.075778  [ 8320/ 8640]\n",
            "loss: 0.818812  [ 8400/ 8640]\n",
            "loss: 1.161408  [ 8480/ 8640]\n",
            "loss: 0.944543  [ 8560/ 8640]\n",
            "Training done\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.915504  [    0/ 8640]\n",
            "loss: 0.877930  [   80/ 8640]\n",
            "loss: 0.732464  [  160/ 8640]\n",
            "loss: 1.125140  [  240/ 8640]\n",
            "loss: 0.733958  [  320/ 8640]\n",
            "loss: 0.923117  [  400/ 8640]\n",
            "loss: 0.824331  [  480/ 8640]\n",
            "loss: 0.925540  [  560/ 8640]\n",
            "loss: 0.992243  [  640/ 8640]\n",
            "loss: 0.996982  [  720/ 8640]\n",
            "loss: 1.412638  [  800/ 8640]\n",
            "loss: 1.199101  [  880/ 8640]\n",
            "loss: 0.833572  [  960/ 8640]\n",
            "loss: 0.788673  [ 1040/ 8640]\n",
            "loss: 1.029532  [ 1120/ 8640]\n",
            "loss: 1.021793  [ 1200/ 8640]\n",
            "loss: 1.098525  [ 1280/ 8640]\n",
            "loss: 0.719522  [ 1360/ 8640]\n",
            "loss: 0.685632  [ 1440/ 8640]\n",
            "loss: 0.809726  [ 1520/ 8640]\n",
            "loss: 0.688923  [ 1600/ 8640]\n",
            "loss: 1.311845  [ 1680/ 8640]\n",
            "loss: 1.234239  [ 1760/ 8640]\n",
            "loss: 0.884134  [ 1840/ 8640]\n",
            "loss: 0.959622  [ 1920/ 8640]\n",
            "loss: 1.207773  [ 2000/ 8640]\n",
            "loss: 1.186106  [ 2080/ 8640]\n",
            "loss: 0.690470  [ 2160/ 8640]\n",
            "loss: 1.231279  [ 2240/ 8640]\n",
            "loss: 0.737567  [ 2320/ 8640]\n",
            "loss: 1.445991  [ 2400/ 8640]\n",
            "loss: 0.982794  [ 2480/ 8640]\n",
            "loss: 0.845232  [ 2560/ 8640]\n",
            "loss: 1.030320  [ 2640/ 8640]\n",
            "loss: 0.759556  [ 2720/ 8640]\n",
            "loss: 1.062311  [ 2800/ 8640]\n",
            "loss: 0.960044  [ 2880/ 8640]\n",
            "loss: 0.725356  [ 2960/ 8640]\n",
            "loss: 1.144775  [ 3040/ 8640]\n",
            "loss: 0.723886  [ 3120/ 8640]\n",
            "loss: 0.779353  [ 3200/ 8640]\n",
            "loss: 0.859792  [ 3280/ 8640]\n",
            "loss: 0.617392  [ 3360/ 8640]\n",
            "loss: 1.330643  [ 3440/ 8640]\n",
            "loss: 0.810149  [ 3520/ 8640]\n",
            "loss: 0.635187  [ 3600/ 8640]\n",
            "loss: 1.244321  [ 3680/ 8640]\n",
            "loss: 1.108300  [ 3760/ 8640]\n",
            "loss: 0.983670  [ 3840/ 8640]\n",
            "loss: 0.685225  [ 3920/ 8640]\n",
            "loss: 1.137944  [ 4000/ 8640]\n",
            "loss: 0.987663  [ 4080/ 8640]\n",
            "loss: 0.966755  [ 4160/ 8640]\n",
            "loss: 1.065169  [ 4240/ 8640]\n",
            "loss: 0.870992  [ 4320/ 8640]\n",
            "loss: 1.146096  [ 4400/ 8640]\n",
            "loss: 0.864711  [ 4480/ 8640]\n",
            "loss: 0.739448  [ 4560/ 8640]\n",
            "loss: 1.315020  [ 4640/ 8640]\n",
            "loss: 1.119559  [ 4720/ 8640]\n",
            "loss: 0.806511  [ 4800/ 8640]\n",
            "loss: 0.869406  [ 4880/ 8640]\n",
            "loss: 1.071543  [ 4960/ 8640]\n",
            "loss: 0.929235  [ 5040/ 8640]\n",
            "loss: 1.254961  [ 5120/ 8640]\n",
            "loss: 0.901214  [ 5200/ 8640]\n",
            "loss: 1.050565  [ 5280/ 8640]\n",
            "loss: 0.579229  [ 5360/ 8640]\n",
            "loss: 0.699383  [ 5440/ 8640]\n",
            "loss: 0.626335  [ 5520/ 8640]\n",
            "loss: 0.784319  [ 5600/ 8640]\n",
            "loss: 0.810140  [ 5680/ 8640]\n",
            "loss: 0.821030  [ 5760/ 8640]\n",
            "loss: 0.318004  [ 5840/ 8640]\n",
            "loss: 1.026075  [ 5920/ 8640]\n",
            "loss: 0.608478  [ 6000/ 8640]\n",
            "loss: 0.585987  [ 6080/ 8640]\n",
            "loss: 1.356486  [ 6160/ 8640]\n",
            "loss: 0.667895  [ 6240/ 8640]\n",
            "loss: 1.533501  [ 6320/ 8640]\n",
            "loss: 1.227672  [ 6400/ 8640]\n",
            "loss: 1.153805  [ 6480/ 8640]\n",
            "loss: 0.406986  [ 6560/ 8640]\n",
            "loss: 0.806559  [ 6640/ 8640]\n",
            "loss: 0.713564  [ 6720/ 8640]\n",
            "loss: 0.728500  [ 6800/ 8640]\n",
            "loss: 0.800300  [ 6880/ 8640]\n",
            "loss: 0.934298  [ 6960/ 8640]\n",
            "loss: 0.954305  [ 7040/ 8640]\n",
            "loss: 1.246117  [ 7120/ 8640]\n",
            "loss: 0.425696  [ 7200/ 8640]\n",
            "loss: 1.171011  [ 7280/ 8640]\n",
            "loss: 0.841980  [ 7360/ 8640]\n",
            "loss: 0.759193  [ 7440/ 8640]\n",
            "loss: 1.336485  [ 7520/ 8640]\n",
            "loss: 0.635870  [ 7600/ 8640]\n",
            "loss: 0.988826  [ 7680/ 8640]\n",
            "loss: 0.472256  [ 7760/ 8640]\n",
            "loss: 1.068599  [ 7840/ 8640]\n",
            "loss: 1.090112  [ 7920/ 8640]\n",
            "loss: 0.921277  [ 8000/ 8640]\n",
            "loss: 0.786343  [ 8080/ 8640]\n",
            "loss: 1.481069  [ 8160/ 8640]\n",
            "loss: 0.792292  [ 8240/ 8640]\n",
            "loss: 0.829055  [ 8320/ 8640]\n",
            "loss: 0.794636  [ 8400/ 8640]\n",
            "loss: 0.689553  [ 8480/ 8640]\n",
            "loss: 1.032973  [ 8560/ 8640]\n",
            "Training done\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.688298  [    0/ 8640]\n",
            "loss: 1.045439  [   80/ 8640]\n",
            "loss: 0.844391  [  160/ 8640]\n",
            "loss: 1.049399  [  240/ 8640]\n",
            "loss: 1.067642  [  320/ 8640]\n",
            "loss: 0.374970  [  400/ 8640]\n",
            "loss: 1.321649  [  480/ 8640]\n",
            "loss: 1.579363  [  560/ 8640]\n",
            "loss: 0.956305  [  640/ 8640]\n",
            "loss: 0.719132  [  720/ 8640]\n",
            "loss: 0.668170  [  800/ 8640]\n",
            "loss: 0.242959  [  880/ 8640]\n",
            "loss: 0.581229  [  960/ 8640]\n",
            "loss: 0.557199  [ 1040/ 8640]\n",
            "loss: 0.674177  [ 1120/ 8640]\n",
            "loss: 0.597566  [ 1200/ 8640]\n",
            "loss: 0.454586  [ 1280/ 8640]\n",
            "loss: 0.621749  [ 1360/ 8640]\n",
            "loss: 0.373502  [ 1440/ 8640]\n",
            "loss: 0.707253  [ 1520/ 8640]\n",
            "loss: 0.780145  [ 1600/ 8640]\n",
            "loss: 0.342269  [ 1680/ 8640]\n",
            "loss: 0.851830  [ 1760/ 8640]\n",
            "loss: 1.101601  [ 1840/ 8640]\n",
            "loss: 0.588077  [ 1920/ 8640]\n",
            "loss: 0.408288  [ 2000/ 8640]\n",
            "loss: 1.052754  [ 2080/ 8640]\n",
            "loss: 0.831550  [ 2160/ 8640]\n",
            "loss: 0.651762  [ 2240/ 8640]\n",
            "loss: 0.503653  [ 2320/ 8640]\n",
            "loss: 0.603853  [ 2400/ 8640]\n",
            "loss: 0.539878  [ 2480/ 8640]\n",
            "loss: 0.503587  [ 2560/ 8640]\n",
            "loss: 0.627668  [ 2640/ 8640]\n",
            "loss: 0.517385  [ 2720/ 8640]\n",
            "loss: 0.370301  [ 2800/ 8640]\n",
            "loss: 1.206574  [ 2880/ 8640]\n",
            "loss: 0.641336  [ 2960/ 8640]\n",
            "loss: 0.442706  [ 3040/ 8640]\n",
            "loss: 1.077302  [ 3120/ 8640]\n",
            "loss: 0.390402  [ 3200/ 8640]\n",
            "loss: 0.440534  [ 3280/ 8640]\n",
            "loss: 0.409119  [ 3360/ 8640]\n",
            "loss: 0.434690  [ 3440/ 8640]\n",
            "loss: 0.962853  [ 3520/ 8640]\n",
            "loss: 1.217002  [ 3600/ 8640]\n",
            "loss: 0.616091  [ 3680/ 8640]\n",
            "loss: 0.426983  [ 3760/ 8640]\n",
            "loss: 0.467846  [ 3840/ 8640]\n",
            "loss: 0.460707  [ 3920/ 8640]\n",
            "loss: 0.726251  [ 4000/ 8640]\n",
            "loss: 0.537931  [ 4080/ 8640]\n",
            "loss: 1.725401  [ 4160/ 8640]\n",
            "loss: 0.374922  [ 4240/ 8640]\n",
            "loss: 0.265182  [ 4320/ 8640]\n",
            "loss: 0.685156  [ 4400/ 8640]\n",
            "loss: 0.451212  [ 4480/ 8640]\n",
            "loss: 0.513493  [ 4560/ 8640]\n",
            "loss: 0.517863  [ 4640/ 8640]\n",
            "loss: 0.661122  [ 4720/ 8640]\n",
            "loss: 0.597160  [ 4800/ 8640]\n",
            "loss: 1.228038  [ 4880/ 8640]\n",
            "loss: 0.804475  [ 4960/ 8640]\n",
            "loss: 0.492514  [ 5040/ 8640]\n",
            "loss: 1.057562  [ 5120/ 8640]\n",
            "loss: 1.290769  [ 5200/ 8640]\n",
            "loss: 0.956519  [ 5280/ 8640]\n",
            "loss: 0.538227  [ 5360/ 8640]\n",
            "loss: 0.391805  [ 5440/ 8640]\n",
            "loss: 0.446062  [ 5520/ 8640]\n",
            "loss: 0.370931  [ 5600/ 8640]\n",
            "loss: 0.467566  [ 5680/ 8640]\n",
            "loss: 0.895305  [ 5760/ 8640]\n",
            "loss: 0.327561  [ 5840/ 8640]\n",
            "loss: 0.805131  [ 5920/ 8640]\n",
            "loss: 0.410197  [ 6000/ 8640]\n",
            "loss: 0.731089  [ 6080/ 8640]\n",
            "loss: 1.070542  [ 6160/ 8640]\n",
            "loss: 0.438402  [ 6240/ 8640]\n",
            "loss: 0.358206  [ 6320/ 8640]\n",
            "loss: 0.913503  [ 6400/ 8640]\n",
            "loss: 0.368922  [ 6480/ 8640]\n",
            "loss: 0.791373  [ 6560/ 8640]\n",
            "loss: 0.173426  [ 6640/ 8640]\n",
            "loss: 0.279784  [ 6720/ 8640]\n",
            "loss: 0.328549  [ 6800/ 8640]\n",
            "loss: 0.740713  [ 6880/ 8640]\n",
            "loss: 0.706967  [ 6960/ 8640]\n",
            "loss: 0.959736  [ 7040/ 8640]\n",
            "loss: 0.250780  [ 7120/ 8640]\n",
            "loss: 0.737010  [ 7200/ 8640]\n",
            "loss: 0.584804  [ 7280/ 8640]\n",
            "loss: 0.345856  [ 7360/ 8640]\n",
            "loss: 0.715278  [ 7440/ 8640]\n",
            "loss: 0.754642  [ 7520/ 8640]\n",
            "loss: 0.437536  [ 7600/ 8640]\n",
            "loss: 0.412194  [ 7680/ 8640]\n",
            "loss: 0.257354  [ 7760/ 8640]\n",
            "loss: 0.462830  [ 7840/ 8640]\n",
            "loss: 0.621867  [ 7920/ 8640]\n",
            "loss: 0.941281  [ 8000/ 8640]\n",
            "loss: 0.239343  [ 8080/ 8640]\n",
            "loss: 0.710846  [ 8160/ 8640]\n",
            "loss: 0.830837  [ 8240/ 8640]\n",
            "loss: 0.267528  [ 8320/ 8640]\n",
            "loss: 0.481611  [ 8400/ 8640]\n",
            "loss: 0.750599  [ 8480/ 8640]\n",
            "loss: 0.620125  [ 8560/ 8640]\n",
            "Training done\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.246786  [    0/ 8640]\n",
            "loss: 0.433832  [   80/ 8640]\n",
            "loss: 0.491385  [  160/ 8640]\n",
            "loss: 0.399143  [  240/ 8640]\n",
            "loss: 0.474368  [  320/ 8640]\n",
            "loss: 0.232579  [  400/ 8640]\n",
            "loss: 0.442188  [  480/ 8640]\n",
            "loss: 0.314066  [  560/ 8640]\n",
            "loss: 0.134568  [  640/ 8640]\n",
            "loss: 0.354952  [  720/ 8640]\n",
            "loss: 0.173871  [  800/ 8640]\n",
            "loss: 0.352021  [  880/ 8640]\n",
            "loss: 0.316751  [  960/ 8640]\n",
            "loss: 0.350871  [ 1040/ 8640]\n",
            "loss: 0.613726  [ 1120/ 8640]\n",
            "loss: 0.339462  [ 1200/ 8640]\n",
            "loss: 0.225461  [ 1280/ 8640]\n",
            "loss: 0.489458  [ 1360/ 8640]\n",
            "loss: 0.189348  [ 1440/ 8640]\n",
            "loss: 0.661726  [ 1520/ 8640]\n",
            "loss: 0.814890  [ 1600/ 8640]\n",
            "loss: 0.473308  [ 1680/ 8640]\n",
            "loss: 0.252426  [ 1760/ 8640]\n",
            "loss: 0.216366  [ 1840/ 8640]\n",
            "loss: 0.526387  [ 1920/ 8640]\n",
            "loss: 0.466651  [ 2000/ 8640]\n",
            "loss: 0.519054  [ 2080/ 8640]\n",
            "loss: 0.108803  [ 2160/ 8640]\n",
            "loss: 0.107936  [ 2240/ 8640]\n",
            "loss: 0.762740  [ 2320/ 8640]\n",
            "loss: 0.349867  [ 2400/ 8640]\n",
            "loss: 0.191522  [ 2480/ 8640]\n",
            "loss: 0.436980  [ 2560/ 8640]\n",
            "loss: 1.089975  [ 2640/ 8640]\n",
            "loss: 0.305997  [ 2720/ 8640]\n",
            "loss: 0.705973  [ 2800/ 8640]\n",
            "loss: 0.591625  [ 2880/ 8640]\n",
            "loss: 0.511618  [ 2960/ 8640]\n",
            "loss: 0.153439  [ 3040/ 8640]\n",
            "loss: 1.095468  [ 3120/ 8640]\n",
            "loss: 0.439365  [ 3200/ 8640]\n",
            "loss: 0.929266  [ 3280/ 8640]\n",
            "loss: 0.354812  [ 3360/ 8640]\n",
            "loss: 0.533703  [ 3440/ 8640]\n",
            "loss: 0.343938  [ 3520/ 8640]\n",
            "loss: 0.368159  [ 3600/ 8640]\n",
            "loss: 1.123280  [ 3680/ 8640]\n",
            "loss: 0.078141  [ 3760/ 8640]\n",
            "loss: 0.160755  [ 3840/ 8640]\n",
            "loss: 0.259365  [ 3920/ 8640]\n",
            "loss: 0.887368  [ 4000/ 8640]\n",
            "loss: 1.125317  [ 4080/ 8640]\n",
            "loss: 0.185731  [ 4160/ 8640]\n",
            "loss: 0.311143  [ 4240/ 8640]\n",
            "loss: 0.537661  [ 4320/ 8640]\n",
            "loss: 0.303547  [ 4400/ 8640]\n",
            "loss: 0.419501  [ 4480/ 8640]\n",
            "loss: 0.292577  [ 4560/ 8640]\n",
            "loss: 0.191024  [ 4640/ 8640]\n",
            "loss: 0.254519  [ 4720/ 8640]\n",
            "loss: 0.291508  [ 4800/ 8640]\n",
            "loss: 0.147538  [ 4880/ 8640]\n",
            "loss: 0.478546  [ 4960/ 8640]\n",
            "loss: 0.317394  [ 5040/ 8640]\n",
            "loss: 0.163584  [ 5120/ 8640]\n",
            "loss: 0.215232  [ 5200/ 8640]\n",
            "loss: 0.522826  [ 5280/ 8640]\n",
            "loss: 0.213978  [ 5360/ 8640]\n",
            "loss: 0.441689  [ 5440/ 8640]\n",
            "loss: 0.124133  [ 5520/ 8640]\n",
            "loss: 0.169454  [ 5600/ 8640]\n",
            "loss: 0.323007  [ 5680/ 8640]\n",
            "loss: 0.442133  [ 5760/ 8640]\n",
            "loss: 0.656588  [ 5840/ 8640]\n",
            "loss: 0.148731  [ 5920/ 8640]\n",
            "loss: 0.717021  [ 6000/ 8640]\n",
            "loss: 0.129479  [ 6080/ 8640]\n",
            "loss: 0.614534  [ 6160/ 8640]\n",
            "loss: 0.386878  [ 6240/ 8640]\n",
            "loss: 0.598479  [ 6320/ 8640]\n",
            "loss: 0.279925  [ 6400/ 8640]\n",
            "loss: 0.405161  [ 6480/ 8640]\n",
            "loss: 0.203895  [ 6560/ 8640]\n",
            "loss: 0.223461  [ 6640/ 8640]\n",
            "loss: 0.237484  [ 6720/ 8640]\n",
            "loss: 0.076952  [ 6800/ 8640]\n",
            "loss: 0.395706  [ 6880/ 8640]\n",
            "loss: 0.797501  [ 6960/ 8640]\n",
            "loss: 0.173050  [ 7040/ 8640]\n",
            "loss: 0.325692  [ 7120/ 8640]\n",
            "loss: 0.568121  [ 7200/ 8640]\n",
            "loss: 0.164339  [ 7280/ 8640]\n",
            "loss: 0.586879  [ 7360/ 8640]\n",
            "loss: 0.553298  [ 7440/ 8640]\n",
            "loss: 0.911596  [ 7520/ 8640]\n",
            "loss: 0.463645  [ 7600/ 8640]\n",
            "loss: 0.436016  [ 7680/ 8640]\n",
            "loss: 1.424313  [ 7760/ 8640]\n",
            "loss: 0.152957  [ 7840/ 8640]\n",
            "loss: 0.183227  [ 7920/ 8640]\n",
            "loss: 0.514603  [ 8000/ 8640]\n",
            "loss: 0.562074  [ 8080/ 8640]\n",
            "loss: 0.257056  [ 8160/ 8640]\n",
            "loss: 0.746469  [ 8240/ 8640]\n",
            "loss: 0.125759  [ 8320/ 8640]\n",
            "loss: 0.309774  [ 8400/ 8640]\n",
            "loss: 0.314497  [ 8480/ 8640]\n",
            "loss: 0.369298  [ 8560/ 8640]\n",
            "Training done\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.105702  [    0/ 8640]\n",
            "loss: 0.190185  [   80/ 8640]\n",
            "loss: 0.187320  [  160/ 8640]\n",
            "loss: 0.103904  [  240/ 8640]\n",
            "loss: 0.129768  [  320/ 8640]\n",
            "loss: 0.159235  [  400/ 8640]\n",
            "loss: 0.450249  [  480/ 8640]\n",
            "loss: 0.088791  [  560/ 8640]\n",
            "loss: 0.080625  [  640/ 8640]\n",
            "loss: 0.250205  [  720/ 8640]\n",
            "loss: 0.143718  [  800/ 8640]\n",
            "loss: 0.479050  [  880/ 8640]\n",
            "loss: 0.269331  [  960/ 8640]\n",
            "loss: 0.417267  [ 1040/ 8640]\n",
            "loss: 0.292362  [ 1120/ 8640]\n",
            "loss: 0.179010  [ 1200/ 8640]\n",
            "loss: 0.139884  [ 1280/ 8640]\n",
            "loss: 0.080069  [ 1360/ 8640]\n",
            "loss: 0.081118  [ 1440/ 8640]\n",
            "loss: 0.134194  [ 1520/ 8640]\n",
            "loss: 0.282365  [ 1600/ 8640]\n",
            "loss: 0.099896  [ 1680/ 8640]\n",
            "loss: 0.094427  [ 1760/ 8640]\n",
            "loss: 0.037094  [ 1840/ 8640]\n",
            "loss: 0.228629  [ 1920/ 8640]\n",
            "loss: 0.201949  [ 2000/ 8640]\n",
            "loss: 0.220412  [ 2080/ 8640]\n",
            "loss: 0.346093  [ 2160/ 8640]\n",
            "loss: 0.186838  [ 2240/ 8640]\n",
            "loss: 0.052023  [ 2320/ 8640]\n",
            "loss: 0.523265  [ 2400/ 8640]\n",
            "loss: 0.093646  [ 2480/ 8640]\n",
            "loss: 0.089513  [ 2560/ 8640]\n",
            "loss: 0.148762  [ 2640/ 8640]\n",
            "loss: 0.250279  [ 2720/ 8640]\n",
            "loss: 0.072466  [ 2800/ 8640]\n",
            "loss: 0.068022  [ 2880/ 8640]\n",
            "loss: 0.069202  [ 2960/ 8640]\n",
            "loss: 0.180192  [ 3040/ 8640]\n",
            "loss: 0.059051  [ 3120/ 8640]\n",
            "loss: 0.763798  [ 3200/ 8640]\n",
            "loss: 0.861958  [ 3280/ 8640]\n",
            "loss: 0.182177  [ 3360/ 8640]\n",
            "loss: 0.070087  [ 3440/ 8640]\n",
            "loss: 0.127551  [ 3520/ 8640]\n",
            "loss: 0.192189  [ 3600/ 8640]\n",
            "loss: 0.122415  [ 3680/ 8640]\n",
            "loss: 0.070730  [ 3760/ 8640]\n",
            "loss: 0.069781  [ 3840/ 8640]\n",
            "loss: 0.529657  [ 3920/ 8640]\n",
            "loss: 0.030538  [ 4000/ 8640]\n",
            "loss: 0.296582  [ 4080/ 8640]\n",
            "loss: 0.135280  [ 4160/ 8640]\n",
            "loss: 0.970771  [ 4240/ 8640]\n",
            "loss: 0.608804  [ 4320/ 8640]\n",
            "loss: 0.076091  [ 4400/ 8640]\n",
            "loss: 0.284311  [ 4480/ 8640]\n",
            "loss: 0.095840  [ 4560/ 8640]\n",
            "loss: 0.129703  [ 4640/ 8640]\n",
            "loss: 0.061131  [ 4720/ 8640]\n",
            "loss: 0.185731  [ 4800/ 8640]\n",
            "loss: 0.282107  [ 4880/ 8640]\n",
            "loss: 0.174089  [ 4960/ 8640]\n",
            "loss: 0.126085  [ 5040/ 8640]\n",
            "loss: 0.131263  [ 5120/ 8640]\n",
            "loss: 0.439677  [ 5200/ 8640]\n",
            "loss: 0.240168  [ 5280/ 8640]\n",
            "loss: 0.349058  [ 5360/ 8640]\n",
            "loss: 0.046065  [ 5440/ 8640]\n",
            "loss: 0.314788  [ 5520/ 8640]\n",
            "loss: 0.250545  [ 5600/ 8640]\n",
            "loss: 0.120740  [ 5680/ 8640]\n",
            "loss: 0.058054  [ 5760/ 8640]\n",
            "loss: 0.271235  [ 5840/ 8640]\n",
            "loss: 0.069074  [ 5920/ 8640]\n",
            "loss: 0.236619  [ 6000/ 8640]\n",
            "loss: 0.063818  [ 6080/ 8640]\n",
            "loss: 0.055574  [ 6160/ 8640]\n",
            "loss: 0.092747  [ 6240/ 8640]\n",
            "loss: 0.324590  [ 6320/ 8640]\n",
            "loss: 0.622145  [ 6400/ 8640]\n",
            "loss: 0.574830  [ 6480/ 8640]\n",
            "loss: 0.040679  [ 6560/ 8640]\n",
            "loss: 0.130684  [ 6640/ 8640]\n",
            "loss: 0.055555  [ 6720/ 8640]\n",
            "loss: 0.342346  [ 6800/ 8640]\n",
            "loss: 0.316488  [ 6880/ 8640]\n",
            "loss: 0.035577  [ 6960/ 8640]\n",
            "loss: 0.032583  [ 7040/ 8640]\n",
            "loss: 0.535469  [ 7120/ 8640]\n",
            "loss: 0.612673  [ 7200/ 8640]\n",
            "loss: 0.205170  [ 7280/ 8640]\n",
            "loss: 0.044328  [ 7360/ 8640]\n",
            "loss: 0.118575  [ 7440/ 8640]\n",
            "loss: 0.067430  [ 7520/ 8640]\n",
            "loss: 0.058191  [ 7600/ 8640]\n",
            "loss: 0.641769  [ 7680/ 8640]\n",
            "loss: 0.025055  [ 7760/ 8640]\n",
            "loss: 0.320742  [ 7840/ 8640]\n",
            "loss: 0.608703  [ 7920/ 8640]\n",
            "loss: 0.146919  [ 8000/ 8640]\n",
            "loss: 0.127105  [ 8080/ 8640]\n",
            "loss: 0.054454  [ 8160/ 8640]\n",
            "loss: 0.022761  [ 8240/ 8640]\n",
            "loss: 0.699085  [ 8320/ 8640]\n",
            "loss: 1.400088  [ 8400/ 8640]\n",
            "loss: 0.350203  [ 8480/ 8640]\n",
            "loss: 0.024409  [ 8560/ 8640]\n",
            "Training done\n",
            "Test Accuracy: 75.94%\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_8e9ce8d0-95cd-478c-8478-b5810cbfef43\", \"sample_text_add_lem_17e4_e5.csv\", 8504)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "import random\n",
        "import spacy\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import CamembertTokenizer, CamembertModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load Spacy French model\n",
        "nlp = spacy.load('fr_core_news_sm')\n",
        "\n",
        "# Lemmatization function\n",
        "def lemmatize_text(text):\n",
        "    doc = nlp(text)\n",
        "    return ' '.join([token.lemma_ for token in doc])\n",
        "\n",
        "# Synonym Replacement Function\n",
        "def synonym_replacement(sentence, n):\n",
        "    words = sentence.split()\n",
        "    new_words = words.copy()\n",
        "    french_stopwords = set(nltk.corpus.stopwords.words('french'))\n",
        "    random_word_list = list(set([word for word in words if word not in french_stopwords]))\n",
        "    random.shuffle(random_word_list)\n",
        "    num_replaced = 0\n",
        "    for random_word in random_word_list:\n",
        "        synonyms = get_synonyms(random_word)\n",
        "        if len(synonyms) > 0:\n",
        "            synonym = random.choice(synonyms)\n",
        "            new_words = [synonym if word == random_word else word for word in new_words]\n",
        "            num_replaced += 1\n",
        "        if num_replaced >= n:  # Only replace up to n words\n",
        "            break\n",
        "    return ' '.join(new_words)\n",
        "\n",
        "# Get synonyms using NLTK's WordNet\n",
        "def get_synonyms(word):\n",
        "    synonyms = set()\n",
        "    for syn in wordnet.synsets(word, lang='fra'):\n",
        "        for lemma in syn.lemmas(lang='fra'):\n",
        "            synonym = lemma.name().replace(\"_\", \" \").replace(\"-\", \" \").lower()\n",
        "            synonym = \"\".join([char for char in synonym if char.isalnum() or char.isspace()])\n",
        "            synonyms.add(synonym)\n",
        "    if word in synonyms:\n",
        "        synonyms.remove(word)\n",
        "    return list(synonyms)\n",
        "\n",
        "# Augment and Lemmatize Data\n",
        "new_sentences = []\n",
        "new_difficulties = []\n",
        "for _, row in df_train.iterrows():\n",
        "    original_sentence = row['sentence']\n",
        "    difficulty = row['difficulty']\n",
        "    # First, lemmatize\n",
        "    lemmatized_sentence = lemmatize_text(original_sentence)\n",
        "    # Then, augment via synonym replacement\n",
        "    augmented_sentence = synonym_replacement(lemmatized_sentence, 2)\n",
        "    new_sentences.append(augmented_sentence)\n",
        "    new_difficulties.append(difficulty)\n",
        "\n",
        "# Create a new DataFrame for the augmented sentences\n",
        "df_augmented = pd.DataFrame({'sentence': new_sentences, 'difficulty': new_difficulties})\n",
        "\n",
        "# Concatenate the original and augmented DataFrames\n",
        "df_combined = pd.concat([df_train, df_augmented], ignore_index=True)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(df_combined['difficulty'].tolist())\n",
        "\n",
        "# Load Camembert tokenizer and model\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
        "camembert = CamembertModel.from_pretrained('camembert-base')\n",
        "\n",
        "# Tokenization function\n",
        "def tokenize_and_encode(sentences):\n",
        "    return tokenizer(sentences, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
        "\n",
        "# Custom Dataset Class\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.encodings = tokenize_and_encode(texts)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: self.encodings[key][idx] for key in self.encodings}, self.labels[idx]\n",
        "\n",
        "# Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df_combined['sentence'].tolist(), encoded_labels, test_size=0.1, random_state=42, stratify=encoded_labels\n",
        ")\n",
        "\n",
        "# DataLoader\n",
        "train_dataset = TextDataset(X_train, y_train)\n",
        "test_dataset = TextDataset(X_test, y_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# Neural Network Model Definition\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Net, self).__init__()\n",
        "        self.camembert = camembert\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.fc = nn.Linear(self.camembert.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        outputs = self.camembert(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.fc(pooled_output)\n",
        "        return logits\n",
        "\n",
        "# Instantiate the model, loss, and optimizer\n",
        "model = Net(len(label_encoder.classes_)).to('cuda')\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.000017)\n",
        "\n",
        "# Compute Accuracy Function\n",
        "def compute_accuracy(dataloader, model):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            inputs, labels = batch\n",
        "            inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
        "            labels = labels.to('cuda')\n",
        "            outputs = model(**inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "# Training Loop\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (inputs, labels) in enumerate(dataloader):\n",
        "        inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
        "        labels = labels.to('cuda')\n",
        "        pred = model(**inputs)\n",
        "        loss = loss_fn(pred, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 10 == 0:\n",
        "            loss, current = loss.item(), batch * len(inputs['input_ids'])\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "# Execute Training\n",
        "for epoch in range(5):  # Number of epochs\n",
        "    print(f\"Epoch {epoch + 1}\\n-------------------------------\")\n",
        "    train_loop(train_loader, model, criterion, optimizer)\n",
        "    print(\"Training done\")\n",
        "\n",
        "# Test the Model\n",
        "accuracy = compute_accuracy(test_loader, model)\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "# Prediction & Submission\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, texts):\n",
        "        self.encodings = tokenize_and_encode(texts)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings['input_ids'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: self.encodings[key][idx] for key in self.encodings}\n",
        "\n",
        "test_dataset = TestDataset(df_test['sentence'].tolist())\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model.eval()\n",
        "all_predictions = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        inputs = {key: value.to(device) for key, value in batch.items()}\n",
        "        outputs = model(**inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "predicted_labels = label_encoder.inverse_transform(all_predictions)\n",
        "\n",
        "submission_df = pd.DataFrame({\n",
        "    'id': df_test['id'],\n",
        "    'difficulty': predicted_labels\n",
        "})\n",
        "\n",
        "submission_df.to_csv('sample_text_add_lem_17e4_e5.csv', index=False)\n",
        "from google.colab import files\n",
        "files.download('sample_text_add_lem_17e4_e5.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKaB-SdhA9kx"
      },
      "source": [
        "## Other models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOqM4aQ7BB48"
      },
      "source": [
        "I decided to try the most advanced model - **ChatGPT** 4.0. However, without paid token I couldn't even run 3.5-turbo version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Dutm18cEBUMc",
        "outputId": "e75ed094-a8d0-44f8-879c-6eb23572156c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.30.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Classifying training data...\n",
            "Error: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Error: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-0212ff4b7e20>\u001b[0m in \u001b[0;36mclassify_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         response = client.chat.completions.create(\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    589\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 590\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    591\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1239\u001b[0m         )\n\u001b[0;32m-> 1240\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    920\u001b[0m     ) -> ResponseT | _StreamT:\n\u001b[0;32m--> 921\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    922\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1004\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1005\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m   1006\u001b[0m                     \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1053\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m   1054\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1004\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1005\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m   1006\u001b[0m                     \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1053\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m   1054\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mHTTPStatusError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    998\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m             \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPStatusError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# thrown on 4xx and 5xx status code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPStatusError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPStatusError\u001b[0m: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mHTTPStatusError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    998\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m             \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPStatusError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# thrown on 4xx and 5xx status code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPStatusError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPStatusError\u001b[0m: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-0212ff4b7e20>\u001b[0m in \u001b[0;36m<cell line: 65>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;31m# Classify training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Classifying training data...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0mtrain_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mclassify_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;31m# Classify test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-0212ff4b7e20>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;31m# Classify training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Classifying training data...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0mtrain_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mclassify_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;31m# Classify test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-0212ff4b7e20>\u001b[0m in \u001b[0;36mclassify_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# To handle rate limits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mclassify_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Retry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# Function to compute accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-0212ff4b7e20>\u001b[0m in \u001b[0;36mclassify_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# To handle rate limits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mclassify_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Retry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# Function to compute accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-0212ff4b7e20>\u001b[0m in \u001b[0;36mclassify_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclassify_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         response = client.chat.completions.create(\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             messages=[\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeout\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mNotGiven\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 590\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    591\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1238\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m         )\n\u001b[0;32m-> 1240\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    919\u001b[0m         \u001b[0mstream_cls\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_StreamT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m     ) -> ResponseT | _StreamT:\n\u001b[0;32m--> 921\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    922\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1003\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mretries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1005\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m   1006\u001b[0m                     \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1051\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1053\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m   1054\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1003\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mretries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1005\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m   1006\u001b[0m                     \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;31m# different thread if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         return self._request(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "!pip install --upgrade openai\n",
        "\n",
        "import openai\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import time\n",
        "\n",
        "# Set up your OpenAI API key\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    # api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
        "    api_key = \"sk-proj-UIqiUVzkxTzPPfCRvUDhT3BlbkFJ4XRZNwu8VGByj40XypG7\"\n",
        ")\n",
        "\n",
        "# Load your data\n",
        "data = df_train\n",
        "sentences = data['sentence'].tolist()\n",
        "difficulties = data['difficulty'].tolist()\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(difficulties)\n",
        "\n",
        "# Data preparation\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    sentences, encoded_labels, test_size=0.1, random_state=42, stratify=encoded_labels\n",
        ")\n",
        "\n",
        "# Function to classify text using OpenAI GPT\n",
        "def classify_text(text):\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a text classification assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": f\"Classify the following sentence into one of the predefined difficulty levels: '{text}'\"}\n",
        "            ]\n",
        "        )\n",
        "        classification = response['choices'][0]['message']['content'].strip()\n",
        "        return classification\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        time.sleep(1)  # To handle rate limits\n",
        "        return classify_text(text)  # Retry\n",
        "\n",
        "# Function to compute accuracy\n",
        "def compute_accuracy(X, y, model):\n",
        "    correct, total = 0, 0\n",
        "    for text, label in zip(X, y):\n",
        "        prediction = model(text)\n",
        "        try:\n",
        "            predicted_label = label_encoder.transform([prediction])[0]\n",
        "        except ValueError:\n",
        "            continue  # Handle cases where prediction is not a valid label\n",
        "        if predicted_label == label:\n",
        "            correct += 1\n",
        "        total += 1\n",
        "    return 100 * correct / total\n",
        "\n",
        "# Classify training data\n",
        "print(\"Classifying training data...\")\n",
        "train_predictions = [classify_text(text) for text in X_train]\n",
        "\n",
        "# Classify test data\n",
        "print(\"Classifying test data...\")\n",
        "test_predictions = [classify_text(text) for text in X_test]\n",
        "\n",
        "# Convert predictions to encoded labels\n",
        "y_train_pred = label_encoder.transform(train_predictions)\n",
        "y_test_pred = label_encoder.transform(test_predictions)\n",
        "\n",
        "# Compute accuracy\n",
        "train_accuracy = compute_accuracy(X_train, y_train, classify_text)\n",
        "test_accuracy = compute_accuracy(X_test, y_test, classify_text)\n",
        "\n",
        "print(f\"Train Accuracy: {train_accuracy:.2f}%\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
        "\n",
        "# Create the dataset and dataloader for df_test\n",
        "class TestDataset:\n",
        "    def __init__(self, texts):\n",
        "        self.texts = texts\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.texts[idx]\n",
        "\n",
        "test_dataset = TestDataset(df_test['sentence'].tolist())\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# Generate predictions for df_test\n",
        "all_predictions = []\n",
        "with torch.no_grad():\n",
        "    for text in test_loader:\n",
        "        predicted_label = classify_text(text)\n",
        "        all_predictions.append(predicted_label)\n",
        "\n",
        "# Convert numeric predictions back to labels\n",
        "predicted_labels = label_encoder.inverse_transform(all_predictions)\n",
        "\n",
        "# Prepare and save the submission file\n",
        "submission_df = pd.DataFrame({\n",
        "    'id': df_test['id'],  # Ensure df_test includes an 'id' column\n",
        "    'difficulty': predicted_labels\n",
        "})\n",
        "\n",
        "submission_df.to_csv('sample_api.csv', index=False)\n",
        "from google.colab import files\n",
        "files.download('sample_api.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkDl_HeP8a2g"
      },
      "source": [
        "Further, I wanted to check some interesting models from Hugging Face such as a large version of Camembert. Nevertheless, it requires special access to it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAgZVlqqIe0w"
      },
      "source": [
        "**Camembert-large** - [link](https://huggingface.co/almanach/camembert-large)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 949
        },
        "id": "SqIioAB1Ii6M",
        "outputId": "2fae86a2-4dfb-4dba-a716-730cef085c8d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "OSError",
          "evalue": "camembert-large is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/camembert-large/resolve/main/tokenizer_config.json",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    399\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[1;32m   1367\u001b[0m             \u001b[0;31m# Repo not found => let's raise the actual error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1368\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mhead_call_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1369\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[1;32m   1237\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1238\u001b[0;31m                 metadata = get_hf_file_metadata(\n\u001b[0m\u001b[1;32m   1239\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent)\u001b[0m\n\u001b[1;32m   1630\u001b[0m     \u001b[0;31m# Retrieve metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1631\u001b[0;31m     r = _request_wrapper(\n\u001b[0m\u001b[1;32m   1632\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfollow_relative_redirects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         response = _request_wrapper(\n\u001b[0m\u001b[1;32m    386\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m     \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    322\u001b[0m             )\n\u001b[0;32m--> 323\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-66461fc8-3f73e0d818f6a1b94f9a2314;76675cd7-2801-4db1-b2a3-a7c8fa3392cc)\n\nRepository Not Found for url: https://huggingface.co/camembert-large/resolve/main/tokenizer_config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-b8e831e29e05>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Load CamemBERT tokenizer and model (using 'camembert-large' instead of 'camembert-base')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCamembertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'camembert-large'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mcamembert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCamembertModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'camembert-large'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2008\u001b[0m                 \u001b[0;31m# Try to get the tokenizer config to see if there are versioned tokenizer files.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m                 \u001b[0mfast_tokenizer_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFULL_TOKENIZER_FILE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m                 resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m   2011\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m                     \u001b[0mTOKENIZER_CONFIG_FILE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    419\u001b[0m         ) from e\n\u001b[1;32m    420\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m         raise EnvironmentError(\n\u001b[0m\u001b[1;32m    422\u001b[0m             \u001b[0;34mf\"{path_or_repo_id} is not a local folder and is not a valid model identifier \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;34m\"listed on 'https://huggingface.co/models'\\nIf this is a private repository, make sure to pass a token \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: camembert-large is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import CamembertTokenizer, CamembertModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load your data\n",
        "data = df_train\n",
        "sentences = data['sentence'].tolist()\n",
        "difficulties = data['difficulty'].tolist()\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(difficulties)\n",
        "\n",
        "# Load CamemBERT tokenizer and model (using 'camembert-large' instead of 'camembert-base')\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-large')\n",
        "camembert = CamembertModel.from_pretrained('camembert-large')\n",
        "\n",
        "# Tokenize sentences and convert to tensor\n",
        "def tokenize_and_encode(sentences):\n",
        "    return tokenizer(sentences, padding=True, truncation=True, max_length=800, return_tensors='pt')\n",
        "\n",
        "# Custom Dataset class\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.encodings = tokenize_and_encode(texts)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: self.encodings[key][idx] for key in self.encodings}, self.labels[idx]\n",
        "\n",
        "# Data preparation\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    sentences, encoded_labels, test_size=0.1, random_state=42, stratify=encoded_labels\n",
        ")\n",
        "\n",
        "train_dataset = TextDataset(X_train, y_train)\n",
        "test_dataset = TextDataset(X_test, y_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# Neural network model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Net, self).__init__()\n",
        "        self.camembert = camembert\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.fc = nn.Linear(self.camembert.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        outputs = self.camembert(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.fc(pooled_output)\n",
        "        return logits\n",
        "\n",
        "# Instantiate the model, loss, and optimizer\n",
        "model = Net(len(label_encoder.classes_)).to('cuda')\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
        "\n",
        "# Function to compute accuracy\n",
        "def compute_accuracy(dataloader, model):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            inputs, labels = batch\n",
        "            inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
        "            labels = labels.to('cuda')\n",
        "            outputs = model(**inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "# Training loop\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()  # Set model to training mode\n",
        "    for batch, (inputs, labels) in enumerate(dataloader):\n",
        "        inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
        "        labels = labels.to('cuda')\n",
        "        pred = model(**inputs)\n",
        "        loss = loss_fn(pred, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 10 == 0:\n",
        "            loss, current = loss.item(), batch * len(inputs['input_ids'])\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "# Execute training\n",
        "for epoch in range(5):  # Number of epochs\n",
        "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
        "    train_loop(train_loader, model, criterion, optimizer)\n",
        "    print(\"Training done\")\n",
        "\n",
        "# Test the model\n",
        "accuracy = compute_accuracy(test_loader, model)\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "# Load the tokenizer for test data\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-large')\n",
        "\n",
        "# Tokenize and encode the test data\n",
        "def tokenize_and_encode(sentences):\n",
        "    return tokenizer(sentences, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
        "\n",
        "# Custom Dataset class for test data\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, texts):\n",
        "        self.encodings = tokenize_and_encode(texts)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings['input_ids'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: self.encodings[key][idx] for key in self.encodings}\n",
        "\n",
        "# Create the dataset and dataloader for df_test\n",
        "test_dataset = TestDataset(df_test['sentence'].tolist())\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# Define the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Generate predictions for df_test\n",
        "model.eval()  # Make sure the model is in evaluation mode\n",
        "all_predictions = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        inputs = {key: value.to(device) for key, value in batch.items()}\n",
        "        outputs = model(**inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "# Convert numeric predictions back to labels\n",
        "predicted_labels = label_encoder.inverse_transform(all_predictions)\n",
        "\n",
        "# Prepare and save the submission file\n",
        "submission_df = pd.DataFrame({\n",
        "    'id': df_test['id'],  # Ensure df_test includes an 'id' column\n",
        "    'difficulty': predicted_labels\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSPCRn5b81yY"
      },
      "source": [
        "**Flaubert large (& base)** - [link](https://huggingface.co/flaubert/flaubert_large_cased)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 949
        },
        "id": "nBxyTItvN-l4",
        "outputId": "17dff602-2b48-4f34-a812-6769a4af665b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "OSError",
          "evalue": "flaubert-large-cased is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/flaubert-large-cased/resolve/main/tokenizer_config.json",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    399\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[1;32m   1367\u001b[0m             \u001b[0;31m# Repo not found => let's raise the actual error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1368\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mhead_call_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1369\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[1;32m   1237\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1238\u001b[0;31m                 metadata = get_hf_file_metadata(\n\u001b[0m\u001b[1;32m   1239\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent)\u001b[0m\n\u001b[1;32m   1630\u001b[0m     \u001b[0;31m# Retrieve metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1631\u001b[0;31m     r = _request_wrapper(\n\u001b[0m\u001b[1;32m   1632\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfollow_relative_redirects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         response = _request_wrapper(\n\u001b[0m\u001b[1;32m    386\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m     \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    322\u001b[0m             )\n\u001b[0;32m--> 323\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-66476d5b-33b75df94163499a76cd7ff6;b0a3724f-25b6-4f18-a3ef-3ed5fb655d97)\n\nRepository Not Found for url: https://huggingface.co/flaubert-large-cased/resolve/main/tokenizer_config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-b1600d1aee06>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Load Flaubert tokenizer and model (using 'flaubert-large-cased' instead of 'camembert-base')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFlaubertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'flaubert-large-cased'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mflaubert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFlaubertModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'flaubert-large-cased'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2008\u001b[0m                 \u001b[0;31m# Try to get the tokenizer config to see if there are versioned tokenizer files.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m                 \u001b[0mfast_tokenizer_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFULL_TOKENIZER_FILE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m                 resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m   2011\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m                     \u001b[0mTOKENIZER_CONFIG_FILE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    419\u001b[0m         ) from e\n\u001b[1;32m    420\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m         raise EnvironmentError(\n\u001b[0m\u001b[1;32m    422\u001b[0m             \u001b[0;34mf\"{path_or_repo_id} is not a local folder and is not a valid model identifier \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;34m\"listed on 'https://huggingface.co/models'\\nIf this is a private repository, make sure to pass a token \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: flaubert-large-cased is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import FlaubertTokenizer, FlaubertModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load your data\n",
        "data = df_train\n",
        "sentences = data['sentence'].tolist()\n",
        "difficulties = data['difficulty'].tolist()\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(difficulties)\n",
        "\n",
        "# Load Flaubert tokenizer and model (using 'flaubert-large-cased' instead of 'camembert-base')\n",
        "tokenizer = FlaubertTokenizer.from_pretrained('flaubert-large-cased')\n",
        "flaubert = FlaubertModel.from_pretrained('flaubert-large-cased')\n",
        "\n",
        "# Tokenize sentences and convert to tensor\n",
        "def tokenize_and_encode(sentences):\n",
        "    return tokenizer(sentences, padding=True, truncation=True, max_length=800, return_tensors='pt')\n",
        "\n",
        "# Custom Dataset class\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.encodings = tokenize_and_encode(texts)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: self.encodings[key][idx] for key in self.encodings}, self.labels[idx]\n",
        "\n",
        "# Data preparation\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    sentences, encoded_labels, test_size=0.1, random_state=42, stratify=encoded_labels\n",
        ")\n",
        "\n",
        "train_dataset = TextDataset(X_train, y_train)\n",
        "test_dataset = TextDataset(X_test, y_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# Neural network model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Net, self).__init__()\n",
        "        self.flaubert = flaubert\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.fc = nn.Linear(self.flaubert.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        outputs = self.flaubert(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs[0][:, 0]  # Use the first token's hidden state\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.fc(pooled_output)\n",
        "        return logits\n",
        "\n",
        "# Instantiate the model, loss, and optimizer\n",
        "model = Net(len(label_encoder.classes_)).to('cuda')\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
        "\n",
        "# Function to compute accuracy\n",
        "def compute_accuracy(dataloader, model):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            inputs, labels = batch\n",
        "            inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
        "            labels = labels.to('cuda')\n",
        "            outputs = model(**inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "# Training loop\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()  # Set model to training mode\n",
        "    for batch, (inputs, labels) in enumerate(dataloader):\n",
        "        inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
        "        labels = labels.to('cuda')\n",
        "        pred = model(**inputs)\n",
        "        loss = loss_fn(pred, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 10 == 0:\n",
        "            loss, current = loss.item(), batch * len(inputs['input_ids'])\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "# Execute training\n",
        "for epoch in range(5):  # Number of epochs\n",
        "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
        "    train_loop(train_loader, model, criterion, optimizer)\n",
        "    print(\"Training done\")\n",
        "\n",
        "# Test the model\n",
        "accuracy = compute_accuracy(test_loader, model)\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "# Load the tokenizer for test data\n",
        "tokenizer = FlaubertTokenizer.from_pretrained('flaubert-large-cased')\n",
        "\n",
        "# Tokenize and encode the test data\n",
        "def tokenize_and_encode(sentences):\n",
        "    return tokenizer(sentences, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
        "\n",
        "# Custom Dataset class for test data\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, texts):\n",
        "        self.encodings = tokenize_and_encode(texts)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings['input_ids'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: self.encodings[key][idx] for key in self.encodings}\n",
        "\n",
        "# Create the dataset and dataloader for df_test\n",
        "test_dataset = TestDataset(df_test['sentence'].tolist())\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# Define the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Generate predictions for df_test\n",
        "model.eval()  # Make sure the model is in evaluation mode\n",
        "all_predictions = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        inputs = {key: value.to(device) for key, value in batch.items()}\n",
        "        outputs = model(**inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "# Convert numeric predictions back to labels\n",
        "predicted_labels = label_encoder.inverse_transform(all_predictions)\n",
        "\n",
        "# Prepare and save the submission file\n",
        "submission_df = pd.DataFrame({\n",
        "    'id': df_test['id'],  # Ensure df_test includes an 'id' column\n",
        "    'difficulty': predicted_labels\n",
        "})\n",
        "\n",
        "\n",
        "submission_df.to_csv('sample_flaubert_large.csv', index=False)\n",
        "from google.colab import files\n",
        "files.download('sample_flaubert_large.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 824
        },
        "id": "AJ0jjBZyPAwd",
        "outputId": "e77ed0d0-dc27-489d-ed83-b6b32ab8e22f"
      },
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "flaubert-base-cased is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/flaubert-base-cased/resolve/main/tokenizer_config.json",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    399\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[1;32m   1367\u001b[0m             \u001b[0;31m# Repo not found => let's raise the actual error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1368\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mhead_call_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1369\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[1;32m   1237\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1238\u001b[0;31m                 metadata = get_hf_file_metadata(\n\u001b[0m\u001b[1;32m   1239\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent)\u001b[0m\n\u001b[1;32m   1630\u001b[0m     \u001b[0;31m# Retrieve metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1631\u001b[0;31m     r = _request_wrapper(\n\u001b[0m\u001b[1;32m   1632\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfollow_relative_redirects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         response = _request_wrapper(\n\u001b[0m\u001b[1;32m    386\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m     \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    322\u001b[0m             )\n\u001b[0;32m--> 323\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-66476e1f-5d04d314124661c54373531c;313744c5-9508-40fb-a1cc-d4876f35e061)\n\nRepository Not Found for url: https://huggingface.co/flaubert-base-cased/resolve/main/tokenizer_config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-745a31f08215>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Load Flaubert tokenizer and model (using 'flaubert-base-cased' instead of 'flaubert-large-cased')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFlaubertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'flaubert-base-cased'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mflaubert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFlaubertModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'flaubert-base-cased'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2008\u001b[0m                 \u001b[0;31m# Try to get the tokenizer config to see if there are versioned tokenizer files.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m                 \u001b[0mfast_tokenizer_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFULL_TOKENIZER_FILE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m                 resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m   2011\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m                     \u001b[0mTOKENIZER_CONFIG_FILE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    419\u001b[0m         ) from e\n\u001b[1;32m    420\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m         raise EnvironmentError(\n\u001b[0m\u001b[1;32m    422\u001b[0m             \u001b[0;34mf\"{path_or_repo_id} is not a local folder and is not a valid model identifier \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;34m\"listed on 'https://huggingface.co/models'\\nIf this is a private repository, make sure to pass a token \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: flaubert-base-cased is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import FlaubertTokenizer, FlaubertModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load your data\n",
        "data = df_train\n",
        "sentences = data['sentence'].tolist()\n",
        "difficulties = data['difficulty'].tolist()\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(difficulties)\n",
        "\n",
        "# Load Flaubert tokenizer and model (using 'flaubert-base-cased' instead of 'flaubert-large-cased')\n",
        "tokenizer = FlaubertTokenizer.from_pretrained('flaubert-base-cased')\n",
        "flaubert = FlaubertModel.from_pretrained('flaubert-base-cased')\n",
        "\n",
        "# Tokenize sentences and convert to tensor\n",
        "def tokenize_and_encode(sentences):\n",
        "    return tokenizer(sentences, padding=True, truncation=True, max_length=800, return_tensors='pt')\n",
        "\n",
        "# Custom Dataset class\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.encodings = tokenize_and_encode(texts)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: self.encodings[key][idx] for key in self.encodings}, self.labels[idx]\n",
        "\n",
        "# Data preparation\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    sentences, encoded_labels, test_size=0.1, random_state=42, stratify=encoded_labels\n",
        ")\n",
        "\n",
        "train_dataset = TextDataset(X_train, y_train)\n",
        "test_dataset = TextDataset(X_test, y_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# Neural network model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Net, self).__init__()\n",
        "        self.flaubert = flaubert\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.fc = nn.Linear(self.flaubert.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        outputs = self.flaubert(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs[0][:, 0]  # Use the first token's hidden state\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.fc(pooled_output)\n",
        "        return logits\n",
        "\n",
        "# Instantiate the model, loss, and optimizer\n",
        "model = Net(len(label_encoder.classes_)).to('cuda')\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
        "\n",
        "# Function to compute accuracy\n",
        "def compute_accuracy(dataloader, model):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            inputs, labels = batch\n",
        "            inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
        "            labels = labels.to('cuda')\n",
        "            outputs = model(**inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "# Training loop\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()  # Set model to training mode\n",
        "    for batch, (inputs, labels) in enumerate(dataloader):\n",
        "        inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
        "        labels = labels.to('cuda')\n",
        "        pred = model(**inputs)\n",
        "        loss = loss_fn(pred, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 10 == 0:\n",
        "            loss, current = loss.item(), batch * len(inputs['input_ids'])\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "# Execute training\n",
        "for epoch in range(5):  # Number of epochs\n",
        "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
        "    train_loop(train_loader, model, criterion, optimizer)\n",
        "    print(\"Training done\")\n",
        "\n",
        "# Test the model\n",
        "accuracy = compute_accuracy(test_loader, model)\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "# Load the tokenizer for test data\n",
        "tokenizer = FlaubertTokenizer.from_pretrained('flaubert-base-cased')\n",
        "\n",
        "# Tokenize and encode the test data\n",
        "def tokenize_and_encode(sentences):\n",
        "    return tokenizer(sentences, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
        "\n",
        "# Custom Dataset class for test data\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, texts):\n",
        "        self.encodings = tokenize_and_encode(texts)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings['input_ids'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: self.encodings[key][idx] for key in self.encodings}\n",
        "\n",
        "# Create the dataset and dataloader for df_test\n",
        "test_dataset = TestDataset(df_test['sentence'].tolist())\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# Define the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Generate predictions for df_test\n",
        "model.eval()  # Make sure the model is in evaluation mode\n",
        "all_predictions = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        inputs = {key: value.to(device) for key, value in batch.items()}\n",
        "        outputs = model(**inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "# Convert numeric predictions back to labels\n",
        "predicted_labels = label_encoder.inverse_transform(all_predictions)\n",
        "\n",
        "# Prepare and save the submission file\n",
        "submission_df = pd.DataFrame({\n",
        "    'id': df_test['id'],  # Ensure df_test includes an 'id' column\n",
        "    'difficulty': predicted_labels\n",
        "})\n",
        "\n",
        "submission_df.to_csv('sample_flaubert_base.csv', index=False)\n",
        "from google.colab import files\n",
        "files.download('sample_flaubert_base.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbGd0ca-EY48"
      },
      "source": [
        "**T5 Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559,
          "referenced_widgets": [
            "adf68bfb71bf4a3380e1272b2db9d790",
            "26d06bf2e02742b7bb84ee2f5ec1269c",
            "0565df96847f43dfb476f0740926361f",
            "355e2f60de1a4843964119bae2bd66d3",
            "197d27be265f45428b59dca56a602df8",
            "120aebe6a4d24eaa8c84bdd14ff46e42"
          ]
        },
        "id": "Kr58s1WbFd9L",
        "outputId": "50fa0059-52c1-457a-fcdd-3b619ae569e4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "adf68bfb71bf4a3380e1272b2db9d790",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "26d06bf2e02742b7bb84ee2f5ec1269c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0565df96847f43dfb476f0740926361f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "355e2f60de1a4843964119bae2bd66d3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "197d27be265f45428b59dca56a602df8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "120aebe6a4d24eaa8c84bdd14ff46e42",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:497: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (558 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   id                                           sentence difficulty  \\\n",
            "0   0  Les coûts kilométriques réels peuvent diverger...         C1   \n",
            "1   1  Le bleu, c'est ma couleur préférée mais je n'a...         A1   \n",
            "2   2  Le test de niveau en français est sur le site ...         A1   \n",
            "3   3           Est-ce que ton mari est aussi de Boston?         A1   \n",
            "4   4  Dans les écoles de commerce, dans les couloirs...         B1   \n",
            "\n",
            "   encoded_labels                                   similar_sentence  \n",
            "0               0                                         Paraphrase  \n",
            "1               1  Paraphrase: Le bleu, c'est ma couleur préférée...  \n",
            "2               1                                         Paraphrase  \n",
            "3               1  Paraphraser: Est-ce que ton mari est aussi de ...  \n",
            "4               2                                         Paraphrase  \n"
          ]
        }
      ],
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "# Load T5 model and tokenizer for French\n",
        "t5_tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "t5_model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "\n",
        "def paraphrase(sentence, max_length=70):\n",
        "    input_text = f\"paraphrase: {sentence}\"\n",
        "    input_ids = t5_tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "    output_ids = t5_model.generate(\n",
        "        input_ids,\n",
        "        max_length=max_length,\n",
        "        num_return_sequences=1,\n",
        "        no_repeat_ngram_size=2,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "        temperature=0.7\n",
        "    )\n",
        "    return t5_tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "# Apply paraphrasing to each sentence in the training set\n",
        "df_train[\"similar_sentence\"] = df_train[\"sentence\"].apply(paraphrase)\n",
        "print(df_train.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmgezV9TEkmu"
      },
      "outputs": [],
      "source": [
        "df_train.to_csv('text_paraphrase.csv', index=False)\n",
        "from google.colab import files\n",
        "files.download('text_paraphrase.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5texNKtHStx"
      },
      "source": [
        "Additional **data augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_W6n4vjaMFOf",
        "outputId": "e766764c-369d-41a1-e788-b22a0b38958c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "from random import randint\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "def get_synonyms(word):\n",
        "    synonyms = set()\n",
        "    for syn in wordnet.synsets(word, lang='fra'):  # Ensure using French synsets\n",
        "        for lemma in syn.lemmas('fra'):\n",
        "            synonyms.add(lemma.name().replace('_', ' '))\n",
        "    return list(synonyms)\n",
        "\n",
        "def augment_sentence(sentence, num_changes=1):\n",
        "    words = sentence.split()\n",
        "    new_sentence = words[:]\n",
        "    changed_indices = []\n",
        "    for _ in range(num_changes):\n",
        "        index = randint(0, len(words) - 1)\n",
        "        if index in changed_indices:\n",
        "            continue\n",
        "        synonyms = get_synonyms(words[index])\n",
        "        if synonyms:\n",
        "            new_sentence[index] = synonyms[0]  # Replace with the first synonym\n",
        "            changed_indices.append(index)\n",
        "    return ' '.join(new_sentence)\n",
        "\n",
        "# Load initial data\n",
        "\n",
        "\n",
        "# Augment data\n",
        "augmented_sentences = []\n",
        "for index, row in df_train.iterrows():\n",
        "    for _ in range(5):  # Generate 1000 similar sentences per existing sentence\n",
        "        new_sentence = augment_sentence(row['sentence'])\n",
        "        augmented_sentences.append({'sentence': new_sentence, 'difficulty': row['difficulty']})\n",
        "\n",
        "# Save augmented data\n",
        "df_augmented = pd.DataFrame(augmented_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "qkA74zo-HoCx",
        "outputId": "4265fa71-aab3-493a-bc69-df8208967e1a"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_c094ff78-0934-4956-94a6-aef03bea91a5\", \"new_vocabulary_5.csv\", 2883877)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df_augmented.to_csv('new_vocabulary_5.csv', index=False)\n",
        "from google.colab import files\n",
        "files.download('new_vocabulary_5.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "wXgfQQwGIiak",
        "outputId": "c047b6ea-4f88-447a-dc00-5d2bb11838d9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-dc9e6053-6f5d-44cc-9e1d-67637f7a95f5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-dc9e6053-6f5d-44cc-9e1d-67637f7a95f5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2VPz8ly7HrvG"
      },
      "outputs": [],
      "source": [
        "df_combined = pd.concat([df_train, df_augmented], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 931
        },
        "id": "NztDGScRHwZl",
        "outputId": "888bbd6e-5b43-4e3a-8026-be2940305c98"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 1.805302  [    0/25920]\n",
            "loss: 1.785404  [   80/25920]\n",
            "loss: 1.790908  [  160/25920]\n",
            "loss: 1.779276  [  240/25920]\n",
            "loss: 1.828247  [  320/25920]\n",
            "loss: 1.730804  [  400/25920]\n",
            "loss: 1.743793  [  480/25920]\n",
            "loss: 1.674758  [  560/25920]\n",
            "loss: 1.663870  [  640/25920]\n",
            "loss: 1.642494  [  720/25920]\n",
            "loss: 1.683785  [  800/25920]\n",
            "loss: 1.574817  [  880/25920]\n",
            "loss: 1.503770  [  960/25920]\n",
            "loss: 1.620801  [ 1040/25920]\n",
            "loss: 1.605268  [ 1120/25920]\n",
            "loss: 1.158272  [ 1200/25920]\n",
            "loss: 1.762192  [ 1280/25920]\n",
            "loss: 1.283984  [ 1360/25920]\n",
            "loss: 1.216051  [ 1440/25920]\n",
            "loss: 1.415188  [ 1520/25920]\n",
            "loss: 1.279339  [ 1600/25920]\n",
            "loss: 1.365729  [ 1680/25920]\n",
            "loss: 1.228086  [ 1760/25920]\n",
            "loss: 1.237842  [ 1840/25920]\n",
            "loss: 1.270229  [ 1920/25920]\n",
            "loss: 1.173385  [ 2000/25920]\n",
            "loss: 1.257395  [ 2080/25920]\n",
            "loss: 1.211244  [ 2160/25920]\n",
            "loss: 1.286227  [ 2240/25920]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-27e4f7125577>\u001b[0m in \u001b[0;36m<cell line: 103>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Number of epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch+1}\\n-------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training done\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-27e4f7125577>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Set model to training mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-27e4f7125577>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Set model to training mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import CamembertTokenizer, CamembertModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load your data\n",
        "data = df_combined\n",
        "sentences = data['sentence'].tolist()\n",
        "difficulties = data['difficulty'].tolist()\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(difficulties)\n",
        "\n",
        "# Load CamemBERT tokenizer and model\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
        "camembert = CamembertModel.from_pretrained('camembert-base')\n",
        "\n",
        "# Tokenize sentences and convert to tensor\n",
        "def tokenize_and_encode(sentences):\n",
        "    return tokenizer(sentences, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
        "\n",
        "# Custom Dataset class\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.encodings = tokenize_and_encode(texts)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: self.encodings[key][idx] for key in self.encodings}, self.labels[idx]\n",
        "\n",
        "# Data preparation\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    sentences, encoded_labels, test_size=0.1, random_state=42, stratify=encoded_labels\n",
        ")\n",
        "\n",
        "train_dataset = TextDataset(X_train, y_train)\n",
        "test_dataset = TextDataset(X_test, y_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# Neural network model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Net, self).__init__()\n",
        "        self.camembert = camembert\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.fc = nn.Linear(self.camembert.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        outputs = self.camembert(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.fc(pooled_output)\n",
        "        return logits\n",
        "\n",
        "# Instantiate the model, loss, and optimizer\n",
        "model = Net(len(label_encoder.classes_)).to('cuda')\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
        "\n",
        "# Function to compute accuracy\n",
        "def compute_accuracy(dataloader, model):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            inputs, labels = batch\n",
        "            inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
        "            labels = labels.to('cuda')\n",
        "            outputs = model(**inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "# Training loop\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()  # Set model to training mode\n",
        "    for batch, (inputs, labels) in enumerate(dataloader):\n",
        "        inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
        "        labels = labels.to('cuda')\n",
        "        pred = model(**inputs)\n",
        "        loss = loss_fn(pred, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 10 == 0:\n",
        "            loss, current = loss.item(), batch * len(inputs['input_ids'])\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "# Execute training\n",
        "for epoch in range(5):  # Number of epochs\n",
        "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
        "    train_loop(train_loader, model, criterion, optimizer)\n",
        "    print(\"Training done\")\n",
        "\n",
        "# Test the model\n",
        "accuracy = compute_accuracy(test_loader, model)\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import CamembertTokenizer\n",
        "\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
        "\n",
        "# Tokenize and encode the test data\n",
        "def tokenize_and_encode(sentences):\n",
        "    return tokenizer(sentences, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
        "\n",
        "# Custom Dataset class for test data\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, texts):\n",
        "        self.encodings = tokenize_and_encode(texts)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings['input_ids'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: self.encodings[key][idx] for key in self.encodings}\n",
        "\n",
        "# Create the dataset and dataloader for df_test\n",
        "test_dataset = TestDataset(df_test['sentence'].tolist())\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# Define the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Generate predictions for df_test\n",
        "model.eval()  # Make sure the model is in evaluation mode\n",
        "all_predictions = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        inputs = {key: value.to(device) for key, value in batch.items()}\n",
        "        outputs = model(**inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "# Convert numeric predictions back to labels\n",
        "predicted_labels = label_encoder.inverse_transform(all_predictions)\n",
        "\n",
        "# Prepare and save the submission file\n",
        "submission_df = pd.DataFrame({\n",
        "    'id': df_test['id'],  # Ensure df_test includes an 'id' column\n",
        "    'difficulty': predicted_labels\n",
        "})\n",
        "\n",
        "submission_df.to_csv('sample_new_WordsGen.csv', index=False)\n",
        "from google.colab import files\n",
        "files.download('sample_new_WordsGen.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoGsbsWnF5m8"
      },
      "source": [
        "Another note - **cross validation** also didn't work out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "db41f65157a94d04ba2e6790749560e0",
            "acecb7e618c1439ca41bb656fbb4dbb7",
            "8d915eba542f4275be5982621398a9e6",
            "540356f1f643425b91189ccec4ced718",
            "f4fc9bb067814f8fbf95d351616b9656"
          ]
        },
        "id": "51m4_J71cE0B",
        "outputId": "972f8785-5b7c-43cb-8375-ae74da4aedba"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db41f65157a94d04ba2e6790749560e0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "acecb7e618c1439ca41bb656fbb4dbb7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/811k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d915eba542f4275be5982621398a9e6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.40M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "540356f1f643425b91189ccec4ced718",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/508 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training fold 1/5\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4fc9bb067814f8fbf95d351616b9656",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2400' max='2400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2400/2400 05:06, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.291600</td>\n",
              "      <td>1.145762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.019300</td>\n",
              "      <td>1.103047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.818700</td>\n",
              "      <td>1.259418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.364300</td>\n",
              "      <td>1.259056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.163000</td>\n",
              "      <td>1.444034</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy for fold 1: 0.5697916666666667\n",
            "Training fold 2/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2400' max='2400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2400/2400 05:06, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.117000</td>\n",
              "      <td>1.179946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.019900</td>\n",
              "      <td>1.132445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.680200</td>\n",
              "      <td>1.178783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.529100</td>\n",
              "      <td>1.354828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.274600</td>\n",
              "      <td>1.477984</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy for fold 2: 0.578125\n",
            "Training fold 3/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2400' max='2400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2400/2400 05:09, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.255900</td>\n",
              "      <td>1.211411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.915500</td>\n",
              "      <td>1.048545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.698800</td>\n",
              "      <td>1.113452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.449900</td>\n",
              "      <td>1.253222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.252300</td>\n",
              "      <td>1.459146</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy for fold 3: 0.5864583333333333\n",
            "Training fold 4/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2400' max='2400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2400/2400 05:08, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.214600</td>\n",
              "      <td>1.156578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.033800</td>\n",
              "      <td>1.082945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.739200</td>\n",
              "      <td>1.096159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.627600</td>\n",
              "      <td>1.292094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.234700</td>\n",
              "      <td>1.428923</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy for fold 4: 0.55625\n",
            "Training fold 5/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2400' max='2400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2400/2400 05:09, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.190300</td>\n",
              "      <td>1.192980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.885700</td>\n",
              "      <td>1.015978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.785200</td>\n",
              "      <td>1.115724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.572900</td>\n",
              "      <td>1.261300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.324000</td>\n",
              "      <td>1.475785</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy for fold 5: 0.5604166666666667\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'DataLoader' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-3e1842d1fba8>\u001b[0m in \u001b[0;36m<cell line: 97>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;31m# Prepare test data and predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrenchTextDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0mtest_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0mtest_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'DataLoader' is not defined"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from transformers import CamembertTokenizer, CamembertForSequenceClassification, Trainer, TrainingArguments\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Load data\n",
        "training_data = df_train\n",
        "test_data = df_test\n",
        "\n",
        "# Initialize tokenizer\n",
        "tokenizer = CamembertTokenizer.from_pretrained(\"camembert-base\")\n",
        "\n",
        "# Tokenization and dataset preparation\n",
        "class FrenchTextDataset(Dataset):\n",
        "    def __init__(self, texts, labels=None, max_length=128):\n",
        "        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=max_length)\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.labels:\n",
        "            item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)\n",
        "\n",
        "# Encoding the labels\n",
        "label_dict = {label: i for i, label in enumerate(training_data['difficulty'].unique())}\n",
        "training_data['encoded_labels'] = training_data['difficulty'].map(label_dict)\n",
        "\n",
        "# K-Fold Cross-Validation setup\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "best_accuracy = 0\n",
        "best_model = None\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(training_data)):\n",
        "    print(f\"Training fold {fold+1}/{kf.get_n_splits()}\")\n",
        "\n",
        "    # Split data\n",
        "    train_texts = training_data.iloc[train_idx]['sentence'].tolist()\n",
        "    train_labels = training_data.iloc[train_idx]['encoded_labels'].tolist()\n",
        "    val_texts = training_data.iloc[val_idx]['sentence'].tolist()\n",
        "    val_labels = training_data.iloc[val_idx]['encoded_labels'].tolist()\n",
        "\n",
        "    # Prepare datasets\n",
        "    train_dataset = FrenchTextDataset(train_texts, train_labels)\n",
        "    val_dataset = FrenchTextDataset(val_texts, val_labels)\n",
        "\n",
        "    # Load pretrained CamemBERT model\n",
        "    model = CamembertForSequenceClassification.from_pretrained(\"camembert-base\", num_labels=len(label_dict))\n",
        "\n",
        "    # Define training arguments\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=f'./results/fold_{fold}',\n",
        "        num_train_epochs=5,\n",
        "        per_device_train_batch_size=8,\n",
        "        per_device_eval_batch_size=16,\n",
        "        warmup_steps=500,\n",
        "        weight_decay=0.01,\n",
        "        logging_dir=f'./logs/fold_{fold}',\n",
        "        logging_steps=10,\n",
        "        evaluation_strategy=\"epoch\"\n",
        "    )\n",
        "\n",
        "    # Initialize Trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    trainer.train()\n",
        "\n",
        "    # Prediction on validation data for evaluation\n",
        "    outputs = trainer.predict(val_dataset)\n",
        "    val_preds = np.argmax(outputs.predictions, axis=-1)\n",
        "    val_accuracy = accuracy_score(val_labels, val_preds)\n",
        "    print(f\"Validation Accuracy for fold {fold+1}: {val_accuracy}\")\n",
        "\n",
        "    # Save the best model\n",
        "    if val_accuracy > best_accuracy:\n",
        "        best_accuracy = val_accuracy\n",
        "        best_model = model\n",
        "        torch.save(best_model.state_dict(), 'best_model.pth')\n",
        "\n",
        "# Load the best model for prediction\n",
        "best_model.load_state_dict(torch.load('best_model.pth'))\n",
        "\n",
        "# Prepare test data and predict\n",
        "test_dataset = FrenchTextDataset(test_data['sentence'].tolist())\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "test_outputs = trainer.predict(test_loader)\n",
        "test_preds = np.argmax(test_outputs.predictions, axis=-1)\n",
        "\n",
        "# Convert numeric predictions back to labels\n",
        "inv_label_dict = {v: k for k, v in label_dict.items()}\n",
        "test_difficulties = [inv_label_dict[pred] for pred in test_preds]\n",
        "\n",
        "# Prepare the submission file\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_data['id'],\n",
        "    'difficulty': test_difficulties\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFD1sSnE39TW"
      },
      "source": [
        "## Using Optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjd6g7h1Pve6"
      },
      "source": [
        "Finally, I decided to do modelling with optuna optimization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqmFGeEn4CDe",
        "outputId": "25449960-1584-4bc2-f386-a5f9cb5647b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.30)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.11.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
            "Installing collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.5 alembic-1.13.1 colorlog-6.8.2 optuna-3.6.1\n"
          ]
        }
      ],
      "source": [
        "pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6c0ffd1bf2ee4427b84165e16f4589b3",
            "11b563ebd7e943eda2b7e27a8ad5fdff",
            "7603024b2d7d48768e2c12a18030813c",
            "844fbcd3090d44b8b3902c445de92e51",
            "0088be2426ce4cd1a2b9f71a0a0b0db0",
            "c3b4b36e27524eb1b0718ad3244db173",
            "ad15f2602a254a29949ad322e92efeb5",
            "7710ac86579e4f4789b651c930a51e5d",
            "4beff63d28b940edae9e88f7a290f2dc",
            "2a87f4fb419646b5a4df6df533b83d98",
            "370253c6b9f543d29c3f2a3a58236701",
            "3b59a07648d34de1bfa22778d456fc70",
            "a41717fd78f54b9e95944d964f525cf0",
            "0c26626bbb524c39afc8b079298af14d",
            "97b75e666f384c39ac197271bdc505b3",
            "d833d52f441a41768b9af91734900719",
            "3d3211a97a744e4b9db5eadabb378d21",
            "327cc60a92cd494fb7c5518c70ff6dce",
            "525f64f9f111410382068a541695fc6e",
            "673af21beafb488c8b5e9352ab6e87de",
            "fc4ce59a74204a68b10aab0bbc430420",
            "7b35f2114aa340188599c49212356532",
            "4c4e12c6d0ba4103aba64f7f96aea2d1",
            "33c9234ae412435cb350679e044f5c89",
            "3a9ca0401ec249aa825409f8fb44137c",
            "355cdea776c14bfab32cfd15a2df2f55",
            "9bc783ec821d4830ad340d0fadb70f61",
            "8216f129dc7047bca0313f481a566756",
            "2cb4531602fc4f09b4c2097f1e2de0e2",
            "57095b1ee01542358895ab9b1bd29499",
            "0fd90e7057fa4ee19ad655a51c1c5a04",
            "30130fbe60844b5d8af3d4f5b236bb2b",
            "aa4a80ec971546cf9e1359f5c865f3ec",
            "0a28f43e991248a6b0be274a8f20c7fc",
            "ff4a1cefcd5d4ea69bcde8b043022b6f",
            "dbb5e146d066417f9381965e22c6e00d",
            "43bf11b0de1d4e8aab6198f5225a7fa4",
            "ed7eb56c48354fd181d675ee17dc9f93",
            "152df182e7554fb28d517fe4a18554cd",
            "1b93d98d00b34563b14ecadc3826f375",
            "20c51a5214b54517bf2daad06c4c969d",
            "2a0e6ad5d3064cb0a8dda8ac70da75b9",
            "7481059fbbfc41e591703849f61d2333",
            "4dbb9eade36348e9af8882d207d83bc6",
            "47f716f8c9e24eecbd6baceb2963ffd4",
            "cffdd21282ef495da58c634d5ff05aa1",
            "6551cf9d7ab4444a88ebd6b615bfd373",
            "ce119c52402444b6bf3fe138704d3814",
            "37f63104ecc543fc9431364fd4f1909d",
            "14a3dc73bf114e58afc4b2c4c3628e5c",
            "3d7ee66c65f1496ab8e786545375c296",
            "7279fd8f57f242c4913f9a6865eefe63",
            "51d6f1ea3d0b441c9f3de2ef43a35e69",
            "cefee8f9f3d04237be793c61ebd0ea44",
            "f0fbb2b1156f44c7b49cb183e91fff7b"
          ]
        },
        "id": "fcDFyZhj4mW2",
        "outputId": "79c71bd7-6c45-418b-f270-6d20e0023a78"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c0ffd1bf2ee4427b84165e16f4589b3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3b59a07648d34de1bfa22778d456fc70",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/811k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4c4e12c6d0ba4103aba64f7f96aea2d1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.40M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0a28f43e991248a6b0be274a8f20c7fc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/508 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "[I 2024-05-19 19:31:36,094] A new study created in memory with name: no-name-d091a717-7ae2-445a-a17c-969389ee3af2\n",
            "<ipython-input-8-46fc274c4b47>:138: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-4)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "47f716f8c9e24eecbd6baceb2963ffd4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 1.804740  [    0/ 3840]\n",
            "loss: 1.839486  [   80/ 3840]\n",
            "loss: 1.816295  [  160/ 3840]\n",
            "loss: 1.806470  [  240/ 3840]\n",
            "loss: 1.815006  [  320/ 3840]\n",
            "loss: 1.768090  [  400/ 3840]\n",
            "loss: 1.765148  [  480/ 3840]\n",
            "loss: 1.690339  [  560/ 3840]\n",
            "loss: 1.698686  [  640/ 3840]\n",
            "loss: 1.693074  [  720/ 3840]\n",
            "loss: 1.624849  [  800/ 3840]\n",
            "loss: 1.642503  [  880/ 3840]\n",
            "loss: 1.575388  [  960/ 3840]\n",
            "loss: 1.495263  [ 1040/ 3840]\n",
            "loss: 1.587470  [ 1120/ 3840]\n",
            "loss: 1.432971  [ 1200/ 3840]\n",
            "loss: 1.322150  [ 1280/ 3840]\n",
            "loss: 1.319568  [ 1360/ 3840]\n",
            "loss: 1.428153  [ 1440/ 3840]\n",
            "loss: 1.414761  [ 1520/ 3840]\n",
            "loss: 1.321584  [ 1600/ 3840]\n",
            "loss: 1.417205  [ 1680/ 3840]\n",
            "loss: 1.259113  [ 1760/ 3840]\n",
            "loss: 1.370366  [ 1840/ 3840]\n",
            "loss: 1.569066  [ 1920/ 3840]\n",
            "loss: 1.297238  [ 2000/ 3840]\n",
            "loss: 1.218673  [ 2080/ 3840]\n",
            "loss: 1.439214  [ 2160/ 3840]\n",
            "loss: 1.392552  [ 2240/ 3840]\n",
            "loss: 1.132473  [ 2320/ 3840]\n",
            "loss: 1.272238  [ 2400/ 3840]\n",
            "loss: 1.389297  [ 2480/ 3840]\n",
            "loss: 1.135224  [ 2560/ 3840]\n",
            "loss: 1.125298  [ 2640/ 3840]\n",
            "loss: 1.045134  [ 2720/ 3840]\n",
            "loss: 1.584223  [ 2800/ 3840]\n",
            "loss: 1.214921  [ 2880/ 3840]\n",
            "loss: 1.179119  [ 2960/ 3840]\n",
            "loss: 1.307708  [ 3040/ 3840]\n",
            "loss: 1.000553  [ 3120/ 3840]\n",
            "loss: 1.077785  [ 3200/ 3840]\n",
            "loss: 1.368481  [ 3280/ 3840]\n",
            "loss: 0.953203  [ 3360/ 3840]\n",
            "loss: 1.048640  [ 3440/ 3840]\n",
            "loss: 1.025689  [ 3520/ 3840]\n",
            "loss: 1.034838  [ 3600/ 3840]\n",
            "loss: 0.958178  [ 3680/ 3840]\n",
            "loss: 1.394411  [ 3760/ 3840]\n",
            "Validation loss after epoch 1: 1.210170\n",
            "loss: 0.967556  [    0/ 3840]\n",
            "loss: 0.875164  [   80/ 3840]\n",
            "loss: 1.076406  [  160/ 3840]\n",
            "loss: 0.932033  [  240/ 3840]\n",
            "loss: 0.993874  [  320/ 3840]\n",
            "loss: 1.116943  [  400/ 3840]\n",
            "loss: 1.172150  [  480/ 3840]\n",
            "loss: 1.031083  [  560/ 3840]\n",
            "loss: 1.255257  [  640/ 3840]\n",
            "loss: 0.844297  [  720/ 3840]\n",
            "loss: 0.978845  [  800/ 3840]\n",
            "loss: 0.904971  [  880/ 3840]\n",
            "loss: 0.910349  [  960/ 3840]\n",
            "loss: 1.093724  [ 1040/ 3840]\n",
            "loss: 0.965514  [ 1120/ 3840]\n",
            "loss: 1.159361  [ 1200/ 3840]\n",
            "loss: 1.170153  [ 1280/ 3840]\n",
            "loss: 0.802423  [ 1360/ 3840]\n",
            "loss: 1.014364  [ 1440/ 3840]\n",
            "loss: 0.922619  [ 1520/ 3840]\n",
            "loss: 0.797120  [ 1600/ 3840]\n",
            "loss: 0.860348  [ 1680/ 3840]\n",
            "loss: 1.341971  [ 1760/ 3840]\n",
            "loss: 0.998002  [ 1840/ 3840]\n",
            "loss: 0.884791  [ 1920/ 3840]\n",
            "loss: 1.056071  [ 2000/ 3840]\n",
            "loss: 0.712746  [ 2080/ 3840]\n",
            "loss: 0.811054  [ 2160/ 3840]\n",
            "loss: 1.203231  [ 2240/ 3840]\n",
            "loss: 0.808211  [ 2320/ 3840]\n",
            "loss: 0.841337  [ 2400/ 3840]\n",
            "loss: 1.191450  [ 2480/ 3840]\n",
            "loss: 0.790084  [ 2560/ 3840]\n",
            "loss: 1.141601  [ 2640/ 3840]\n",
            "loss: 0.920010  [ 2720/ 3840]\n",
            "loss: 1.052985  [ 2800/ 3840]\n",
            "loss: 0.636443  [ 2880/ 3840]\n",
            "loss: 0.687282  [ 2960/ 3840]\n",
            "loss: 0.793759  [ 3040/ 3840]\n",
            "loss: 0.700588  [ 3120/ 3840]\n",
            "loss: 0.897989  [ 3200/ 3840]\n",
            "loss: 1.248788  [ 3280/ 3840]\n",
            "loss: 0.805910  [ 3360/ 3840]\n",
            "loss: 1.010166  [ 3440/ 3840]\n",
            "loss: 1.250276  [ 3520/ 3840]\n",
            "loss: 1.034730  [ 3600/ 3840]\n",
            "loss: 1.086669  [ 3680/ 3840]\n",
            "loss: 0.925875  [ 3760/ 3840]\n",
            "Validation loss after epoch 2: 1.042738\n",
            "loss: 0.723886  [    0/ 3840]\n",
            "loss: 0.960301  [   80/ 3840]\n",
            "loss: 0.880730  [  160/ 3840]\n",
            "loss: 0.691611  [  240/ 3840]\n",
            "loss: 0.692731  [  320/ 3840]\n",
            "loss: 0.571098  [  400/ 3840]\n",
            "loss: 0.736358  [  480/ 3840]\n",
            "loss: 0.677534  [  560/ 3840]\n",
            "loss: 0.611666  [  640/ 3840]\n",
            "loss: 0.539108  [  720/ 3840]\n",
            "loss: 0.503980  [  800/ 3840]\n",
            "loss: 0.770359  [  880/ 3840]\n",
            "loss: 0.925044  [  960/ 3840]\n",
            "loss: 1.133507  [ 1040/ 3840]\n",
            "loss: 0.584826  [ 1120/ 3840]\n",
            "loss: 0.913219  [ 1200/ 3840]\n",
            "loss: 0.739507  [ 1280/ 3840]\n",
            "loss: 0.757741  [ 1360/ 3840]\n",
            "loss: 0.822501  [ 1440/ 3840]\n",
            "loss: 0.459071  [ 1520/ 3840]\n",
            "loss: 0.717912  [ 1600/ 3840]\n",
            "loss: 0.766366  [ 1680/ 3840]\n",
            "loss: 1.245291  [ 1760/ 3840]\n",
            "loss: 0.498565  [ 1840/ 3840]\n",
            "loss: 0.541279  [ 1920/ 3840]\n",
            "loss: 0.734607  [ 2000/ 3840]\n",
            "loss: 0.739125  [ 2080/ 3840]\n",
            "loss: 0.946026  [ 2160/ 3840]\n",
            "loss: 0.659705  [ 2240/ 3840]\n",
            "loss: 1.062567  [ 2320/ 3840]\n",
            "loss: 1.401377  [ 2400/ 3840]\n",
            "loss: 1.240161  [ 2480/ 3840]\n",
            "loss: 0.846278  [ 2560/ 3840]\n",
            "loss: 1.137569  [ 2640/ 3840]\n",
            "loss: 0.613084  [ 2720/ 3840]\n",
            "loss: 0.806316  [ 2800/ 3840]\n",
            "loss: 1.180559  [ 2880/ 3840]\n",
            "loss: 0.759296  [ 2960/ 3840]\n",
            "loss: 0.768636  [ 3040/ 3840]\n",
            "loss: 0.657072  [ 3120/ 3840]\n",
            "loss: 0.591423  [ 3200/ 3840]\n",
            "loss: 0.788381  [ 3280/ 3840]\n",
            "loss: 0.684586  [ 3360/ 3840]\n",
            "loss: 1.005575  [ 3440/ 3840]\n",
            "loss: 0.502526  [ 3520/ 3840]\n",
            "loss: 0.612642  [ 3600/ 3840]\n",
            "loss: 1.120415  [ 3680/ 3840]\n",
            "loss: 0.927110  [ 3760/ 3840]\n",
            "Validation loss after epoch 3: 1.145507\n",
            "loss: 0.468647  [    0/ 3840]\n",
            "loss: 0.598322  [   80/ 3840]\n",
            "loss: 0.996000  [  160/ 3840]\n",
            "loss: 0.729539  [  240/ 3840]\n",
            "loss: 0.469093  [  320/ 3840]\n",
            "loss: 0.476004  [  400/ 3840]\n",
            "loss: 0.441197  [  480/ 3840]\n",
            "loss: 0.419622  [  560/ 3840]\n",
            "loss: 0.381073  [  640/ 3840]\n",
            "loss: 0.535735  [  720/ 3840]\n",
            "loss: 0.339730  [  800/ 3840]\n",
            "loss: 0.657895  [  880/ 3840]\n",
            "loss: 0.822522  [  960/ 3840]\n",
            "loss: 0.598094  [ 1040/ 3840]\n",
            "loss: 0.444693  [ 1120/ 3840]\n",
            "loss: 0.583609  [ 1200/ 3840]\n",
            "loss: 0.550067  [ 1280/ 3840]\n",
            "loss: 0.759622  [ 1360/ 3840]\n",
            "loss: 0.317302  [ 1440/ 3840]\n",
            "loss: 0.459831  [ 1520/ 3840]\n",
            "loss: 0.487188  [ 1600/ 3840]\n",
            "loss: 0.540026  [ 1680/ 3840]\n",
            "loss: 0.692419  [ 1760/ 3840]\n",
            "loss: 0.422872  [ 1840/ 3840]\n",
            "loss: 0.479872  [ 1920/ 3840]\n",
            "loss: 0.542419  [ 2000/ 3840]\n",
            "loss: 0.544752  [ 2080/ 3840]\n",
            "loss: 0.426524  [ 2160/ 3840]\n",
            "loss: 0.820362  [ 2240/ 3840]\n",
            "loss: 0.665083  [ 2320/ 3840]\n",
            "loss: 0.501589  [ 2400/ 3840]\n",
            "loss: 0.800338  [ 2480/ 3840]\n",
            "loss: 0.591485  [ 2560/ 3840]\n",
            "loss: 0.617680  [ 2640/ 3840]\n",
            "loss: 0.750502  [ 2720/ 3840]\n",
            "loss: 0.565234  [ 2800/ 3840]\n",
            "loss: 0.774568  [ 2880/ 3840]\n",
            "loss: 0.289425  [ 2960/ 3840]\n",
            "loss: 0.515235  [ 3040/ 3840]\n",
            "loss: 0.253347  [ 3120/ 3840]\n",
            "loss: 0.398250  [ 3200/ 3840]\n",
            "loss: 0.284973  [ 3280/ 3840]\n",
            "loss: 0.373360  [ 3360/ 3840]\n",
            "loss: 0.482765  [ 3440/ 3840]\n",
            "loss: 0.244255  [ 3520/ 3840]\n",
            "loss: 0.299611  [ 3600/ 3840]\n",
            "loss: 0.638786  [ 3680/ 3840]\n",
            "loss: 0.260888  [ 3760/ 3840]\n",
            "Validation loss after epoch 4: 1.351430\n",
            "loss: 0.282375  [    0/ 3840]\n",
            "loss: 0.693712  [   80/ 3840]\n",
            "loss: 0.635329  [  160/ 3840]\n",
            "loss: 0.320334  [  240/ 3840]\n",
            "loss: 0.371396  [  320/ 3840]\n",
            "loss: 0.353450  [  400/ 3840]\n",
            "loss: 0.799592  [  480/ 3840]\n",
            "loss: 0.536029  [  560/ 3840]\n",
            "loss: 0.576095  [  640/ 3840]\n",
            "loss: 0.426638  [  720/ 3840]\n",
            "loss: 0.276872  [  800/ 3840]\n",
            "loss: 0.534116  [  880/ 3840]\n",
            "loss: 1.060617  [  960/ 3840]\n",
            "loss: 0.188582  [ 1040/ 3840]\n",
            "loss: 0.480356  [ 1120/ 3840]\n",
            "loss: 0.324695  [ 1200/ 3840]\n",
            "loss: 0.523248  [ 1280/ 3840]\n",
            "loss: 0.393450  [ 1360/ 3840]\n",
            "loss: 0.633410  [ 1440/ 3840]\n",
            "loss: 0.394459  [ 1520/ 3840]\n",
            "loss: 0.681303  [ 1600/ 3840]\n",
            "loss: 0.212154  [ 1680/ 3840]\n",
            "loss: 0.297351  [ 1760/ 3840]\n",
            "loss: 0.569741  [ 1840/ 3840]\n",
            "loss: 0.244150  [ 1920/ 3840]\n",
            "loss: 0.580258  [ 2000/ 3840]\n",
            "loss: 0.453592  [ 2080/ 3840]\n",
            "loss: 0.741343  [ 2160/ 3840]\n",
            "loss: 0.331531  [ 2240/ 3840]\n",
            "loss: 0.267124  [ 2320/ 3840]\n",
            "loss: 0.154717  [ 2400/ 3840]\n",
            "loss: 0.233682  [ 2480/ 3840]\n",
            "loss: 0.125655  [ 2560/ 3840]\n",
            "loss: 0.683096  [ 2640/ 3840]\n",
            "loss: 0.248759  [ 2720/ 3840]\n",
            "loss: 1.175120  [ 2800/ 3840]\n",
            "loss: 0.692534  [ 2880/ 3840]\n",
            "loss: 0.645609  [ 2960/ 3840]\n",
            "loss: 0.231538  [ 3040/ 3840]\n",
            "loss: 0.403923  [ 3120/ 3840]\n",
            "loss: 0.336507  [ 3200/ 3840]\n",
            "loss: 0.338163  [ 3280/ 3840]\n",
            "loss: 0.134765  [ 3360/ 3840]\n",
            "loss: 0.885497  [ 3440/ 3840]\n",
            "loss: 0.181182  [ 3520/ 3840]\n",
            "loss: 1.023981  [ 3600/ 3840]\n",
            "loss: 0.631103  [ 3680/ 3840]\n",
            "loss: 0.351898  [ 3760/ 3840]\n",
            "Validation loss after epoch 5: 1.344402\n",
            "Early stopping at epoch 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-05-19 19:37:23,131] Trial 0 finished with value: 57.1875 and parameters: {'dropout_rate': 0.2523736797164531, 'learning_rate': 1.749675551493842e-05, 'batch_size': 8}. Best is trial 0 with value: 57.1875.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 1.784968  [    0/ 3840]\n",
            "loss: 1.799333  [  320/ 3840]\n",
            "loss: 1.753833  [  640/ 3840]\n",
            "loss: 1.752848  [  960/ 3840]\n",
            "loss: 1.643321  [ 1280/ 3840]\n",
            "loss: 1.638949  [ 1600/ 3840]\n",
            "loss: 1.467924  [ 1920/ 3840]\n",
            "loss: 1.475083  [ 2240/ 3840]\n",
            "loss: 1.349489  [ 2560/ 3840]\n",
            "loss: 1.468958  [ 2880/ 3840]\n",
            "loss: 1.354433  [ 3200/ 3840]\n",
            "loss: 1.247247  [ 3520/ 3840]\n",
            "Validation loss after epoch 1: 1.277064\n",
            "loss: 1.212088  [    0/ 3840]\n",
            "loss: 1.139315  [  320/ 3840]\n",
            "loss: 1.343988  [  640/ 3840]\n",
            "loss: 1.177180  [  960/ 3840]\n",
            "loss: 1.176459  [ 1280/ 3840]\n",
            "loss: 0.998167  [ 1600/ 3840]\n",
            "loss: 1.290231  [ 1920/ 3840]\n",
            "loss: 1.097370  [ 2240/ 3840]\n",
            "loss: 1.062878  [ 2560/ 3840]\n",
            "loss: 1.187481  [ 2880/ 3840]\n",
            "loss: 1.155627  [ 3200/ 3840]\n",
            "loss: 0.957570  [ 3520/ 3840]\n",
            "Validation loss after epoch 2: 1.096498\n",
            "loss: 0.920736  [    0/ 3840]\n",
            "loss: 0.831333  [  320/ 3840]\n",
            "loss: 1.000189  [  640/ 3840]\n",
            "loss: 1.042633  [  960/ 3840]\n",
            "loss: 0.812085  [ 1280/ 3840]\n",
            "loss: 1.072022  [ 1600/ 3840]\n",
            "loss: 1.119975  [ 1920/ 3840]\n",
            "loss: 1.089890  [ 2240/ 3840]\n",
            "loss: 0.908686  [ 2560/ 3840]\n",
            "loss: 1.027288  [ 2880/ 3840]\n",
            "loss: 0.882534  [ 3200/ 3840]\n",
            "loss: 0.895020  [ 3520/ 3840]\n",
            "Validation loss after epoch 3: 1.101197\n",
            "loss: 0.899446  [    0/ 3840]\n",
            "loss: 0.970856  [  320/ 3840]\n",
            "loss: 0.967204  [  640/ 3840]\n",
            "loss: 0.775508  [  960/ 3840]\n",
            "loss: 0.712754  [ 1280/ 3840]\n",
            "loss: 0.773131  [ 1600/ 3840]\n",
            "loss: 0.808609  [ 1920/ 3840]\n",
            "loss: 1.035532  [ 2240/ 3840]\n",
            "loss: 0.770334  [ 2560/ 3840]\n",
            "loss: 0.864186  [ 2880/ 3840]\n",
            "loss: 0.991437  [ 3200/ 3840]\n",
            "loss: 0.799637  [ 3520/ 3840]\n",
            "Validation loss after epoch 4: 1.163901\n",
            "loss: 0.655077  [    0/ 3840]\n",
            "loss: 0.705086  [  320/ 3840]\n",
            "loss: 0.642983  [  640/ 3840]\n",
            "loss: 0.730640  [  960/ 3840]\n",
            "loss: 0.700457  [ 1280/ 3840]\n",
            "loss: 0.496422  [ 1600/ 3840]\n",
            "loss: 0.590721  [ 1920/ 3840]\n",
            "loss: 0.579923  [ 2240/ 3840]\n",
            "loss: 0.626842  [ 2560/ 3840]\n",
            "loss: 0.557610  [ 2880/ 3840]\n",
            "loss: 0.609362  [ 3200/ 3840]\n",
            "loss: 0.641216  [ 3520/ 3840]\n",
            "Validation loss after epoch 5: 1.103715\n",
            "Early stopping at epoch 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-05-19 19:42:28,695] Trial 1 finished with value: 56.458333333333336 and parameters: {'dropout_rate': 0.11054179058535647, 'learning_rate': 2.0703379381519423e-05, 'batch_size': 32}. Best is trial 0 with value: 57.1875.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 1.758137  [    0/ 3840]\n",
            "loss: 1.783344  [   80/ 3840]\n",
            "loss: 1.815266  [  160/ 3840]\n",
            "loss: 1.786881  [  240/ 3840]\n",
            "loss: 1.793463  [  320/ 3840]\n",
            "loss: 1.733646  [  400/ 3840]\n",
            "loss: 1.766444  [  480/ 3840]\n",
            "loss: 1.679493  [  560/ 3840]\n",
            "loss: 1.736482  [  640/ 3840]\n",
            "loss: 1.588256  [  720/ 3840]\n",
            "loss: 1.610598  [  800/ 3840]\n",
            "loss: 1.577407  [  880/ 3840]\n",
            "loss: 1.615445  [  960/ 3840]\n",
            "loss: 1.524351  [ 1040/ 3840]\n",
            "loss: 1.527225  [ 1120/ 3840]\n",
            "loss: 1.452814  [ 1200/ 3840]\n",
            "loss: 1.546550  [ 1280/ 3840]\n",
            "loss: 1.522699  [ 1360/ 3840]\n",
            "loss: 1.400386  [ 1440/ 3840]\n",
            "loss: 1.428893  [ 1520/ 3840]\n",
            "loss: 1.104228  [ 1600/ 3840]\n",
            "loss: 1.128068  [ 1680/ 3840]\n",
            "loss: 1.336132  [ 1760/ 3840]\n",
            "loss: 1.239441  [ 1840/ 3840]\n",
            "loss: 1.257433  [ 1920/ 3840]\n",
            "loss: 1.320642  [ 2000/ 3840]\n",
            "loss: 1.176942  [ 2080/ 3840]\n",
            "loss: 1.273632  [ 2160/ 3840]\n",
            "loss: 1.481123  [ 2240/ 3840]\n",
            "loss: 1.098170  [ 2320/ 3840]\n",
            "loss: 1.559949  [ 2400/ 3840]\n",
            "loss: 1.441891  [ 2480/ 3840]\n",
            "loss: 1.277103  [ 2560/ 3840]\n",
            "loss: 1.169101  [ 2640/ 3840]\n",
            "loss: 1.196692  [ 2720/ 3840]\n",
            "loss: 1.100531  [ 2800/ 3840]\n",
            "loss: 1.258744  [ 2880/ 3840]\n",
            "loss: 1.376799  [ 2960/ 3840]\n",
            "loss: 1.461631  [ 3040/ 3840]\n",
            "loss: 1.183881  [ 3120/ 3840]\n",
            "loss: 1.191027  [ 3200/ 3840]\n",
            "loss: 1.559424  [ 3280/ 3840]\n",
            "loss: 1.098163  [ 3360/ 3840]\n",
            "loss: 1.131559  [ 3440/ 3840]\n",
            "loss: 1.342952  [ 3520/ 3840]\n",
            "loss: 1.224639  [ 3600/ 3840]\n",
            "loss: 1.052629  [ 3680/ 3840]\n",
            "loss: 1.267037  [ 3760/ 3840]\n",
            "Validation loss after epoch 1: 1.201334\n",
            "loss: 1.243231  [    0/ 3840]\n",
            "loss: 1.164386  [   80/ 3840]\n",
            "loss: 1.054904  [  160/ 3840]\n",
            "loss: 0.918349  [  240/ 3840]\n",
            "loss: 1.224824  [  320/ 3840]\n",
            "loss: 1.069669  [  400/ 3840]\n",
            "loss: 1.025743  [  480/ 3840]\n",
            "loss: 0.657511  [  560/ 3840]\n",
            "loss: 1.225967  [  640/ 3840]\n",
            "loss: 0.867147  [  720/ 3840]\n",
            "loss: 1.024457  [  800/ 3840]\n",
            "loss: 1.194569  [  880/ 3840]\n",
            "loss: 1.280894  [  960/ 3840]\n",
            "loss: 0.822743  [ 1040/ 3840]\n",
            "loss: 1.524398  [ 1120/ 3840]\n",
            "loss: 0.952282  [ 1200/ 3840]\n",
            "loss: 0.788462  [ 1280/ 3840]\n",
            "loss: 1.008458  [ 1360/ 3840]\n",
            "loss: 1.116908  [ 1440/ 3840]\n",
            "loss: 1.010525  [ 1520/ 3840]\n",
            "loss: 1.053536  [ 1600/ 3840]\n",
            "loss: 1.347476  [ 1680/ 3840]\n",
            "loss: 0.878007  [ 1760/ 3840]\n",
            "loss: 0.978830  [ 1840/ 3840]\n",
            "loss: 1.106129  [ 1920/ 3840]\n",
            "loss: 0.910223  [ 2000/ 3840]\n",
            "loss: 0.976832  [ 2080/ 3840]\n",
            "loss: 0.895875  [ 2160/ 3840]\n",
            "loss: 0.775771  [ 2240/ 3840]\n",
            "loss: 0.701153  [ 2320/ 3840]\n",
            "loss: 1.292419  [ 2400/ 3840]\n",
            "loss: 1.203887  [ 2480/ 3840]\n",
            "loss: 0.747829  [ 2560/ 3840]\n",
            "loss: 1.356120  [ 2640/ 3840]\n",
            "loss: 0.980210  [ 2720/ 3840]\n",
            "loss: 1.275894  [ 2800/ 3840]\n",
            "loss: 0.807403  [ 2880/ 3840]\n",
            "loss: 1.346423  [ 2960/ 3840]\n",
            "loss: 0.859346  [ 3040/ 3840]\n",
            "loss: 0.638494  [ 3120/ 3840]\n",
            "loss: 0.834744  [ 3200/ 3840]\n",
            "loss: 0.909637  [ 3280/ 3840]\n",
            "loss: 0.936148  [ 3360/ 3840]\n",
            "loss: 0.897820  [ 3440/ 3840]\n",
            "loss: 0.887445  [ 3520/ 3840]\n",
            "loss: 0.753541  [ 3600/ 3840]\n",
            "loss: 1.169368  [ 3680/ 3840]\n",
            "loss: 1.176090  [ 3760/ 3840]\n",
            "Validation loss after epoch 2: 1.116896\n",
            "loss: 0.590941  [    0/ 3840]\n",
            "loss: 0.836038  [   80/ 3840]\n",
            "loss: 0.655615  [  160/ 3840]\n",
            "loss: 0.680023  [  240/ 3840]\n",
            "loss: 0.712683  [  320/ 3840]\n",
            "loss: 0.887101  [  400/ 3840]\n",
            "loss: 0.674143  [  480/ 3840]\n",
            "loss: 0.573626  [  560/ 3840]\n",
            "loss: 1.164844  [  640/ 3840]\n",
            "loss: 0.602303  [  720/ 3840]\n",
            "loss: 0.754878  [  800/ 3840]\n",
            "loss: 0.861275  [  880/ 3840]\n",
            "loss: 0.753387  [  960/ 3840]\n",
            "loss: 0.940133  [ 1040/ 3840]\n",
            "loss: 0.699597  [ 1120/ 3840]\n",
            "loss: 0.937609  [ 1200/ 3840]\n",
            "loss: 0.657484  [ 1280/ 3840]\n",
            "loss: 0.836417  [ 1360/ 3840]\n",
            "loss: 0.844382  [ 1440/ 3840]\n",
            "loss: 0.914554  [ 1520/ 3840]\n",
            "loss: 0.498757  [ 1600/ 3840]\n",
            "loss: 0.798346  [ 1680/ 3840]\n",
            "loss: 0.900131  [ 1760/ 3840]\n",
            "loss: 1.527891  [ 1840/ 3840]\n",
            "loss: 0.774059  [ 1920/ 3840]\n",
            "loss: 0.849252  [ 2000/ 3840]\n",
            "loss: 1.295824  [ 2080/ 3840]\n",
            "loss: 0.955756  [ 2160/ 3840]\n",
            "loss: 0.947542  [ 2240/ 3840]\n",
            "loss: 0.925340  [ 2320/ 3840]\n",
            "loss: 0.879324  [ 2400/ 3840]\n",
            "loss: 0.895520  [ 2480/ 3840]\n",
            "loss: 0.711179  [ 2560/ 3840]\n",
            "loss: 0.941263  [ 2640/ 3840]\n",
            "loss: 0.525367  [ 2720/ 3840]\n",
            "loss: 0.884072  [ 2800/ 3840]\n",
            "loss: 0.787495  [ 2880/ 3840]\n",
            "loss: 1.459801  [ 2960/ 3840]\n",
            "loss: 0.792065  [ 3040/ 3840]\n",
            "loss: 1.045376  [ 3120/ 3840]\n",
            "loss: 1.019958  [ 3200/ 3840]\n",
            "loss: 0.586608  [ 3280/ 3840]\n",
            "loss: 0.763252  [ 3360/ 3840]\n",
            "loss: 0.850666  [ 3440/ 3840]\n",
            "loss: 0.495835  [ 3520/ 3840]\n",
            "loss: 0.463594  [ 3600/ 3840]\n",
            "loss: 0.917692  [ 3680/ 3840]\n",
            "loss: 0.964831  [ 3760/ 3840]\n",
            "Validation loss after epoch 3: 1.056828\n",
            "loss: 0.749142  [    0/ 3840]\n",
            "loss: 1.025695  [   80/ 3840]\n",
            "loss: 0.654446  [  160/ 3840]\n",
            "loss: 0.689536  [  240/ 3840]\n",
            "loss: 0.536620  [  320/ 3840]\n",
            "loss: 0.406222  [  400/ 3840]\n",
            "loss: 0.930658  [  480/ 3840]\n",
            "loss: 0.767989  [  560/ 3840]\n",
            "loss: 0.460828  [  640/ 3840]\n",
            "loss: 0.637167  [  720/ 3840]\n",
            "loss: 0.712876  [  800/ 3840]\n",
            "loss: 0.840102  [  880/ 3840]\n",
            "loss: 0.282932  [  960/ 3840]\n",
            "loss: 1.406793  [ 1040/ 3840]\n",
            "loss: 0.493350  [ 1120/ 3840]\n",
            "loss: 0.450762  [ 1200/ 3840]\n",
            "loss: 0.403431  [ 1280/ 3840]\n",
            "loss: 1.285899  [ 1360/ 3840]\n",
            "loss: 0.355642  [ 1440/ 3840]\n",
            "loss: 0.373835  [ 1520/ 3840]\n",
            "loss: 0.859874  [ 1600/ 3840]\n",
            "loss: 0.907634  [ 1680/ 3840]\n",
            "loss: 0.990088  [ 1760/ 3840]\n",
            "loss: 0.500936  [ 1840/ 3840]\n",
            "loss: 0.670683  [ 1920/ 3840]\n",
            "loss: 0.595153  [ 2000/ 3840]\n",
            "loss: 0.446984  [ 2080/ 3840]\n",
            "loss: 0.618835  [ 2160/ 3840]\n",
            "loss: 0.530302  [ 2240/ 3840]\n",
            "loss: 0.925204  [ 2320/ 3840]\n",
            "loss: 0.618467  [ 2400/ 3840]\n",
            "loss: 0.809492  [ 2480/ 3840]\n",
            "loss: 0.553195  [ 2560/ 3840]\n",
            "loss: 0.603063  [ 2640/ 3840]\n",
            "loss: 0.647377  [ 2720/ 3840]\n",
            "loss: 0.575770  [ 2800/ 3840]\n",
            "loss: 0.466987  [ 2880/ 3840]\n",
            "loss: 0.889006  [ 2960/ 3840]\n",
            "loss: 0.499449  [ 3040/ 3840]\n",
            "loss: 0.357817  [ 3120/ 3840]\n",
            "loss: 0.329777  [ 3200/ 3840]\n",
            "loss: 0.397639  [ 3280/ 3840]\n",
            "loss: 0.606365  [ 3360/ 3840]\n",
            "loss: 0.699990  [ 3440/ 3840]\n",
            "loss: 0.383612  [ 3520/ 3840]\n",
            "loss: 0.468124  [ 3600/ 3840]\n",
            "loss: 0.427281  [ 3680/ 3840]\n",
            "loss: 0.542990  [ 3760/ 3840]\n",
            "Validation loss after epoch 4: 1.253138\n",
            "loss: 0.397350  [    0/ 3840]\n",
            "loss: 0.466495  [   80/ 3840]\n",
            "loss: 0.606906  [  160/ 3840]\n",
            "loss: 0.428771  [  240/ 3840]\n",
            "loss: 1.110031  [  320/ 3840]\n",
            "loss: 0.664073  [  400/ 3840]\n",
            "loss: 0.608824  [  480/ 3840]\n",
            "loss: 0.221591  [  560/ 3840]\n",
            "loss: 0.666075  [  640/ 3840]\n",
            "loss: 0.299980  [  720/ 3840]\n",
            "loss: 0.461391  [  800/ 3840]\n",
            "loss: 0.387075  [  880/ 3840]\n",
            "loss: 0.527142  [  960/ 3840]\n",
            "loss: 1.537007  [ 1040/ 3840]\n",
            "loss: 0.244811  [ 1120/ 3840]\n",
            "loss: 0.743873  [ 1200/ 3840]\n",
            "loss: 0.209757  [ 1280/ 3840]\n",
            "loss: 0.946175  [ 1360/ 3840]\n",
            "loss: 0.515774  [ 1440/ 3840]\n",
            "loss: 0.238031  [ 1520/ 3840]\n",
            "loss: 0.582393  [ 1600/ 3840]\n",
            "loss: 0.314322  [ 1680/ 3840]\n",
            "loss: 1.009781  [ 1760/ 3840]\n",
            "loss: 0.242731  [ 1840/ 3840]\n",
            "loss: 0.291538  [ 1920/ 3840]\n",
            "loss: 0.346274  [ 2000/ 3840]\n",
            "loss: 0.333286  [ 2080/ 3840]\n",
            "loss: 0.475413  [ 2160/ 3840]\n",
            "loss: 0.278124  [ 2240/ 3840]\n",
            "loss: 0.398746  [ 2320/ 3840]\n",
            "loss: 0.430556  [ 2400/ 3840]\n",
            "loss: 0.464547  [ 2480/ 3840]\n",
            "loss: 0.672168  [ 2560/ 3840]\n",
            "loss: 0.202696  [ 2640/ 3840]\n",
            "loss: 0.419240  [ 2720/ 3840]\n",
            "loss: 0.845744  [ 2800/ 3840]\n",
            "loss: 0.391148  [ 2880/ 3840]\n",
            "loss: 0.680302  [ 2960/ 3840]\n",
            "loss: 0.726929  [ 3040/ 3840]\n",
            "loss: 0.297300  [ 3120/ 3840]\n",
            "loss: 0.831123  [ 3200/ 3840]\n",
            "loss: 0.906285  [ 3280/ 3840]\n",
            "loss: 0.756951  [ 3360/ 3840]\n",
            "loss: 0.670173  [ 3440/ 3840]\n",
            "loss: 0.455918  [ 3520/ 3840]\n",
            "loss: 0.294642  [ 3600/ 3840]\n",
            "loss: 0.743010  [ 3680/ 3840]\n",
            "loss: 0.280180  [ 3760/ 3840]\n",
            "Validation loss after epoch 5: 1.399393\n",
            "loss: 0.775505  [    0/ 3840]\n",
            "loss: 0.357892  [   80/ 3840]\n",
            "loss: 0.692170  [  160/ 3840]\n",
            "loss: 0.144747  [  240/ 3840]\n",
            "loss: 0.432011  [  320/ 3840]\n",
            "loss: 0.233609  [  400/ 3840]\n",
            "loss: 0.213874  [  480/ 3840]\n",
            "loss: 0.153031  [  560/ 3840]\n",
            "loss: 0.345623  [  640/ 3840]\n",
            "loss: 0.142221  [  720/ 3840]\n",
            "loss: 0.372745  [  800/ 3840]\n",
            "loss: 0.261326  [  880/ 3840]\n",
            "loss: 0.686913  [  960/ 3840]\n",
            "loss: 0.142986  [ 1040/ 3840]\n",
            "loss: 0.103842  [ 1120/ 3840]\n",
            "loss: 0.285745  [ 1200/ 3840]\n",
            "loss: 0.337890  [ 1280/ 3840]\n",
            "loss: 0.141329  [ 1360/ 3840]\n",
            "loss: 0.224042  [ 1440/ 3840]\n",
            "loss: 0.217111  [ 1520/ 3840]\n",
            "loss: 0.208867  [ 1600/ 3840]\n",
            "loss: 0.131097  [ 1680/ 3840]\n",
            "loss: 0.201854  [ 1760/ 3840]\n",
            "loss: 0.878164  [ 1840/ 3840]\n",
            "loss: 0.141653  [ 1920/ 3840]\n",
            "loss: 0.169025  [ 2000/ 3840]\n",
            "loss: 0.488768  [ 2080/ 3840]\n",
            "loss: 0.143652  [ 2160/ 3840]\n",
            "loss: 0.532096  [ 2240/ 3840]\n",
            "loss: 0.167668  [ 2320/ 3840]\n",
            "loss: 0.108230  [ 2400/ 3840]\n",
            "loss: 0.185702  [ 2480/ 3840]\n",
            "loss: 0.304028  [ 2560/ 3840]\n",
            "loss: 0.162657  [ 2640/ 3840]\n",
            "loss: 0.210466  [ 2720/ 3840]\n",
            "loss: 0.492194  [ 2800/ 3840]\n",
            "loss: 0.464733  [ 2880/ 3840]\n",
            "loss: 0.166336  [ 2960/ 3840]\n",
            "loss: 0.615172  [ 3040/ 3840]\n",
            "loss: 0.297920  [ 3120/ 3840]\n",
            "loss: 0.135716  [ 3200/ 3840]\n",
            "loss: 0.302023  [ 3280/ 3840]\n",
            "loss: 0.607361  [ 3360/ 3840]\n",
            "loss: 0.513594  [ 3440/ 3840]\n",
            "loss: 0.211610  [ 3520/ 3840]\n",
            "loss: 0.129863  [ 3600/ 3840]\n",
            "loss: 0.188119  [ 3680/ 3840]\n",
            "loss: 0.208129  [ 3760/ 3840]\n",
            "Validation loss after epoch 6: 1.469478\n",
            "Early stopping at epoch 7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-05-19 19:49:20,423] Trial 2 finished with value: 55.0 and parameters: {'dropout_rate': 0.26977933306023555, 'learning_rate': 1.765642932015516e-05, 'batch_size': 8}. Best is trial 0 with value: 57.1875.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 1.794141  [    0/ 3840]\n",
            "loss: 1.762084  [  320/ 3840]\n",
            "loss: 1.766277  [  640/ 3840]\n",
            "loss: 1.640809  [  960/ 3840]\n",
            "loss: 1.623968  [ 1280/ 3840]\n",
            "loss: 1.560212  [ 1600/ 3840]\n",
            "loss: 1.472100  [ 1920/ 3840]\n",
            "loss: 1.326975  [ 2240/ 3840]\n",
            "loss: 1.203300  [ 2560/ 3840]\n",
            "loss: 1.209474  [ 2880/ 3840]\n",
            "loss: 1.195788  [ 3200/ 3840]\n",
            "loss: 1.325761  [ 3520/ 3840]\n",
            "Validation loss after epoch 1: 1.189063\n",
            "loss: 1.148228  [    0/ 3840]\n",
            "loss: 1.032156  [  320/ 3840]\n",
            "loss: 1.212910  [  640/ 3840]\n",
            "loss: 0.998857  [  960/ 3840]\n",
            "loss: 0.958625  [ 1280/ 3840]\n",
            "loss: 1.076544  [ 1600/ 3840]\n",
            "loss: 0.940556  [ 1920/ 3840]\n",
            "loss: 1.030061  [ 2240/ 3840]\n",
            "loss: 0.857009  [ 2560/ 3840]\n",
            "loss: 1.172804  [ 2880/ 3840]\n",
            "loss: 1.184546  [ 3200/ 3840]\n",
            "loss: 1.355449  [ 3520/ 3840]\n",
            "Validation loss after epoch 2: 1.049646\n",
            "loss: 0.783249  [    0/ 3840]\n",
            "loss: 0.789941  [  320/ 3840]\n",
            "loss: 0.982033  [  640/ 3840]\n",
            "loss: 0.866399  [  960/ 3840]\n",
            "loss: 0.842566  [ 1280/ 3840]\n",
            "loss: 0.879953  [ 1600/ 3840]\n",
            "loss: 0.790391  [ 1920/ 3840]\n",
            "loss: 0.944452  [ 2240/ 3840]\n",
            "loss: 0.695294  [ 2560/ 3840]\n",
            "loss: 0.680274  [ 2880/ 3840]\n",
            "loss: 0.900048  [ 3200/ 3840]\n",
            "loss: 0.903739  [ 3520/ 3840]\n",
            "Validation loss after epoch 3: 1.262342\n",
            "loss: 0.915308  [    0/ 3840]\n",
            "loss: 0.640819  [  320/ 3840]\n",
            "loss: 0.662890  [  640/ 3840]\n",
            "loss: 0.624228  [  960/ 3840]\n",
            "loss: 0.620292  [ 1280/ 3840]\n",
            "loss: 0.538282  [ 1600/ 3840]\n",
            "loss: 0.722227  [ 1920/ 3840]\n",
            "loss: 0.694940  [ 2240/ 3840]\n",
            "loss: 0.489455  [ 2560/ 3840]\n",
            "loss: 0.646807  [ 2880/ 3840]\n",
            "loss: 0.523493  [ 3200/ 3840]\n",
            "loss: 0.677410  [ 3520/ 3840]\n",
            "Validation loss after epoch 4: 1.275485\n",
            "loss: 0.457142  [    0/ 3840]\n",
            "loss: 0.368519  [  320/ 3840]\n",
            "loss: 0.384496  [  640/ 3840]\n",
            "loss: 0.341387  [  960/ 3840]\n",
            "loss: 0.363416  [ 1280/ 3840]\n",
            "loss: 0.441556  [ 1600/ 3840]\n",
            "loss: 0.481507  [ 1920/ 3840]\n",
            "loss: 0.275595  [ 2240/ 3840]\n",
            "loss: 0.565161  [ 2560/ 3840]\n",
            "loss: 0.230698  [ 2880/ 3840]\n",
            "loss: 0.499854  [ 3200/ 3840]\n",
            "loss: 0.332724  [ 3520/ 3840]\n",
            "Validation loss after epoch 5: 1.347320\n",
            "Early stopping at epoch 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-05-19 19:54:26,336] Trial 3 finished with value: 54.0625 and parameters: {'dropout_rate': 0.14142088399633237, 'learning_rate': 3.216651103486957e-05, 'batch_size': 32}. Best is trial 0 with value: 57.1875.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 1.781508  [    0/ 3840]\n",
            "loss: 1.781065  [  320/ 3840]\n",
            "loss: 1.773642  [  640/ 3840]\n",
            "loss: 1.760377  [  960/ 3840]\n",
            "loss: 1.679076  [ 1280/ 3840]\n",
            "loss: 1.682806  [ 1600/ 3840]\n",
            "loss: 1.523122  [ 1920/ 3840]\n",
            "loss: 1.498101  [ 2240/ 3840]\n",
            "loss: 1.429997  [ 2560/ 3840]\n",
            "loss: 1.426476  [ 2880/ 3840]\n",
            "loss: 1.403176  [ 3200/ 3840]\n",
            "loss: 1.332449  [ 3520/ 3840]\n",
            "Validation loss after epoch 1: 1.336954\n",
            "loss: 1.315761  [    0/ 3840]\n",
            "loss: 1.275985  [  320/ 3840]\n",
            "loss: 1.258048  [  640/ 3840]\n",
            "loss: 1.347165  [  960/ 3840]\n",
            "loss: 1.264021  [ 1280/ 3840]\n",
            "loss: 1.199207  [ 1600/ 3840]\n",
            "loss: 1.135242  [ 1920/ 3840]\n",
            "loss: 1.228306  [ 2240/ 3840]\n",
            "loss: 1.150085  [ 2560/ 3840]\n",
            "loss: 1.123047  [ 2880/ 3840]\n",
            "loss: 1.108450  [ 3200/ 3840]\n",
            "loss: 1.103240  [ 3520/ 3840]\n",
            "Validation loss after epoch 2: 1.127168\n",
            "loss: 1.125752  [    0/ 3840]\n",
            "loss: 0.929413  [  320/ 3840]\n",
            "loss: 1.098489  [  640/ 3840]\n",
            "loss: 0.916760  [  960/ 3840]\n",
            "loss: 1.095042  [ 1280/ 3840]\n",
            "loss: 0.901449  [ 1600/ 3840]\n",
            "loss: 0.859206  [ 1920/ 3840]\n",
            "loss: 1.051930  [ 2240/ 3840]\n",
            "loss: 0.841882  [ 2560/ 3840]\n",
            "loss: 0.967572  [ 2880/ 3840]\n",
            "loss: 0.970289  [ 3200/ 3840]\n",
            "loss: 0.983412  [ 3520/ 3840]\n",
            "Validation loss after epoch 3: 1.073594\n",
            "loss: 0.824954  [    0/ 3840]\n",
            "loss: 0.790611  [  320/ 3840]\n",
            "loss: 0.928940  [  640/ 3840]\n",
            "loss: 0.812546  [  960/ 3840]\n",
            "loss: 0.975454  [ 1280/ 3840]\n",
            "loss: 0.740950  [ 1600/ 3840]\n",
            "loss: 0.852383  [ 1920/ 3840]\n",
            "loss: 0.970826  [ 2240/ 3840]\n",
            "loss: 0.715651  [ 2560/ 3840]\n",
            "loss: 0.791648  [ 2880/ 3840]\n",
            "loss: 0.982798  [ 3200/ 3840]\n",
            "loss: 0.768677  [ 3520/ 3840]\n",
            "Validation loss after epoch 4: 1.112563\n",
            "loss: 0.877859  [    0/ 3840]\n",
            "loss: 0.769943  [  320/ 3840]\n",
            "loss: 0.751750  [  640/ 3840]\n",
            "loss: 0.764914  [  960/ 3840]\n",
            "loss: 0.771081  [ 1280/ 3840]\n",
            "loss: 0.687083  [ 1600/ 3840]\n",
            "loss: 0.742808  [ 1920/ 3840]\n",
            "loss: 0.586643  [ 2240/ 3840]\n",
            "loss: 0.757197  [ 2560/ 3840]\n",
            "loss: 0.697760  [ 2880/ 3840]\n",
            "loss: 0.654056  [ 3200/ 3840]\n",
            "loss: 0.728976  [ 3520/ 3840]\n",
            "Validation loss after epoch 5: 1.174215\n",
            "loss: 0.873333  [    0/ 3840]\n",
            "loss: 0.628428  [  320/ 3840]\n",
            "loss: 0.415968  [  640/ 3840]\n",
            "loss: 0.581906  [  960/ 3840]\n",
            "loss: 0.511218  [ 1280/ 3840]\n",
            "loss: 0.501938  [ 1600/ 3840]\n",
            "loss: 0.607513  [ 1920/ 3840]\n",
            "loss: 0.449782  [ 2240/ 3840]\n",
            "loss: 0.487693  [ 2560/ 3840]\n",
            "loss: 0.515411  [ 2880/ 3840]\n",
            "loss: 0.538973  [ 3200/ 3840]\n",
            "loss: 0.726724  [ 3520/ 3840]\n",
            "Validation loss after epoch 6: 1.162902\n",
            "Early stopping at epoch 7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-05-19 20:00:31,941] Trial 4 finished with value: 55.833333333333336 and parameters: {'dropout_rate': 0.2093781648506189, 'learning_rate': 1.7826361168050103e-05, 'batch_size': 32}. Best is trial 0 with value: 57.1875.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 1.795749  [    0/ 3840]\n",
            "loss: 1.780093  [  160/ 3840]\n",
            "loss: 1.736391  [  320/ 3840]\n",
            "loss: 1.772603  [  480/ 3840]\n",
            "loss: 1.755370  [  640/ 3840]\n",
            "loss: 1.714677  [  800/ 3840]\n",
            "loss: 1.739787  [  960/ 3840]\n",
            "loss: 1.635365  [ 1120/ 3840]\n",
            "loss: 1.571914  [ 1280/ 3840]\n",
            "loss: 1.594687  [ 1440/ 3840]\n",
            "loss: 1.493412  [ 1600/ 3840]\n",
            "loss: 1.365610  [ 1760/ 3840]\n",
            "loss: 1.567494  [ 1920/ 3840]\n",
            "loss: 1.355951  [ 2080/ 3840]\n",
            "loss: 1.375308  [ 2240/ 3840]\n",
            "loss: 1.311695  [ 2400/ 3840]\n",
            "loss: 1.479805  [ 2560/ 3840]\n",
            "loss: 1.499112  [ 2720/ 3840]\n",
            "loss: 1.234447  [ 2880/ 3840]\n",
            "loss: 1.280948  [ 3040/ 3840]\n",
            "loss: 1.209285  [ 3200/ 3840]\n",
            "loss: 1.308418  [ 3360/ 3840]\n",
            "loss: 1.199549  [ 3520/ 3840]\n",
            "loss: 1.162813  [ 3680/ 3840]\n",
            "Validation loss after epoch 1: 1.221226\n",
            "loss: 1.199699  [    0/ 3840]\n",
            "loss: 1.214541  [  160/ 3840]\n",
            "loss: 1.230724  [  320/ 3840]\n",
            "loss: 1.302636  [  480/ 3840]\n",
            "loss: 1.177099  [  640/ 3840]\n",
            "loss: 1.248332  [  800/ 3840]\n",
            "loss: 1.093569  [  960/ 3840]\n",
            "loss: 0.976632  [ 1120/ 3840]\n",
            "loss: 1.319759  [ 1280/ 3840]\n",
            "loss: 0.981875  [ 1440/ 3840]\n",
            "loss: 1.270625  [ 1600/ 3840]\n",
            "loss: 1.056851  [ 1760/ 3840]\n",
            "loss: 1.184277  [ 1920/ 3840]\n",
            "loss: 1.238775  [ 2080/ 3840]\n",
            "loss: 1.209984  [ 2240/ 3840]\n",
            "loss: 1.118732  [ 2400/ 3840]\n",
            "loss: 0.887025  [ 2560/ 3840]\n",
            "loss: 0.962921  [ 2720/ 3840]\n",
            "loss: 0.909436  [ 2880/ 3840]\n",
            "loss: 1.050752  [ 3040/ 3840]\n",
            "loss: 0.970485  [ 3200/ 3840]\n",
            "loss: 0.982061  [ 3360/ 3840]\n",
            "loss: 0.752913  [ 3520/ 3840]\n",
            "loss: 0.971797  [ 3680/ 3840]\n",
            "Validation loss after epoch 2: 1.142045\n",
            "loss: 0.842474  [    0/ 3840]\n",
            "loss: 0.914698  [  160/ 3840]\n",
            "loss: 1.048201  [  320/ 3840]\n",
            "loss: 0.951459  [  480/ 3840]\n",
            "loss: 0.853066  [  640/ 3840]\n",
            "loss: 0.905061  [  800/ 3840]\n",
            "loss: 1.000673  [  960/ 3840]\n",
            "loss: 0.778779  [ 1120/ 3840]\n",
            "loss: 0.767527  [ 1280/ 3840]\n",
            "loss: 0.876810  [ 1440/ 3840]\n",
            "loss: 0.952566  [ 1600/ 3840]\n",
            "loss: 0.942456  [ 1760/ 3840]\n",
            "loss: 0.608944  [ 1920/ 3840]\n",
            "loss: 0.753629  [ 2080/ 3840]\n",
            "loss: 0.809025  [ 2240/ 3840]\n",
            "loss: 0.851517  [ 2400/ 3840]\n",
            "loss: 1.186505  [ 2560/ 3840]\n",
            "loss: 1.118560  [ 2720/ 3840]\n",
            "loss: 0.883331  [ 2880/ 3840]\n",
            "loss: 0.892099  [ 3040/ 3840]\n",
            "loss: 0.862748  [ 3200/ 3840]\n",
            "loss: 0.810850  [ 3360/ 3840]\n",
            "loss: 0.704891  [ 3520/ 3840]\n",
            "loss: 0.992232  [ 3680/ 3840]\n",
            "Validation loss after epoch 3: 1.061913\n",
            "loss: 0.952573  [    0/ 3840]\n",
            "loss: 0.595571  [  160/ 3840]\n",
            "loss: 0.761075  [  320/ 3840]\n",
            "loss: 1.051465  [  480/ 3840]\n",
            "loss: 0.864896  [  640/ 3840]\n",
            "loss: 0.712861  [  800/ 3840]\n",
            "loss: 0.882857  [  960/ 3840]\n",
            "loss: 0.803480  [ 1120/ 3840]\n",
            "loss: 0.983963  [ 1280/ 3840]\n",
            "loss: 0.853078  [ 1440/ 3840]\n",
            "loss: 0.780291  [ 1600/ 3840]\n",
            "loss: 0.757395  [ 1760/ 3840]\n",
            "loss: 0.541504  [ 1920/ 3840]\n",
            "loss: 0.627272  [ 2080/ 3840]\n",
            "loss: 0.850594  [ 2240/ 3840]\n",
            "loss: 0.683365  [ 2400/ 3840]\n",
            "loss: 0.778149  [ 2560/ 3840]\n",
            "loss: 0.764965  [ 2720/ 3840]\n",
            "loss: 1.069379  [ 2880/ 3840]\n",
            "loss: 0.561981  [ 3040/ 3840]\n",
            "loss: 0.518021  [ 3200/ 3840]\n",
            "loss: 0.761468  [ 3360/ 3840]\n",
            "loss: 0.694663  [ 3520/ 3840]\n",
            "loss: 0.680964  [ 3680/ 3840]\n",
            "Validation loss after epoch 4: 1.081109\n",
            "loss: 0.786089  [    0/ 3840]\n",
            "loss: 0.756516  [  160/ 3840]\n",
            "loss: 0.583464  [  320/ 3840]\n",
            "loss: 0.630052  [  480/ 3840]\n",
            "loss: 0.834858  [  640/ 3840]\n",
            "loss: 0.872315  [  800/ 3840]\n",
            "loss: 0.620494  [  960/ 3840]\n",
            "loss: 0.335369  [ 1120/ 3840]\n",
            "loss: 0.464533  [ 1280/ 3840]\n",
            "loss: 0.624417  [ 1440/ 3840]\n",
            "loss: 0.699637  [ 1600/ 3840]\n",
            "loss: 0.525008  [ 1760/ 3840]\n",
            "loss: 0.530571  [ 1920/ 3840]\n",
            "loss: 0.849081  [ 2080/ 3840]\n",
            "loss: 0.761724  [ 2240/ 3840]\n",
            "loss: 0.427712  [ 2400/ 3840]\n",
            "loss: 0.787252  [ 2560/ 3840]\n",
            "loss: 0.320165  [ 2720/ 3840]\n",
            "loss: 0.270022  [ 2880/ 3840]\n",
            "loss: 0.553055  [ 3040/ 3840]\n",
            "loss: 0.694315  [ 3200/ 3840]\n",
            "loss: 0.402658  [ 3360/ 3840]\n",
            "loss: 0.759112  [ 3520/ 3840]\n",
            "loss: 0.611547  [ 3680/ 3840]\n",
            "Validation loss after epoch 5: 1.155535\n",
            "loss: 0.461821  [    0/ 3840]\n",
            "loss: 0.404263  [  160/ 3840]\n",
            "loss: 0.720250  [  320/ 3840]\n",
            "loss: 0.872842  [  480/ 3840]\n",
            "loss: 0.695776  [  640/ 3840]\n",
            "loss: 0.383289  [  800/ 3840]\n",
            "loss: 0.522553  [  960/ 3840]\n",
            "loss: 0.219904  [ 1120/ 3840]\n",
            "loss: 0.236892  [ 1280/ 3840]\n",
            "loss: 0.420933  [ 1440/ 3840]\n",
            "loss: 0.494263  [ 1600/ 3840]\n",
            "loss: 0.362110  [ 1760/ 3840]\n",
            "loss: 0.335670  [ 1920/ 3840]\n",
            "loss: 0.349036  [ 2080/ 3840]\n",
            "loss: 0.798882  [ 2240/ 3840]\n",
            "loss: 0.600928  [ 2400/ 3840]\n",
            "loss: 0.607758  [ 2560/ 3840]\n",
            "loss: 0.615952  [ 2720/ 3840]\n",
            "loss: 0.350465  [ 2880/ 3840]\n",
            "loss: 0.443571  [ 3040/ 3840]\n",
            "loss: 0.526928  [ 3200/ 3840]\n",
            "loss: 0.301721  [ 3360/ 3840]\n",
            "loss: 0.391858  [ 3520/ 3840]\n",
            "loss: 0.273812  [ 3680/ 3840]\n",
            "Validation loss after epoch 6: 1.303638\n",
            "Early stopping at epoch 7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-05-19 20:06:58,759] Trial 5 finished with value: 55.520833333333336 and parameters: {'dropout_rate': 0.16510669205050457, 'learning_rate': 1.6698446537668165e-05, 'batch_size': 16}. Best is trial 0 with value: 57.1875.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 1.791642  [    0/ 3840]\n",
            "loss: 1.811780  [   80/ 3840]\n",
            "loss: 1.751713  [  160/ 3840]\n",
            "loss: 1.751878  [  240/ 3840]\n",
            "loss: 1.723746  [  320/ 3840]\n",
            "loss: 1.701014  [  400/ 3840]\n",
            "loss: 1.673486  [  480/ 3840]\n",
            "loss: 1.600258  [  560/ 3840]\n",
            "loss: 1.671111  [  640/ 3840]\n",
            "loss: 1.382566  [  720/ 3840]\n",
            "loss: 1.360020  [  800/ 3840]\n",
            "loss: 1.227667  [  880/ 3840]\n",
            "loss: 1.445034  [  960/ 3840]\n",
            "loss: 1.150291  [ 1040/ 3840]\n",
            "loss: 1.371322  [ 1120/ 3840]\n",
            "loss: 1.296644  [ 1200/ 3840]\n",
            "loss: 1.156937  [ 1280/ 3840]\n",
            "loss: 1.137607  [ 1360/ 3840]\n",
            "loss: 1.414165  [ 1440/ 3840]\n",
            "loss: 1.262173  [ 1520/ 3840]\n",
            "loss: 1.256029  [ 1600/ 3840]\n",
            "loss: 1.230148  [ 1680/ 3840]\n",
            "loss: 1.482404  [ 1760/ 3840]\n",
            "loss: 1.129685  [ 1840/ 3840]\n",
            "loss: 1.071145  [ 1920/ 3840]\n",
            "loss: 1.193789  [ 2000/ 3840]\n",
            "loss: 1.168455  [ 2080/ 3840]\n",
            "loss: 0.884928  [ 2160/ 3840]\n",
            "loss: 0.932964  [ 2240/ 3840]\n",
            "loss: 0.917017  [ 2320/ 3840]\n",
            "loss: 1.292318  [ 2400/ 3840]\n",
            "loss: 0.971193  [ 2480/ 3840]\n",
            "loss: 0.899751  [ 2560/ 3840]\n",
            "loss: 1.385304  [ 2640/ 3840]\n",
            "loss: 0.943624  [ 2720/ 3840]\n",
            "loss: 1.096315  [ 2800/ 3840]\n",
            "loss: 1.005176  [ 2880/ 3840]\n",
            "loss: 1.170262  [ 2960/ 3840]\n",
            "loss: 1.782059  [ 3040/ 3840]\n",
            "loss: 1.439499  [ 3120/ 3840]\n",
            "loss: 1.212419  [ 3200/ 3840]\n",
            "loss: 1.114361  [ 3280/ 3840]\n",
            "loss: 1.390092  [ 3360/ 3840]\n",
            "loss: 1.416173  [ 3440/ 3840]\n",
            "loss: 1.012405  [ 3520/ 3840]\n",
            "loss: 0.929564  [ 3600/ 3840]\n",
            "loss: 0.832258  [ 3680/ 3840]\n",
            "loss: 1.500463  [ 3760/ 3840]\n",
            "Validation loss after epoch 1: 1.205104\n",
            "loss: 0.983994  [    0/ 3840]\n",
            "loss: 0.893130  [   80/ 3840]\n",
            "loss: 1.154980  [  160/ 3840]\n",
            "loss: 0.529998  [  240/ 3840]\n",
            "loss: 0.941104  [  320/ 3840]\n",
            "loss: 0.652208  [  400/ 3840]\n",
            "loss: 1.054304  [  480/ 3840]\n",
            "loss: 0.743579  [  560/ 3840]\n",
            "loss: 0.974444  [  640/ 3840]\n",
            "loss: 0.906112  [  720/ 3840]\n",
            "loss: 1.133154  [  800/ 3840]\n",
            "loss: 1.124676  [  880/ 3840]\n",
            "loss: 1.174435  [  960/ 3840]\n",
            "loss: 0.650327  [ 1040/ 3840]\n",
            "loss: 0.720538  [ 1120/ 3840]\n",
            "loss: 0.985183  [ 1200/ 3840]\n",
            "loss: 1.203603  [ 1280/ 3840]\n",
            "loss: 1.126879  [ 1360/ 3840]\n",
            "loss: 0.781075  [ 1440/ 3840]\n",
            "loss: 1.072282  [ 1520/ 3840]\n",
            "loss: 0.691902  [ 1600/ 3840]\n",
            "loss: 0.953782  [ 1680/ 3840]\n",
            "loss: 0.955198  [ 1760/ 3840]\n",
            "loss: 0.849485  [ 1840/ 3840]\n",
            "loss: 1.146756  [ 1920/ 3840]\n",
            "loss: 1.105460  [ 2000/ 3840]\n",
            "loss: 1.019345  [ 2080/ 3840]\n",
            "loss: 1.044598  [ 2160/ 3840]\n",
            "loss: 0.925252  [ 2240/ 3840]\n",
            "loss: 0.983551  [ 2320/ 3840]\n",
            "loss: 0.991006  [ 2400/ 3840]\n",
            "loss: 0.617332  [ 2480/ 3840]\n",
            "loss: 1.063655  [ 2560/ 3840]\n",
            "loss: 0.907426  [ 2640/ 3840]\n",
            "loss: 0.686993  [ 2720/ 3840]\n",
            "loss: 0.680840  [ 2800/ 3840]\n",
            "loss: 0.833567  [ 2880/ 3840]\n",
            "loss: 0.952848  [ 2960/ 3840]\n",
            "loss: 0.991203  [ 3040/ 3840]\n",
            "loss: 1.287786  [ 3120/ 3840]\n",
            "loss: 0.741057  [ 3200/ 3840]\n",
            "loss: 0.699943  [ 3280/ 3840]\n",
            "loss: 0.828203  [ 3360/ 3840]\n",
            "loss: 0.712526  [ 3440/ 3840]\n",
            "loss: 0.927846  [ 3520/ 3840]\n",
            "loss: 1.143048  [ 3600/ 3840]\n",
            "loss: 0.566649  [ 3680/ 3840]\n",
            "loss: 0.762584  [ 3760/ 3840]\n",
            "Validation loss after epoch 2: 1.070182\n",
            "loss: 0.864282  [    0/ 3840]\n",
            "loss: 0.795505  [   80/ 3840]\n",
            "loss: 0.449773  [  160/ 3840]\n",
            "loss: 0.694638  [  240/ 3840]\n",
            "loss: 0.532189  [  320/ 3840]\n",
            "loss: 0.713769  [  400/ 3840]\n",
            "loss: 1.177874  [  480/ 3840]\n",
            "loss: 0.383763  [  560/ 3840]\n",
            "loss: 0.499186  [  640/ 3840]\n",
            "loss: 0.865777  [  720/ 3840]\n",
            "loss: 0.837834  [  800/ 3840]\n",
            "loss: 0.611775  [  880/ 3840]\n",
            "loss: 0.519048  [  960/ 3840]\n",
            "loss: 0.466528  [ 1040/ 3840]\n",
            "loss: 0.647847  [ 1120/ 3840]\n",
            "loss: 0.779534  [ 1200/ 3840]\n",
            "loss: 0.524233  [ 1280/ 3840]\n",
            "loss: 0.481232  [ 1360/ 3840]\n",
            "loss: 0.703156  [ 1440/ 3840]\n",
            "loss: 1.072859  [ 1520/ 3840]\n",
            "loss: 0.450204  [ 1600/ 3840]\n",
            "loss: 0.999186  [ 1680/ 3840]\n",
            "loss: 0.449058  [ 1760/ 3840]\n",
            "loss: 0.695831  [ 1840/ 3840]\n",
            "loss: 0.690252  [ 1920/ 3840]\n",
            "loss: 0.447574  [ 2000/ 3840]\n",
            "loss: 0.226960  [ 2080/ 3840]\n",
            "loss: 1.425466  [ 2160/ 3840]\n",
            "loss: 0.432093  [ 2240/ 3840]\n",
            "loss: 0.194632  [ 2320/ 3840]\n",
            "loss: 1.024809  [ 2400/ 3840]\n",
            "loss: 0.546262  [ 2480/ 3840]\n",
            "loss: 0.510708  [ 2560/ 3840]\n",
            "loss: 0.927437  [ 2640/ 3840]\n",
            "loss: 0.780064  [ 2720/ 3840]\n",
            "loss: 0.520049  [ 2800/ 3840]\n",
            "loss: 1.369749  [ 2880/ 3840]\n",
            "loss: 0.515906  [ 2960/ 3840]\n",
            "loss: 0.537599  [ 3040/ 3840]\n",
            "loss: 0.866849  [ 3120/ 3840]\n",
            "loss: 1.344560  [ 3200/ 3840]\n",
            "loss: 0.589219  [ 3280/ 3840]\n",
            "loss: 0.872116  [ 3360/ 3840]\n",
            "loss: 0.768491  [ 3440/ 3840]\n",
            "loss: 1.058858  [ 3520/ 3840]\n",
            "loss: 0.653893  [ 3600/ 3840]\n",
            "loss: 0.868706  [ 3680/ 3840]\n",
            "loss: 1.137934  [ 3760/ 3840]\n",
            "Validation loss after epoch 3: 1.046543\n",
            "loss: 1.027559  [    0/ 3840]\n",
            "loss: 0.763076  [   80/ 3840]\n",
            "loss: 0.419590  [  160/ 3840]\n",
            "loss: 1.058865  [  240/ 3840]\n",
            "loss: 0.186795  [  320/ 3840]\n",
            "loss: 0.486676  [  400/ 3840]\n",
            "loss: 0.594056  [  480/ 3840]\n",
            "loss: 0.316874  [  560/ 3840]\n",
            "loss: 1.201538  [  640/ 3840]\n",
            "loss: 0.423773  [  720/ 3840]\n",
            "loss: 0.613736  [  800/ 3840]\n",
            "loss: 0.574695  [  880/ 3840]\n",
            "loss: 0.268925  [  960/ 3840]\n",
            "loss: 0.353404  [ 1040/ 3840]\n",
            "loss: 0.323785  [ 1120/ 3840]\n",
            "loss: 0.214195  [ 1200/ 3840]\n",
            "loss: 0.617776  [ 1280/ 3840]\n",
            "loss: 0.242995  [ 1360/ 3840]\n",
            "loss: 0.362152  [ 1440/ 3840]\n",
            "loss: 0.642763  [ 1520/ 3840]\n",
            "loss: 0.615282  [ 1600/ 3840]\n",
            "loss: 0.127224  [ 1680/ 3840]\n",
            "loss: 0.536992  [ 1760/ 3840]\n",
            "loss: 1.220831  [ 1840/ 3840]\n",
            "loss: 0.304840  [ 1920/ 3840]\n",
            "loss: 1.196048  [ 2000/ 3840]\n",
            "loss: 0.111512  [ 2080/ 3840]\n",
            "loss: 0.239335  [ 2160/ 3840]\n",
            "loss: 0.524723  [ 2240/ 3840]\n",
            "loss: 0.291183  [ 2320/ 3840]\n",
            "loss: 0.261407  [ 2400/ 3840]\n",
            "loss: 1.194457  [ 2480/ 3840]\n",
            "loss: 0.796247  [ 2560/ 3840]\n",
            "loss: 0.837317  [ 2640/ 3840]\n",
            "loss: 0.575202  [ 2720/ 3840]\n",
            "loss: 0.651331  [ 2800/ 3840]\n",
            "loss: 0.913685  [ 2880/ 3840]\n",
            "loss: 0.598654  [ 2960/ 3840]\n",
            "loss: 0.483677  [ 3040/ 3840]\n",
            "loss: 0.834796  [ 3120/ 3840]\n",
            "loss: 0.396046  [ 3200/ 3840]\n",
            "loss: 0.635297  [ 3280/ 3840]\n",
            "loss: 0.193534  [ 3360/ 3840]\n",
            "loss: 0.338940  [ 3440/ 3840]\n",
            "loss: 0.317838  [ 3520/ 3840]\n",
            "loss: 0.703607  [ 3600/ 3840]\n",
            "loss: 0.405243  [ 3680/ 3840]\n",
            "loss: 0.219571  [ 3760/ 3840]\n",
            "Validation loss after epoch 4: 1.240771\n",
            "loss: 0.565989  [    0/ 3840]\n",
            "loss: 0.430411  [   80/ 3840]\n",
            "loss: 0.205675  [  160/ 3840]\n",
            "loss: 0.120191  [  240/ 3840]\n",
            "loss: 0.077723  [  320/ 3840]\n",
            "loss: 0.469876  [  400/ 3840]\n",
            "loss: 0.199665  [  480/ 3840]\n",
            "loss: 0.126078  [  560/ 3840]\n",
            "loss: 0.406106  [  640/ 3840]\n",
            "loss: 0.606083  [  720/ 3840]\n",
            "loss: 0.088428  [  800/ 3840]\n",
            "loss: 0.076378  [  880/ 3840]\n",
            "loss: 0.212505  [  960/ 3840]\n",
            "loss: 0.580601  [ 1040/ 3840]\n",
            "loss: 0.477334  [ 1120/ 3840]\n",
            "loss: 0.452215  [ 1200/ 3840]\n",
            "loss: 0.789921  [ 1280/ 3840]\n",
            "loss: 0.317715  [ 1360/ 3840]\n",
            "loss: 0.391778  [ 1440/ 3840]\n",
            "loss: 0.102150  [ 1520/ 3840]\n",
            "loss: 0.685580  [ 1600/ 3840]\n",
            "loss: 0.563644  [ 1680/ 3840]\n",
            "loss: 0.496754  [ 1760/ 3840]\n",
            "loss: 0.094035  [ 1840/ 3840]\n",
            "loss: 0.112533  [ 1920/ 3840]\n",
            "loss: 0.083726  [ 2000/ 3840]\n",
            "loss: 0.229473  [ 2080/ 3840]\n",
            "loss: 0.206907  [ 2160/ 3840]\n",
            "loss: 0.242085  [ 2240/ 3840]\n",
            "loss: 0.084430  [ 2320/ 3840]\n",
            "loss: 0.344179  [ 2400/ 3840]\n",
            "loss: 0.235266  [ 2480/ 3840]\n",
            "loss: 0.521583  [ 2560/ 3840]\n",
            "loss: 0.619065  [ 2640/ 3840]\n",
            "loss: 0.347435  [ 2720/ 3840]\n",
            "loss: 0.059041  [ 2800/ 3840]\n",
            "loss: 0.202846  [ 2880/ 3840]\n",
            "loss: 0.619821  [ 2960/ 3840]\n",
            "loss: 0.390075  [ 3040/ 3840]\n",
            "loss: 0.458196  [ 3120/ 3840]\n",
            "loss: 0.214749  [ 3200/ 3840]\n",
            "loss: 0.075097  [ 3280/ 3840]\n",
            "loss: 0.317362  [ 3360/ 3840]\n",
            "loss: 0.091730  [ 3440/ 3840]\n",
            "loss: 0.443470  [ 3520/ 3840]\n",
            "loss: 0.453373  [ 3600/ 3840]\n",
            "loss: 0.394000  [ 3680/ 3840]\n",
            "loss: 0.285735  [ 3760/ 3840]\n",
            "Validation loss after epoch 5: 1.307173\n",
            "loss: 0.138025  [    0/ 3840]\n",
            "loss: 0.051920  [   80/ 3840]\n",
            "loss: 0.059970  [  160/ 3840]\n",
            "loss: 0.239923  [  240/ 3840]\n",
            "loss: 0.143278  [  320/ 3840]\n",
            "loss: 0.691300  [  400/ 3840]\n",
            "loss: 0.087454  [  480/ 3840]\n",
            "loss: 0.096621  [  560/ 3840]\n",
            "loss: 0.073325  [  640/ 3840]\n",
            "loss: 0.108519  [  720/ 3840]\n",
            "loss: 0.184010  [  800/ 3840]\n",
            "loss: 0.218179  [  880/ 3840]\n",
            "loss: 0.620632  [  960/ 3840]\n",
            "loss: 0.063572  [ 1040/ 3840]\n",
            "loss: 0.283914  [ 1120/ 3840]\n",
            "loss: 0.039972  [ 1200/ 3840]\n",
            "loss: 0.160132  [ 1280/ 3840]\n",
            "loss: 0.142037  [ 1360/ 3840]\n",
            "loss: 0.237617  [ 1440/ 3840]\n",
            "loss: 0.083883  [ 1520/ 3840]\n",
            "loss: 0.033165  [ 1600/ 3840]\n",
            "loss: 0.502936  [ 1680/ 3840]\n",
            "loss: 0.271375  [ 1760/ 3840]\n",
            "loss: 0.371211  [ 1840/ 3840]\n",
            "loss: 0.118486  [ 1920/ 3840]\n",
            "loss: 0.047270  [ 2000/ 3840]\n",
            "loss: 0.194791  [ 2080/ 3840]\n",
            "loss: 0.199073  [ 2160/ 3840]\n",
            "loss: 0.240368  [ 2240/ 3840]\n",
            "loss: 0.243152  [ 2320/ 3840]\n",
            "loss: 0.112796  [ 2400/ 3840]\n",
            "loss: 0.065655  [ 2480/ 3840]\n",
            "loss: 0.073941  [ 2560/ 3840]\n",
            "loss: 0.399872  [ 2640/ 3840]\n",
            "loss: 0.030550  [ 2720/ 3840]\n",
            "loss: 0.073703  [ 2800/ 3840]\n",
            "loss: 0.572244  [ 2880/ 3840]\n",
            "loss: 0.186128  [ 2960/ 3840]\n",
            "loss: 0.125966  [ 3040/ 3840]\n",
            "loss: 0.045084  [ 3120/ 3840]\n",
            "loss: 0.087965  [ 3200/ 3840]\n",
            "loss: 0.058041  [ 3280/ 3840]\n",
            "loss: 0.044989  [ 3360/ 3840]\n",
            "loss: 0.077349  [ 3440/ 3840]\n",
            "loss: 0.053501  [ 3520/ 3840]\n",
            "loss: 0.038816  [ 3600/ 3840]\n",
            "loss: 0.031166  [ 3680/ 3840]\n",
            "loss: 1.235394  [ 3760/ 3840]\n",
            "Validation loss after epoch 6: 1.577767\n",
            "Early stopping at epoch 7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-05-19 20:13:50,635] Trial 6 finished with value: 56.770833333333336 and parameters: {'dropout_rate': 0.21535729712988136, 'learning_rate': 3.286607220264114e-05, 'batch_size': 8}. Best is trial 0 with value: 57.1875.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 1.801138  [    0/ 3840]\n",
            "loss: 1.734853  [  160/ 3840]\n",
            "loss: 1.719693  [  320/ 3840]\n",
            "loss: 1.511726  [  480/ 3840]\n",
            "loss: 1.458647  [  640/ 3840]\n",
            "loss: 1.470159  [  800/ 3840]\n",
            "loss: 1.253058  [  960/ 3840]\n",
            "loss: 1.176525  [ 1120/ 3840]\n",
            "loss: 1.276942  [ 1280/ 3840]\n",
            "loss: 1.301191  [ 1440/ 3840]\n",
            "loss: 1.170704  [ 1600/ 3840]\n",
            "loss: 1.232754  [ 1760/ 3840]\n",
            "loss: 1.112718  [ 1920/ 3840]\n",
            "loss: 1.300033  [ 2080/ 3840]\n",
            "loss: 1.086923  [ 2240/ 3840]\n",
            "loss: 0.891632  [ 2400/ 3840]\n",
            "loss: 1.211126  [ 2560/ 3840]\n",
            "loss: 1.007790  [ 2720/ 3840]\n",
            "loss: 1.131388  [ 2880/ 3840]\n",
            "loss: 1.038096  [ 3040/ 3840]\n",
            "loss: 1.020921  [ 3200/ 3840]\n",
            "loss: 1.087424  [ 3360/ 3840]\n",
            "loss: 1.134423  [ 3520/ 3840]\n",
            "loss: 1.032115  [ 3680/ 3840]\n",
            "Validation loss after epoch 1: 1.076164\n",
            "loss: 0.820176  [    0/ 3840]\n",
            "loss: 1.071114  [  160/ 3840]\n",
            "loss: 1.046209  [  320/ 3840]\n",
            "loss: 0.765031  [  480/ 3840]\n",
            "loss: 0.733714  [  640/ 3840]\n",
            "loss: 0.654483  [  800/ 3840]\n",
            "loss: 0.873516  [  960/ 3840]\n",
            "loss: 1.028963  [ 1120/ 3840]\n",
            "loss: 0.640556  [ 1280/ 3840]\n",
            "loss: 1.043775  [ 1440/ 3840]\n",
            "loss: 1.339927  [ 1600/ 3840]\n",
            "loss: 0.822525  [ 1760/ 3840]\n",
            "loss: 1.070850  [ 1920/ 3840]\n",
            "loss: 0.637184  [ 2080/ 3840]\n",
            "loss: 0.876488  [ 2240/ 3840]\n",
            "loss: 0.939640  [ 2400/ 3840]\n",
            "loss: 0.796553  [ 2560/ 3840]\n",
            "loss: 0.772266  [ 2720/ 3840]\n",
            "loss: 0.872783  [ 2880/ 3840]\n",
            "loss: 0.939571  [ 3040/ 3840]\n",
            "loss: 0.978491  [ 3200/ 3840]\n",
            "loss: 0.735731  [ 3360/ 3840]\n",
            "loss: 1.291459  [ 3520/ 3840]\n",
            "loss: 1.030396  [ 3680/ 3840]\n",
            "Validation loss after epoch 2: 1.060761\n",
            "loss: 0.678056  [    0/ 3840]\n",
            "loss: 0.587653  [  160/ 3840]\n",
            "loss: 0.813550  [  320/ 3840]\n",
            "loss: 1.450078  [  480/ 3840]\n",
            "loss: 0.937328  [  640/ 3840]\n",
            "loss: 0.778777  [  800/ 3840]\n",
            "loss: 0.794430  [  960/ 3840]\n",
            "loss: 0.749247  [ 1120/ 3840]\n",
            "loss: 0.720636  [ 1280/ 3840]\n",
            "loss: 0.799418  [ 1440/ 3840]\n",
            "loss: 0.434654  [ 1600/ 3840]\n",
            "loss: 0.560352  [ 1760/ 3840]\n",
            "loss: 0.698811  [ 1920/ 3840]\n",
            "loss: 1.167321  [ 2080/ 3840]\n",
            "loss: 0.524789  [ 2240/ 3840]\n",
            "loss: 0.867508  [ 2400/ 3840]\n",
            "loss: 0.465088  [ 2560/ 3840]\n",
            "loss: 0.778287  [ 2720/ 3840]\n",
            "loss: 0.414238  [ 2880/ 3840]\n",
            "loss: 0.536329  [ 3040/ 3840]\n",
            "loss: 0.823174  [ 3200/ 3840]\n",
            "loss: 0.830816  [ 3360/ 3840]\n",
            "loss: 1.203729  [ 3520/ 3840]\n",
            "loss: 0.579253  [ 3680/ 3840]\n",
            "Validation loss after epoch 3: 1.143798\n",
            "loss: 0.726620  [    0/ 3840]\n",
            "loss: 0.428712  [  160/ 3840]\n",
            "loss: 0.434857  [  320/ 3840]\n",
            "loss: 0.350680  [  480/ 3840]\n",
            "loss: 0.490152  [  640/ 3840]\n",
            "loss: 0.425821  [  800/ 3840]\n",
            "loss: 0.516329  [  960/ 3840]\n",
            "loss: 0.275700  [ 1120/ 3840]\n",
            "loss: 0.254750  [ 1280/ 3840]\n",
            "loss: 0.458256  [ 1440/ 3840]\n",
            "loss: 0.523453  [ 1600/ 3840]\n",
            "loss: 0.507153  [ 1760/ 3840]\n",
            "loss: 0.261829  [ 1920/ 3840]\n",
            "loss: 0.601251  [ 2080/ 3840]\n",
            "loss: 0.523152  [ 2240/ 3840]\n",
            "loss: 0.427095  [ 2400/ 3840]\n",
            "loss: 0.796965  [ 2560/ 3840]\n",
            "loss: 0.269544  [ 2720/ 3840]\n",
            "loss: 0.817927  [ 2880/ 3840]\n",
            "loss: 0.441202  [ 3040/ 3840]\n",
            "loss: 0.937139  [ 3200/ 3840]\n",
            "loss: 1.891853  [ 3360/ 3840]\n",
            "loss: 1.829826  [ 3520/ 3840]\n",
            "loss: 1.787129  [ 3680/ 3840]\n",
            "Validation loss after epoch 4: 1.800183\n",
            "loss: 1.820158  [    0/ 3840]\n",
            "loss: 1.727620  [  160/ 3840]\n",
            "loss: 1.891188  [  320/ 3840]\n",
            "loss: 1.842804  [  480/ 3840]\n",
            "loss: 1.826103  [  640/ 3840]\n",
            "loss: 1.915501  [  800/ 3840]\n",
            "loss: 1.847655  [  960/ 3840]\n",
            "loss: 1.823995  [ 1120/ 3840]\n",
            "loss: 1.785427  [ 1280/ 3840]\n",
            "loss: 1.843860  [ 1440/ 3840]\n",
            "loss: 1.792226  [ 1600/ 3840]\n",
            "loss: 1.776109  [ 1760/ 3840]\n",
            "loss: 1.814632  [ 1920/ 3840]\n",
            "loss: 1.825416  [ 2080/ 3840]\n",
            "loss: 1.855555  [ 2240/ 3840]\n",
            "loss: 1.784036  [ 2400/ 3840]\n",
            "loss: 1.817293  [ 2560/ 3840]\n",
            "loss: 1.728968  [ 2720/ 3840]\n",
            "loss: 1.835232  [ 2880/ 3840]\n",
            "loss: 1.756361  [ 3040/ 3840]\n",
            "loss: 1.771220  [ 3200/ 3840]\n",
            "loss: 1.782995  [ 3360/ 3840]\n",
            "loss: 1.682320  [ 3520/ 3840]\n",
            "loss: 1.818022  [ 3680/ 3840]\n",
            "Validation loss after epoch 5: 1.819223\n",
            "Early stopping at epoch 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-05-19 20:19:14,246] Trial 7 finished with value: 16.979166666666668 and parameters: {'dropout_rate': 0.14600654737005986, 'learning_rate': 6.078572787249776e-05, 'batch_size': 16}. Best is trial 0 with value: 57.1875.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 1.759778  [    0/ 3840]\n",
            "loss: 1.801699  [   80/ 3840]\n",
            "loss: 1.749295  [  160/ 3840]\n",
            "loss: 1.653861  [  240/ 3840]\n",
            "loss: 1.486014  [  320/ 3840]\n",
            "loss: 1.385620  [  400/ 3840]\n",
            "loss: 1.583618  [  480/ 3840]\n",
            "loss: 1.266204  [  560/ 3840]\n",
            "loss: 1.309281  [  640/ 3840]\n",
            "loss: 1.463844  [  720/ 3840]\n",
            "loss: 1.303913  [  800/ 3840]\n",
            "loss: 1.151703  [  880/ 3840]\n",
            "loss: 1.128492  [  960/ 3840]\n",
            "loss: 1.242483  [ 1040/ 3840]\n",
            "loss: 1.465264  [ 1120/ 3840]\n",
            "loss: 1.245613  [ 1200/ 3840]\n",
            "loss: 1.161566  [ 1280/ 3840]\n",
            "loss: 1.283560  [ 1360/ 3840]\n",
            "loss: 1.248312  [ 1440/ 3840]\n",
            "loss: 1.048841  [ 1520/ 3840]\n",
            "loss: 1.442273  [ 1600/ 3840]\n",
            "loss: 1.335078  [ 1680/ 3840]\n",
            "loss: 1.457207  [ 1760/ 3840]\n",
            "loss: 2.188250  [ 1840/ 3840]\n",
            "loss: 1.350370  [ 1920/ 3840]\n",
            "loss: 1.732276  [ 2000/ 3840]\n",
            "loss: 1.603429  [ 2080/ 3840]\n",
            "loss: 1.634296  [ 2160/ 3840]\n",
            "loss: 1.617651  [ 2240/ 3840]\n",
            "loss: 1.830763  [ 2320/ 3840]\n",
            "loss: 1.297105  [ 2400/ 3840]\n",
            "loss: 1.922544  [ 2480/ 3840]\n",
            "loss: 1.765848  [ 2560/ 3840]\n",
            "loss: 1.547434  [ 2640/ 3840]\n",
            "loss: 1.796817  [ 2720/ 3840]\n",
            "loss: 1.316533  [ 2800/ 3840]\n",
            "loss: 1.360889  [ 2880/ 3840]\n",
            "loss: 1.042825  [ 2960/ 3840]\n",
            "loss: 1.470220  [ 3040/ 3840]\n",
            "loss: 1.592216  [ 3120/ 3840]\n",
            "loss: 1.589413  [ 3200/ 3840]\n",
            "loss: 1.819464  [ 3280/ 3840]\n",
            "loss: 1.075862  [ 3360/ 3840]\n",
            "loss: 1.296866  [ 3440/ 3840]\n",
            "loss: 1.279146  [ 3520/ 3840]\n",
            "loss: 1.090093  [ 3600/ 3840]\n",
            "loss: 1.370843  [ 3680/ 3840]\n",
            "loss: 1.705994  [ 3760/ 3840]\n",
            "Validation loss after epoch 1: 1.530972\n",
            "loss: 0.885571  [    0/ 3840]\n",
            "loss: 1.461641  [   80/ 3840]\n",
            "loss: 1.214897  [  160/ 3840]\n",
            "loss: 1.281697  [  240/ 3840]\n",
            "loss: 0.965918  [  320/ 3840]\n",
            "loss: 1.153427  [  400/ 3840]\n",
            "loss: 1.242174  [  480/ 3840]\n",
            "loss: 1.085023  [  560/ 3840]\n",
            "loss: 1.078951  [  640/ 3840]\n",
            "loss: 1.134129  [  720/ 3840]\n",
            "loss: 0.841720  [  800/ 3840]\n",
            "loss: 0.923048  [  880/ 3840]\n",
            "loss: 1.209693  [  960/ 3840]\n",
            "loss: 1.032758  [ 1040/ 3840]\n",
            "loss: 0.861433  [ 1120/ 3840]\n",
            "loss: 1.548012  [ 1200/ 3840]\n",
            "loss: 1.206333  [ 1280/ 3840]\n",
            "loss: 0.576747  [ 1360/ 3840]\n",
            "loss: 0.776908  [ 1440/ 3840]\n",
            "loss: 0.928497  [ 1520/ 3840]\n",
            "loss: 1.463370  [ 1600/ 3840]\n",
            "loss: 1.268758  [ 1680/ 3840]\n",
            "loss: 1.120493  [ 1760/ 3840]\n",
            "loss: 0.984713  [ 1840/ 3840]\n",
            "loss: 0.879812  [ 1920/ 3840]\n",
            "loss: 1.458507  [ 2000/ 3840]\n",
            "loss: 1.051131  [ 2080/ 3840]\n",
            "loss: 0.820625  [ 2160/ 3840]\n",
            "loss: 1.110755  [ 2240/ 3840]\n",
            "loss: 1.928873  [ 2320/ 3840]\n",
            "loss: 1.009787  [ 2400/ 3840]\n",
            "loss: 1.214524  [ 2480/ 3840]\n",
            "loss: 0.952906  [ 2560/ 3840]\n",
            "loss: 0.727733  [ 2640/ 3840]\n",
            "loss: 0.981482  [ 2720/ 3840]\n",
            "loss: 0.987706  [ 2800/ 3840]\n",
            "loss: 0.782725  [ 2880/ 3840]\n",
            "loss: 1.093652  [ 2960/ 3840]\n",
            "loss: 1.054944  [ 3040/ 3840]\n",
            "loss: 0.838882  [ 3120/ 3840]\n",
            "loss: 0.946935  [ 3200/ 3840]\n",
            "loss: 0.845613  [ 3280/ 3840]\n",
            "loss: 0.975665  [ 3360/ 3840]\n",
            "loss: 0.897552  [ 3440/ 3840]\n",
            "loss: 0.829450  [ 3520/ 3840]\n",
            "loss: 1.003669  [ 3600/ 3840]\n",
            "loss: 0.661780  [ 3680/ 3840]\n",
            "loss: 1.615426  [ 3760/ 3840]\n",
            "Validation loss after epoch 2: 1.163713\n",
            "loss: 0.989740  [    0/ 3840]\n",
            "loss: 0.862188  [   80/ 3840]\n",
            "loss: 0.740828  [  160/ 3840]\n",
            "loss: 1.051202  [  240/ 3840]\n",
            "loss: 0.838057  [  320/ 3840]\n",
            "loss: 0.729686  [  400/ 3840]\n",
            "loss: 0.797470  [  480/ 3840]\n",
            "loss: 1.364140  [  560/ 3840]\n",
            "loss: 0.662009  [  640/ 3840]\n",
            "loss: 0.887962  [  720/ 3840]\n",
            "loss: 0.519856  [  800/ 3840]\n",
            "loss: 1.210897  [  880/ 3840]\n",
            "loss: 0.748083  [  960/ 3840]\n",
            "loss: 0.889913  [ 1040/ 3840]\n",
            "loss: 0.794014  [ 1120/ 3840]\n",
            "loss: 0.990071  [ 1200/ 3840]\n",
            "loss: 0.646412  [ 1280/ 3840]\n",
            "loss: 0.882380  [ 1360/ 3840]\n",
            "loss: 0.989525  [ 1440/ 3840]\n",
            "loss: 1.392684  [ 1520/ 3840]\n",
            "loss: 1.088788  [ 1600/ 3840]\n",
            "loss: 1.497773  [ 1680/ 3840]\n",
            "loss: 1.348622  [ 1760/ 3840]\n",
            "loss: 0.971490  [ 1840/ 3840]\n",
            "loss: 0.708380  [ 1920/ 3840]\n",
            "loss: 0.905457  [ 2000/ 3840]\n",
            "loss: 0.678014  [ 2080/ 3840]\n",
            "loss: 1.044153  [ 2160/ 3840]\n",
            "loss: 0.686616  [ 2240/ 3840]\n",
            "loss: 0.771648  [ 2320/ 3840]\n",
            "loss: 0.937564  [ 2400/ 3840]\n",
            "loss: 1.056129  [ 2480/ 3840]\n",
            "loss: 0.736883  [ 2560/ 3840]\n",
            "loss: 0.904288  [ 2640/ 3840]\n",
            "loss: 0.803546  [ 2720/ 3840]\n",
            "loss: 1.428044  [ 2800/ 3840]\n",
            "loss: 1.023844  [ 2880/ 3840]\n",
            "loss: 1.387406  [ 2960/ 3840]\n",
            "loss: 1.128125  [ 3040/ 3840]\n",
            "loss: 1.282664  [ 3120/ 3840]\n",
            "loss: 0.854621  [ 3200/ 3840]\n",
            "loss: 0.794072  [ 3280/ 3840]\n",
            "loss: 1.223072  [ 3360/ 3840]\n",
            "loss: 0.609535  [ 3440/ 3840]\n",
            "loss: 0.695647  [ 3520/ 3840]\n",
            "loss: 0.924520  [ 3600/ 3840]\n",
            "loss: 0.800301  [ 3680/ 3840]\n",
            "loss: 0.985414  [ 3760/ 3840]\n",
            "Validation loss after epoch 3: 1.167837\n",
            "loss: 0.578192  [    0/ 3840]\n",
            "loss: 0.945661  [   80/ 3840]\n",
            "loss: 0.566370  [  160/ 3840]\n",
            "loss: 0.765891  [  240/ 3840]\n",
            "loss: 0.727033  [  320/ 3840]\n",
            "loss: 1.168442  [  400/ 3840]\n",
            "loss: 0.707966  [  480/ 3840]\n",
            "loss: 0.595962  [  560/ 3840]\n",
            "loss: 0.586771  [  640/ 3840]\n",
            "loss: 1.339195  [  720/ 3840]\n",
            "loss: 0.986910  [  800/ 3840]\n",
            "loss: 1.754290  [  880/ 3840]\n",
            "loss: 1.244243  [  960/ 3840]\n",
            "loss: 1.166687  [ 1040/ 3840]\n",
            "loss: 0.969106  [ 1120/ 3840]\n",
            "loss: 1.172403  [ 1200/ 3840]\n",
            "loss: 1.168806  [ 1280/ 3840]\n",
            "loss: 1.048266  [ 1360/ 3840]\n",
            "loss: 0.770805  [ 1440/ 3840]\n",
            "loss: 0.869442  [ 1520/ 3840]\n",
            "loss: 0.803022  [ 1600/ 3840]\n",
            "loss: 1.173490  [ 1680/ 3840]\n",
            "loss: 0.749521  [ 1760/ 3840]\n",
            "loss: 0.888745  [ 1840/ 3840]\n",
            "loss: 0.847108  [ 1920/ 3840]\n",
            "loss: 1.562611  [ 2000/ 3840]\n",
            "loss: 1.060604  [ 2080/ 3840]\n",
            "loss: 0.825202  [ 2160/ 3840]\n",
            "loss: 0.896031  [ 2240/ 3840]\n",
            "loss: 1.143333  [ 2320/ 3840]\n",
            "loss: 0.820455  [ 2400/ 3840]\n",
            "loss: 0.780886  [ 2480/ 3840]\n",
            "loss: 0.746442  [ 2560/ 3840]\n",
            "loss: 1.361158  [ 2640/ 3840]\n",
            "loss: 0.834215  [ 2720/ 3840]\n",
            "loss: 0.764662  [ 2800/ 3840]\n",
            "loss: 0.637163  [ 2880/ 3840]\n",
            "loss: 0.786911  [ 2960/ 3840]\n",
            "loss: 0.937545  [ 3040/ 3840]\n",
            "loss: 0.532237  [ 3120/ 3840]\n",
            "loss: 0.741352  [ 3200/ 3840]\n",
            "loss: 1.123529  [ 3280/ 3840]\n",
            "loss: 0.888015  [ 3360/ 3840]\n",
            "loss: 0.580511  [ 3440/ 3840]\n",
            "loss: 0.806319  [ 3520/ 3840]\n",
            "loss: 0.325588  [ 3600/ 3840]\n",
            "loss: 0.299771  [ 3680/ 3840]\n",
            "loss: 0.742228  [ 3760/ 3840]\n",
            "Validation loss after epoch 4: 1.260358\n",
            "loss: 0.747397  [    0/ 3840]\n",
            "loss: 0.456775  [   80/ 3840]\n",
            "loss: 0.356850  [  160/ 3840]\n",
            "loss: 0.696655  [  240/ 3840]\n",
            "loss: 0.596156  [  320/ 3840]\n",
            "loss: 0.542970  [  400/ 3840]\n",
            "loss: 1.220363  [  480/ 3840]\n",
            "loss: 0.479937  [  560/ 3840]\n",
            "loss: 0.589851  [  640/ 3840]\n",
            "loss: 0.885260  [  720/ 3840]\n",
            "loss: 0.652224  [  800/ 3840]\n",
            "loss: 0.827690  [  880/ 3840]\n",
            "loss: 0.480550  [  960/ 3840]\n",
            "loss: 0.455116  [ 1040/ 3840]\n",
            "loss: 0.370860  [ 1120/ 3840]\n",
            "loss: 0.694057  [ 1200/ 3840]\n",
            "loss: 0.798540  [ 1280/ 3840]\n",
            "loss: 0.709797  [ 1360/ 3840]\n",
            "loss: 0.632200  [ 1440/ 3840]\n",
            "loss: 0.554112  [ 1520/ 3840]\n",
            "loss: 0.611727  [ 1600/ 3840]\n",
            "loss: 0.834727  [ 1680/ 3840]\n",
            "loss: 0.630712  [ 1760/ 3840]\n",
            "loss: 0.566644  [ 1840/ 3840]\n",
            "loss: 0.700572  [ 1920/ 3840]\n",
            "loss: 1.709579  [ 2000/ 3840]\n",
            "loss: 1.104266  [ 2080/ 3840]\n",
            "loss: 2.427308  [ 2160/ 3840]\n",
            "loss: 1.262185  [ 2240/ 3840]\n",
            "loss: 2.075586  [ 2320/ 3840]\n",
            "loss: 1.466957  [ 2400/ 3840]\n",
            "loss: 1.567844  [ 2480/ 3840]\n",
            "loss: 1.851714  [ 2560/ 3840]\n",
            "loss: 1.796657  [ 2640/ 3840]\n",
            "loss: 1.920347  [ 2720/ 3840]\n",
            "loss: 2.001420  [ 2800/ 3840]\n",
            "loss: 1.707139  [ 2880/ 3840]\n",
            "loss: 1.773862  [ 2960/ 3840]\n",
            "loss: 1.613536  [ 3040/ 3840]\n",
            "loss: 1.897321  [ 3120/ 3840]\n",
            "loss: 2.017616  [ 3200/ 3840]\n",
            "loss: 1.761424  [ 3280/ 3840]\n",
            "loss: 1.956333  [ 3360/ 3840]\n",
            "loss: 1.802796  [ 3440/ 3840]\n",
            "loss: 1.844706  [ 3520/ 3840]\n",
            "loss: 1.855403  [ 3600/ 3840]\n",
            "loss: 1.842214  [ 3680/ 3840]\n",
            "loss: 1.690480  [ 3760/ 3840]\n",
            "Validation loss after epoch 5: 1.820017\n",
            "Early stopping at epoch 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-05-19 20:24:58,143] Trial 8 finished with value: 16.5625 and parameters: {'dropout_rate': 0.21680230774581252, 'learning_rate': 7.218851585414927e-05, 'batch_size': 8}. Best is trial 0 with value: 57.1875.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 1.772724  [    0/ 3840]\n",
            "loss: 1.794781  [  160/ 3840]\n",
            "loss: 1.740477  [  320/ 3840]\n",
            "loss: 1.762596  [  480/ 3840]\n",
            "loss: 1.696613  [  640/ 3840]\n",
            "loss: 1.651944  [  800/ 3840]\n",
            "loss: 1.510861  [  960/ 3840]\n",
            "loss: 1.669775  [ 1120/ 3840]\n",
            "loss: 1.425458  [ 1280/ 3840]\n",
            "loss: 1.348425  [ 1440/ 3840]\n",
            "loss: 1.361950  [ 1600/ 3840]\n",
            "loss: 1.277778  [ 1760/ 3840]\n",
            "loss: 1.367550  [ 1920/ 3840]\n",
            "loss: 1.414651  [ 2080/ 3840]\n",
            "loss: 1.458266  [ 2240/ 3840]\n",
            "loss: 1.252931  [ 2400/ 3840]\n",
            "loss: 1.281924  [ 2560/ 3840]\n",
            "loss: 1.198006  [ 2720/ 3840]\n",
            "loss: 1.477433  [ 2880/ 3840]\n",
            "loss: 1.226539  [ 3040/ 3840]\n",
            "loss: 1.230293  [ 3200/ 3840]\n",
            "loss: 1.181292  [ 3360/ 3840]\n",
            "loss: 1.191907  [ 3520/ 3840]\n",
            "loss: 1.218617  [ 3680/ 3840]\n",
            "Validation loss after epoch 1: 1.192899\n",
            "loss: 1.324124  [    0/ 3840]\n",
            "loss: 1.172847  [  160/ 3840]\n",
            "loss: 0.879855  [  320/ 3840]\n",
            "loss: 1.010533  [  480/ 3840]\n",
            "loss: 0.927704  [  640/ 3840]\n",
            "loss: 1.115209  [  800/ 3840]\n",
            "loss: 0.918942  [  960/ 3840]\n",
            "loss: 1.185006  [ 1120/ 3840]\n",
            "loss: 1.092708  [ 1280/ 3840]\n",
            "loss: 1.300929  [ 1440/ 3840]\n",
            "loss: 1.176654  [ 1600/ 3840]\n",
            "loss: 0.951492  [ 1760/ 3840]\n",
            "loss: 1.288170  [ 1920/ 3840]\n",
            "loss: 1.003428  [ 2080/ 3840]\n",
            "loss: 1.034947  [ 2240/ 3840]\n",
            "loss: 0.918966  [ 2400/ 3840]\n",
            "loss: 0.910111  [ 2560/ 3840]\n",
            "loss: 0.916456  [ 2720/ 3840]\n",
            "loss: 1.108825  [ 2880/ 3840]\n",
            "loss: 1.062334  [ 3040/ 3840]\n",
            "loss: 1.273345  [ 3200/ 3840]\n",
            "loss: 1.208189  [ 3360/ 3840]\n",
            "loss: 1.403437  [ 3520/ 3840]\n",
            "loss: 0.948863  [ 3680/ 3840]\n",
            "Validation loss after epoch 2: 1.063334\n",
            "loss: 1.222164  [    0/ 3840]\n",
            "loss: 0.988217  [  160/ 3840]\n",
            "loss: 0.611415  [  320/ 3840]\n",
            "loss: 0.674026  [  480/ 3840]\n",
            "loss: 0.949839  [  640/ 3840]\n",
            "loss: 0.617423  [  800/ 3840]\n",
            "loss: 0.945809  [  960/ 3840]\n",
            "loss: 0.545989  [ 1120/ 3840]\n",
            "loss: 0.922930  [ 1280/ 3840]\n",
            "loss: 0.863708  [ 1440/ 3840]\n",
            "loss: 0.829236  [ 1600/ 3840]\n",
            "loss: 0.682135  [ 1760/ 3840]\n",
            "loss: 0.676638  [ 1920/ 3840]\n",
            "loss: 0.600167  [ 2080/ 3840]\n",
            "loss: 0.594770  [ 2240/ 3840]\n",
            "loss: 0.934725  [ 2400/ 3840]\n",
            "loss: 0.954489  [ 2560/ 3840]\n",
            "loss: 0.581599  [ 2720/ 3840]\n",
            "loss: 0.958834  [ 2880/ 3840]\n",
            "loss: 0.772590  [ 3040/ 3840]\n",
            "loss: 0.819038  [ 3200/ 3840]\n",
            "loss: 0.793791  [ 3360/ 3840]\n",
            "loss: 0.676197  [ 3520/ 3840]\n",
            "loss: 0.742192  [ 3680/ 3840]\n",
            "Validation loss after epoch 3: 1.163105\n",
            "loss: 0.549998  [    0/ 3840]\n",
            "loss: 0.599036  [  160/ 3840]\n",
            "loss: 0.479384  [  320/ 3840]\n",
            "loss: 0.594349  [  480/ 3840]\n",
            "loss: 0.597856  [  640/ 3840]\n",
            "loss: 0.523448  [  800/ 3840]\n",
            "loss: 0.523086  [  960/ 3840]\n",
            "loss: 0.629732  [ 1120/ 3840]\n",
            "loss: 0.339578  [ 1280/ 3840]\n",
            "loss: 0.688768  [ 1440/ 3840]\n",
            "loss: 0.812907  [ 1600/ 3840]\n",
            "loss: 0.455016  [ 1760/ 3840]\n",
            "loss: 0.757734  [ 1920/ 3840]\n",
            "loss: 0.406945  [ 2080/ 3840]\n",
            "loss: 0.631692  [ 2240/ 3840]\n",
            "loss: 0.804239  [ 2400/ 3840]\n",
            "loss: 1.022601  [ 2560/ 3840]\n",
            "loss: 0.640390  [ 2720/ 3840]\n",
            "loss: 0.862688  [ 2880/ 3840]\n",
            "loss: 0.926385  [ 3040/ 3840]\n",
            "loss: 0.452459  [ 3200/ 3840]\n",
            "loss: 0.352266  [ 3360/ 3840]\n",
            "loss: 0.670898  [ 3520/ 3840]\n",
            "loss: 0.559978  [ 3680/ 3840]\n",
            "Validation loss after epoch 4: 1.202518\n",
            "loss: 0.399627  [    0/ 3840]\n",
            "loss: 0.379107  [  160/ 3840]\n",
            "loss: 0.301843  [  320/ 3840]\n",
            "loss: 0.461631  [  480/ 3840]\n",
            "loss: 0.305961  [  640/ 3840]\n",
            "loss: 0.391570  [  800/ 3840]\n",
            "loss: 0.773661  [  960/ 3840]\n",
            "loss: 0.736504  [ 1120/ 3840]\n",
            "loss: 0.409369  [ 1280/ 3840]\n",
            "loss: 0.197254  [ 1440/ 3840]\n",
            "loss: 0.666264  [ 1600/ 3840]\n",
            "loss: 0.410577  [ 1760/ 3840]\n",
            "loss: 0.274250  [ 1920/ 3840]\n",
            "loss: 0.850309  [ 2080/ 3840]\n",
            "loss: 0.525722  [ 2240/ 3840]\n",
            "loss: 0.727276  [ 2400/ 3840]\n",
            "loss: 0.557977  [ 2560/ 3840]\n",
            "loss: 0.324842  [ 2720/ 3840]\n",
            "loss: 0.156800  [ 2880/ 3840]\n",
            "loss: 0.547107  [ 3040/ 3840]\n",
            "loss: 0.301981  [ 3200/ 3840]\n",
            "loss: 0.208122  [ 3360/ 3840]\n",
            "loss: 0.770544  [ 3520/ 3840]\n",
            "loss: 0.566979  [ 3680/ 3840]\n",
            "Validation loss after epoch 5: 1.398040\n",
            "Early stopping at epoch 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-05-19 20:30:21,402] Trial 9 finished with value: 54.270833333333336 and parameters: {'dropout_rate': 0.2547199397220309, 'learning_rate': 2.8126699154961662e-05, 'batch_size': 16}. Best is trial 0 with value: 57.1875.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 1.803991  [    0/ 3840]\n",
            "loss: 1.762937  [   80/ 3840]\n",
            "loss: 1.757087  [  160/ 3840]\n",
            "loss: 1.805534  [  240/ 3840]\n",
            "loss: 1.818688  [  320/ 3840]\n",
            "loss: 1.738936  [  400/ 3840]\n",
            "loss: 1.771736  [  480/ 3840]\n",
            "loss: 1.751715  [  560/ 3840]\n",
            "loss: 1.748684  [  640/ 3840]\n",
            "loss: 1.749450  [  720/ 3840]\n",
            "loss: 1.682903  [  800/ 3840]\n",
            "loss: 1.699103  [  880/ 3840]\n",
            "loss: 1.685126  [  960/ 3840]\n",
            "loss: 1.719036  [ 1040/ 3840]\n",
            "loss: 1.625442  [ 1120/ 3840]\n",
            "loss: 1.614563  [ 1200/ 3840]\n",
            "loss: 1.651366  [ 1280/ 3840]\n",
            "loss: 1.554643  [ 1360/ 3840]\n",
            "loss: 1.698586  [ 1440/ 3840]\n",
            "loss: 1.533662  [ 1520/ 3840]\n",
            "loss: 1.379528  [ 1600/ 3840]\n",
            "loss: 1.512586  [ 1680/ 3840]\n",
            "loss: 1.385056  [ 1760/ 3840]\n",
            "loss: 1.540999  [ 1840/ 3840]\n",
            "loss: 1.351382  [ 1920/ 3840]\n",
            "loss: 1.361549  [ 2000/ 3840]\n",
            "loss: 1.402041  [ 2080/ 3840]\n",
            "loss: 1.616820  [ 2160/ 3840]\n",
            "loss: 1.429553  [ 2240/ 3840]\n",
            "loss: 1.364997  [ 2320/ 3840]\n",
            "loss: 1.455126  [ 2400/ 3840]\n",
            "loss: 1.350714  [ 2480/ 3840]\n",
            "loss: 1.360701  [ 2560/ 3840]\n",
            "loss: 1.535612  [ 2640/ 3840]\n",
            "loss: 1.313068  [ 2720/ 3840]\n",
            "loss: 1.144059  [ 2800/ 3840]\n",
            "loss: 1.143453  [ 2880/ 3840]\n",
            "loss: 1.288628  [ 2960/ 3840]\n",
            "loss: 1.256570  [ 3040/ 3840]\n",
            "loss: 1.144609  [ 3120/ 3840]\n",
            "loss: 1.227399  [ 3200/ 3840]\n",
            "loss: 1.402788  [ 3280/ 3840]\n",
            "loss: 1.158475  [ 3360/ 3840]\n",
            "loss: 1.097752  [ 3440/ 3840]\n",
            "loss: 1.262563  [ 3520/ 3840]\n",
            "loss: 1.296704  [ 3600/ 3840]\n",
            "loss: 1.460568  [ 3680/ 3840]\n",
            "loss: 1.267802  [ 3760/ 3840]\n",
            "Validation loss after epoch 1: 1.220700\n",
            "loss: 1.230429  [    0/ 3840]\n",
            "loss: 1.186686  [   80/ 3840]\n",
            "loss: 1.544437  [  160/ 3840]\n",
            "loss: 0.999536  [  240/ 3840]\n",
            "loss: 1.097978  [  320/ 3840]\n",
            "loss: 1.214544  [  400/ 3840]\n",
            "loss: 1.613191  [  480/ 3840]\n",
            "loss: 1.131882  [  560/ 3840]\n",
            "loss: 1.088944  [  640/ 3840]\n",
            "loss: 0.924742  [  720/ 3840]\n",
            "loss: 1.091557  [  800/ 3840]\n",
            "loss: 1.040037  [  880/ 3840]\n",
            "loss: 0.934420  [  960/ 3840]\n",
            "loss: 1.098569  [ 1040/ 3840]\n",
            "loss: 1.137821  [ 1120/ 3840]\n",
            "loss: 1.517899  [ 1200/ 3840]\n",
            "loss: 1.069944  [ 1280/ 3840]\n",
            "loss: 1.240592  [ 1360/ 3840]\n",
            "loss: 1.044428  [ 1440/ 3840]\n",
            "loss: 1.056453  [ 1520/ 3840]\n",
            "loss: 1.016629  [ 1600/ 3840]\n",
            "loss: 1.145332  [ 1680/ 3840]\n",
            "loss: 1.154960  [ 1760/ 3840]\n",
            "loss: 0.823049  [ 1840/ 3840]\n",
            "loss: 1.095630  [ 1920/ 3840]\n",
            "loss: 1.240674  [ 2000/ 3840]\n",
            "loss: 0.889612  [ 2080/ 3840]\n",
            "loss: 0.937952  [ 2160/ 3840]\n",
            "loss: 1.090596  [ 2240/ 3840]\n",
            "loss: 1.269879  [ 2320/ 3840]\n",
            "loss: 1.243978  [ 2400/ 3840]\n",
            "loss: 0.920009  [ 2480/ 3840]\n",
            "loss: 1.221120  [ 2560/ 3840]\n",
            "loss: 1.019727  [ 2640/ 3840]\n",
            "loss: 1.347095  [ 2720/ 3840]\n",
            "loss: 1.239238  [ 2800/ 3840]\n",
            "loss: 1.241640  [ 2880/ 3840]\n",
            "loss: 0.991695  [ 2960/ 3840]\n",
            "loss: 0.893977  [ 3040/ 3840]\n",
            "loss: 1.010137  [ 3120/ 3840]\n",
            "loss: 1.098094  [ 3200/ 3840]\n",
            "loss: 1.034321  [ 3280/ 3840]\n",
            "loss: 1.203498  [ 3360/ 3840]\n",
            "loss: 0.698243  [ 3440/ 3840]\n",
            "loss: 1.266852  [ 3520/ 3840]\n",
            "loss: 0.943682  [ 3600/ 3840]\n",
            "loss: 0.781514  [ 3680/ 3840]\n",
            "loss: 0.951081  [ 3760/ 3840]\n",
            "Validation loss after epoch 2: 1.086621\n",
            "loss: 0.693889  [    0/ 3840]\n",
            "loss: 0.824499  [   80/ 3840]\n",
            "loss: 0.818118  [  160/ 3840]\n",
            "loss: 0.653839  [  240/ 3840]\n",
            "loss: 0.840948  [  320/ 3840]\n",
            "loss: 0.881590  [  400/ 3840]\n",
            "loss: 1.234729  [  480/ 3840]\n",
            "loss: 1.001865  [  560/ 3840]\n",
            "loss: 0.863343  [  640/ 3840]\n",
            "loss: 0.965062  [  720/ 3840]\n",
            "loss: 0.933024  [  800/ 3840]\n",
            "loss: 0.678013  [  880/ 3840]\n",
            "loss: 0.894405  [  960/ 3840]\n",
            "loss: 0.764306  [ 1040/ 3840]\n",
            "loss: 0.665250  [ 1120/ 3840]\n",
            "loss: 0.907826  [ 1200/ 3840]\n",
            "loss: 1.158717  [ 1280/ 3840]\n",
            "loss: 0.993493  [ 1360/ 3840]\n",
            "loss: 1.173439  [ 1440/ 3840]\n",
            "loss: 0.818467  [ 1520/ 3840]\n",
            "loss: 0.985880  [ 1600/ 3840]\n",
            "loss: 0.891473  [ 1680/ 3840]\n",
            "loss: 0.714307  [ 1760/ 3840]\n",
            "loss: 0.658560  [ 1840/ 3840]\n",
            "loss: 0.594367  [ 1920/ 3840]\n",
            "loss: 1.117837  [ 2000/ 3840]\n",
            "loss: 1.047559  [ 2080/ 3840]\n",
            "loss: 0.939749  [ 2160/ 3840]\n",
            "loss: 0.684904  [ 2240/ 3840]\n",
            "loss: 0.938400  [ 2320/ 3840]\n",
            "loss: 0.635505  [ 2400/ 3840]\n",
            "loss: 0.940003  [ 2480/ 3840]\n",
            "loss: 0.832949  [ 2560/ 3840]\n",
            "loss: 0.633556  [ 2640/ 3840]\n",
            "loss: 0.513244  [ 2720/ 3840]\n",
            "loss: 0.720098  [ 2800/ 3840]\n",
            "loss: 0.807280  [ 2880/ 3840]\n",
            "loss: 0.966877  [ 2960/ 3840]\n",
            "loss: 0.820972  [ 3040/ 3840]\n",
            "loss: 0.692720  [ 3120/ 3840]\n",
            "loss: 0.606575  [ 3200/ 3840]\n",
            "loss: 0.712963  [ 3280/ 3840]\n",
            "loss: 0.989469  [ 3360/ 3840]\n",
            "loss: 1.076919  [ 3440/ 3840]\n",
            "loss: 0.432603  [ 3520/ 3840]\n",
            "loss: 1.057960  [ 3600/ 3840]\n",
            "loss: 1.151197  [ 3680/ 3840]\n",
            "loss: 0.718547  [ 3760/ 3840]\n",
            "Validation loss after epoch 3: 1.132578\n",
            "loss: 0.684475  [    0/ 3840]\n",
            "loss: 0.674679  [   80/ 3840]\n",
            "loss: 0.506663  [  160/ 3840]\n",
            "loss: 1.242605  [  240/ 3840]\n",
            "loss: 0.641023  [  320/ 3840]\n",
            "loss: 1.066612  [  400/ 3840]\n",
            "loss: 0.566132  [  480/ 3840]\n",
            "loss: 0.689746  [  560/ 3840]\n",
            "loss: 1.030473  [  640/ 3840]\n",
            "loss: 0.725672  [  720/ 3840]\n",
            "loss: 0.759035  [  800/ 3840]\n",
            "loss: 0.508268  [  880/ 3840]\n",
            "loss: 0.729357  [  960/ 3840]\n",
            "loss: 0.828490  [ 1040/ 3840]\n",
            "loss: 0.556582  [ 1120/ 3840]\n",
            "loss: 0.745820  [ 1200/ 3840]\n",
            "loss: 0.673573  [ 1280/ 3840]\n",
            "loss: 0.579590  [ 1360/ 3840]\n",
            "loss: 0.602925  [ 1440/ 3840]\n",
            "loss: 0.999804  [ 1520/ 3840]\n",
            "loss: 0.857346  [ 1600/ 3840]\n",
            "loss: 0.564389  [ 1680/ 3840]\n",
            "loss: 1.554564  [ 1760/ 3840]\n",
            "loss: 0.593546  [ 1840/ 3840]\n",
            "loss: 0.912500  [ 1920/ 3840]\n",
            "loss: 0.540755  [ 2000/ 3840]\n",
            "loss: 0.890632  [ 2080/ 3840]\n",
            "loss: 0.558282  [ 2160/ 3840]\n",
            "loss: 0.789657  [ 2240/ 3840]\n",
            "loss: 0.962345  [ 2320/ 3840]\n",
            "loss: 0.942360  [ 2400/ 3840]\n",
            "loss: 1.100615  [ 2480/ 3840]\n",
            "loss: 0.509742  [ 2560/ 3840]\n",
            "loss: 1.486969  [ 2640/ 3840]\n",
            "loss: 0.754400  [ 2720/ 3840]\n",
            "loss: 0.901824  [ 2800/ 3840]\n",
            "loss: 0.760343  [ 2880/ 3840]\n",
            "loss: 0.698419  [ 2960/ 3840]\n",
            "loss: 0.593180  [ 3040/ 3840]\n",
            "loss: 0.766089  [ 3120/ 3840]\n",
            "loss: 0.523571  [ 3200/ 3840]\n",
            "loss: 0.717331  [ 3280/ 3840]\n",
            "loss: 0.829497  [ 3360/ 3840]\n",
            "loss: 0.652995  [ 3440/ 3840]\n",
            "loss: 1.012824  [ 3520/ 3840]\n",
            "loss: 0.461722  [ 3600/ 3840]\n",
            "loss: 0.584024  [ 3680/ 3840]\n",
            "loss: 0.539072  [ 3760/ 3840]\n",
            "Validation loss after epoch 4: 1.092271\n",
            "loss: 0.721468  [    0/ 3840]\n",
            "loss: 0.667932  [   80/ 3840]\n",
            "loss: 0.622842  [  160/ 3840]\n",
            "loss: 0.654070  [  240/ 3840]\n",
            "loss: 1.121943  [  320/ 3840]\n",
            "loss: 0.676096  [  400/ 3840]\n",
            "loss: 0.666005  [  480/ 3840]\n",
            "loss: 0.266303  [  560/ 3840]\n",
            "loss: 0.752998  [  640/ 3840]\n",
            "loss: 0.300400  [  720/ 3840]\n",
            "loss: 0.633880  [  800/ 3840]\n",
            "loss: 0.896921  [  880/ 3840]\n",
            "loss: 0.449356  [  960/ 3840]\n",
            "loss: 0.773883  [ 1040/ 3840]\n",
            "loss: 0.641576  [ 1120/ 3840]\n",
            "loss: 0.299925  [ 1200/ 3840]\n",
            "loss: 0.966647  [ 1280/ 3840]\n",
            "loss: 0.864546  [ 1360/ 3840]\n",
            "loss: 0.281322  [ 1440/ 3840]\n",
            "loss: 0.273135  [ 1520/ 3840]\n",
            "loss: 0.594714  [ 1600/ 3840]\n",
            "loss: 0.437469  [ 1680/ 3840]\n",
            "loss: 0.466598  [ 1760/ 3840]\n",
            "loss: 0.273014  [ 1840/ 3840]\n",
            "loss: 0.492915  [ 1920/ 3840]\n",
            "loss: 0.992590  [ 2000/ 3840]\n",
            "loss: 0.549846  [ 2080/ 3840]\n",
            "loss: 0.776290  [ 2160/ 3840]\n",
            "loss: 0.328062  [ 2240/ 3840]\n",
            "loss: 0.984868  [ 2320/ 3840]\n",
            "loss: 0.583250  [ 2400/ 3840]\n",
            "loss: 0.578146  [ 2480/ 3840]\n",
            "loss: 0.569157  [ 2560/ 3840]\n",
            "loss: 0.494742  [ 2640/ 3840]\n",
            "loss: 0.465050  [ 2720/ 3840]\n",
            "loss: 0.810689  [ 2800/ 3840]\n",
            "loss: 0.807348  [ 2880/ 3840]\n",
            "loss: 0.608623  [ 2960/ 3840]\n",
            "loss: 0.545411  [ 3040/ 3840]\n",
            "loss: 0.635573  [ 3120/ 3840]\n",
            "loss: 0.664382  [ 3200/ 3840]\n",
            "loss: 0.364698  [ 3280/ 3840]\n",
            "loss: 0.760979  [ 3360/ 3840]\n",
            "loss: 0.333649  [ 3440/ 3840]\n",
            "loss: 0.702390  [ 3520/ 3840]\n",
            "loss: 0.532142  [ 3600/ 3840]\n",
            "loss: 0.371952  [ 3680/ 3840]\n",
            "loss: 1.083667  [ 3760/ 3840]\n",
            "Validation loss after epoch 5: 1.190729\n",
            "Early stopping at epoch 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-05-19 20:36:05,495] Trial 10 finished with value: 57.1875 and parameters: {'dropout_rate': 0.2966050832849558, 'learning_rate': 1.0913777203820318e-05, 'batch_size': 8}. Best is trial 0 with value: 57.1875.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 1.800329  [    0/ 3840]\n",
            "loss: 1.806790  [   80/ 3840]\n",
            "loss: 1.755720  [  160/ 3840]\n",
            "loss: 1.791056  [  240/ 3840]\n",
            "loss: 1.773137  [  320/ 3840]\n",
            "loss: 1.778527  [  400/ 3840]\n",
            "loss: 1.749097  [  480/ 3840]\n",
            "loss: 1.717401  [  560/ 3840]\n",
            "loss: 1.760790  [  640/ 3840]\n",
            "loss: 1.737756  [  720/ 3840]\n",
            "loss: 1.747980  [  800/ 3840]\n",
            "loss: 1.750713  [  880/ 3840]\n",
            "loss: 1.664871  [  960/ 3840]\n",
            "loss: 1.625270  [ 1040/ 3840]\n",
            "loss: 1.818245  [ 1120/ 3840]\n",
            "loss: 1.607177  [ 1200/ 3840]\n",
            "loss: 1.668313  [ 1280/ 3840]\n",
            "loss: 1.619181  [ 1360/ 3840]\n",
            "loss: 1.507530  [ 1440/ 3840]\n",
            "loss: 1.612039  [ 1520/ 3840]\n",
            "loss: 1.455975  [ 1600/ 3840]\n",
            "loss: 1.448509  [ 1680/ 3840]\n",
            "loss: 1.478015  [ 1760/ 3840]\n",
            "loss: 1.536513  [ 1840/ 3840]\n",
            "loss: 1.486985  [ 1920/ 3840]\n",
            "loss: 1.492711  [ 2000/ 3840]\n",
            "loss: 1.511030  [ 2080/ 3840]\n",
            "loss: 1.670952  [ 2160/ 3840]\n",
            "loss: 1.378063  [ 2240/ 3840]\n",
            "loss: 1.442890  [ 2320/ 3840]\n",
            "loss: 1.330664  [ 2400/ 3840]\n",
            "loss: 1.196759  [ 2480/ 3840]\n",
            "loss: 1.354222  [ 2560/ 3840]\n",
            "loss: 1.294419  [ 2640/ 3840]\n",
            "loss: 1.420436  [ 2720/ 3840]\n",
            "loss: 1.365440  [ 2800/ 3840]\n",
            "loss: 1.361875  [ 2880/ 3840]\n",
            "loss: 1.255236  [ 2960/ 3840]\n",
            "loss: 1.064981  [ 3040/ 3840]\n",
            "loss: 1.280901  [ 3120/ 3840]\n",
            "loss: 1.205565  [ 3200/ 3840]\n",
            "loss: 1.268057  [ 3280/ 3840]\n",
            "loss: 1.251634  [ 3360/ 3840]\n",
            "loss: 1.331860  [ 3440/ 3840]\n",
            "loss: 1.145666  [ 3520/ 3840]\n",
            "loss: 1.336230  [ 3600/ 3840]\n",
            "loss: 1.186985  [ 3680/ 3840]\n",
            "loss: 1.225671  [ 3760/ 3840]\n",
            "Validation loss after epoch 1: 1.246456\n",
            "loss: 1.258063  [    0/ 3840]\n",
            "loss: 1.204178  [   80/ 3840]\n",
            "loss: 1.049186  [  160/ 3840]\n",
            "loss: 1.172855  [  240/ 3840]\n",
            "loss: 1.307383  [  320/ 3840]\n",
            "loss: 1.231213  [  400/ 3840]\n",
            "loss: 1.137483  [  480/ 3840]\n",
            "loss: 1.406821  [  560/ 3840]\n",
            "loss: 1.054691  [  640/ 3840]\n",
            "loss: 1.126060  [  720/ 3840]\n",
            "loss: 1.277776  [  800/ 3840]\n",
            "loss: 0.888889  [  880/ 3840]\n",
            "loss: 1.063406  [  960/ 3840]\n",
            "loss: 0.992588  [ 1040/ 3840]\n",
            "loss: 1.273452  [ 1120/ 3840]\n",
            "loss: 0.866081  [ 1200/ 3840]\n",
            "loss: 1.182524  [ 1280/ 3840]\n",
            "loss: 1.277467  [ 1360/ 3840]\n",
            "loss: 1.296044  [ 1440/ 3840]\n",
            "loss: 1.031344  [ 1520/ 3840]\n",
            "loss: 1.025110  [ 1600/ 3840]\n",
            "loss: 1.099003  [ 1680/ 3840]\n",
            "loss: 1.099523  [ 1760/ 3840]\n",
            "loss: 0.844071  [ 1840/ 3840]\n",
            "loss: 0.955143  [ 1920/ 3840]\n",
            "loss: 0.992835  [ 2000/ 3840]\n",
            "loss: 1.332182  [ 2080/ 3840]\n",
            "loss: 1.167290  [ 2160/ 3840]\n",
            "loss: 1.175677  [ 2240/ 3840]\n",
            "loss: 1.310790  [ 2320/ 3840]\n",
            "loss: 1.298600  [ 2400/ 3840]\n",
            "loss: 1.140440  [ 2480/ 3840]\n",
            "loss: 0.856611  [ 2560/ 3840]\n",
            "loss: 1.387626  [ 2640/ 3840]\n",
            "loss: 1.276001  [ 2720/ 3840]\n",
            "loss: 0.954475  [ 2800/ 3840]\n",
            "loss: 1.060490  [ 2880/ 3840]\n",
            "loss: 0.996170  [ 2960/ 3840]\n",
            "loss: 1.096745  [ 3040/ 3840]\n",
            "loss: 1.165635  [ 3120/ 3840]\n",
            "loss: 0.977421  [ 3200/ 3840]\n",
            "loss: 0.955899  [ 3280/ 3840]\n",
            "loss: 0.936962  [ 3360/ 3840]\n",
            "loss: 0.875368  [ 3440/ 3840]\n",
            "loss: 0.856631  [ 3520/ 3840]\n",
            "loss: 0.944089  [ 3600/ 3840]\n",
            "loss: 0.905026  [ 3680/ 3840]\n",
            "loss: 0.998695  [ 3760/ 3840]\n",
            "Validation loss after epoch 2: 1.137216\n",
            "loss: 0.641086  [    0/ 3840]\n",
            "loss: 0.680264  [   80/ 3840]\n",
            "loss: 0.944292  [  160/ 3840]\n",
            "loss: 0.952049  [  240/ 3840]\n",
            "loss: 0.847150  [  320/ 3840]\n",
            "loss: 1.116287  [  400/ 3840]\n",
            "loss: 0.964931  [  480/ 3840]\n",
            "loss: 0.871604  [  560/ 3840]\n",
            "loss: 0.943114  [  640/ 3840]\n",
            "loss: 0.937713  [  720/ 3840]\n",
            "loss: 1.108884  [  800/ 3840]\n",
            "loss: 1.651109  [  880/ 3840]\n",
            "loss: 0.805762  [  960/ 3840]\n",
            "loss: 1.078379  [ 1040/ 3840]\n",
            "loss: 1.070503  [ 1120/ 3840]\n",
            "loss: 0.748491  [ 1200/ 3840]\n",
            "loss: 0.819177  [ 1280/ 3840]\n",
            "loss: 1.136631  [ 1360/ 3840]\n",
            "loss: 1.047516  [ 1440/ 3840]\n",
            "loss: 0.656354  [ 1520/ 3840]\n",
            "loss: 0.952096  [ 1600/ 3840]\n",
            "loss: 0.700441  [ 1680/ 3840]\n",
            "loss: 0.577266  [ 1760/ 3840]\n",
            "loss: 1.040537  [ 1840/ 3840]\n",
            "loss: 0.562639  [ 1920/ 3840]\n",
            "loss: 1.070464  [ 2000/ 3840]\n",
            "loss: 0.905584  [ 2080/ 3840]\n",
            "loss: 0.877333  [ 2160/ 3840]\n",
            "loss: 1.007314  [ 2240/ 3840]\n",
            "loss: 0.776787  [ 2320/ 3840]\n",
            "loss: 0.918096  [ 2400/ 3840]\n",
            "loss: 1.179665  [ 2480/ 3840]\n",
            "loss: 0.994938  [ 2560/ 3840]\n",
            "loss: 1.011225  [ 2640/ 3840]\n",
            "loss: 0.797863  [ 2720/ 3840]\n",
            "loss: 0.841861  [ 2800/ 3840]\n",
            "loss: 1.015881  [ 2880/ 3840]\n",
            "loss: 0.904413  [ 2960/ 3840]\n",
            "loss: 0.925576  [ 3040/ 3840]\n",
            "loss: 0.744887  [ 3120/ 3840]\n",
            "loss: 0.940270  [ 3200/ 3840]\n",
            "loss: 0.618068  [ 3280/ 3840]\n",
            "loss: 0.888709  [ 3360/ 3840]\n",
            "loss: 0.791516  [ 3440/ 3840]\n",
            "loss: 0.724598  [ 3520/ 3840]\n",
            "loss: 0.730793  [ 3600/ 3840]\n",
            "loss: 0.668958  [ 3680/ 3840]\n",
            "loss: 0.506844  [ 3760/ 3840]\n",
            "Validation loss after epoch 3: 1.057987\n",
            "loss: 0.788063  [    0/ 3840]\n",
            "loss: 0.792443  [   80/ 3840]\n",
            "loss: 0.804137  [  160/ 3840]\n",
            "loss: 0.907565  [  240/ 3840]\n",
            "loss: 0.770388  [  320/ 3840]\n",
            "loss: 0.612054  [  400/ 3840]\n",
            "loss: 0.602313  [  480/ 3840]\n",
            "loss: 0.626616  [  560/ 3840]\n",
            "loss: 0.951866  [  640/ 3840]\n",
            "loss: 0.765709  [  720/ 3840]\n",
            "loss: 0.728235  [  800/ 3840]\n",
            "loss: 0.641268  [  880/ 3840]\n",
            "loss: 0.538478  [  960/ 3840]\n",
            "loss: 0.768216  [ 1040/ 3840]\n",
            "loss: 0.892755  [ 1120/ 3840]\n",
            "loss: 0.665858  [ 1200/ 3840]\n",
            "loss: 0.598506  [ 1280/ 3840]\n",
            "loss: 0.706372  [ 1360/ 3840]\n",
            "loss: 0.501365  [ 1440/ 3840]\n",
            "loss: 0.674278  [ 1520/ 3840]\n",
            "loss: 0.694617  [ 1600/ 3840]\n",
            "loss: 0.968385  [ 1680/ 3840]\n",
            "loss: 0.546380  [ 1760/ 3840]\n",
            "loss: 0.897988  [ 1840/ 3840]\n",
            "loss: 0.738975  [ 1920/ 3840]\n",
            "loss: 0.845460  [ 2000/ 3840]\n",
            "loss: 0.713346  [ 2080/ 3840]\n",
            "loss: 1.051963  [ 2160/ 3840]\n",
            "loss: 0.794614  [ 2240/ 3840]\n",
            "loss: 1.406077  [ 2320/ 3840]\n",
            "loss: 0.497840  [ 2400/ 3840]\n",
            "loss: 0.517666  [ 2480/ 3840]\n",
            "loss: 1.106966  [ 2560/ 3840]\n",
            "loss: 0.479829  [ 2640/ 3840]\n",
            "loss: 0.437165  [ 2720/ 3840]\n",
            "loss: 0.567290  [ 2800/ 3840]\n",
            "loss: 0.322882  [ 2880/ 3840]\n",
            "loss: 1.759105  [ 2960/ 3840]\n",
            "loss: 0.611392  [ 3040/ 3840]\n",
            "loss: 0.959691  [ 3120/ 3840]\n",
            "loss: 0.553379  [ 3200/ 3840]\n",
            "loss: 1.160300  [ 3280/ 3840]\n",
            "loss: 0.711431  [ 3360/ 3840]\n",
            "loss: 0.318391  [ 3440/ 3840]\n",
            "loss: 0.659508  [ 3520/ 3840]\n",
            "loss: 1.362355  [ 3600/ 3840]\n",
            "loss: 0.821408  [ 3680/ 3840]\n",
            "loss: 0.334308  [ 3760/ 3840]\n",
            "Validation loss after epoch 4: 1.138569\n",
            "loss: 0.769915  [    0/ 3840]\n",
            "loss: 0.574872  [   80/ 3840]\n",
            "loss: 0.399778  [  160/ 3840]\n",
            "loss: 0.617541  [  240/ 3840]\n",
            "loss: 0.602738  [  320/ 3840]\n",
            "loss: 0.423384  [  400/ 3840]\n",
            "loss: 0.611359  [  480/ 3840]\n",
            "loss: 0.633351  [  560/ 3840]\n",
            "loss: 0.444983  [  640/ 3840]\n",
            "loss: 0.493177  [  720/ 3840]\n",
            "loss: 1.024952  [  800/ 3840]\n",
            "loss: 0.811232  [  880/ 3840]\n",
            "loss: 0.746603  [  960/ 3840]\n",
            "loss: 0.405456  [ 1040/ 3840]\n",
            "loss: 0.429026  [ 1120/ 3840]\n",
            "loss: 0.829939  [ 1200/ 3840]\n",
            "loss: 0.742298  [ 1280/ 3840]\n",
            "loss: 0.434417  [ 1360/ 3840]\n",
            "loss: 0.571261  [ 1440/ 3840]\n",
            "loss: 0.606054  [ 1520/ 3840]\n",
            "loss: 0.600650  [ 1600/ 3840]\n",
            "loss: 0.757755  [ 1680/ 3840]\n",
            "loss: 0.989517  [ 1760/ 3840]\n",
            "loss: 0.821894  [ 1840/ 3840]\n",
            "loss: 0.454381  [ 1920/ 3840]\n",
            "loss: 0.480555  [ 2000/ 3840]\n",
            "loss: 0.857787  [ 2080/ 3840]\n",
            "loss: 0.510249  [ 2160/ 3840]\n",
            "loss: 0.778071  [ 2240/ 3840]\n",
            "loss: 1.108705  [ 2320/ 3840]\n",
            "loss: 1.009005  [ 2400/ 3840]\n",
            "loss: 0.380205  [ 2480/ 3840]\n",
            "loss: 0.469382  [ 2560/ 3840]\n",
            "loss: 0.373239  [ 2640/ 3840]\n",
            "loss: 0.558661  [ 2720/ 3840]\n",
            "loss: 0.387511  [ 2800/ 3840]\n",
            "loss: 0.948353  [ 2880/ 3840]\n",
            "loss: 0.720588  [ 2960/ 3840]\n",
            "loss: 0.395783  [ 3040/ 3840]\n",
            "loss: 1.074234  [ 3120/ 3840]\n",
            "loss: 0.550819  [ 3200/ 3840]\n",
            "loss: 0.686998  [ 3280/ 3840]\n",
            "loss: 0.213358  [ 3360/ 3840]\n",
            "loss: 0.379340  [ 3440/ 3840]\n",
            "loss: 0.458804  [ 3520/ 3840]\n",
            "loss: 0.811647  [ 3600/ 3840]\n",
            "loss: 0.935258  [ 3680/ 3840]\n",
            "loss: 0.320395  [ 3760/ 3840]\n",
            "Validation loss after epoch 5: 1.306442\n",
            "loss: 0.277480  [    0/ 3840]\n",
            "loss: 0.718266  [   80/ 3840]\n",
            "loss: 0.357479  [  160/ 3840]\n",
            "loss: 0.646528  [  240/ 3840]\n",
            "loss: 0.985945  [  320/ 3840]\n",
            "loss: 0.342040  [  400/ 3840]\n",
            "loss: 0.456586  [  480/ 3840]\n",
            "loss: 0.616409  [  560/ 3840]\n",
            "loss: 0.419053  [  640/ 3840]\n",
            "loss: 0.266403  [  720/ 3840]\n",
            "loss: 0.361131  [  800/ 3840]\n",
            "loss: 0.212375  [  880/ 3840]\n",
            "loss: 0.399912  [  960/ 3840]\n",
            "loss: 0.786318  [ 1040/ 3840]\n",
            "loss: 0.482594  [ 1120/ 3840]\n",
            "loss: 0.285366  [ 1200/ 3840]\n",
            "loss: 0.749858  [ 1280/ 3840]\n",
            "loss: 0.274061  [ 1360/ 3840]\n",
            "loss: 0.596921  [ 1440/ 3840]\n",
            "loss: 0.258812  [ 1520/ 3840]\n",
            "loss: 0.248864  [ 1600/ 3840]\n",
            "loss: 0.351360  [ 1680/ 3840]\n",
            "loss: 0.408307  [ 1760/ 3840]\n",
            "loss: 0.264120  [ 1840/ 3840]\n",
            "loss: 0.378810  [ 1920/ 3840]\n",
            "loss: 0.705076  [ 2000/ 3840]\n",
            "loss: 0.533065  [ 2080/ 3840]\n",
            "loss: 0.287583  [ 2160/ 3840]\n",
            "loss: 0.258420  [ 2240/ 3840]\n",
            "loss: 0.262049  [ 2320/ 3840]\n",
            "loss: 0.260305  [ 2400/ 3840]\n",
            "loss: 0.193706  [ 2480/ 3840]\n",
            "loss: 0.771775  [ 2560/ 3840]\n",
            "loss: 0.545796  [ 2640/ 3840]\n",
            "loss: 0.209707  [ 2720/ 3840]\n",
            "loss: 0.415936  [ 2800/ 3840]\n",
            "loss: 0.266379  [ 2880/ 3840]\n",
            "loss: 0.705170  [ 2960/ 3840]\n",
            "loss: 0.188457  [ 3040/ 3840]\n",
            "loss: 1.040423  [ 3120/ 3840]\n",
            "loss: 0.707972  [ 3200/ 3840]\n",
            "loss: 0.340037  [ 3280/ 3840]\n",
            "loss: 0.420991  [ 3360/ 3840]\n",
            "loss: 0.541674  [ 3440/ 3840]\n",
            "loss: 0.246495  [ 3520/ 3840]\n",
            "loss: 0.307953  [ 3600/ 3840]\n",
            "loss: 0.652822  [ 3680/ 3840]\n",
            "loss: 1.133787  [ 3760/ 3840]\n",
            "Validation loss after epoch 6: 1.330525\n",
            "Early stopping at epoch 7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-05-19 20:42:57,168] Trial 11 finished with value: 53.4375 and parameters: {'dropout_rate': 0.2962443365520232, 'learning_rate': 1.013136619850021e-05, 'batch_size': 8}. Best is trial 0 with value: 57.1875.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 1.803863  [    0/ 3840]\n",
            "loss: 1.789879  [   80/ 3840]\n",
            "loss: 1.776979  [  160/ 3840]\n",
            "loss: 1.769239  [  240/ 3840]\n",
            "loss: 1.803255  [  320/ 3840]\n",
            "loss: 1.787060  [  400/ 3840]\n",
            "loss: 1.812553  [  480/ 3840]\n",
            "loss: 1.747170  [  560/ 3840]\n",
            "loss: 1.783709  [  640/ 3840]\n",
            "loss: 1.758328  [  720/ 3840]\n",
            "loss: 1.773925  [  800/ 3840]\n",
            "loss: 1.766698  [  880/ 3840]\n",
            "loss: 1.714194  [  960/ 3840]\n",
            "loss: 1.705171  [ 1040/ 3840]\n",
            "loss: 1.626514  [ 1120/ 3840]\n",
            "loss: 1.631704  [ 1200/ 3840]\n",
            "loss: 1.676335  [ 1280/ 3840]\n",
            "loss: 1.575749  [ 1360/ 3840]\n",
            "loss: 1.605995  [ 1440/ 3840]\n",
            "loss: 1.671682  [ 1520/ 3840]\n",
            "loss: 1.526705  [ 1600/ 3840]\n",
            "loss: 1.560141  [ 1680/ 3840]\n",
            "loss: 1.544321  [ 1760/ 3840]\n",
            "loss: 1.607767  [ 1840/ 3840]\n",
            "loss: 1.477294  [ 1920/ 3840]\n",
            "loss: 1.478114  [ 2000/ 3840]\n",
            "loss: 1.368649  [ 2080/ 3840]\n",
            "loss: 1.457687  [ 2160/ 3840]\n",
            "loss: 1.434580  [ 2240/ 3840]\n",
            "loss: 1.429767  [ 2320/ 3840]\n",
            "loss: 1.342080  [ 2400/ 3840]\n",
            "loss: 1.311737  [ 2480/ 3840]\n",
            "loss: 1.496544  [ 2560/ 3840]\n",
            "loss: 1.496360  [ 2640/ 3840]\n",
            "loss: 1.216286  [ 2720/ 3840]\n",
            "loss: 1.341874  [ 2800/ 3840]\n",
            "loss: 1.522373  [ 2880/ 3840]\n",
            "loss: 1.588977  [ 2960/ 3840]\n",
            "loss: 1.369016  [ 3040/ 3840]\n",
            "loss: 1.305812  [ 3120/ 3840]\n",
            "loss: 1.409733  [ 3200/ 3840]\n",
            "loss: 1.184678  [ 3280/ 3840]\n",
            "loss: 1.322669  [ 3360/ 3840]\n",
            "loss: 1.328477  [ 3440/ 3840]\n",
            "loss: 1.440561  [ 3520/ 3840]\n",
            "loss: 1.400497  [ 3600/ 3840]\n",
            "loss: 1.214744  [ 3680/ 3840]\n",
            "loss: 1.080739  [ 3760/ 3840]\n",
            "Validation loss after epoch 1: 1.256627\n",
            "loss: 1.192575  [    0/ 3840]\n",
            "loss: 1.047309  [   80/ 3840]\n",
            "loss: 1.308140  [  160/ 3840]\n",
            "loss: 1.243977  [  240/ 3840]\n",
            "loss: 1.539838  [  320/ 3840]\n",
            "loss: 0.911014  [  400/ 3840]\n",
            "loss: 1.350077  [  480/ 3840]\n",
            "loss: 1.397495  [  560/ 3840]\n",
            "loss: 1.267794  [  640/ 3840]\n",
            "loss: 0.943607  [  720/ 3840]\n",
            "loss: 0.994988  [  800/ 3840]\n",
            "loss: 1.137136  [  880/ 3840]\n",
            "loss: 1.173510  [  960/ 3840]\n",
            "loss: 0.983130  [ 1040/ 3840]\n",
            "loss: 1.271675  [ 1120/ 3840]\n",
            "loss: 1.003304  [ 1200/ 3840]\n",
            "loss: 1.351473  [ 1280/ 3840]\n",
            "loss: 1.095875  [ 1360/ 3840]\n",
            "loss: 1.005553  [ 1440/ 3840]\n",
            "loss: 1.521303  [ 1520/ 3840]\n",
            "loss: 1.338954  [ 1600/ 3840]\n",
            "loss: 1.026778  [ 1680/ 3840]\n",
            "loss: 1.083945  [ 1760/ 3840]\n",
            "loss: 1.331071  [ 1840/ 3840]\n",
            "loss: 1.217621  [ 1920/ 3840]\n",
            "loss: 0.949115  [ 2000/ 3840]\n",
            "loss: 1.251089  [ 2080/ 3840]\n",
            "loss: 1.289297  [ 2160/ 3840]\n",
            "loss: 1.051798  [ 2240/ 3840]\n",
            "loss: 0.917658  [ 2320/ 3840]\n",
            "loss: 0.900011  [ 2400/ 3840]\n",
            "loss: 1.199158  [ 2480/ 3840]\n",
            "loss: 1.162682  [ 2560/ 3840]\n",
            "loss: 1.240404  [ 2640/ 3840]\n",
            "loss: 1.198680  [ 2720/ 3840]\n",
            "loss: 1.088543  [ 2800/ 3840]\n",
            "loss: 1.206651  [ 2880/ 3840]\n",
            "loss: 0.738050  [ 2960/ 3840]\n",
            "loss: 1.134590  [ 3040/ 3840]\n",
            "loss: 1.100549  [ 3120/ 3840]\n",
            "loss: 1.014135  [ 3200/ 3840]\n",
            "loss: 0.859044  [ 3280/ 3840]\n",
            "loss: 1.021373  [ 3360/ 3840]\n",
            "loss: 1.065697  [ 3440/ 3840]\n",
            "loss: 0.957944  [ 3520/ 3840]\n",
            "loss: 1.315053  [ 3600/ 3840]\n",
            "loss: 1.330964  [ 3680/ 3840]\n",
            "loss: 1.082419  [ 3760/ 3840]\n",
            "Validation loss after epoch 2: 1.114321\n",
            "loss: 1.058272  [    0/ 3840]\n",
            "loss: 0.961903  [   80/ 3840]\n",
            "loss: 0.932251  [  160/ 3840]\n",
            "loss: 1.015019  [  240/ 3840]\n",
            "loss: 1.452555  [  320/ 3840]\n",
            "loss: 0.890040  [  400/ 3840]\n",
            "loss: 0.930435  [  480/ 3840]\n",
            "loss: 0.995449  [  560/ 3840]\n",
            "loss: 0.980096  [  640/ 3840]\n",
            "loss: 0.787833  [  720/ 3840]\n",
            "loss: 1.062324  [  800/ 3840]\n",
            "loss: 0.835904  [  880/ 3840]\n",
            "loss: 0.668863  [  960/ 3840]\n",
            "loss: 0.797375  [ 1040/ 3840]\n",
            "loss: 1.029056  [ 1120/ 3840]\n",
            "loss: 0.885596  [ 1200/ 3840]\n",
            "loss: 1.094582  [ 1280/ 3840]\n",
            "loss: 1.133011  [ 1360/ 3840]\n",
            "loss: 0.803756  [ 1440/ 3840]\n",
            "loss: 0.929508  [ 1520/ 3840]\n",
            "loss: 0.944264  [ 1600/ 3840]\n",
            "loss: 1.197614  [ 1680/ 3840]\n",
            "loss: 0.985035  [ 1760/ 3840]\n",
            "loss: 1.227581  [ 1840/ 3840]\n",
            "loss: 0.547753  [ 1920/ 3840]\n",
            "loss: 0.839339  [ 2000/ 3840]\n",
            "loss: 1.341132  [ 2080/ 3840]\n",
            "loss: 0.839962  [ 2160/ 3840]\n",
            "loss: 0.914768  [ 2240/ 3840]\n",
            "loss: 0.918192  [ 2320/ 3840]\n",
            "loss: 0.988352  [ 2400/ 3840]\n",
            "loss: 1.140722  [ 2480/ 3840]\n",
            "loss: 1.090610  [ 2560/ 3840]\n",
            "loss: 0.726951  [ 2640/ 3840]\n",
            "loss: 0.788894  [ 2720/ 3840]\n",
            "loss: 1.327461  [ 2800/ 3840]\n",
            "loss: 0.553305  [ 2880/ 3840]\n",
            "loss: 0.944786  [ 2960/ 3840]\n",
            "loss: 0.771906  [ 3040/ 3840]\n",
            "loss: 0.791621  [ 3120/ 3840]\n",
            "loss: 1.032199  [ 3200/ 3840]\n",
            "loss: 0.594454  [ 3280/ 3840]\n",
            "loss: 0.989314  [ 3360/ 3840]\n",
            "loss: 0.936693  [ 3440/ 3840]\n",
            "loss: 1.146864  [ 3520/ 3840]\n",
            "loss: 1.016221  [ 3600/ 3840]\n",
            "loss: 0.931034  [ 3680/ 3840]\n",
            "loss: 1.222704  [ 3760/ 3840]\n",
            "Validation loss after epoch 3: 1.102716\n",
            "loss: 1.033808  [    0/ 3840]\n",
            "loss: 0.912195  [   80/ 3840]\n",
            "loss: 0.820618  [  160/ 3840]\n",
            "loss: 0.964899  [  240/ 3840]\n",
            "loss: 0.788047  [  320/ 3840]\n",
            "loss: 0.960750  [  400/ 3840]\n",
            "loss: 0.869667  [  480/ 3840]\n",
            "loss: 0.804343  [  560/ 3840]\n",
            "loss: 0.943493  [  640/ 3840]\n",
            "loss: 0.877277  [  720/ 3840]\n",
            "loss: 1.088454  [  800/ 3840]\n",
            "loss: 0.882769  [  880/ 3840]\n",
            "loss: 0.770255  [  960/ 3840]\n",
            "loss: 0.666961  [ 1040/ 3840]\n",
            "loss: 1.095316  [ 1120/ 3840]\n",
            "loss: 0.636152  [ 1200/ 3840]\n",
            "loss: 0.446561  [ 1280/ 3840]\n",
            "loss: 0.716226  [ 1360/ 3840]\n",
            "loss: 0.825134  [ 1440/ 3840]\n",
            "loss: 0.764493  [ 1520/ 3840]\n",
            "loss: 0.648286  [ 1600/ 3840]\n",
            "loss: 0.788161  [ 1680/ 3840]\n",
            "loss: 0.735270  [ 1760/ 3840]\n",
            "loss: 0.850484  [ 1840/ 3840]\n",
            "loss: 0.791403  [ 1920/ 3840]\n",
            "loss: 0.584310  [ 2000/ 3840]\n",
            "loss: 0.669749  [ 2080/ 3840]\n",
            "loss: 0.629526  [ 2160/ 3840]\n",
            "loss: 0.441771  [ 2240/ 3840]\n",
            "loss: 0.712490  [ 2320/ 3840]\n",
            "loss: 0.613384  [ 2400/ 3840]\n",
            "loss: 0.472732  [ 2480/ 3840]\n",
            "loss: 0.678564  [ 2560/ 3840]\n",
            "loss: 0.660287  [ 2640/ 3840]\n",
            "loss: 1.351979  [ 2720/ 3840]\n",
            "loss: 0.576138  [ 2800/ 3840]\n",
            "loss: 1.006100  [ 2880/ 3840]\n",
            "loss: 0.868039  [ 2960/ 3840]\n",
            "loss: 0.643070  [ 3040/ 3840]\n",
            "loss: 0.609539  [ 3120/ 3840]\n",
            "loss: 0.450256  [ 3200/ 3840]\n",
            "loss: 0.593676  [ 3280/ 3840]\n",
            "loss: 0.655507  [ 3360/ 3840]\n",
            "loss: 2.037653  [ 3440/ 3840]\n",
            "loss: 0.721654  [ 3520/ 3840]\n",
            "loss: 0.635887  [ 3600/ 3840]\n",
            "loss: 0.767016  [ 3680/ 3840]\n",
            "loss: 0.990739  [ 3760/ 3840]\n",
            "Validation loss after epoch 4: 1.107663\n",
            "loss: 0.480089  [    0/ 3840]\n",
            "loss: 0.487299  [   80/ 3840]\n",
            "loss: 0.483939  [  160/ 3840]\n",
            "loss: 0.555622  [  240/ 3840]\n",
            "loss: 0.705530  [  320/ 3840]\n",
            "loss: 0.625007  [  400/ 3840]\n",
            "loss: 0.532933  [  480/ 3840]\n",
            "loss: 0.311183  [  560/ 3840]\n",
            "loss: 0.764452  [  640/ 3840]\n",
            "loss: 0.412534  [  720/ 3840]\n",
            "loss: 0.868532  [  800/ 3840]\n",
            "loss: 0.609691  [  880/ 3840]\n",
            "loss: 0.721386  [  960/ 3840]\n",
            "loss: 1.189149  [ 1040/ 3840]\n",
            "loss: 0.597281  [ 1120/ 3840]\n",
            "loss: 0.784240  [ 1200/ 3840]\n",
            "loss: 1.114163  [ 1280/ 3840]\n",
            "loss: 0.479081  [ 1360/ 3840]\n",
            "loss: 0.614122  [ 1440/ 3840]\n",
            "loss: 0.537387  [ 1520/ 3840]\n",
            "loss: 0.500187  [ 1600/ 3840]\n",
            "loss: 0.479645  [ 1680/ 3840]\n",
            "loss: 0.592078  [ 1760/ 3840]\n",
            "loss: 0.561077  [ 1840/ 3840]\n",
            "loss: 0.308240  [ 1920/ 3840]\n",
            "loss: 0.512387  [ 2000/ 3840]\n",
            "loss: 0.826696  [ 2080/ 3840]\n",
            "loss: 0.551695  [ 2160/ 3840]\n",
            "loss: 0.334317  [ 2240/ 3840]\n",
            "loss: 0.562681  [ 2320/ 3840]\n",
            "loss: 0.756424  [ 2400/ 3840]\n",
            "loss: 1.038406  [ 2480/ 3840]\n",
            "loss: 1.251245  [ 2560/ 3840]\n",
            "loss: 0.591737  [ 2640/ 3840]\n",
            "loss: 0.535026  [ 2720/ 3840]\n",
            "loss: 0.773138  [ 2800/ 3840]\n",
            "loss: 0.474384  [ 2880/ 3840]\n",
            "loss: 0.802159  [ 2960/ 3840]\n",
            "loss: 0.312132  [ 3040/ 3840]\n",
            "loss: 0.633121  [ 3120/ 3840]\n",
            "loss: 1.063099  [ 3200/ 3840]\n",
            "loss: 1.209587  [ 3280/ 3840]\n",
            "loss: 0.739880  [ 3360/ 3840]\n",
            "loss: 0.702203  [ 3440/ 3840]\n",
            "loss: 0.653859  [ 3520/ 3840]\n",
            "loss: 0.776758  [ 3600/ 3840]\n",
            "loss: 0.777607  [ 3680/ 3840]\n",
            "loss: 1.005556  [ 3760/ 3840]\n",
            "Validation loss after epoch 5: 1.189515\n",
            "loss: 0.695488  [    0/ 3840]\n",
            "loss: 0.389148  [   80/ 3840]\n",
            "loss: 0.567460  [  160/ 3840]\n",
            "loss: 0.493969  [  240/ 3840]\n",
            "loss: 0.632259  [  320/ 3840]\n",
            "loss: 0.409809  [  400/ 3840]\n",
            "loss: 0.907192  [  480/ 3840]\n",
            "loss: 0.357667  [  560/ 3840]\n",
            "loss: 0.574305  [  640/ 3840]\n",
            "loss: 0.336537  [  720/ 3840]\n",
            "loss: 0.623667  [  800/ 3840]\n",
            "loss: 0.423423  [  880/ 3840]\n",
            "loss: 0.622191  [  960/ 3840]\n",
            "loss: 0.701568  [ 1040/ 3840]\n",
            "loss: 0.561857  [ 1120/ 3840]\n",
            "loss: 0.918174  [ 1200/ 3840]\n",
            "loss: 0.521588  [ 1280/ 3840]\n",
            "loss: 0.276816  [ 1360/ 3840]\n",
            "loss: 1.450869  [ 1440/ 3840]\n",
            "loss: 0.892517  [ 1520/ 3840]\n",
            "loss: 0.552041  [ 1600/ 3840]\n",
            "loss: 0.704619  [ 1680/ 3840]\n",
            "loss: 0.255751  [ 1760/ 3840]\n",
            "loss: 0.637005  [ 1840/ 3840]\n",
            "loss: 0.766391  [ 1920/ 3840]\n",
            "loss: 1.036744  [ 2000/ 3840]\n",
            "loss: 0.789731  [ 2080/ 3840]\n",
            "loss: 0.527524  [ 2160/ 3840]\n",
            "loss: 0.429961  [ 2240/ 3840]\n",
            "loss: 0.548925  [ 2320/ 3840]\n",
            "loss: 0.734168  [ 2400/ 3840]\n",
            "loss: 0.589641  [ 2480/ 3840]\n",
            "loss: 0.477553  [ 2560/ 3840]\n",
            "loss: 0.329898  [ 2640/ 3840]\n",
            "loss: 0.849587  [ 2720/ 3840]\n",
            "loss: 0.735637  [ 2800/ 3840]\n",
            "loss: 0.480282  [ 2880/ 3840]\n",
            "loss: 0.415989  [ 2960/ 3840]\n",
            "loss: 0.842506  [ 3040/ 3840]\n",
            "loss: 0.960549  [ 3120/ 3840]\n",
            "loss: 0.282734  [ 3200/ 3840]\n",
            "loss: 0.571897  [ 3280/ 3840]\n",
            "loss: 0.498323  [ 3360/ 3840]\n",
            "loss: 0.610441  [ 3440/ 3840]\n",
            "loss: 0.522850  [ 3520/ 3840]\n",
            "loss: 0.715358  [ 3600/ 3840]\n",
            "loss: 0.484837  [ 3680/ 3840]\n",
            "loss: 0.495519  [ 3760/ 3840]\n",
            "Validation loss after epoch 6: 1.222909\n",
            "Early stopping at epoch 7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-05-19 20:49:48,950] Trial 12 finished with value: 54.895833333333336 and parameters: {'dropout_rate': 0.29974045618588463, 'learning_rate': 1.0135227998923422e-05, 'batch_size': 8}. Best is trial 0 with value: 57.1875.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 1.786362  [    0/ 3840]\n",
            "loss: 1.790351  [   80/ 3840]\n",
            "loss: 1.765431  [  160/ 3840]\n",
            "loss: 1.797515  [  240/ 3840]\n",
            "loss: 1.731149  [  320/ 3840]\n",
            "loss: 1.794801  [  400/ 3840]\n",
            "loss: 1.757921  [  480/ 3840]\n",
            "loss: 1.826045  [  560/ 3840]\n",
            "loss: 1.764560  [  640/ 3840]\n",
            "loss: 1.623708  [  720/ 3840]\n",
            "loss: 1.704113  [  800/ 3840]\n",
            "loss: 1.634840  [  880/ 3840]\n",
            "loss: 1.663308  [  960/ 3840]\n",
            "loss: 1.681170  [ 1040/ 3840]\n",
            "loss: 1.552502  [ 1120/ 3840]\n",
            "loss: 1.664826  [ 1200/ 3840]\n",
            "loss: 1.451234  [ 1280/ 3840]\n",
            "loss: 1.553387  [ 1360/ 3840]\n",
            "loss: 1.436412  [ 1440/ 3840]\n",
            "loss: 1.410013  [ 1520/ 3840]\n",
            "loss: 1.566639  [ 1600/ 3840]\n",
            "loss: 1.545242  [ 1680/ 3840]\n",
            "loss: 1.371487  [ 1760/ 3840]\n",
            "loss: 1.314204  [ 1840/ 3840]\n",
            "loss: 1.418365  [ 1920/ 3840]\n",
            "loss: 1.304538  [ 2000/ 3840]\n",
            "loss: 1.342505  [ 2080/ 3840]\n",
            "loss: 1.360565  [ 2160/ 3840]\n",
            "loss: 1.141312  [ 2240/ 3840]\n",
            "loss: 1.243597  [ 2320/ 3840]\n",
            "loss: 1.221091  [ 2400/ 3840]\n",
            "loss: 1.459352  [ 2480/ 3840]\n",
            "loss: 1.358787  [ 2560/ 3840]\n",
            "loss: 1.222526  [ 2640/ 3840]\n",
            "loss: 1.266350  [ 2720/ 3840]\n",
            "loss: 1.196147  [ 2800/ 3840]\n",
            "loss: 1.334885  [ 2880/ 3840]\n",
            "loss: 1.255218  [ 2960/ 3840]\n",
            "loss: 1.106776  [ 3040/ 3840]\n",
            "loss: 1.303931  [ 3120/ 3840]\n",
            "loss: 1.098300  [ 3200/ 3840]\n",
            "loss: 1.387431  [ 3280/ 3840]\n",
            "loss: 1.139984  [ 3360/ 3840]\n",
            "loss: 1.188403  [ 3440/ 3840]\n",
            "loss: 1.391847  [ 3520/ 3840]\n",
            "loss: 1.124583  [ 3600/ 3840]\n",
            "loss: 1.561246  [ 3680/ 3840]\n",
            "loss: 1.179142  [ 3760/ 3840]\n",
            "Validation loss after epoch 1: 1.221255\n",
            "loss: 1.230664  [    0/ 3840]\n",
            "loss: 1.399083  [   80/ 3840]\n",
            "loss: 1.071661  [  160/ 3840]\n",
            "loss: 1.118404  [  240/ 3840]\n",
            "loss: 1.223283  [  320/ 3840]\n",
            "loss: 1.366066  [  400/ 3840]\n",
            "loss: 0.953683  [  480/ 3840]\n",
            "loss: 1.157603  [  560/ 3840]\n",
            "loss: 1.263471  [  640/ 3840]\n",
            "loss: 1.221434  [  720/ 3840]\n",
            "loss: 0.978941  [  800/ 3840]\n",
            "loss: 0.854525  [  880/ 3840]\n",
            "loss: 1.003943  [  960/ 3840]\n",
            "loss: 1.182563  [ 1040/ 3840]\n",
            "loss: 0.678675  [ 1120/ 3840]\n",
            "loss: 0.832946  [ 1200/ 3840]\n",
            "loss: 0.855154  [ 1280/ 3840]\n",
            "loss: 0.927667  [ 1360/ 3840]\n",
            "loss: 1.294959  [ 1440/ 3840]\n",
            "loss: 1.337412  [ 1520/ 3840]\n",
            "loss: 1.222118  [ 1600/ 3840]\n",
            "loss: 0.939601  [ 1680/ 3840]\n",
            "loss: 0.722969  [ 1760/ 3840]\n",
            "loss: 0.955887  [ 1840/ 3840]\n",
            "loss: 0.849780  [ 1920/ 3840]\n",
            "loss: 1.054160  [ 2000/ 3840]\n",
            "loss: 0.700293  [ 2080/ 3840]\n",
            "loss: 0.875700  [ 2160/ 3840]\n",
            "loss: 1.021521  [ 2240/ 3840]\n",
            "loss: 0.963484  [ 2320/ 3840]\n",
            "loss: 1.074249  [ 2400/ 3840]\n",
            "loss: 0.952683  [ 2480/ 3840]\n",
            "loss: 0.908984  [ 2560/ 3840]\n",
            "loss: 0.983547  [ 2640/ 3840]\n",
            "loss: 1.081720  [ 2720/ 3840]\n",
            "loss: 1.333248  [ 2800/ 3840]\n",
            "loss: 1.407742  [ 2880/ 3840]\n",
            "loss: 1.106282  [ 2960/ 3840]\n",
            "loss: 0.774498  [ 3040/ 3840]\n",
            "loss: 1.301903  [ 3120/ 3840]\n",
            "loss: 0.913765  [ 3200/ 3840]\n",
            "loss: 1.071634  [ 3280/ 3840]\n",
            "loss: 1.181581  [ 3360/ 3840]\n",
            "loss: 1.032521  [ 3440/ 3840]\n",
            "loss: 1.168792  [ 3520/ 3840]\n",
            "loss: 0.912722  [ 3600/ 3840]\n",
            "loss: 0.879101  [ 3680/ 3840]\n",
            "loss: 1.280005  [ 3760/ 3840]\n",
            "Validation loss after epoch 2: 1.173213\n",
            "loss: 0.731090  [    0/ 3840]\n",
            "loss: 1.236184  [   80/ 3840]\n",
            "loss: 0.991238  [  160/ 3840]\n",
            "loss: 0.742342  [  240/ 3840]\n",
            "loss: 0.564939  [  320/ 3840]\n",
            "loss: 1.146941  [  400/ 3840]\n",
            "loss: 0.854359  [  480/ 3840]\n",
            "loss: 0.727136  [  560/ 3840]\n",
            "loss: 0.720829  [  640/ 3840]\n",
            "loss: 1.029354  [  720/ 3840]\n",
            "loss: 0.988305  [  800/ 3840]\n",
            "loss: 0.960563  [  880/ 3840]\n",
            "loss: 0.732856  [  960/ 3840]\n",
            "loss: 0.855899  [ 1040/ 3840]\n",
            "loss: 1.104184  [ 1120/ 3840]\n",
            "loss: 0.836655  [ 1200/ 3840]\n",
            "loss: 0.772762  [ 1280/ 3840]\n",
            "loss: 1.098166  [ 1360/ 3840]\n",
            "loss: 0.960415  [ 1440/ 3840]\n",
            "loss: 0.783296  [ 1520/ 3840]\n",
            "loss: 0.920709  [ 1600/ 3840]\n",
            "loss: 0.662326  [ 1680/ 3840]\n",
            "loss: 0.647276  [ 1760/ 3840]\n",
            "loss: 0.764737  [ 1840/ 3840]\n",
            "loss: 0.640991  [ 1920/ 3840]\n",
            "loss: 0.790025  [ 2000/ 3840]\n",
            "loss: 1.286511  [ 2080/ 3840]\n",
            "loss: 0.747295  [ 2160/ 3840]\n",
            "loss: 1.317399  [ 2240/ 3840]\n",
            "loss: 0.768031  [ 2320/ 3840]\n",
            "loss: 0.794484  [ 2400/ 3840]\n",
            "loss: 0.754368  [ 2480/ 3840]\n",
            "loss: 0.902145  [ 2560/ 3840]\n",
            "loss: 0.812497  [ 2640/ 3840]\n",
            "loss: 0.692099  [ 2720/ 3840]\n",
            "loss: 0.781664  [ 2800/ 3840]\n",
            "loss: 0.784389  [ 2880/ 3840]\n",
            "loss: 0.807809  [ 2960/ 3840]\n",
            "loss: 0.706928  [ 3040/ 3840]\n",
            "loss: 0.608348  [ 3120/ 3840]\n",
            "loss: 0.773546  [ 3200/ 3840]\n",
            "loss: 0.649523  [ 3280/ 3840]\n",
            "loss: 0.658725  [ 3360/ 3840]\n",
            "loss: 0.725906  [ 3440/ 3840]\n",
            "loss: 0.908627  [ 3520/ 3840]\n",
            "loss: 0.699620  [ 3600/ 3840]\n",
            "loss: 0.852845  [ 3680/ 3840]\n",
            "loss: 0.768386  [ 3760/ 3840]\n",
            "Validation loss after epoch 3: 1.109014\n",
            "loss: 1.214515  [    0/ 3840]\n",
            "loss: 0.359197  [   80/ 3840]\n",
            "loss: 0.839149  [  160/ 3840]\n",
            "loss: 0.749780  [  240/ 3840]\n",
            "loss: 0.573074  [  320/ 3840]\n",
            "loss: 0.556477  [  400/ 3840]\n",
            "loss: 0.609487  [  480/ 3840]\n",
            "loss: 0.862730  [  560/ 3840]\n",
            "loss: 0.707268  [  640/ 3840]\n",
            "loss: 0.483375  [  720/ 3840]\n",
            "loss: 0.850843  [  800/ 3840]\n",
            "loss: 0.528492  [  880/ 3840]\n",
            "loss: 0.463136  [  960/ 3840]\n",
            "loss: 0.796891  [ 1040/ 3840]\n",
            "loss: 1.026189  [ 1120/ 3840]\n",
            "loss: 0.521857  [ 1200/ 3840]\n",
            "loss: 0.554886  [ 1280/ 3840]\n",
            "loss: 0.344709  [ 1360/ 3840]\n",
            "loss: 0.655979  [ 1440/ 3840]\n",
            "loss: 0.827978  [ 1520/ 3840]\n",
            "loss: 0.564763  [ 1600/ 3840]\n",
            "loss: 0.616942  [ 1680/ 3840]\n",
            "loss: 0.577311  [ 1760/ 3840]\n",
            "loss: 0.528630  [ 1840/ 3840]\n",
            "loss: 1.480897  [ 1920/ 3840]\n",
            "loss: 0.738459  [ 2000/ 3840]\n",
            "loss: 0.571573  [ 2080/ 3840]\n",
            "loss: 0.600983  [ 2160/ 3840]\n",
            "loss: 1.637218  [ 2240/ 3840]\n",
            "loss: 0.504139  [ 2320/ 3840]\n",
            "loss: 0.737738  [ 2400/ 3840]\n",
            "loss: 0.678939  [ 2480/ 3840]\n",
            "loss: 0.754239  [ 2560/ 3840]\n",
            "loss: 0.713528  [ 2640/ 3840]\n",
            "loss: 0.438743  [ 2720/ 3840]\n",
            "loss: 0.737815  [ 2800/ 3840]\n",
            "loss: 0.641500  [ 2880/ 3840]\n",
            "loss: 0.831128  [ 2960/ 3840]\n",
            "loss: 0.469026  [ 3040/ 3840]\n",
            "loss: 0.495644  [ 3120/ 3840]\n",
            "loss: 0.634239  [ 3200/ 3840]\n",
            "loss: 0.700028  [ 3280/ 3840]\n",
            "loss: 0.436413  [ 3360/ 3840]\n",
            "loss: 0.641400  [ 3440/ 3840]\n",
            "loss: 1.567959  [ 3520/ 3840]\n",
            "loss: 0.544994  [ 3600/ 3840]\n",
            "loss: 0.790968  [ 3680/ 3840]\n",
            "loss: 1.126208  [ 3760/ 3840]\n",
            "Validation loss after epoch 4: 1.142737\n",
            "loss: 0.681551  [    0/ 3840]\n",
            "loss: 0.579656  [   80/ 3840]\n",
            "loss: 1.199953  [  160/ 3840]\n",
            "loss: 0.344216  [  240/ 3840]\n",
            "loss: 0.519076  [  320/ 3840]\n",
            "loss: 0.327976  [  400/ 3840]\n",
            "loss: 0.493986  [  480/ 3840]\n",
            "loss: 0.867719  [  560/ 3840]\n",
            "loss: 0.605156  [  640/ 3840]\n",
            "loss: 0.382478  [  720/ 3840]\n",
            "loss: 0.437009  [  800/ 3840]\n",
            "loss: 0.629722  [  880/ 3840]\n",
            "loss: 0.377675  [  960/ 3840]\n",
            "loss: 0.321305  [ 1040/ 3840]\n",
            "loss: 1.345894  [ 1120/ 3840]\n",
            "loss: 0.364562  [ 1200/ 3840]\n",
            "loss: 0.309469  [ 1280/ 3840]\n",
            "loss: 0.497888  [ 1360/ 3840]\n",
            "loss: 0.252679  [ 1440/ 3840]\n",
            "loss: 0.677562  [ 1520/ 3840]\n",
            "loss: 0.398097  [ 1600/ 3840]\n",
            "loss: 1.323391  [ 1680/ 3840]\n",
            "loss: 0.679823  [ 1760/ 3840]\n",
            "loss: 0.560540  [ 1840/ 3840]\n",
            "loss: 0.425809  [ 1920/ 3840]\n",
            "loss: 0.734080  [ 2000/ 3840]\n",
            "loss: 0.723181  [ 2080/ 3840]\n",
            "loss: 0.364918  [ 2160/ 3840]\n",
            "loss: 0.656832  [ 2240/ 3840]\n",
            "loss: 0.633356  [ 2320/ 3840]\n",
            "loss: 0.250162  [ 2400/ 3840]\n",
            "loss: 0.503193  [ 2480/ 3840]\n",
            "loss: 0.400966  [ 2560/ 3840]\n",
            "loss: 0.506275  [ 2640/ 3840]\n",
            "loss: 0.394257  [ 2720/ 3840]\n",
            "loss: 0.513350  [ 2800/ 3840]\n",
            "loss: 0.388145  [ 2880/ 3840]\n",
            "loss: 0.611652  [ 2960/ 3840]\n",
            "loss: 0.337547  [ 3040/ 3840]\n",
            "loss: 0.618425  [ 3120/ 3840]\n",
            "loss: 0.685491  [ 3200/ 3840]\n",
            "loss: 0.332802  [ 3280/ 3840]\n",
            "loss: 0.280964  [ 3360/ 3840]\n",
            "loss: 0.868707  [ 3440/ 3840]\n",
            "loss: 1.302381  [ 3520/ 3840]\n",
            "loss: 0.666629  [ 3600/ 3840]\n",
            "loss: 0.692097  [ 3680/ 3840]\n",
            "loss: 0.213853  [ 3760/ 3840]\n",
            "Validation loss after epoch 5: 1.150076\n",
            "loss: 0.325407  [    0/ 3840]\n",
            "loss: 0.288154  [   80/ 3840]\n",
            "loss: 0.790312  [  160/ 3840]\n",
            "loss: 0.252659  [  240/ 3840]\n",
            "loss: 0.437762  [  320/ 3840]\n",
            "loss: 0.679492  [  400/ 3840]\n",
            "loss: 0.645615  [  480/ 3840]\n",
            "loss: 0.436722  [  560/ 3840]\n",
            "loss: 0.219398  [  640/ 3840]\n",
            "loss: 0.301295  [  720/ 3840]\n",
            "loss: 0.292725  [  800/ 3840]\n",
            "loss: 0.217172  [  880/ 3840]\n",
            "loss: 0.776892  [  960/ 3840]\n",
            "loss: 0.866527  [ 1040/ 3840]\n",
            "loss: 0.575092  [ 1120/ 3840]\n",
            "loss: 0.619464  [ 1200/ 3840]\n",
            "loss: 0.711568  [ 1280/ 3840]\n",
            "loss: 0.214950  [ 1360/ 3840]\n",
            "loss: 0.361209  [ 1440/ 3840]\n",
            "loss: 0.556787  [ 1520/ 3840]\n",
            "loss: 0.228661  [ 1600/ 3840]\n",
            "loss: 0.146769  [ 1680/ 3840]\n",
            "loss: 1.466762  [ 1760/ 3840]\n",
            "loss: 0.286484  [ 1840/ 3840]\n",
            "loss: 0.286844  [ 1920/ 3840]\n",
            "loss: 1.190936  [ 2000/ 3840]\n",
            "loss: 0.294546  [ 2080/ 3840]\n",
            "loss: 0.225022  [ 2160/ 3840]\n",
            "loss: 0.317172  [ 2240/ 3840]\n",
            "loss: 0.231359  [ 2320/ 3840]\n",
            "loss: 0.578607  [ 2400/ 3840]\n",
            "loss: 0.672366  [ 2480/ 3840]\n",
            "loss: 0.206234  [ 2560/ 3840]\n",
            "loss: 0.227051  [ 2640/ 3840]\n",
            "loss: 0.815426  [ 2720/ 3840]\n",
            "loss: 0.761213  [ 2800/ 3840]\n",
            "loss: 0.614441  [ 2880/ 3840]\n",
            "loss: 0.412654  [ 2960/ 3840]\n",
            "loss: 0.263052  [ 3040/ 3840]\n",
            "loss: 0.511044  [ 3120/ 3840]\n",
            "loss: 0.640041  [ 3200/ 3840]\n",
            "loss: 0.388707  [ 3280/ 3840]\n",
            "loss: 0.375905  [ 3360/ 3840]\n",
            "loss: 1.222107  [ 3440/ 3840]\n",
            "loss: 0.318863  [ 3520/ 3840]\n",
            "loss: 0.266858  [ 3600/ 3840]\n",
            "loss: 0.178802  [ 3680/ 3840]\n",
            "loss: 0.706200  [ 3760/ 3840]\n",
            "Validation loss after epoch 6: 1.270726\n",
            "Early stopping at epoch 7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-05-19 20:56:40,635] Trial 13 finished with value: 56.458333333333336 and parameters: {'dropout_rate': 0.2584425036834111, 'learning_rate': 1.3009319272608355e-05, 'batch_size': 8}. Best is trial 0 with value: 57.1875.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 1.793177  [    0/ 3840]\n",
            "loss: 1.756855  [   80/ 3840]\n",
            "loss: 1.771056  [  160/ 3840]\n",
            "loss: 1.751489  [  240/ 3840]\n",
            "loss: 1.761804  [  320/ 3840]\n",
            "loss: 1.694998  [  400/ 3840]\n",
            "loss: 1.686405  [  480/ 3840]\n",
            "loss: 1.607464  [  560/ 3840]\n",
            "loss: 1.578874  [  640/ 3840]\n",
            "loss: 1.568177  [  720/ 3840]\n",
            "loss: 1.636721  [  800/ 3840]\n",
            "loss: 1.388918  [  880/ 3840]\n",
            "loss: 1.450413  [  960/ 3840]\n",
            "loss: 1.654207  [ 1040/ 3840]\n",
            "loss: 1.405171  [ 1120/ 3840]\n",
            "loss: 1.348331  [ 1200/ 3840]\n",
            "loss: 1.238758  [ 1280/ 3840]\n",
            "loss: 1.283656  [ 1360/ 3840]\n",
            "loss: 1.336477  [ 1440/ 3840]\n",
            "loss: 1.083759  [ 1520/ 3840]\n",
            "loss: 1.174442  [ 1600/ 3840]\n",
            "loss: 1.102781  [ 1680/ 3840]\n",
            "loss: 1.219876  [ 1760/ 3840]\n",
            "loss: 1.419987  [ 1840/ 3840]\n",
            "loss: 1.342508  [ 1920/ 3840]\n",
            "loss: 1.223114  [ 2000/ 3840]\n",
            "loss: 1.077118  [ 2080/ 3840]\n",
            "loss: 1.210067  [ 2160/ 3840]\n",
            "loss: 1.188131  [ 2240/ 3840]\n",
            "loss: 1.376139  [ 2320/ 3840]\n",
            "loss: 1.200672  [ 2400/ 3840]\n",
            "loss: 1.477942  [ 2480/ 3840]\n",
            "loss: 1.256020  [ 2560/ 3840]\n",
            "loss: 1.235100  [ 2640/ 3840]\n",
            "loss: 0.937781  [ 2720/ 3840]\n",
            "loss: 1.021549  [ 2800/ 3840]\n",
            "loss: 0.992051  [ 2880/ 3840]\n",
            "loss: 1.099787  [ 2960/ 3840]\n",
            "loss: 1.161994  [ 3040/ 3840]\n",
            "loss: 1.484224  [ 3120/ 3840]\n",
            "loss: 1.063607  [ 3200/ 3840]\n",
            "loss: 1.389795  [ 3280/ 3840]\n",
            "loss: 2.128792  [ 3360/ 3840]\n",
            "loss: 1.846221  [ 3440/ 3840]\n",
            "loss: 1.646119  [ 3520/ 3840]\n",
            "loss: 1.736935  [ 3600/ 3840]\n",
            "loss: 1.748757  [ 3680/ 3840]\n",
            "loss: 1.621591  [ 3760/ 3840]\n",
            "Validation loss after epoch 1: 1.476144\n",
            "loss: 1.513574  [    0/ 3840]\n",
            "loss: 1.341815  [   80/ 3840]\n",
            "loss: 0.949386  [  160/ 3840]\n",
            "loss: 1.542809  [  240/ 3840]\n",
            "loss: 1.139346  [  320/ 3840]\n",
            "loss: 0.987514  [  400/ 3840]\n",
            "loss: 0.851188  [  480/ 3840]\n",
            "loss: 1.124314  [  560/ 3840]\n",
            "loss: 1.357924  [  640/ 3840]\n",
            "loss: 0.992249  [  720/ 3840]\n",
            "loss: 1.156847  [  800/ 3840]\n",
            "loss: 1.177403  [  880/ 3840]\n",
            "loss: 0.888734  [  960/ 3840]\n",
            "loss: 1.528416  [ 1040/ 3840]\n",
            "loss: 0.880100  [ 1120/ 3840]\n",
            "loss: 0.770481  [ 1200/ 3840]\n",
            "loss: 1.036513  [ 1280/ 3840]\n",
            "loss: 0.999368  [ 1360/ 3840]\n",
            "loss: 1.415595  [ 1440/ 3840]\n",
            "loss: 1.090999  [ 1520/ 3840]\n",
            "loss: 1.056807  [ 1600/ 3840]\n",
            "loss: 0.858577  [ 1680/ 3840]\n",
            "loss: 1.139875  [ 1760/ 3840]\n",
            "loss: 1.222535  [ 1840/ 3840]\n",
            "loss: 1.462600  [ 1920/ 3840]\n",
            "loss: 1.720540  [ 2000/ 3840]\n",
            "loss: 1.784534  [ 2080/ 3840]\n",
            "loss: 1.477279  [ 2160/ 3840]\n",
            "loss: 1.637423  [ 2240/ 3840]\n",
            "loss: 1.538746  [ 2320/ 3840]\n",
            "loss: 1.464149  [ 2400/ 3840]\n",
            "loss: 1.459843  [ 2480/ 3840]\n",
            "loss: 1.125282  [ 2560/ 3840]\n",
            "loss: 1.066580  [ 2640/ 3840]\n",
            "loss: 0.950153  [ 2720/ 3840]\n",
            "loss: 1.121762  [ 2800/ 3840]\n",
            "loss: 1.492689  [ 2880/ 3840]\n",
            "loss: 1.144474  [ 2960/ 3840]\n",
            "loss: 1.004944  [ 3040/ 3840]\n",
            "loss: 1.708033  [ 3120/ 3840]\n",
            "loss: 1.027684  [ 3200/ 3840]\n",
            "loss: 1.696235  [ 3280/ 3840]\n",
            "loss: 0.868644  [ 3360/ 3840]\n",
            "loss: 0.866342  [ 3440/ 3840]\n",
            "loss: 1.094764  [ 3520/ 3840]\n",
            "loss: 0.836640  [ 3600/ 3840]\n",
            "loss: 1.166941  [ 3680/ 3840]\n",
            "loss: 1.253559  [ 3760/ 3840]\n",
            "Validation loss after epoch 2: 1.092017\n",
            "loss: 0.870513  [    0/ 3840]\n",
            "loss: 1.043625  [   80/ 3840]\n",
            "loss: 0.781752  [  160/ 3840]\n",
            "loss: 1.384879  [  240/ 3840]\n",
            "loss: 0.700659  [  320/ 3840]\n",
            "loss: 0.954552  [  400/ 3840]\n",
            "loss: 1.400671  [  480/ 3840]\n",
            "loss: 1.020654  [  560/ 3840]\n",
            "loss: 1.164855  [  640/ 3840]\n",
            "loss: 1.237209  [  720/ 3840]\n",
            "loss: 1.008252  [  800/ 3840]\n",
            "loss: 1.003658  [  880/ 3840]\n",
            "loss: 0.937312  [  960/ 3840]\n",
            "loss: 1.063997  [ 1040/ 3840]\n",
            "loss: 1.013760  [ 1120/ 3840]\n",
            "loss: 0.918267  [ 1200/ 3840]\n",
            "loss: 0.888592  [ 1280/ 3840]\n",
            "loss: 0.854917  [ 1360/ 3840]\n",
            "loss: 1.389581  [ 1440/ 3840]\n",
            "loss: 1.002899  [ 1520/ 3840]\n",
            "loss: 1.033723  [ 1600/ 3840]\n",
            "loss: 0.909800  [ 1680/ 3840]\n",
            "loss: 1.169858  [ 1760/ 3840]\n",
            "loss: 0.923849  [ 1840/ 3840]\n",
            "loss: 1.116620  [ 1920/ 3840]\n",
            "loss: 1.077635  [ 2000/ 3840]\n",
            "loss: 0.763083  [ 2080/ 3840]\n",
            "loss: 1.386238  [ 2160/ 3840]\n",
            "loss: 0.905263  [ 2240/ 3840]\n",
            "loss: 0.800569  [ 2320/ 3840]\n",
            "loss: 0.836732  [ 2400/ 3840]\n",
            "loss: 0.724476  [ 2480/ 3840]\n",
            "loss: 1.167300  [ 2560/ 3840]\n",
            "loss: 1.429498  [ 2640/ 3840]\n",
            "loss: 0.897227  [ 2720/ 3840]\n",
            "loss: 0.997739  [ 2800/ 3840]\n",
            "loss: 1.141506  [ 2880/ 3840]\n",
            "loss: 1.134738  [ 2960/ 3840]\n",
            "loss: 0.968210  [ 3040/ 3840]\n",
            "loss: 0.839563  [ 3120/ 3840]\n",
            "loss: 0.687590  [ 3200/ 3840]\n",
            "loss: 1.205410  [ 3280/ 3840]\n",
            "loss: 1.140629  [ 3360/ 3840]\n",
            "loss: 1.027943  [ 3440/ 3840]\n",
            "loss: 0.819120  [ 3520/ 3840]\n",
            "loss: 1.118560  [ 3600/ 3840]\n",
            "loss: 0.979854  [ 3680/ 3840]\n",
            "loss: 0.773554  [ 3760/ 3840]\n",
            "Validation loss after epoch 3: 1.039279\n",
            "loss: 0.911239  [    0/ 3840]\n",
            "loss: 0.683772  [   80/ 3840]\n",
            "loss: 0.897103  [  160/ 3840]\n",
            "loss: 1.063310  [  240/ 3840]\n",
            "loss: 0.527540  [  320/ 3840]\n",
            "loss: 0.392351  [  400/ 3840]\n",
            "loss: 0.752659  [  480/ 3840]\n",
            "loss: 0.661214  [  560/ 3840]\n",
            "loss: 0.483570  [  640/ 3840]\n",
            "loss: 0.962145  [  720/ 3840]\n",
            "loss: 0.546708  [  800/ 3840]\n",
            "loss: 0.771180  [  880/ 3840]\n",
            "loss: 0.724139  [  960/ 3840]\n",
            "loss: 0.608345  [ 1040/ 3840]\n",
            "loss: 1.091036  [ 1120/ 3840]\n",
            "loss: 0.636517  [ 1200/ 3840]\n",
            "loss: 1.058394  [ 1280/ 3840]\n",
            "loss: 1.125237  [ 1360/ 3840]\n",
            "loss: 0.718396  [ 1440/ 3840]\n",
            "loss: 0.437315  [ 1520/ 3840]\n",
            "loss: 0.750606  [ 1600/ 3840]\n",
            "loss: 0.716528  [ 1680/ 3840]\n",
            "loss: 0.728681  [ 1760/ 3840]\n",
            "loss: 1.076553  [ 1840/ 3840]\n",
            "loss: 1.454304  [ 1920/ 3840]\n",
            "loss: 0.714102  [ 2000/ 3840]\n",
            "loss: 0.993413  [ 2080/ 3840]\n",
            "loss: 0.573394  [ 2160/ 3840]\n",
            "loss: 0.694383  [ 2240/ 3840]\n",
            "loss: 0.553149  [ 2320/ 3840]\n",
            "loss: 0.394080  [ 2400/ 3840]\n",
            "loss: 0.692280  [ 2480/ 3840]\n",
            "loss: 0.547121  [ 2560/ 3840]\n",
            "loss: 0.649750  [ 2640/ 3840]\n",
            "loss: 0.963920  [ 2720/ 3840]\n",
            "loss: 0.781855  [ 2800/ 3840]\n",
            "loss: 0.694825  [ 2880/ 3840]\n",
            "loss: 0.712248  [ 2960/ 3840]\n",
            "loss: 0.884107  [ 3040/ 3840]\n",
            "loss: 0.622451  [ 3120/ 3840]\n",
            "loss: 0.712429  [ 3200/ 3840]\n",
            "loss: 1.653158  [ 3280/ 3840]\n",
            "loss: 1.125904  [ 3360/ 3840]\n",
            "loss: 0.825839  [ 3440/ 3840]\n",
            "loss: 0.709049  [ 3520/ 3840]\n",
            "loss: 0.787225  [ 3600/ 3840]\n",
            "loss: 0.681665  [ 3680/ 3840]\n",
            "loss: 1.261540  [ 3760/ 3840]\n",
            "Validation loss after epoch 4: 1.118062\n",
            "loss: 0.531476  [    0/ 3840]\n",
            "loss: 0.673772  [   80/ 3840]\n",
            "loss: 0.551335  [  160/ 3840]\n",
            "loss: 0.760556  [  240/ 3840]\n",
            "loss: 0.502788  [  320/ 3840]\n",
            "loss: 0.661073  [  400/ 3840]\n",
            "loss: 0.334582  [  480/ 3840]\n",
            "loss: 0.433761  [  560/ 3840]\n",
            "loss: 1.099555  [  640/ 3840]\n",
            "loss: 0.382904  [  720/ 3840]\n",
            "loss: 0.850448  [  800/ 3840]\n",
            "loss: 0.495429  [  880/ 3840]\n",
            "loss: 0.964043  [  960/ 3840]\n",
            "loss: 0.459193  [ 1040/ 3840]\n",
            "loss: 0.591179  [ 1120/ 3840]\n",
            "loss: 0.793952  [ 1200/ 3840]\n",
            "loss: 0.800182  [ 1280/ 3840]\n",
            "loss: 0.323394  [ 1360/ 3840]\n",
            "loss: 0.604577  [ 1440/ 3840]\n",
            "loss: 0.880511  [ 1520/ 3840]\n",
            "loss: 0.691551  [ 1600/ 3840]\n",
            "loss: 0.473071  [ 1680/ 3840]\n",
            "loss: 0.659920  [ 1760/ 3840]\n",
            "loss: 0.970978  [ 1840/ 3840]\n",
            "loss: 0.767448  [ 1920/ 3840]\n",
            "loss: 0.490402  [ 2000/ 3840]\n",
            "loss: 0.692540  [ 2080/ 3840]\n",
            "loss: 0.696688  [ 2160/ 3840]\n",
            "loss: 0.840114  [ 2240/ 3840]\n",
            "loss: 0.420737  [ 2320/ 3840]\n",
            "loss: 0.340562  [ 2400/ 3840]\n",
            "loss: 0.638398  [ 2480/ 3840]\n",
            "loss: 0.570827  [ 2560/ 3840]\n",
            "loss: 1.003384  [ 2640/ 3840]\n",
            "loss: 0.256271  [ 2720/ 3840]\n",
            "loss: 0.756408  [ 2800/ 3840]\n",
            "loss: 1.078771  [ 2880/ 3840]\n",
            "loss: 0.514619  [ 2960/ 3840]\n",
            "loss: 0.371803  [ 3040/ 3840]\n",
            "loss: 0.622649  [ 3120/ 3840]\n",
            "loss: 0.715216  [ 3200/ 3840]\n",
            "loss: 0.468583  [ 3280/ 3840]\n",
            "loss: 0.689404  [ 3360/ 3840]\n",
            "loss: 0.571839  [ 3440/ 3840]\n",
            "loss: 0.743277  [ 3520/ 3840]\n",
            "loss: 0.344593  [ 3600/ 3840]\n",
            "loss: 0.374729  [ 3680/ 3840]\n",
            "loss: 0.469984  [ 3760/ 3840]\n",
            "Validation loss after epoch 5: 1.181528\n",
            "loss: 0.332228  [    0/ 3840]\n",
            "loss: 0.241398  [   80/ 3840]\n",
            "loss: 0.523361  [  160/ 3840]\n",
            "loss: 0.244368  [  240/ 3840]\n",
            "loss: 1.050582  [  320/ 3840]\n",
            "loss: 0.112494  [  400/ 3840]\n",
            "loss: 0.207126  [  480/ 3840]\n",
            "loss: 0.821381  [  560/ 3840]\n",
            "loss: 0.398485  [  640/ 3840]\n",
            "loss: 0.298566  [  720/ 3840]\n",
            "loss: 0.563635  [  800/ 3840]\n",
            "loss: 0.172244  [  880/ 3840]\n",
            "loss: 0.185641  [  960/ 3840]\n",
            "loss: 0.615173  [ 1040/ 3840]\n",
            "loss: 0.544036  [ 1120/ 3840]\n",
            "loss: 0.354733  [ 1200/ 3840]\n",
            "loss: 0.665324  [ 1280/ 3840]\n",
            "loss: 0.821485  [ 1360/ 3840]\n",
            "loss: 0.506294  [ 1440/ 3840]\n",
            "loss: 0.358396  [ 1520/ 3840]\n",
            "loss: 1.230788  [ 1600/ 3840]\n",
            "loss: 0.466727  [ 1680/ 3840]\n",
            "loss: 0.313043  [ 1760/ 3840]\n",
            "loss: 0.215067  [ 1840/ 3840]\n",
            "loss: 0.334096  [ 1920/ 3840]\n",
            "loss: 1.167761  [ 2000/ 3840]\n",
            "loss: 0.768825  [ 2080/ 3840]\n",
            "loss: 0.681129  [ 2160/ 3840]\n",
            "loss: 0.505799  [ 2240/ 3840]\n",
            "loss: 0.377113  [ 2320/ 3840]\n",
            "loss: 0.464967  [ 2400/ 3840]\n",
            "loss: 0.269579  [ 2480/ 3840]\n",
            "loss: 0.132847  [ 2560/ 3840]\n",
            "loss: 0.551756  [ 2640/ 3840]\n",
            "loss: 0.242523  [ 2720/ 3840]\n",
            "loss: 0.550367  [ 2800/ 3840]\n",
            "loss: 0.119229  [ 2880/ 3840]\n",
            "loss: 0.448885  [ 2960/ 3840]\n",
            "loss: 0.916093  [ 3040/ 3840]\n",
            "loss: 0.217882  [ 3120/ 3840]\n",
            "loss: 0.439772  [ 3200/ 3840]\n",
            "loss: 0.559779  [ 3280/ 3840]\n",
            "loss: 0.453648  [ 3360/ 3840]\n",
            "loss: 0.732500  [ 3440/ 3840]\n",
            "loss: 0.359301  [ 3520/ 3840]\n",
            "loss: 0.884257  [ 3600/ 3840]\n",
            "loss: 0.283114  [ 3680/ 3840]\n",
            "loss: 0.489372  [ 3760/ 3840]\n",
            "Validation loss after epoch 6: 1.358327\n",
            "Early stopping at epoch 7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-05-19 21:03:32,317] Trial 14 finished with value: 54.0625 and parameters: {'dropout_rate': 0.24150982971171725, 'learning_rate': 2.4530268661698093e-05, 'batch_size': 8}. Best is trial 0 with value: 57.1875.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 1.794460  [    0/ 3840]\n",
            "loss: 1.778589  [   80/ 3840]\n",
            "loss: 1.742285  [  160/ 3840]\n",
            "loss: 1.691121  [  240/ 3840]\n",
            "loss: 1.679652  [  320/ 3840]\n",
            "loss: 1.526586  [  400/ 3840]\n",
            "loss: 1.534969  [  480/ 3840]\n",
            "loss: 1.400550  [  560/ 3840]\n",
            "loss: 1.297251  [  640/ 3840]\n",
            "loss: 1.300397  [  720/ 3840]\n",
            "loss: 1.354209  [  800/ 3840]\n",
            "loss: 1.390906  [  880/ 3840]\n",
            "loss: 1.330183  [  960/ 3840]\n",
            "loss: 1.433576  [ 1040/ 3840]\n",
            "loss: 1.206592  [ 1120/ 3840]\n",
            "loss: 1.374290  [ 1200/ 3840]\n",
            "loss: 1.165920  [ 1280/ 3840]\n",
            "loss: 1.324101  [ 1360/ 3840]\n",
            "loss: 1.377563  [ 1440/ 3840]\n",
            "loss: 1.135915  [ 1520/ 3840]\n",
            "loss: 1.063619  [ 1600/ 3840]\n",
            "loss: 1.054268  [ 1680/ 3840]\n",
            "loss: 1.453831  [ 1760/ 3840]\n",
            "loss: 1.569304  [ 1840/ 3840]\n",
            "loss: 1.084148  [ 1920/ 3840]\n",
            "loss: 1.197026  [ 2000/ 3840]\n",
            "loss: 1.042835  [ 2080/ 3840]\n",
            "loss: 1.604648  [ 2160/ 3840]\n",
            "loss: 1.052041  [ 2240/ 3840]\n",
            "loss: 1.516740  [ 2320/ 3840]\n",
            "loss: 0.724717  [ 2400/ 3840]\n",
            "loss: 1.026480  [ 2480/ 3840]\n",
            "loss: 1.295201  [ 2560/ 3840]\n",
            "loss: 1.049876  [ 2640/ 3840]\n",
            "loss: 1.070146  [ 2720/ 3840]\n",
            "loss: 1.160515  [ 2800/ 3840]\n",
            "loss: 0.972068  [ 2880/ 3840]\n",
            "loss: 1.448500  [ 2960/ 3840]\n",
            "loss: 0.992186  [ 3040/ 3840]\n",
            "loss: 0.877520  [ 3120/ 3840]\n",
            "loss: 1.244170  [ 3200/ 3840]\n",
            "loss: 0.794780  [ 3280/ 3840]\n",
            "loss: 1.226302  [ 3360/ 3840]\n",
            "loss: 0.927426  [ 3440/ 3840]\n",
            "loss: 1.496720  [ 3520/ 3840]\n",
            "loss: 1.271368  [ 3600/ 3840]\n",
            "loss: 1.081615  [ 3680/ 3840]\n",
            "loss: 0.852628  [ 3760/ 3840]\n",
            "Validation loss after epoch 1: 1.076507\n",
            "loss: 1.043868  [    0/ 3840]\n",
            "loss: 0.841831  [   80/ 3840]\n",
            "loss: 1.180119  [  160/ 3840]\n",
            "loss: 0.872993  [  240/ 3840]\n",
            "loss: 1.087705  [  320/ 3840]\n",
            "loss: 0.899414  [  400/ 3840]\n",
            "loss: 1.169027  [  480/ 3840]\n",
            "loss: 0.983901  [  560/ 3840]\n",
            "loss: 0.703292  [  640/ 3840]\n",
            "loss: 1.022852  [  720/ 3840]\n",
            "loss: 1.126606  [  800/ 3840]\n",
            "loss: 1.328935  [  880/ 3840]\n",
            "loss: 1.784321  [  960/ 3840]\n",
            "loss: 0.983084  [ 1040/ 3840]\n",
            "loss: 1.114123  [ 1120/ 3840]\n",
            "loss: 0.663610  [ 1200/ 3840]\n",
            "loss: 1.045250  [ 1280/ 3840]\n",
            "loss: 1.630695  [ 1360/ 3840]\n",
            "loss: 1.092034  [ 1440/ 3840]\n",
            "loss: 1.647105  [ 1520/ 3840]\n",
            "loss: 1.153380  [ 1600/ 3840]\n",
            "loss: 1.186309  [ 1680/ 3840]\n",
            "loss: 0.642806  [ 1760/ 3840]\n",
            "loss: 0.832790  [ 1840/ 3840]\n",
            "loss: 1.866544  [ 1920/ 3840]\n",
            "loss: 0.889680  [ 2000/ 3840]\n",
            "loss: 0.865989  [ 2080/ 3840]\n",
            "loss: 0.732953  [ 2160/ 3840]\n",
            "loss: 0.675964  [ 2240/ 3840]\n",
            "loss: 0.894343  [ 2320/ 3840]\n",
            "loss: 1.081831  [ 2400/ 3840]\n",
            "loss: 1.155782  [ 2480/ 3840]\n",
            "loss: 1.288250  [ 2560/ 3840]\n",
            "loss: 0.885064  [ 2640/ 3840]\n",
            "loss: 0.861250  [ 2720/ 3840]\n",
            "loss: 0.707939  [ 2800/ 3840]\n",
            "loss: 0.773334  [ 2880/ 3840]\n",
            "loss: 0.910418  [ 2960/ 3840]\n",
            "loss: 1.101439  [ 3040/ 3840]\n",
            "loss: 0.887393  [ 3120/ 3840]\n",
            "loss: 1.217821  [ 3200/ 3840]\n",
            "loss: 1.286215  [ 3280/ 3840]\n",
            "loss: 0.886937  [ 3360/ 3840]\n",
            "loss: 1.009946  [ 3440/ 3840]\n",
            "loss: 1.224316  [ 3520/ 3840]\n",
            "loss: 0.931630  [ 3600/ 3840]\n",
            "loss: 1.126877  [ 3680/ 3840]\n",
            "loss: 1.314533  [ 3760/ 3840]\n",
            "Validation loss after epoch 2: 1.193372\n",
            "loss: 1.073766  [    0/ 3840]\n",
            "loss: 0.658828  [   80/ 3840]\n",
            "loss: 0.587654  [  160/ 3840]\n",
            "loss: 0.795767  [  240/ 3840]\n",
            "loss: 0.527080  [  320/ 3840]\n",
            "loss: 1.025340  [  400/ 3840]\n",
            "loss: 0.859434  [  480/ 3840]\n",
            "loss: 0.652207  [  560/ 3840]\n",
            "loss: 0.932445  [  640/ 3840]\n",
            "loss: 0.674397  [  720/ 3840]\n",
            "loss: 1.115108  [  800/ 3840]\n",
            "loss: 1.002622  [  880/ 3840]\n",
            "loss: 0.499243  [  960/ 3840]\n",
            "loss: 0.538951  [ 1040/ 3840]\n",
            "loss: 1.208932  [ 1120/ 3840]\n",
            "loss: 0.991726  [ 1200/ 3840]\n",
            "loss: 0.957261  [ 1280/ 3840]\n",
            "loss: 0.568644  [ 1360/ 3840]\n",
            "loss: 0.803705  [ 1440/ 3840]\n",
            "loss: 0.575901  [ 1520/ 3840]\n",
            "loss: 0.712692  [ 1600/ 3840]\n",
            "loss: 0.657529  [ 1680/ 3840]\n",
            "loss: 1.361617  [ 1760/ 3840]\n",
            "loss: 0.900760  [ 1840/ 3840]\n",
            "loss: 0.470962  [ 1920/ 3840]\n",
            "loss: 0.656288  [ 2000/ 3840]\n",
            "loss: 1.222626  [ 2080/ 3840]\n",
            "loss: 0.905886  [ 2160/ 3840]\n",
            "loss: 0.856737  [ 2240/ 3840]\n",
            "loss: 0.730489  [ 2320/ 3840]\n",
            "loss: 1.082890  [ 2400/ 3840]\n",
            "loss: 0.899039  [ 2480/ 3840]\n",
            "loss: 0.465864  [ 2560/ 3840]\n",
            "loss: 0.830428  [ 2640/ 3840]\n",
            "loss: 0.741710  [ 2720/ 3840]\n",
            "loss: 0.534317  [ 2800/ 3840]\n",
            "loss: 1.137612  [ 2880/ 3840]\n",
            "loss: 1.462360  [ 2960/ 3840]\n",
            "loss: 0.678898  [ 3040/ 3840]\n",
            "loss: 0.583980  [ 3120/ 3840]\n",
            "loss: 1.181393  [ 3200/ 3840]\n",
            "loss: 1.338421  [ 3280/ 3840]\n",
            "loss: 0.858237  [ 3360/ 3840]\n",
            "loss: 0.667975  [ 3440/ 3840]\n",
            "loss: 0.666083  [ 3520/ 3840]\n",
            "loss: 0.692972  [ 3600/ 3840]\n",
            "loss: 0.828476  [ 3680/ 3840]\n",
            "loss: 0.484532  [ 3760/ 3840]\n",
            "Validation loss after epoch 3: 1.059085\n",
            "loss: 0.507748  [    0/ 3840]\n",
            "loss: 1.024107  [   80/ 3840]\n",
            "loss: 0.459218  [  160/ 3840]\n",
            "loss: 0.704602  [  240/ 3840]\n",
            "loss: 0.716623  [  320/ 3840]\n",
            "loss: 0.638945  [  400/ 3840]\n",
            "loss: 0.476604  [  480/ 3840]\n",
            "loss: 0.428325  [  560/ 3840]\n",
            "loss: 0.693627  [  640/ 3840]\n",
            "loss: 0.919855  [  720/ 3840]\n",
            "loss: 0.875472  [  800/ 3840]\n",
            "loss: 0.450827  [  880/ 3840]\n",
            "loss: 0.362296  [  960/ 3840]\n",
            "loss: 0.321404  [ 1040/ 3840]\n",
            "loss: 0.816938  [ 1120/ 3840]\n",
            "loss: 0.727056  [ 1200/ 3840]\n",
            "loss: 0.575044  [ 1280/ 3840]\n",
            "loss: 0.856191  [ 1360/ 3840]\n",
            "loss: 0.696076  [ 1440/ 3840]\n",
            "loss: 0.516212  [ 1520/ 3840]\n",
            "loss: 0.415898  [ 1600/ 3840]\n",
            "loss: 0.650451  [ 1680/ 3840]\n",
            "loss: 0.389443  [ 1760/ 3840]\n",
            "loss: 0.247467  [ 1840/ 3840]\n",
            "loss: 0.867996  [ 1920/ 3840]\n",
            "loss: 0.934532  [ 2000/ 3840]\n",
            "loss: 0.778596  [ 2080/ 3840]\n",
            "loss: 0.381846  [ 2160/ 3840]\n",
            "loss: 0.270523  [ 2240/ 3840]\n",
            "loss: 0.797373  [ 2320/ 3840]\n",
            "loss: 0.591799  [ 2400/ 3840]\n",
            "loss: 0.539321  [ 2480/ 3840]\n",
            "loss: 0.584659  [ 2560/ 3840]\n",
            "loss: 0.445824  [ 2640/ 3840]\n",
            "loss: 0.361816  [ 2720/ 3840]\n",
            "loss: 0.686094  [ 2800/ 3840]\n",
            "loss: 0.205999  [ 2880/ 3840]\n",
            "loss: 0.548889  [ 2960/ 3840]\n",
            "loss: 0.893118  [ 3040/ 3840]\n",
            "loss: 1.045992  [ 3120/ 3840]\n",
            "loss: 0.915392  [ 3200/ 3840]\n",
            "loss: 0.684462  [ 3280/ 3840]\n",
            "loss: 0.749839  [ 3360/ 3840]\n",
            "loss: 0.645458  [ 3440/ 3840]\n",
            "loss: 0.528371  [ 3520/ 3840]\n",
            "loss: 0.285177  [ 3600/ 3840]\n",
            "loss: 0.499866  [ 3680/ 3840]\n",
            "loss: 0.661780  [ 3760/ 3840]\n",
            "Validation loss after epoch 4: 1.251761\n",
            "loss: 0.946848  [    0/ 3840]\n",
            "loss: 0.194943  [   80/ 3840]\n",
            "loss: 0.836118  [  160/ 3840]\n",
            "loss: 0.445904  [  240/ 3840]\n",
            "loss: 0.563275  [  320/ 3840]\n",
            "loss: 0.724188  [  400/ 3840]\n",
            "loss: 0.354643  [  480/ 3840]\n",
            "loss: 0.466085  [  560/ 3840]\n",
            "loss: 0.277532  [  640/ 3840]\n",
            "loss: 0.685039  [  720/ 3840]\n",
            "loss: 0.687466  [  800/ 3840]\n",
            "loss: 0.201889  [  880/ 3840]\n",
            "loss: 0.601031  [  960/ 3840]\n",
            "loss: 0.616703  [ 1040/ 3840]\n",
            "loss: 0.302800  [ 1120/ 3840]\n",
            "loss: 0.496553  [ 1200/ 3840]\n",
            "loss: 0.779702  [ 1280/ 3840]\n",
            "loss: 0.508137  [ 1360/ 3840]\n",
            "loss: 0.500207  [ 1440/ 3840]\n",
            "loss: 0.356266  [ 1520/ 3840]\n",
            "loss: 0.677695  [ 1600/ 3840]\n",
            "loss: 0.354261  [ 1680/ 3840]\n",
            "loss: 0.437816  [ 1760/ 3840]\n",
            "loss: 0.476993  [ 1840/ 3840]\n",
            "loss: 0.329846  [ 1920/ 3840]\n",
            "loss: 0.175418  [ 2000/ 3840]\n",
            "loss: 0.755469  [ 2080/ 3840]\n",
            "loss: 0.752812  [ 2160/ 3840]\n",
            "loss: 0.538700  [ 2240/ 3840]\n",
            "loss: 0.592434  [ 2320/ 3840]\n",
            "loss: 0.821712  [ 2400/ 3840]\n",
            "loss: 0.357899  [ 2480/ 3840]\n",
            "loss: 0.379715  [ 2560/ 3840]\n",
            "loss: 0.405971  [ 2640/ 3840]\n",
            "loss: 0.808779  [ 2720/ 3840]\n",
            "loss: 0.521240  [ 2800/ 3840]\n",
            "loss: 1.199539  [ 2880/ 3840]\n",
            "loss: 0.934691  [ 2960/ 3840]\n",
            "loss: 1.546598  [ 3040/ 3840]\n",
            "loss: 0.625142  [ 3120/ 3840]\n",
            "loss: 0.490522  [ 3200/ 3840]\n",
            "loss: 0.183611  [ 3280/ 3840]\n",
            "loss: 0.878803  [ 3360/ 3840]\n",
            "loss: 0.456690  [ 3440/ 3840]\n",
            "loss: 1.073385  [ 3520/ 3840]\n",
            "loss: 0.168455  [ 3600/ 3840]\n",
            "loss: 0.320583  [ 3680/ 3840]\n",
            "loss: 0.207128  [ 3760/ 3840]\n",
            "Validation loss after epoch 5: 1.420937\n",
            "loss: 0.893608  [    0/ 3840]\n",
            "loss: 0.122195  [   80/ 3840]\n",
            "loss: 0.112266  [  160/ 3840]\n",
            "loss: 0.225951  [  240/ 3840]\n",
            "loss: 0.149279  [  320/ 3840]\n",
            "loss: 0.554579  [  400/ 3840]\n",
            "loss: 0.433125  [  480/ 3840]\n",
            "loss: 0.219087  [  560/ 3840]\n",
            "loss: 0.218784  [  640/ 3840]\n",
            "loss: 0.290169  [  720/ 3840]\n",
            "loss: 0.220189  [  800/ 3840]\n",
            "loss: 0.995602  [  880/ 3840]\n",
            "loss: 0.527856  [  960/ 3840]\n",
            "loss: 0.463711  [ 1040/ 3840]\n",
            "loss: 0.321007  [ 1120/ 3840]\n",
            "loss: 0.570381  [ 1200/ 3840]\n",
            "loss: 0.404843  [ 1280/ 3840]\n",
            "loss: 0.394716  [ 1360/ 3840]\n",
            "loss: 0.346582  [ 1440/ 3840]\n",
            "loss: 0.731450  [ 1520/ 3840]\n",
            "loss: 0.735820  [ 1600/ 3840]\n",
            "loss: 0.274445  [ 1680/ 3840]\n",
            "loss: 0.543456  [ 1760/ 3840]\n",
            "loss: 0.154888  [ 1840/ 3840]\n",
            "loss: 0.095702  [ 1920/ 3840]\n",
            "loss: 0.317753  [ 2000/ 3840]\n",
            "loss: 0.461213  [ 2080/ 3840]\n",
            "loss: 0.125878  [ 2160/ 3840]\n",
            "loss: 0.505817  [ 2240/ 3840]\n",
            "loss: 0.529004  [ 2320/ 3840]\n",
            "loss: 0.220991  [ 2400/ 3840]\n",
            "loss: 0.154549  [ 2480/ 3840]\n",
            "loss: 0.167244  [ 2560/ 3840]\n",
            "loss: 0.498633  [ 2640/ 3840]\n",
            "loss: 0.068163  [ 2720/ 3840]\n",
            "loss: 1.106197  [ 2800/ 3840]\n",
            "loss: 0.345729  [ 2880/ 3840]\n",
            "loss: 0.880818  [ 2960/ 3840]\n",
            "loss: 0.254337  [ 3040/ 3840]\n",
            "loss: 0.955234  [ 3120/ 3840]\n",
            "loss: 0.154744  [ 3200/ 3840]\n",
            "loss: 0.096039  [ 3280/ 3840]\n",
            "loss: 0.857919  [ 3360/ 3840]\n",
            "loss: 0.115909  [ 3440/ 3840]\n",
            "loss: 0.365691  [ 3520/ 3840]\n",
            "loss: 0.187413  [ 3600/ 3840]\n",
            "loss: 0.302446  [ 3680/ 3840]\n",
            "loss: 0.139713  [ 3760/ 3840]\n",
            "Validation loss after epoch 6: 1.528646\n",
            "Early stopping at epoch 7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-05-19 21:10:23,974] Trial 15 finished with value: 55.729166666666664 and parameters: {'dropout_rate': 0.27873893536144845, 'learning_rate': 4.9213762629076715e-05, 'batch_size': 8}. Best is trial 0 with value: 57.1875.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 1.827171  [    0/ 3840]\n",
            "loss: 1.777884  [   80/ 3840]\n",
            "loss: 1.760582  [  160/ 3840]\n",
            "loss: 1.833491  [  240/ 3840]\n",
            "loss: 1.781608  [  320/ 3840]\n",
            "loss: 1.766521  [  400/ 3840]\n",
            "loss: 1.776573  [  480/ 3840]\n",
            "loss: 1.747433  [  560/ 3840]\n",
            "loss: 1.702236  [  640/ 3840]\n",
            "loss: 1.659158  [  720/ 3840]\n",
            "loss: 1.688547  [  800/ 3840]\n",
            "loss: 1.617083  [  880/ 3840]\n",
            "loss: 1.704798  [  960/ 3840]\n",
            "loss: 1.676203  [ 1040/ 3840]\n",
            "loss: 1.701262  [ 1120/ 3840]\n",
            "loss: 1.609273  [ 1200/ 3840]\n",
            "loss: 1.397994  [ 1280/ 3840]\n",
            "loss: 1.354736  [ 1360/ 3840]\n",
            "loss: 1.346650  [ 1440/ 3840]\n",
            "loss: 1.493497  [ 1520/ 3840]\n",
            "loss: 1.425689  [ 1600/ 3840]\n",
            "loss: 1.279907  [ 1680/ 3840]\n",
            "loss: 1.470431  [ 1760/ 3840]\n",
            "loss: 1.365661  [ 1840/ 3840]\n",
            "loss: 1.308527  [ 1920/ 3840]\n",
            "loss: 1.320552  [ 2000/ 3840]\n",
            "loss: 1.488201  [ 2080/ 3840]\n",
            "loss: 1.319444  [ 2160/ 3840]\n",
            "loss: 1.208220  [ 2240/ 3840]\n",
            "loss: 1.478287  [ 2320/ 3840]\n",
            "loss: 1.388811  [ 2400/ 3840]\n",
            "loss: 1.193356  [ 2480/ 3840]\n",
            "loss: 1.142453  [ 2560/ 3840]\n",
            "loss: 1.132296  [ 2640/ 3840]\n",
            "loss: 1.247542  [ 2720/ 3840]\n",
            "loss: 1.462956  [ 2800/ 3840]\n",
            "loss: 1.226656  [ 2880/ 3840]\n",
            "loss: 1.258902  [ 2960/ 3840]\n",
            "loss: 1.224044  [ 3040/ 3840]\n",
            "loss: 1.055714  [ 3120/ 3840]\n",
            "loss: 1.209277  [ 3200/ 3840]\n",
            "loss: 1.202408  [ 3280/ 3840]\n",
            "loss: 1.215677  [ 3360/ 3840]\n",
            "loss: 1.124557  [ 3440/ 3840]\n",
            "loss: 1.271126  [ 3520/ 3840]\n",
            "loss: 1.184258  [ 3600/ 3840]\n",
            "loss: 1.111724  [ 3680/ 3840]\n",
            "loss: 1.253329  [ 3760/ 3840]\n",
            "Validation loss after epoch 1: 1.180321\n",
            "loss: 1.018179  [    0/ 3840]\n",
            "loss: 1.008417  [   80/ 3840]\n",
            "loss: 1.212215  [  160/ 3840]\n",
            "loss: 0.866740  [  240/ 3840]\n",
            "loss: 1.094726  [  320/ 3840]\n",
            "loss: 1.177604  [  400/ 3840]\n",
            "loss: 1.093264  [  480/ 3840]\n",
            "loss: 1.056817  [  560/ 3840]\n",
            "loss: 1.006987  [  640/ 3840]\n",
            "loss: 1.263108  [  720/ 3840]\n",
            "loss: 0.915526  [  800/ 3840]\n",
            "loss: 0.945866  [  880/ 3840]\n",
            "loss: 1.038678  [  960/ 3840]\n",
            "loss: 1.073076  [ 1040/ 3840]\n",
            "loss: 1.268753  [ 1120/ 3840]\n",
            "loss: 0.841529  [ 1200/ 3840]\n",
            "loss: 0.812872  [ 1280/ 3840]\n",
            "loss: 1.049433  [ 1360/ 3840]\n",
            "loss: 0.933333  [ 1440/ 3840]\n",
            "loss: 1.268762  [ 1520/ 3840]\n",
            "loss: 0.710939  [ 1600/ 3840]\n",
            "loss: 1.065280  [ 1680/ 3840]\n",
            "loss: 1.005957  [ 1760/ 3840]\n",
            "loss: 1.315418  [ 1840/ 3840]\n",
            "loss: 0.677058  [ 1920/ 3840]\n",
            "loss: 1.398482  [ 2000/ 3840]\n",
            "loss: 0.930741  [ 2080/ 3840]\n",
            "loss: 1.231781  [ 2160/ 3840]\n",
            "loss: 1.401905  [ 2240/ 3840]\n",
            "loss: 1.390045  [ 2320/ 3840]\n",
            "loss: 0.917722  [ 2400/ 3840]\n",
            "loss: 0.996808  [ 2480/ 3840]\n",
            "loss: 0.889327  [ 2560/ 3840]\n",
            "loss: 1.606080  [ 2640/ 3840]\n",
            "loss: 1.105786  [ 2720/ 3840]\n",
            "loss: 1.106707  [ 2800/ 3840]\n",
            "loss: 0.781144  [ 2880/ 3840]\n",
            "loss: 0.949387  [ 2960/ 3840]\n",
            "loss: 0.918012  [ 3040/ 3840]\n",
            "loss: 0.957376  [ 3120/ 3840]\n",
            "loss: 1.179888  [ 3200/ 3840]\n",
            "loss: 1.056826  [ 3280/ 3840]\n",
            "loss: 0.728297  [ 3360/ 3840]\n",
            "loss: 0.679019  [ 3440/ 3840]\n",
            "loss: 0.912269  [ 3520/ 3840]\n",
            "loss: 0.865376  [ 3600/ 3840]\n",
            "loss: 1.114263  [ 3680/ 3840]\n",
            "loss: 1.419086  [ 3760/ 3840]\n",
            "Validation loss after epoch 2: 1.078253\n",
            "loss: 0.533722  [    0/ 3840]\n",
            "loss: 0.819578  [   80/ 3840]\n",
            "loss: 0.720315  [  160/ 3840]\n",
            "loss: 0.652932  [  240/ 3840]\n",
            "loss: 0.591916  [  320/ 3840]\n",
            "loss: 0.851655  [  400/ 3840]\n",
            "loss: 0.632788  [  480/ 3840]\n",
            "loss: 1.220924  [  560/ 3840]\n",
            "loss: 0.917163  [  640/ 3840]\n",
            "loss: 0.895066  [  720/ 3840]\n",
            "loss: 0.833532  [  800/ 3840]\n",
            "loss: 1.095284  [  880/ 3840]\n",
            "loss: 0.799259  [  960/ 3840]\n",
            "loss: 0.747926  [ 1040/ 3840]\n",
            "loss: 0.983532  [ 1120/ 3840]\n",
            "loss: 0.672030  [ 1200/ 3840]\n",
            "loss: 1.285877  [ 1280/ 3840]\n",
            "loss: 1.121553  [ 1360/ 3840]\n",
            "loss: 0.985812  [ 1440/ 3840]\n",
            "loss: 0.740551  [ 1520/ 3840]\n",
            "loss: 0.856255  [ 1600/ 3840]\n",
            "loss: 0.714198  [ 1680/ 3840]\n",
            "loss: 0.992985  [ 1760/ 3840]\n",
            "loss: 1.528349  [ 1840/ 3840]\n",
            "loss: 0.779052  [ 1920/ 3840]\n",
            "loss: 0.560228  [ 2000/ 3840]\n",
            "loss: 0.636263  [ 2080/ 3840]\n",
            "loss: 0.804101  [ 2160/ 3840]\n",
            "loss: 1.167211  [ 2240/ 3840]\n",
            "loss: 0.785307  [ 2320/ 3840]\n",
            "loss: 0.675735  [ 2400/ 3840]\n",
            "loss: 0.735130  [ 2480/ 3840]\n",
            "loss: 0.564510  [ 2560/ 3840]\n",
            "loss: 0.820057  [ 2640/ 3840]\n",
            "loss: 1.118400  [ 2720/ 3840]\n",
            "loss: 0.792346  [ 2800/ 3840]\n",
            "loss: 1.168857  [ 2880/ 3840]\n",
            "loss: 1.148093  [ 2960/ 3840]\n",
            "loss: 0.902063  [ 3040/ 3840]\n",
            "loss: 0.986486  [ 3120/ 3840]\n",
            "loss: 0.752994  [ 3200/ 3840]\n",
            "loss: 0.587862  [ 3280/ 3840]\n",
            "loss: 0.926751  [ 3360/ 3840]\n",
            "loss: 1.005198  [ 3440/ 3840]\n",
            "loss: 1.247491  [ 3520/ 3840]\n",
            "loss: 0.932921  [ 3600/ 3840]\n",
            "loss: 0.672781  [ 3680/ 3840]\n",
            "loss: 0.754160  [ 3760/ 3840]\n",
            "Validation loss after epoch 3: 1.123523\n",
            "loss: 0.610178  [    0/ 3840]\n",
            "loss: 0.500314  [   80/ 3840]\n",
            "loss: 0.526084  [  160/ 3840]\n",
            "loss: 0.492784  [  240/ 3840]\n",
            "loss: 1.244722  [  320/ 3840]\n",
            "loss: 0.491680  [  400/ 3840]\n",
            "loss: 1.139104  [  480/ 3840]\n",
            "loss: 0.659236  [  560/ 3840]\n",
            "loss: 0.600816  [  640/ 3840]\n",
            "loss: 0.511227  [  720/ 3840]\n",
            "loss: 0.736585  [  800/ 3840]\n",
            "loss: 0.688796  [  880/ 3840]\n",
            "loss: 0.904184  [  960/ 3840]\n",
            "loss: 0.526480  [ 1040/ 3840]\n",
            "loss: 0.796444  [ 1120/ 3840]\n",
            "loss: 0.763804  [ 1200/ 3840]\n",
            "loss: 0.723293  [ 1280/ 3840]\n",
            "loss: 0.921750  [ 1360/ 3840]\n",
            "loss: 1.055021  [ 1440/ 3840]\n",
            "loss: 0.348527  [ 1520/ 3840]\n",
            "loss: 0.740044  [ 1600/ 3840]\n",
            "loss: 0.766308  [ 1680/ 3840]\n",
            "loss: 0.488650  [ 1760/ 3840]\n",
            "loss: 0.382448  [ 1840/ 3840]\n",
            "loss: 1.085988  [ 1920/ 3840]\n",
            "loss: 0.604559  [ 2000/ 3840]\n",
            "loss: 0.960257  [ 2080/ 3840]\n",
            "loss: 0.711131  [ 2160/ 3840]\n",
            "loss: 0.637462  [ 2240/ 3840]\n",
            "loss: 1.081361  [ 2320/ 3840]\n",
            "loss: 0.540280  [ 2400/ 3840]\n",
            "loss: 0.474821  [ 2480/ 3840]\n",
            "loss: 0.918860  [ 2560/ 3840]\n",
            "loss: 0.814084  [ 2640/ 3840]\n",
            "loss: 0.863524  [ 2720/ 3840]\n",
            "loss: 0.730299  [ 2800/ 3840]\n",
            "loss: 0.637113  [ 2880/ 3840]\n",
            "loss: 0.727021  [ 2960/ 3840]\n",
            "loss: 0.538683  [ 3040/ 3840]\n",
            "loss: 0.595615  [ 3120/ 3840]\n",
            "loss: 0.994472  [ 3200/ 3840]\n",
            "loss: 1.069420  [ 3280/ 3840]\n",
            "loss: 1.194491  [ 3360/ 3840]\n",
            "loss: 0.565808  [ 3440/ 3840]\n",
            "loss: 0.462669  [ 3520/ 3840]\n",
            "loss: 1.095005  [ 3600/ 3840]\n",
            "loss: 0.449605  [ 3680/ 3840]\n",
            "loss: 0.533081  [ 3760/ 3840]\n",
            "Validation loss after epoch 4: 1.203158\n",
            "loss: 0.861971  [    0/ 3840]\n",
            "loss: 0.398323  [   80/ 3840]\n",
            "loss: 0.818870  [  160/ 3840]\n",
            "loss: 0.295551  [  240/ 3840]\n",
            "loss: 0.534084  [  320/ 3840]\n",
            "loss: 0.454036  [  400/ 3840]\n",
            "loss: 0.352198  [  480/ 3840]\n",
            "loss: 0.714154  [  560/ 3840]\n",
            "loss: 0.643234  [  640/ 3840]\n",
            "loss: 0.605611  [  720/ 3840]\n",
            "loss: 1.010546  [  800/ 3840]\n",
            "loss: 0.265223  [  880/ 3840]\n",
            "loss: 0.295855  [  960/ 3840]\n",
            "loss: 0.389051  [ 1040/ 3840]\n",
            "loss: 0.686642  [ 1120/ 3840]\n",
            "loss: 0.582180  [ 1200/ 3840]\n",
            "loss: 0.484046  [ 1280/ 3840]\n",
            "loss: 0.476882  [ 1360/ 3840]\n",
            "loss: 0.347869  [ 1440/ 3840]\n",
            "loss: 0.602412  [ 1520/ 3840]\n",
            "loss: 0.541171  [ 1600/ 3840]\n",
            "loss: 0.419464  [ 1680/ 3840]\n",
            "loss: 0.454720  [ 1760/ 3840]\n",
            "loss: 0.420988  [ 1840/ 3840]\n",
            "loss: 0.442453  [ 1920/ 3840]\n",
            "loss: 0.232169  [ 2000/ 3840]\n",
            "loss: 0.472932  [ 2080/ 3840]\n",
            "loss: 0.459186  [ 2160/ 3840]\n",
            "loss: 0.451842  [ 2240/ 3840]\n",
            "loss: 0.548793  [ 2320/ 3840]\n",
            "loss: 0.503908  [ 2400/ 3840]\n",
            "loss: 0.970228  [ 2480/ 3840]\n",
            "loss: 0.225359  [ 2560/ 3840]\n",
            "loss: 0.300242  [ 2640/ 3840]\n",
            "loss: 0.714566  [ 2720/ 3840]\n",
            "loss: 0.352064  [ 2800/ 3840]\n",
            "loss: 0.329687  [ 2880/ 3840]\n",
            "loss: 0.727728  [ 2960/ 3840]\n",
            "loss: 0.201068  [ 3040/ 3840]\n",
            "loss: 0.714957  [ 3120/ 3840]\n",
            "loss: 0.271094  [ 3200/ 3840]\n",
            "loss: 1.036308  [ 3280/ 3840]\n",
            "loss: 0.181114  [ 3360/ 3840]\n",
            "loss: 0.732760  [ 3440/ 3840]\n",
            "loss: 0.410387  [ 3520/ 3840]\n",
            "loss: 0.881567  [ 3600/ 3840]\n",
            "loss: 0.324119  [ 3680/ 3840]\n",
            "loss: 0.342273  [ 3760/ 3840]\n",
            "Validation loss after epoch 5: 1.243478\n",
            "Early stopping at epoch 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-05-19 21:16:08,203] Trial 16 finished with value: 54.895833333333336 and parameters: {'dropout_rate': 0.2360456412116807, 'learning_rate': 1.3913722105161326e-05, 'batch_size': 8}. Best is trial 0 with value: 57.1875.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 1.782448  [    0/ 3840]\n",
            "loss: 1.796528  [   80/ 3840]\n",
            "loss: 1.789385  [  160/ 3840]\n",
            "loss: 1.805269  [  240/ 3840]\n",
            "loss: 1.762609  [  320/ 3840]\n",
            "loss: 1.752522  [  400/ 3840]\n",
            "loss: 1.755960  [  480/ 3840]\n",
            "loss: 1.709466  [  560/ 3840]\n",
            "loss: 1.729952  [  640/ 3840]\n",
            "loss: 1.678246  [  720/ 3840]\n",
            "loss: 1.666139  [  800/ 3840]\n",
            "loss: 1.537909  [  880/ 3840]\n",
            "loss: 1.633352  [  960/ 3840]\n",
            "loss: 1.613446  [ 1040/ 3840]\n",
            "loss: 1.452300  [ 1120/ 3840]\n",
            "loss: 1.617595  [ 1200/ 3840]\n",
            "loss: 1.478233  [ 1280/ 3840]\n",
            "loss: 1.627517  [ 1360/ 3840]\n",
            "loss: 1.673118  [ 1440/ 3840]\n",
            "loss: 1.489078  [ 1520/ 3840]\n",
            "loss: 1.295573  [ 1600/ 3840]\n",
            "loss: 1.391150  [ 1680/ 3840]\n",
            "loss: 1.327805  [ 1760/ 3840]\n",
            "loss: 1.360627  [ 1840/ 3840]\n",
            "loss: 1.568414  [ 1920/ 3840]\n",
            "loss: 1.414531  [ 2000/ 3840]\n",
            "loss: 1.427901  [ 2080/ 3840]\n",
            "loss: 1.232468  [ 2160/ 3840]\n",
            "loss: 1.320018  [ 2240/ 3840]\n",
            "loss: 1.218506  [ 2320/ 3840]\n",
            "loss: 1.257405  [ 2400/ 3840]\n",
            "loss: 1.249423  [ 2480/ 3840]\n",
            "loss: 1.476065  [ 2560/ 3840]\n",
            "loss: 1.276738  [ 2640/ 3840]\n",
            "loss: 1.317396  [ 2720/ 3840]\n",
            "loss: 1.237788  [ 2800/ 3840]\n",
            "loss: 1.377295  [ 2880/ 3840]\n",
            "loss: 1.625039  [ 2960/ 3840]\n",
            "loss: 1.283658  [ 3040/ 3840]\n",
            "loss: 1.198525  [ 3120/ 3840]\n",
            "loss: 1.436025  [ 3200/ 3840]\n",
            "loss: 1.148251  [ 3280/ 3840]\n",
            "loss: 1.278734  [ 3360/ 3840]\n",
            "loss: 1.486518  [ 3440/ 3840]\n",
            "loss: 1.063906  [ 3520/ 3840]\n",
            "loss: 1.528433  [ 3600/ 3840]\n",
            "loss: 1.654114  [ 3680/ 3840]\n",
            "loss: 0.984355  [ 3760/ 3840]\n",
            "Validation loss after epoch 1: 1.212650\n",
            "loss: 1.119922  [    0/ 3840]\n",
            "loss: 1.045397  [   80/ 3840]\n",
            "loss: 1.129716  [  160/ 3840]\n",
            "loss: 1.053752  [  240/ 3840]\n",
            "loss: 1.072726  [  320/ 3840]\n",
            "loss: 1.070957  [  400/ 3840]\n",
            "loss: 0.739670  [  480/ 3840]\n",
            "loss: 1.180121  [  560/ 3840]\n",
            "loss: 1.121484  [  640/ 3840]\n",
            "loss: 1.131877  [  720/ 3840]\n",
            "loss: 1.127754  [  800/ 3840]\n",
            "loss: 1.645248  [  880/ 3840]\n",
            "loss: 1.058545  [  960/ 3840]\n",
            "loss: 1.009845  [ 1040/ 3840]\n",
            "loss: 1.198843  [ 1120/ 3840]\n",
            "loss: 1.141539  [ 1200/ 3840]\n",
            "loss: 1.138696  [ 1280/ 3840]\n",
            "loss: 0.872209  [ 1360/ 3840]\n",
            "loss: 0.845727  [ 1440/ 3840]\n",
            "loss: 0.894474  [ 1520/ 3840]\n",
            "loss: 1.104541  [ 1600/ 3840]\n",
            "loss: 0.796512  [ 1680/ 3840]\n",
            "loss: 1.209640  [ 1760/ 3840]\n",
            "loss: 0.786008  [ 1840/ 3840]\n",
            "loss: 1.148892  [ 1920/ 3840]\n",
            "loss: 1.084978  [ 2000/ 3840]\n",
            "loss: 0.758565  [ 2080/ 3840]\n",
            "loss: 1.100820  [ 2160/ 3840]\n",
            "loss: 1.058883  [ 2240/ 3840]\n",
            "loss: 0.633857  [ 2320/ 3840]\n",
            "loss: 1.014293  [ 2400/ 3840]\n",
            "loss: 0.811822  [ 2480/ 3840]\n",
            "loss: 0.686051  [ 2560/ 3840]\n",
            "loss: 1.023084  [ 2640/ 3840]\n",
            "loss: 0.859124  [ 2720/ 3840]\n",
            "loss: 0.926738  [ 2800/ 3840]\n",
            "loss: 1.109610  [ 2880/ 3840]\n",
            "loss: 0.943174  [ 2960/ 3840]\n",
            "loss: 0.870877  [ 3040/ 3840]\n",
            "loss: 1.013880  [ 3120/ 3840]\n",
            "loss: 1.196359  [ 3200/ 3840]\n",
            "loss: 1.050604  [ 3280/ 3840]\n",
            "loss: 1.248848  [ 3360/ 3840]\n",
            "loss: 1.223406  [ 3440/ 3840]\n",
            "loss: 1.054952  [ 3520/ 3840]\n",
            "loss: 0.910161  [ 3600/ 3840]\n",
            "loss: 0.789128  [ 3680/ 3840]\n",
            "loss: 1.101816  [ 3760/ 3840]\n",
            "Validation loss after epoch 2: 1.058407\n",
            "loss: 0.718814  [    0/ 3840]\n",
            "loss: 0.768274  [   80/ 3840]\n",
            "loss: 0.889995  [  160/ 3840]\n",
            "loss: 0.932248  [  240/ 3840]\n",
            "loss: 1.011523  [  320/ 3840]\n",
            "loss: 0.846557  [  400/ 3840]\n",
            "loss: 1.038230  [  480/ 3840]\n",
            "loss: 0.998131  [  560/ 3840]\n",
            "loss: 0.696797  [  640/ 3840]\n",
            "loss: 0.994082  [  720/ 3840]\n",
            "loss: 1.100473  [  800/ 3840]\n",
            "loss: 0.989412  [  880/ 3840]\n",
            "loss: 1.226056  [  960/ 3840]\n",
            "loss: 0.986739  [ 1040/ 3840]\n",
            "loss: 0.687470  [ 1120/ 3840]\n",
            "loss: 0.675793  [ 1200/ 3840]\n",
            "loss: 0.604105  [ 1280/ 3840]\n",
            "loss: 1.070355  [ 1360/ 3840]\n",
            "loss: 0.814064  [ 1440/ 3840]\n",
            "loss: 0.853913  [ 1520/ 3840]\n",
            "loss: 1.196938  [ 1600/ 3840]\n",
            "loss: 1.043688  [ 1680/ 3840]\n",
            "loss: 0.749324  [ 1760/ 3840]\n",
            "loss: 0.683956  [ 1840/ 3840]\n",
            "loss: 0.587593  [ 1920/ 3840]\n",
            "loss: 0.701962  [ 2000/ 3840]\n",
            "loss: 0.466025  [ 2080/ 3840]\n",
            "loss: 0.902806  [ 2160/ 3840]\n",
            "loss: 1.239744  [ 2240/ 3840]\n",
            "loss: 1.635277  [ 2320/ 3840]\n",
            "loss: 0.672961  [ 2400/ 3840]\n",
            "loss: 0.642698  [ 2480/ 3840]\n",
            "loss: 0.928817  [ 2560/ 3840]\n",
            "loss: 0.770905  [ 2640/ 3840]\n",
            "loss: 0.491347  [ 2720/ 3840]\n",
            "loss: 0.700805  [ 2800/ 3840]\n",
            "loss: 0.816555  [ 2880/ 3840]\n",
            "loss: 0.547199  [ 2960/ 3840]\n",
            "loss: 0.895219  [ 3040/ 3840]\n",
            "loss: 0.501622  [ 3120/ 3840]\n",
            "loss: 0.457164  [ 3200/ 3840]\n",
            "loss: 0.889877  [ 3280/ 3840]\n",
            "loss: 0.642174  [ 3360/ 3840]\n",
            "loss: 1.185450  [ 3440/ 3840]\n",
            "loss: 0.510974  [ 3520/ 3840]\n",
            "loss: 1.257481  [ 3600/ 3840]\n",
            "loss: 0.915236  [ 3680/ 3840]\n",
            "loss: 0.914756  [ 3760/ 3840]\n",
            "Validation loss after epoch 3: 1.066745\n",
            "loss: 0.872035  [    0/ 3840]\n",
            "loss: 0.566957  [   80/ 3840]\n",
            "loss: 0.575189  [  160/ 3840]\n",
            "loss: 0.790148  [  240/ 3840]\n",
            "loss: 0.590056  [  320/ 3840]\n",
            "loss: 0.547389  [  400/ 3840]\n",
            "loss: 1.001416  [  480/ 3840]\n",
            "loss: 0.558175  [  560/ 3840]\n",
            "loss: 0.469510  [  640/ 3840]\n",
            "loss: 0.802212  [  720/ 3840]\n",
            "loss: 0.482212  [  800/ 3840]\n",
            "loss: 0.593598  [  880/ 3840]\n",
            "loss: 0.651787  [  960/ 3840]\n",
            "loss: 1.221839  [ 1040/ 3840]\n",
            "loss: 0.949164  [ 1120/ 3840]\n",
            "loss: 0.530847  [ 1200/ 3840]\n",
            "loss: 0.795526  [ 1280/ 3840]\n",
            "loss: 0.763791  [ 1360/ 3840]\n",
            "loss: 0.739321  [ 1440/ 3840]\n",
            "loss: 0.546266  [ 1520/ 3840]\n",
            "loss: 0.391746  [ 1600/ 3840]\n",
            "loss: 0.433311  [ 1680/ 3840]\n",
            "loss: 0.591426  [ 1760/ 3840]\n",
            "loss: 0.432453  [ 1840/ 3840]\n",
            "loss: 0.441942  [ 1920/ 3840]\n",
            "loss: 0.641230  [ 2000/ 3840]\n",
            "loss: 0.644639  [ 2080/ 3840]\n",
            "loss: 0.468669  [ 2160/ 3840]\n",
            "loss: 0.795887  [ 2240/ 3840]\n",
            "loss: 0.564372  [ 2320/ 3840]\n",
            "loss: 0.376451  [ 2400/ 3840]\n",
            "loss: 0.626086  [ 2480/ 3840]\n",
            "loss: 0.761537  [ 2560/ 3840]\n",
            "loss: 1.212163  [ 2640/ 3840]\n",
            "loss: 0.674955  [ 2720/ 3840]\n",
            "loss: 0.541954  [ 2800/ 3840]\n",
            "loss: 1.082187  [ 2880/ 3840]\n",
            "loss: 1.263433  [ 2960/ 3840]\n",
            "loss: 1.534754  [ 3040/ 3840]\n",
            "loss: 0.634101  [ 3120/ 3840]\n",
            "loss: 0.460031  [ 3200/ 3840]\n",
            "loss: 1.283143  [ 3280/ 3840]\n",
            "loss: 0.454060  [ 3360/ 3840]\n",
            "loss: 0.650566  [ 3440/ 3840]\n",
            "loss: 0.444086  [ 3520/ 3840]\n",
            "loss: 0.446997  [ 3600/ 3840]\n",
            "loss: 0.405428  [ 3680/ 3840]\n",
            "loss: 0.278250  [ 3760/ 3840]\n",
            "Validation loss after epoch 4: 1.231837\n",
            "loss: 0.570943  [    0/ 3840]\n",
            "loss: 0.588200  [   80/ 3840]\n",
            "loss: 0.573839  [  160/ 3840]\n",
            "loss: 0.418065  [  240/ 3840]\n",
            "loss: 0.484090  [  320/ 3840]\n",
            "loss: 0.248309  [  400/ 3840]\n",
            "loss: 0.884004  [  480/ 3840]\n",
            "loss: 0.282852  [  560/ 3840]\n",
            "loss: 0.285199  [  640/ 3840]\n",
            "loss: 0.474730  [  720/ 3840]\n",
            "loss: 0.366297  [  800/ 3840]\n",
            "loss: 0.507345  [  880/ 3840]\n",
            "loss: 0.493929  [  960/ 3840]\n",
            "loss: 0.222217  [ 1040/ 3840]\n",
            "loss: 0.272383  [ 1120/ 3840]\n",
            "loss: 0.441065  [ 1200/ 3840]\n",
            "loss: 0.459385  [ 1280/ 3840]\n",
            "loss: 0.497151  [ 1360/ 3840]\n",
            "loss: 0.849848  [ 1440/ 3840]\n",
            "loss: 0.657346  [ 1520/ 3840]\n",
            "loss: 0.449917  [ 1600/ 3840]\n",
            "loss: 0.708659  [ 1680/ 3840]\n",
            "loss: 0.508566  [ 1760/ 3840]\n",
            "loss: 1.036612  [ 1840/ 3840]\n",
            "loss: 1.075893  [ 1920/ 3840]\n",
            "loss: 0.387953  [ 2000/ 3840]\n",
            "loss: 0.108582  [ 2080/ 3840]\n",
            "loss: 0.939043  [ 2160/ 3840]\n",
            "loss: 0.266521  [ 2240/ 3840]\n",
            "loss: 0.477891  [ 2320/ 3840]\n",
            "loss: 0.488346  [ 2400/ 3840]\n",
            "loss: 0.449263  [ 2480/ 3840]\n",
            "loss: 0.540567  [ 2560/ 3840]\n",
            "loss: 0.550130  [ 2640/ 3840]\n",
            "loss: 1.040194  [ 2720/ 3840]\n",
            "loss: 0.176329  [ 2800/ 3840]\n",
            "loss: 0.322489  [ 2880/ 3840]\n",
            "loss: 0.272732  [ 2960/ 3840]\n",
            "loss: 0.173599  [ 3040/ 3840]\n",
            "loss: 0.576603  [ 3120/ 3840]\n",
            "loss: 0.455312  [ 3200/ 3840]\n",
            "loss: 0.200968  [ 3280/ 3840]\n",
            "loss: 0.981792  [ 3360/ 3840]\n",
            "loss: 0.272823  [ 3440/ 3840]\n",
            "loss: 0.533959  [ 3520/ 3840]\n",
            "loss: 0.367594  [ 3600/ 3840]\n",
            "loss: 0.620758  [ 3680/ 3840]\n",
            "loss: 0.349384  [ 3760/ 3840]\n",
            "Validation loss after epoch 5: 1.232787\n",
            "Early stopping at epoch 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-05-19 21:21:52,165] Trial 17 finished with value: 56.458333333333336 and parameters: {'dropout_rate': 0.28164448133404796, 'learning_rate': 1.3489037971416393e-05, 'batch_size': 8}. Best is trial 0 with value: 57.1875.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 1.801202  [    0/ 3840]\n",
            "loss: 1.726505  [  160/ 3840]\n",
            "loss: 1.617953  [  320/ 3840]\n",
            "loss: 1.733262  [  480/ 3840]\n",
            "loss: 1.282575  [  640/ 3840]\n",
            "loss: 1.284037  [  800/ 3840]\n",
            "loss: 1.298669  [  960/ 3840]\n",
            "loss: 1.398881  [ 1120/ 3840]\n",
            "loss: 1.215397  [ 1280/ 3840]\n",
            "loss: 1.608696  [ 1440/ 3840]\n",
            "loss: 1.535506  [ 1600/ 3840]\n",
            "loss: 1.075477  [ 1760/ 3840]\n",
            "loss: 1.379975  [ 1920/ 3840]\n",
            "loss: 1.298061  [ 2080/ 3840]\n",
            "loss: 1.235291  [ 2240/ 3840]\n",
            "loss: 1.237603  [ 2400/ 3840]\n",
            "loss: 1.079203  [ 2560/ 3840]\n",
            "loss: 1.140659  [ 2720/ 3840]\n",
            "loss: 1.156126  [ 2880/ 3840]\n",
            "loss: 0.987377  [ 3040/ 3840]\n",
            "loss: 1.001239  [ 3200/ 3840]\n",
            "loss: 0.948272  [ 3360/ 3840]\n",
            "loss: 1.086642  [ 3520/ 3840]\n",
            "loss: 1.290239  [ 3680/ 3840]\n",
            "Validation loss after epoch 1: 1.082921\n",
            "loss: 1.018153  [    0/ 3840]\n",
            "loss: 0.971961  [  160/ 3840]\n",
            "loss: 1.037943  [  320/ 3840]\n",
            "loss: 0.942455  [  480/ 3840]\n",
            "loss: 1.002780  [  640/ 3840]\n",
            "loss: 1.247078  [  800/ 3840]\n",
            "loss: 1.224928  [  960/ 3840]\n",
            "loss: 0.879668  [ 1120/ 3840]\n",
            "loss: 1.062436  [ 1280/ 3840]\n",
            "loss: 1.134186  [ 1440/ 3840]\n",
            "loss: 0.883056  [ 1600/ 3840]\n",
            "loss: 1.083536  [ 1760/ 3840]\n",
            "loss: 0.723517  [ 1920/ 3840]\n",
            "loss: 1.147980  [ 2080/ 3840]\n",
            "loss: 0.818013  [ 2240/ 3840]\n",
            "loss: 0.722798  [ 2400/ 3840]\n",
            "loss: 0.869175  [ 2560/ 3840]\n",
            "loss: 1.413740  [ 2720/ 3840]\n",
            "loss: 1.216757  [ 2880/ 3840]\n",
            "loss: 1.045907  [ 3040/ 3840]\n",
            "loss: 0.898479  [ 3200/ 3840]\n",
            "loss: 0.980457  [ 3360/ 3840]\n",
            "loss: 0.723384  [ 3520/ 3840]\n",
            "loss: 0.952779  [ 3680/ 3840]\n",
            "Validation loss after epoch 2: 1.164450\n",
            "loss: 0.957366  [    0/ 3840]\n",
            "loss: 0.937221  [  160/ 3840]\n",
            "loss: 0.686615  [  320/ 3840]\n",
            "loss: 0.728597  [  480/ 3840]\n",
            "loss: 0.835829  [  640/ 3840]\n",
            "loss: 0.616826  [  800/ 3840]\n",
            "loss: 0.542164  [  960/ 3840]\n",
            "loss: 1.097076  [ 1120/ 3840]\n",
            "loss: 0.757948  [ 1280/ 3840]\n",
            "loss: 0.801070  [ 1440/ 3840]\n",
            "loss: 0.523033  [ 1600/ 3840]\n",
            "loss: 0.907538  [ 1760/ 3840]\n",
            "loss: 0.887156  [ 1920/ 3840]\n",
            "loss: 1.098176  [ 2080/ 3840]\n",
            "loss: 1.178116  [ 2240/ 3840]\n",
            "loss: 0.716274  [ 2400/ 3840]\n",
            "loss: 1.113858  [ 2560/ 3840]\n",
            "loss: 0.689911  [ 2720/ 3840]\n",
            "loss: 0.770381  [ 2880/ 3840]\n",
            "loss: 0.762732  [ 3040/ 3840]\n",
            "loss: 0.444072  [ 3200/ 3840]\n",
            "loss: 0.988750  [ 3360/ 3840]\n",
            "loss: 0.665428  [ 3520/ 3840]\n",
            "loss: 0.545751  [ 3680/ 3840]\n",
            "Validation loss after epoch 3: 1.140152\n",
            "loss: 0.544672  [    0/ 3840]\n",
            "loss: 0.276943  [  160/ 3840]\n",
            "loss: 0.690751  [  320/ 3840]\n",
            "loss: 0.689108  [  480/ 3840]\n",
            "loss: 0.731197  [  640/ 3840]\n",
            "loss: 0.658219  [  800/ 3840]\n",
            "loss: 0.407914  [  960/ 3840]\n",
            "loss: 0.784403  [ 1120/ 3840]\n",
            "loss: 0.586659  [ 1280/ 3840]\n",
            "loss: 0.549264  [ 1440/ 3840]\n",
            "loss: 0.339322  [ 1600/ 3840]\n",
            "loss: 0.325358  [ 1760/ 3840]\n",
            "loss: 0.571398  [ 1920/ 3840]\n",
            "loss: 0.496065  [ 2080/ 3840]\n",
            "loss: 0.538434  [ 2240/ 3840]\n",
            "loss: 0.255057  [ 2400/ 3840]\n",
            "loss: 0.522923  [ 2560/ 3840]\n",
            "loss: 0.432886  [ 2720/ 3840]\n",
            "loss: 0.744064  [ 2880/ 3840]\n",
            "loss: 0.312522  [ 3040/ 3840]\n",
            "loss: 0.864127  [ 3200/ 3840]\n",
            "loss: 0.868645  [ 3360/ 3840]\n",
            "loss: 0.530212  [ 3520/ 3840]\n",
            "loss: 0.581884  [ 3680/ 3840]\n",
            "Validation loss after epoch 4: 1.229152\n",
            "Early stopping at epoch 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-05-19 21:26:11,792] Trial 18 finished with value: 56.145833333333336 and parameters: {'dropout_rate': 0.19021460097409612, 'learning_rate': 9.917715974773634e-05, 'batch_size': 16}. Best is trial 0 with value: 57.1875.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 1.794352  [    0/ 3840]\n",
            "loss: 1.779471  [  320/ 3840]\n",
            "loss: 1.698121  [  640/ 3840]\n",
            "loss: 1.608974  [  960/ 3840]\n",
            "loss: 1.535112  [ 1280/ 3840]\n",
            "loss: 1.497649  [ 1600/ 3840]\n",
            "loss: 1.434772  [ 1920/ 3840]\n",
            "loss: 1.242314  [ 2240/ 3840]\n",
            "loss: 1.312907  [ 2560/ 3840]\n",
            "loss: 1.226405  [ 2880/ 3840]\n",
            "loss: 1.353528  [ 3200/ 3840]\n",
            "loss: 1.146842  [ 3520/ 3840]\n",
            "Validation loss after epoch 1: 1.144596\n",
            "loss: 1.057906  [    0/ 3840]\n",
            "loss: 0.990792  [  320/ 3840]\n",
            "loss: 1.014521  [  640/ 3840]\n",
            "loss: 1.034852  [  960/ 3840]\n",
            "loss: 0.929700  [ 1280/ 3840]\n",
            "loss: 1.031501  [ 1600/ 3840]\n",
            "loss: 1.030407  [ 1920/ 3840]\n",
            "loss: 1.044115  [ 2240/ 3840]\n",
            "loss: 1.116666  [ 2560/ 3840]\n",
            "loss: 1.009580  [ 2880/ 3840]\n",
            "loss: 0.978244  [ 3200/ 3840]\n",
            "loss: 1.061434  [ 3520/ 3840]\n",
            "Validation loss after epoch 2: 1.050550\n",
            "loss: 0.907203  [    0/ 3840]\n",
            "loss: 0.776194  [  320/ 3840]\n",
            "loss: 1.120545  [  640/ 3840]\n",
            "loss: 0.793579  [  960/ 3840]\n",
            "loss: 0.905533  [ 1280/ 3840]\n",
            "loss: 0.972419  [ 1600/ 3840]\n",
            "loss: 0.658386  [ 1920/ 3840]\n",
            "loss: 0.949888  [ 2240/ 3840]\n",
            "loss: 0.994532  [ 2560/ 3840]\n",
            "loss: 0.877284  [ 2880/ 3840]\n",
            "loss: 0.747055  [ 3200/ 3840]\n",
            "loss: 0.847695  [ 3520/ 3840]\n",
            "Validation loss after epoch 3: 1.053012\n",
            "loss: 0.552512  [    0/ 3840]\n",
            "loss: 0.740739  [  320/ 3840]\n",
            "loss: 0.692993  [  640/ 3840]\n",
            "loss: 0.618080  [  960/ 3840]\n",
            "loss: 0.572662  [ 1280/ 3840]\n",
            "loss: 0.660048  [ 1600/ 3840]\n",
            "loss: 0.850979  [ 1920/ 3840]\n",
            "loss: 0.546044  [ 2240/ 3840]\n",
            "loss: 0.574521  [ 2560/ 3840]\n",
            "loss: 0.612641  [ 2880/ 3840]\n",
            "loss: 0.500094  [ 3200/ 3840]\n",
            "loss: 0.652358  [ 3520/ 3840]\n",
            "Validation loss after epoch 4: 1.148426\n",
            "loss: 0.339021  [    0/ 3840]\n",
            "loss: 0.518133  [  320/ 3840]\n",
            "loss: 0.447832  [  640/ 3840]\n",
            "loss: 0.496615  [  960/ 3840]\n",
            "loss: 0.565104  [ 1280/ 3840]\n",
            "loss: 0.419689  [ 1600/ 3840]\n",
            "loss: 0.459224  [ 1920/ 3840]\n",
            "loss: 0.480210  [ 2240/ 3840]\n",
            "loss: 0.419972  [ 2560/ 3840]\n",
            "loss: 0.474292  [ 2880/ 3840]\n",
            "loss: 0.253321  [ 3200/ 3840]\n",
            "loss: 0.527648  [ 3520/ 3840]\n",
            "Validation loss after epoch 5: 1.317009\n",
            "Early stopping at epoch 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-05-19 21:31:17,263] Trial 19 finished with value: 57.708333333333336 and parameters: {'dropout_rate': 0.23742662960934047, 'learning_rate': 4.0765029937311724e-05, 'batch_size': 32}. Best is trial 19 with value: 57.708333333333336.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best hyperparameters: {'dropout_rate': 0.23742662960934047, 'learning_rate': 4.0765029937311724e-05, 'batch_size': 32}\n",
            "Best validation accuracy: 57.71%\n",
            "loss: 1.793178  [    0/ 3840]\n",
            "loss: 1.763588  [  320/ 3840]\n",
            "loss: 1.724024  [  640/ 3840]\n",
            "loss: 1.610174  [  960/ 3840]\n",
            "loss: 1.528123  [ 1280/ 3840]\n",
            "loss: 1.426278  [ 1600/ 3840]\n",
            "loss: 1.419563  [ 1920/ 3840]\n",
            "loss: 1.300993  [ 2240/ 3840]\n",
            "loss: 1.279669  [ 2560/ 3840]\n",
            "loss: 1.194616  [ 2880/ 3840]\n",
            "loss: 1.376317  [ 3200/ 3840]\n",
            "loss: 1.271466  [ 3520/ 3840]\n",
            "Validation loss after epoch 1: 1.119990\n",
            "loss: 0.955432  [    0/ 3840]\n",
            "loss: 1.114572  [  320/ 3840]\n",
            "loss: 0.890392  [  640/ 3840]\n",
            "loss: 0.817946  [  960/ 3840]\n",
            "loss: 1.141749  [ 1280/ 3840]\n",
            "loss: 0.946002  [ 1600/ 3840]\n",
            "loss: 0.926838  [ 1920/ 3840]\n",
            "loss: 1.036017  [ 2240/ 3840]\n",
            "loss: 0.933069  [ 2560/ 3840]\n",
            "loss: 1.104693  [ 2880/ 3840]\n",
            "loss: 0.945609  [ 3200/ 3840]\n",
            "loss: 1.022922  [ 3520/ 3840]\n",
            "Validation loss after epoch 2: 1.056385\n",
            "loss: 0.778352  [    0/ 3840]\n",
            "loss: 0.600761  [  320/ 3840]\n",
            "loss: 0.886999  [  640/ 3840]\n",
            "loss: 0.896602  [  960/ 3840]\n",
            "loss: 0.649672  [ 1280/ 3840]\n",
            "loss: 0.842301  [ 1600/ 3840]\n",
            "loss: 0.686826  [ 1920/ 3840]\n",
            "loss: 0.679473  [ 2240/ 3840]\n",
            "loss: 0.671250  [ 2560/ 3840]\n",
            "loss: 0.796635  [ 2880/ 3840]\n",
            "loss: 0.675568  [ 3200/ 3840]\n",
            "loss: 0.722104  [ 3520/ 3840]\n",
            "Validation loss after epoch 3: 1.119053\n",
            "loss: 0.505564  [    0/ 3840]\n",
            "loss: 0.564184  [  320/ 3840]\n",
            "loss: 0.600311  [  640/ 3840]\n",
            "loss: 0.658461  [  960/ 3840]\n",
            "loss: 0.446042  [ 1280/ 3840]\n",
            "loss: 0.445259  [ 1600/ 3840]\n",
            "loss: 0.404481  [ 1920/ 3840]\n",
            "loss: 0.488416  [ 2240/ 3840]\n",
            "loss: 0.781425  [ 2560/ 3840]\n",
            "loss: 0.602208  [ 2880/ 3840]\n",
            "loss: 0.553091  [ 3200/ 3840]\n",
            "loss: 0.677975  [ 3520/ 3840]\n",
            "Validation loss after epoch 4: 1.180130\n",
            "loss: 0.394756  [    0/ 3840]\n",
            "loss: 0.552394  [  320/ 3840]\n",
            "loss: 0.325926  [  640/ 3840]\n",
            "loss: 0.199232  [  960/ 3840]\n",
            "loss: 0.671073  [ 1280/ 3840]\n",
            "loss: 0.438763  [ 1600/ 3840]\n",
            "loss: 0.527776  [ 1920/ 3840]\n",
            "loss: 0.221314  [ 2240/ 3840]\n",
            "loss: 0.282380  [ 2560/ 3840]\n",
            "loss: 0.213010  [ 2880/ 3840]\n",
            "loss: 0.274912  [ 3200/ 3840]\n",
            "loss: 0.390234  [ 3520/ 3840]\n",
            "Validation loss after epoch 5: 1.344831\n",
            "Early stopping at epoch 6\n",
            "Final Test Accuracy: 56.35%\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-46fc274c4b47>\u001b[0m in \u001b[0;36m<cell line: 186>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Make sure the model is in evaluation mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0mall_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import CamembertTokenizer, CamembertModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load your data\n",
        "data = df_train\n",
        "sentences = data['sentence'].tolist()\n",
        "difficulties = data['difficulty'].tolist()\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(difficulties)\n",
        "\n",
        "# Load CamemBERT tokenizer and model\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
        "\n",
        "# Tokenize sentences and convert to tensor\n",
        "def tokenize_and_encode(sentences):\n",
        "    return tokenizer(sentences, padding=True, truncation=True, max_length=600, return_tensors='pt')\n",
        "\n",
        "# Custom Dataset class\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.encodings = tokenize_and_encode(texts)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: self.encodings[key][idx] for key in self.encodings}, self.labels[idx]\n",
        "\n",
        "# Data preparation\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    sentences, encoded_labels, test_size=0.2, random_state=42, stratify=encoded_labels\n",
        ")\n",
        "\n",
        "train_dataset = TextDataset(X_train, y_train)\n",
        "test_dataset = TextDataset(X_test, y_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# Neural network model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes, dropout_rate):\n",
        "        super(Net, self).__init__()\n",
        "        self.camembert = CamembertModel.from_pretrained('camembert-base')\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.fc = nn.Linear(self.camembert.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        outputs = self.camembert(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.fc(pooled_output)\n",
        "        return logits\n",
        "\n",
        "# Function to compute accuracy\n",
        "def compute_accuracy(dataloader, model):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            inputs, labels = batch\n",
        "            inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
        "            labels = labels.to('cuda')\n",
        "            outputs = model(**inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "# Function to compute validation loss\n",
        "def compute_validation_loss(dataloader, model, loss_fn):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            inputs, labels = batch\n",
        "            inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
        "            labels = labels.to('cuda')\n",
        "            outputs = model(**inputs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "# Training loop with early stopping\n",
        "def train_loop_with_early_stopping(dataloader, model, loss_fn, optimizer, val_loader, patience=3):\n",
        "    size = len(dataloader.dataset)\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_no_improve = 0\n",
        "    early_stop = False\n",
        "\n",
        "    for epoch in range(10):  # Set a high number of epochs\n",
        "        if early_stop:\n",
        "            print(f\"Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "        model.train()  # Set model to training mode\n",
        "        for batch, (inputs, labels) in enumerate(dataloader):\n",
        "            inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
        "            labels = labels.to('cuda')\n",
        "            pred = model(**inputs)\n",
        "            loss = loss_fn(pred, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if batch % 10 == 0:\n",
        "                loss, current = loss.item(), batch * len(inputs['input_ids'])\n",
        "                print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "        # Compute validation loss\n",
        "        val_loss = compute_validation_loss(val_loader, model, loss_fn)\n",
        "        print(f\"Validation loss after epoch {epoch+1}: {val_loss:>7f}\")\n",
        "\n",
        "        # Check for early stopping\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve == patience:\n",
        "                early_stop = True\n",
        "\n",
        "# Objective function for Optuna\n",
        "def objective(trial):\n",
        "    # Hyperparameters to tune\n",
        "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.3)\n",
        "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-4)\n",
        "    batch_size = trial.suggest_categorical('batch_size', [8, 16, 32])\n",
        "\n",
        "    # Re-create the DataLoader with the new batch size\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Instantiate the model, loss, and optimizer with the suggested hyperparameters\n",
        "    model = Net(len(label_encoder.classes_), dropout_rate).to('cuda')\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Training loop with early stopping\n",
        "    train_loop_with_early_stopping(train_loader, model, criterion, optimizer, test_loader)\n",
        "\n",
        "    # Compute validation accuracy\n",
        "    accuracy = compute_accuracy(test_loader, model)\n",
        "    return accuracy\n",
        "\n",
        "# Set up and run the study\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=20)  # Number of trials\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(f\"Best hyperparameters: {study.best_params}\")\n",
        "print(f\"Best validation accuracy: {study.best_value:.2f}%\")\n",
        "\n",
        "# Use the best hyperparameters to train the final model\n",
        "best_params = study.best_params\n",
        "final_model = Net(len(label_encoder.classes_), best_params['dropout_rate']).to('cuda')\n",
        "final_criterion = nn.CrossEntropyLoss()\n",
        "final_optimizer = torch.optim.Adam(final_model.parameters(), lr=best_params['learning_rate'])\n",
        "\n",
        "# Re-create the DataLoader with the best batch size\n",
        "train_loader = DataLoader(train_dataset, batch_size=best_params['batch_size'], shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=best_params['batch_size'], shuffle=False)\n",
        "\n",
        "# Final training loop with early stopping\n",
        "train_loop_with_early_stopping(train_loader, final_model, final_criterion, final_optimizer, test_loader)\n",
        "\n",
        "# Test the final model\n",
        "final_accuracy = compute_accuracy(test_loader, final_model)\n",
        "print(f\"Final Test Accuracy: {final_accuracy:.2f}%\")\n",
        "\n",
        "# Generate predictions for df_test\n",
        "test_dataset = TextDataset(df_test['sentence'].tolist(), np.zeros(len(df_test)))\n",
        "test_loader = DataLoader(test_dataset, batch_size=best_params['batch_size'], shuffle=False)\n",
        "\n",
        "final_model.eval()  # Make sure the model is in evaluation mode\n",
        "all_predictions = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        inputs, _ = batch\n",
        "        inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
        "        outputs = final_model(**inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "# Convert numeric predictions back to labels\n",
        "predicted_labels = label_encoder.inverse_transform(all_predictions)\n",
        "\n",
        "# Prepare and save the submission file\n",
        "submission_df = pd.DataFrame({\n",
        "    'id': df_test['id'],  # Ensure df_test includes an 'id' column\n",
        "    'difficulty': predicted_labels\n",
        "})\n",
        "submission_df.to_csv('submission_optuna.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-XYXtFxJAUyX"
      },
      "outputs": [],
      "source": [
        "final_model.eval()  # Make sure the model is in evaluation mode\n",
        "all_predictions = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        inputs, _ = batch\n",
        "        inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
        "        outputs = final_model(**inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "# Convert numeric predictions back to labels\n",
        "predicted_labels = label_encoder.inverse_transform(all_predictions)\n",
        "\n",
        "# Prepare and save the submission file\n",
        "submission_df = pd.DataFrame({\n",
        "    'id': df_test['id'],  # Ensure df_test includes an 'id' column\n",
        "    'difficulty': predicted_labels\n",
        "})\n",
        "submission_df.to_csv('submission_optuna.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "DdJKZLdwD4hC",
        "outputId": "f70d996b-998e-4e64-bcdc-a0468a6bf126"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'final_model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-9b894dbe968a>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Assuming final_model is the trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"final_model.pth\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Model saved to {model_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'final_model' is not defined"
          ]
        }
      ],
      "source": [
        "# Assuming final_model is the trained model\n",
        "model_path = \"final_model.pth\"\n",
        "torch.save(final_model.state_dict(), model_path)\n",
        "print(f\"Model saved to {model_path}\")\n",
        "\n",
        "from google.colab import files\n",
        "files.download(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ceYI-_7kTLMU",
        "outputId": "bede7fd0-b76d-47ad-d711-a388f6f2e729"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "[I 2024-05-20 17:58:21,059] A new study created in memory with name: no-name-797e712f-42c6-4ae7-acdb-1c37a9a20769\n",
            "<ipython-input-13-b7e8d5179b74>:139: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 8e-5)\n",
            "<ipython-input-13-b7e8d5179b74>:141: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-4, 0.2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 1.789351  [    0/ 4320]\n",
            "loss: 1.785539  [  160/ 4320]\n",
            "loss: 1.767970  [  320/ 4320]\n",
            "loss: 1.793332  [  480/ 4320]\n",
            "loss: 1.724029  [  640/ 4320]\n",
            "loss: 1.672614  [  800/ 4320]\n",
            "loss: 1.683579  [  960/ 4320]\n",
            "loss: 1.529402  [ 1120/ 4320]\n",
            "loss: 1.538710  [ 1280/ 4320]\n",
            "loss: 1.500074  [ 1440/ 4320]\n",
            "loss: 1.396442  [ 1600/ 4320]\n",
            "loss: 1.391447  [ 1760/ 4320]\n",
            "loss: 1.371301  [ 1920/ 4320]\n",
            "loss: 1.421499  [ 2080/ 4320]\n",
            "loss: 1.199289  [ 2240/ 4320]\n",
            "loss: 1.167632  [ 2400/ 4320]\n",
            "loss: 1.155649  [ 2560/ 4320]\n",
            "loss: 1.143013  [ 2720/ 4320]\n",
            "loss: 1.020059  [ 2880/ 4320]\n",
            "loss: 1.050261  [ 3040/ 4320]\n",
            "loss: 1.108748  [ 3200/ 4320]\n",
            "loss: 1.211463  [ 3360/ 4320]\n",
            "loss: 1.298265  [ 3520/ 4320]\n",
            "loss: 0.931503  [ 3680/ 4320]\n",
            "loss: 0.987199  [ 3840/ 4320]\n",
            "loss: 0.846241  [ 4000/ 4320]\n",
            "loss: 0.979629  [ 4160/ 4320]\n",
            "Validation loss after epoch 1: 1.094302\n",
            "loss: 0.971393  [    0/ 4320]\n",
            "loss: 1.093918  [  160/ 4320]\n",
            "loss: 1.110291  [  320/ 4320]\n",
            "loss: 0.919415  [  480/ 4320]\n",
            "loss: 1.146944  [  640/ 4320]\n",
            "loss: 0.948747  [  800/ 4320]\n",
            "loss: 0.896250  [  960/ 4320]\n",
            "loss: 0.831687  [ 1120/ 4320]\n",
            "loss: 0.850799  [ 1280/ 4320]\n",
            "loss: 1.159401  [ 1440/ 4320]\n",
            "loss: 1.018385  [ 1600/ 4320]\n",
            "loss: 0.927473  [ 1760/ 4320]\n",
            "loss: 0.933430  [ 1920/ 4320]\n",
            "loss: 0.928137  [ 2080/ 4320]\n",
            "loss: 0.714971  [ 2240/ 4320]\n",
            "loss: 0.837413  [ 2400/ 4320]\n",
            "loss: 0.931714  [ 2560/ 4320]\n",
            "loss: 0.979153  [ 2720/ 4320]\n",
            "loss: 0.947029  [ 2880/ 4320]\n",
            "loss: 0.907937  [ 3040/ 4320]\n",
            "loss: 1.024397  [ 3200/ 4320]\n",
            "loss: 1.437293  [ 3360/ 4320]\n",
            "loss: 0.799672  [ 3520/ 4320]\n",
            "loss: 0.962149  [ 3680/ 4320]\n",
            "loss: 1.386366  [ 3840/ 4320]\n",
            "loss: 1.155154  [ 4000/ 4320]\n",
            "loss: 0.666198  [ 4160/ 4320]\n",
            "Validation loss after epoch 2: 1.194273\n",
            "loss: 1.035998  [    0/ 4320]\n",
            "loss: 0.711597  [  160/ 4320]\n",
            "loss: 0.614925  [  320/ 4320]\n",
            "loss: 0.774650  [  480/ 4320]\n",
            "loss: 0.706036  [  640/ 4320]\n",
            "loss: 0.890422  [  800/ 4320]\n",
            "loss: 0.730385  [  960/ 4320]\n",
            "loss: 0.814369  [ 1120/ 4320]\n",
            "loss: 0.668624  [ 1280/ 4320]\n",
            "loss: 0.545160  [ 1440/ 4320]\n",
            "loss: 0.856115  [ 1600/ 4320]\n",
            "loss: 0.818445  [ 1760/ 4320]\n",
            "loss: 0.704121  [ 1920/ 4320]\n",
            "loss: 0.781243  [ 2080/ 4320]\n",
            "loss: 1.032125  [ 2240/ 4320]\n",
            "loss: 0.697611  [ 2400/ 4320]\n",
            "loss: 0.624520  [ 2560/ 4320]\n",
            "loss: 0.820136  [ 2720/ 4320]\n",
            "loss: 0.820228  [ 2880/ 4320]\n",
            "loss: 0.471901  [ 3040/ 4320]\n",
            "loss: 0.773452  [ 3200/ 4320]\n",
            "loss: 0.638680  [ 3360/ 4320]\n",
            "loss: 0.575497  [ 3520/ 4320]\n",
            "loss: 0.766576  [ 3680/ 4320]\n",
            "loss: 0.581265  [ 3840/ 4320]\n",
            "loss: 0.814922  [ 4000/ 4320]\n",
            "loss: 0.674812  [ 4160/ 4320]\n",
            "Validation loss after epoch 3: 1.191535\n",
            "Early stopping at epoch 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-05-20 18:05:39,990] Trial 0 finished with value: 49.166666666666664 and parameters: {'dropout_rate': 0.10984683618771487, 'learning_rate': 2.3983729703882534e-05, 'batch_size': 16, 'weight_decay': 0.07648435613555293, 'warmup_steps': 609}. Best is trial 0 with value: 49.166666666666664.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 1.815657  [    0/ 4320]\n",
            "loss: 1.771174  [   80/ 4320]\n",
            "loss: 1.745711  [  160/ 4320]\n",
            "loss: 1.731846  [  240/ 4320]\n",
            "loss: 1.588895  [  320/ 4320]\n",
            "loss: 1.553400  [  400/ 4320]\n",
            "loss: 1.435228  [  480/ 4320]\n",
            "loss: 1.426178  [  560/ 4320]\n",
            "loss: 1.366038  [  640/ 4320]\n",
            "loss: 1.428538  [  720/ 4320]\n",
            "loss: 1.270504  [  800/ 4320]\n",
            "loss: 1.434379  [  880/ 4320]\n",
            "loss: 1.464235  [  960/ 4320]\n",
            "loss: 1.383133  [ 1040/ 4320]\n",
            "loss: 1.166668  [ 1120/ 4320]\n",
            "loss: 1.775114  [ 1200/ 4320]\n",
            "loss: 1.382324  [ 1280/ 4320]\n",
            "loss: 1.125482  [ 1360/ 4320]\n",
            "loss: 1.197218  [ 1440/ 4320]\n",
            "loss: 1.201373  [ 1520/ 4320]\n",
            "loss: 1.296485  [ 1600/ 4320]\n",
            "loss: 1.414706  [ 1680/ 4320]\n",
            "loss: 1.231912  [ 1760/ 4320]\n",
            "loss: 1.509982  [ 1840/ 4320]\n",
            "loss: 0.930319  [ 1920/ 4320]\n",
            "loss: 0.989417  [ 2000/ 4320]\n",
            "loss: 1.217479  [ 2080/ 4320]\n",
            "loss: 0.885680  [ 2160/ 4320]\n",
            "loss: 0.968888  [ 2240/ 4320]\n",
            "loss: 0.990482  [ 2320/ 4320]\n",
            "loss: 1.064267  [ 2400/ 4320]\n",
            "loss: 1.042628  [ 2480/ 4320]\n",
            "loss: 1.029715  [ 2560/ 4320]\n",
            "loss: 0.997702  [ 2640/ 4320]\n",
            "loss: 1.173223  [ 2720/ 4320]\n",
            "loss: 1.055992  [ 2800/ 4320]\n",
            "loss: 0.963024  [ 2880/ 4320]\n",
            "loss: 1.255965  [ 2960/ 4320]\n",
            "loss: 1.238174  [ 3040/ 4320]\n",
            "loss: 1.002820  [ 3120/ 4320]\n",
            "loss: 1.089924  [ 3200/ 4320]\n",
            "loss: 0.987026  [ 3280/ 4320]\n",
            "loss: 1.074419  [ 3360/ 4320]\n",
            "loss: 1.141815  [ 3440/ 4320]\n",
            "loss: 0.994795  [ 3520/ 4320]\n",
            "loss: 0.841580  [ 3600/ 4320]\n",
            "loss: 0.904605  [ 3680/ 4320]\n",
            "loss: 1.305059  [ 3760/ 4320]\n",
            "loss: 1.492720  [ 3840/ 4320]\n",
            "loss: 1.301256  [ 3920/ 4320]\n",
            "loss: 1.025342  [ 4000/ 4320]\n",
            "loss: 1.039207  [ 4080/ 4320]\n",
            "loss: 1.222576  [ 4160/ 4320]\n",
            "loss: 0.834778  [ 4240/ 4320]\n",
            "Validation loss after epoch 1: 1.084133\n",
            "loss: 0.800608  [    0/ 4320]\n",
            "loss: 0.979441  [   80/ 4320]\n",
            "loss: 1.211928  [  160/ 4320]\n",
            "loss: 0.940068  [  240/ 4320]\n",
            "loss: 0.767836  [  320/ 4320]\n",
            "loss: 0.637997  [  400/ 4320]\n",
            "loss: 0.513868  [  480/ 4320]\n",
            "loss: 0.996429  [  560/ 4320]\n",
            "loss: 0.901359  [  640/ 4320]\n",
            "loss: 0.860120  [  720/ 4320]\n",
            "loss: 0.752367  [  800/ 4320]\n",
            "loss: 0.902435  [  880/ 4320]\n",
            "loss: 0.956871  [  960/ 4320]\n",
            "loss: 0.997550  [ 1040/ 4320]\n",
            "loss: 0.744397  [ 1120/ 4320]\n",
            "loss: 0.690521  [ 1200/ 4320]\n",
            "loss: 0.789791  [ 1280/ 4320]\n",
            "loss: 0.731944  [ 1360/ 4320]\n",
            "loss: 1.288823  [ 1440/ 4320]\n",
            "loss: 1.001833  [ 1520/ 4320]\n",
            "loss: 0.756545  [ 1600/ 4320]\n",
            "loss: 0.739091  [ 1680/ 4320]\n",
            "loss: 1.635970  [ 1760/ 4320]\n",
            "loss: 1.216421  [ 1840/ 4320]\n",
            "loss: 0.952948  [ 1920/ 4320]\n",
            "loss: 0.768464  [ 2000/ 4320]\n",
            "loss: 1.300857  [ 2080/ 4320]\n",
            "loss: 0.588446  [ 2160/ 4320]\n",
            "loss: 0.870282  [ 2240/ 4320]\n",
            "loss: 1.007460  [ 2320/ 4320]\n",
            "loss: 1.205594  [ 2400/ 4320]\n",
            "loss: 0.837858  [ 2480/ 4320]\n",
            "loss: 0.686707  [ 2560/ 4320]\n",
            "loss: 1.083245  [ 2640/ 4320]\n",
            "loss: 0.880098  [ 2720/ 4320]\n",
            "loss: 0.832101  [ 2800/ 4320]\n",
            "loss: 1.076288  [ 2880/ 4320]\n",
            "loss: 1.221361  [ 2960/ 4320]\n",
            "loss: 0.895292  [ 3040/ 4320]\n",
            "loss: 1.106012  [ 3120/ 4320]\n",
            "loss: 0.910895  [ 3200/ 4320]\n",
            "loss: 0.930739  [ 3280/ 4320]\n",
            "loss: 0.986273  [ 3360/ 4320]\n",
            "loss: 0.994306  [ 3440/ 4320]\n",
            "loss: 1.152512  [ 3520/ 4320]\n",
            "loss: 0.803699  [ 3600/ 4320]\n",
            "loss: 0.947137  [ 3680/ 4320]\n",
            "loss: 0.762497  [ 3760/ 4320]\n",
            "loss: 0.538816  [ 3840/ 4320]\n",
            "loss: 1.220767  [ 3920/ 4320]\n",
            "loss: 0.680737  [ 4000/ 4320]\n",
            "loss: 0.765812  [ 4080/ 4320]\n",
            "loss: 0.618582  [ 4160/ 4320]\n",
            "loss: 0.897180  [ 4240/ 4320]\n",
            "Validation loss after epoch 2: 1.100340\n",
            "loss: 0.754498  [    0/ 4320]\n",
            "loss: 0.524772  [   80/ 4320]\n",
            "loss: 0.540083  [  160/ 4320]\n",
            "loss: 0.559214  [  240/ 4320]\n",
            "loss: 0.901152  [  320/ 4320]\n",
            "loss: 0.324266  [  400/ 4320]\n",
            "loss: 0.712521  [  480/ 4320]\n",
            "loss: 0.348788  [  560/ 4320]\n",
            "loss: 0.635914  [  640/ 4320]\n",
            "loss: 0.337451  [  720/ 4320]\n",
            "loss: 0.377324  [  800/ 4320]\n",
            "loss: 0.657385  [  880/ 4320]\n",
            "loss: 0.432157  [  960/ 4320]\n",
            "loss: 0.494794  [ 1040/ 4320]\n",
            "loss: 0.576404  [ 1120/ 4320]\n",
            "loss: 0.848011  [ 1200/ 4320]\n",
            "loss: 0.735843  [ 1280/ 4320]\n",
            "loss: 0.476637  [ 1360/ 4320]\n",
            "loss: 0.786224  [ 1440/ 4320]\n",
            "loss: 0.651744  [ 1520/ 4320]\n",
            "loss: 0.958573  [ 1600/ 4320]\n",
            "loss: 0.483121  [ 1680/ 4320]\n",
            "loss: 0.207326  [ 1760/ 4320]\n",
            "loss: 0.809294  [ 1840/ 4320]\n",
            "loss: 0.250321  [ 1920/ 4320]\n",
            "loss: 1.005683  [ 2000/ 4320]\n",
            "loss: 0.389746  [ 2080/ 4320]\n",
            "loss: 0.404217  [ 2160/ 4320]\n",
            "loss: 0.577447  [ 2240/ 4320]\n",
            "loss: 0.449040  [ 2320/ 4320]\n",
            "loss: 0.513542  [ 2400/ 4320]\n",
            "loss: 1.474469  [ 2480/ 4320]\n",
            "loss: 0.714560  [ 2560/ 4320]\n",
            "loss: 0.277872  [ 2640/ 4320]\n",
            "loss: 0.783212  [ 2720/ 4320]\n",
            "loss: 0.692743  [ 2800/ 4320]\n",
            "loss: 1.294481  [ 2880/ 4320]\n",
            "loss: 0.327871  [ 2960/ 4320]\n",
            "loss: 1.278208  [ 3040/ 4320]\n",
            "loss: 0.310799  [ 3120/ 4320]\n",
            "loss: 0.897057  [ 3200/ 4320]\n",
            "loss: 0.459085  [ 3280/ 4320]\n",
            "loss: 0.314193  [ 3360/ 4320]\n",
            "loss: 0.723395  [ 3440/ 4320]\n",
            "loss: 0.435776  [ 3520/ 4320]\n",
            "loss: 0.823522  [ 3600/ 4320]\n",
            "loss: 1.250113  [ 3680/ 4320]\n",
            "loss: 0.563951  [ 3760/ 4320]\n",
            "loss: 0.536028  [ 3840/ 4320]\n",
            "loss: 0.649333  [ 3920/ 4320]\n",
            "loss: 0.712692  [ 4000/ 4320]\n",
            "loss: 0.925833  [ 4080/ 4320]\n",
            "loss: 0.884927  [ 4160/ 4320]\n",
            "loss: 0.669841  [ 4240/ 4320]\n",
            "Validation loss after epoch 3: 1.144493\n",
            "Early stopping at epoch 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-05-20 18:13:22,273] Trial 1 finished with value: 56.458333333333336 and parameters: {'dropout_rate': 0.25684844784098715, 'learning_rate': 6.107023049408309e-05, 'batch_size': 8, 'weight_decay': 0.0014773851737630895, 'warmup_steps': 982}. Best is trial 1 with value: 56.458333333333336.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 1.795612  [    0/ 4320]\n",
            "loss: 1.772055  [  160/ 4320]\n",
            "loss: 1.750592  [  320/ 4320]\n",
            "loss: 1.741776  [  480/ 4320]\n",
            "loss: 1.791931  [  640/ 4320]\n",
            "loss: 1.785134  [  800/ 4320]\n",
            "loss: 1.729050  [  960/ 4320]\n",
            "loss: 1.691164  [ 1120/ 4320]\n",
            "loss: 1.727781  [ 1280/ 4320]\n",
            "loss: 1.719763  [ 1440/ 4320]\n",
            "loss: 1.679182  [ 1600/ 4320]\n",
            "loss: 1.638703  [ 1760/ 4320]\n",
            "loss: 1.698054  [ 1920/ 4320]\n",
            "loss: 1.592749  [ 2080/ 4320]\n",
            "loss: 1.564352  [ 2240/ 4320]\n",
            "loss: 1.480351  [ 2400/ 4320]\n",
            "loss: 1.585480  [ 2560/ 4320]\n",
            "loss: 1.545683  [ 2720/ 4320]\n",
            "loss: 1.404787  [ 2880/ 4320]\n",
            "loss: 1.489779  [ 3040/ 4320]\n",
            "loss: 1.386872  [ 3200/ 4320]\n",
            "loss: 1.437552  [ 3360/ 4320]\n",
            "loss: 1.454621  [ 3520/ 4320]\n",
            "loss: 1.357888  [ 3680/ 4320]\n",
            "loss: 1.528720  [ 3840/ 4320]\n",
            "loss: 1.269154  [ 4000/ 4320]\n",
            "loss: 1.466698  [ 4160/ 4320]\n",
            "Validation loss after epoch 1: 1.321061\n",
            "loss: 1.244472  [    0/ 4320]\n",
            "loss: 1.454977  [  160/ 4320]\n",
            "loss: 1.321867  [  320/ 4320]\n",
            "loss: 1.225508  [  480/ 4320]\n",
            "loss: 1.388873  [  640/ 4320]\n",
            "loss: 1.448839  [  800/ 4320]\n",
            "loss: 1.318077  [  960/ 4320]\n",
            "loss: 1.300240  [ 1120/ 4320]\n",
            "loss: 1.185430  [ 1280/ 4320]\n",
            "loss: 1.266728  [ 1440/ 4320]\n",
            "loss: 1.283330  [ 1600/ 4320]\n",
            "loss: 1.309881  [ 1760/ 4320]\n",
            "loss: 1.251978  [ 1920/ 4320]\n",
            "loss: 1.328181  [ 2080/ 4320]\n",
            "loss: 1.247478  [ 2240/ 4320]\n",
            "loss: 1.303434  [ 2400/ 4320]\n",
            "loss: 1.394825  [ 2560/ 4320]\n",
            "loss: 1.085196  [ 2720/ 4320]\n",
            "loss: 0.911613  [ 2880/ 4320]\n",
            "loss: 1.111046  [ 3040/ 4320]\n",
            "loss: 1.029842  [ 3200/ 4320]\n",
            "loss: 1.194159  [ 3360/ 4320]\n",
            "loss: 1.130865  [ 3520/ 4320]\n",
            "loss: 1.021826  [ 3680/ 4320]\n",
            "loss: 1.262133  [ 3840/ 4320]\n",
            "loss: 1.075309  [ 4000/ 4320]\n",
            "loss: 1.041527  [ 4160/ 4320]\n",
            "Validation loss after epoch 2: 1.132262\n",
            "loss: 0.941839  [    0/ 4320]\n",
            "loss: 0.900290  [  160/ 4320]\n",
            "loss: 1.249266  [  320/ 4320]\n",
            "loss: 1.051060  [  480/ 4320]\n",
            "loss: 0.947894  [  640/ 4320]\n",
            "loss: 1.141462  [  800/ 4320]\n",
            "loss: 1.082876  [  960/ 4320]\n",
            "loss: 0.984689  [ 1120/ 4320]\n",
            "loss: 0.837581  [ 1280/ 4320]\n",
            "loss: 0.895082  [ 1440/ 4320]\n",
            "loss: 0.909950  [ 1600/ 4320]\n",
            "loss: 1.308259  [ 1760/ 4320]\n",
            "loss: 0.972414  [ 1920/ 4320]\n",
            "loss: 0.966831  [ 2080/ 4320]\n",
            "loss: 0.980067  [ 2240/ 4320]\n",
            "loss: 0.723531  [ 2400/ 4320]\n",
            "loss: 0.945680  [ 2560/ 4320]\n",
            "loss: 1.189901  [ 2720/ 4320]\n",
            "loss: 0.962514  [ 2880/ 4320]\n",
            "loss: 0.829415  [ 3040/ 4320]\n",
            "loss: 0.889885  [ 3200/ 4320]\n",
            "loss: 0.889297  [ 3360/ 4320]\n",
            "loss: 1.167818  [ 3520/ 4320]\n",
            "loss: 0.979791  [ 3680/ 4320]\n",
            "loss: 0.877958  [ 3840/ 4320]\n",
            "loss: 0.811908  [ 4000/ 4320]\n",
            "loss: 1.055109  [ 4160/ 4320]\n",
            "Validation loss after epoch 3: 1.217002\n",
            "loss: 1.267091  [    0/ 4320]\n",
            "loss: 0.881656  [  160/ 4320]\n",
            "loss: 0.915667  [  320/ 4320]\n",
            "loss: 0.951303  [  480/ 4320]\n",
            "loss: 1.030985  [  640/ 4320]\n",
            "loss: 0.993580  [  800/ 4320]\n",
            "loss: 0.959703  [  960/ 4320]\n",
            "loss: 0.857844  [ 1120/ 4320]\n",
            "loss: 1.132600  [ 1280/ 4320]\n",
            "loss: 0.882754  [ 1440/ 4320]\n",
            "loss: 0.805040  [ 1600/ 4320]\n",
            "loss: 1.026118  [ 1760/ 4320]\n",
            "loss: 1.015141  [ 1920/ 4320]\n",
            "loss: 0.968992  [ 2080/ 4320]\n",
            "loss: 0.907282  [ 2240/ 4320]\n",
            "loss: 0.956064  [ 2400/ 4320]\n",
            "loss: 1.093521  [ 2560/ 4320]\n",
            "loss: 0.959223  [ 2720/ 4320]\n",
            "loss: 0.703833  [ 2880/ 4320]\n",
            "loss: 1.016172  [ 3040/ 4320]\n",
            "loss: 1.051029  [ 3200/ 4320]\n",
            "loss: 1.131793  [ 3360/ 4320]\n",
            "loss: 0.840636  [ 3520/ 4320]\n",
            "loss: 0.777324  [ 3680/ 4320]\n",
            "loss: 0.771665  [ 3840/ 4320]\n",
            "loss: 0.943802  [ 4000/ 4320]\n",
            "loss: 1.017412  [ 4160/ 4320]\n",
            "Validation loss after epoch 4: 1.012611\n",
            "loss: 0.537971  [    0/ 4320]\n",
            "loss: 0.947789  [  160/ 4320]\n",
            "loss: 0.728350  [  320/ 4320]\n",
            "loss: 1.215700  [  480/ 4320]\n",
            "loss: 0.831657  [  640/ 4320]\n",
            "loss: 0.887309  [  800/ 4320]\n",
            "loss: 0.855746  [  960/ 4320]\n",
            "loss: 0.637414  [ 1120/ 4320]\n",
            "loss: 0.706719  [ 1280/ 4320]\n",
            "loss: 0.767501  [ 1440/ 4320]\n",
            "loss: 0.743590  [ 1600/ 4320]\n",
            "loss: 0.870924  [ 1760/ 4320]\n",
            "loss: 0.963587  [ 1920/ 4320]\n",
            "loss: 0.847646  [ 2080/ 4320]\n",
            "loss: 0.787713  [ 2240/ 4320]\n",
            "loss: 0.861904  [ 2400/ 4320]\n",
            "loss: 0.631873  [ 2560/ 4320]\n",
            "loss: 0.649949  [ 2720/ 4320]\n",
            "loss: 0.661443  [ 2880/ 4320]\n",
            "loss: 0.734925  [ 3040/ 4320]\n",
            "loss: 0.794571  [ 3200/ 4320]\n",
            "loss: 0.661526  [ 3360/ 4320]\n",
            "loss: 0.982056  [ 3520/ 4320]\n",
            "loss: 0.707620  [ 3680/ 4320]\n",
            "loss: 0.839009  [ 3840/ 4320]\n",
            "loss: 0.585117  [ 4000/ 4320]\n",
            "loss: 0.515952  [ 4160/ 4320]\n",
            "Validation loss after epoch 5: 1.078589\n",
            "loss: 0.789019  [    0/ 4320]\n",
            "loss: 0.695841  [  160/ 4320]\n",
            "loss: 0.759746  [  320/ 4320]\n",
            "loss: 0.721672  [  480/ 4320]\n",
            "loss: 0.635350  [  640/ 4320]\n",
            "loss: 0.627591  [  800/ 4320]\n",
            "loss: 0.729919  [  960/ 4320]\n",
            "loss: 0.419105  [ 1120/ 4320]\n",
            "loss: 0.580937  [ 1280/ 4320]\n",
            "loss: 0.699193  [ 1440/ 4320]\n",
            "loss: 0.479273  [ 1600/ 4320]\n",
            "loss: 0.655320  [ 1760/ 4320]\n",
            "loss: 0.782181  [ 1920/ 4320]\n",
            "loss: 0.638711  [ 2080/ 4320]\n",
            "loss: 0.857037  [ 2240/ 4320]\n",
            "loss: 0.570179  [ 2400/ 4320]\n",
            "loss: 0.474911  [ 2560/ 4320]\n",
            "loss: 0.453467  [ 2720/ 4320]\n",
            "loss: 0.824354  [ 2880/ 4320]\n",
            "loss: 0.682178  [ 3040/ 4320]\n",
            "loss: 0.494489  [ 3200/ 4320]\n",
            "loss: 0.781340  [ 3360/ 4320]\n",
            "loss: 0.573482  [ 3520/ 4320]\n",
            "loss: 0.539651  [ 3680/ 4320]\n",
            "loss: 0.801068  [ 3840/ 4320]\n",
            "loss: 0.671481  [ 4000/ 4320]\n",
            "loss: 0.784832  [ 4160/ 4320]\n",
            "Validation loss after epoch 6: 1.139086\n",
            "Early stopping at epoch 7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-05-20 18:27:53,910] Trial 2 finished with value: 54.583333333333336 and parameters: {'dropout_rate': 0.10276186696702282, 'learning_rate': 1.0098820739306831e-05, 'batch_size': 16, 'weight_decay': 0.09673695844822465, 'warmup_steps': 882}. Best is trial 1 with value: 56.458333333333336.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 1.782130  [    0/ 4320]\n",
            "loss: 1.757846  [  160/ 4320]\n",
            "loss: 1.782969  [  320/ 4320]\n",
            "loss: 1.758538  [  480/ 4320]\n",
            "loss: 1.735377  [  640/ 4320]\n",
            "loss: 1.727774  [  800/ 4320]\n",
            "loss: 1.748188  [  960/ 4320]\n",
            "loss: 1.658208  [ 1120/ 4320]\n",
            "loss: 1.738409  [ 1280/ 4320]\n",
            "loss: 1.620796  [ 1440/ 4320]\n",
            "loss: 1.616753  [ 1600/ 4320]\n",
            "loss: 1.553214  [ 1760/ 4320]\n",
            "loss: 1.480387  [ 1920/ 4320]\n",
            "loss: 1.460280  [ 2080/ 4320]\n",
            "loss: 1.427809  [ 2240/ 4320]\n",
            "loss: 1.477815  [ 2400/ 4320]\n",
            "loss: 1.300190  [ 2560/ 4320]\n",
            "loss: 1.296996  [ 2720/ 4320]\n",
            "loss: 1.241129  [ 2880/ 4320]\n",
            "loss: 1.436278  [ 3040/ 4320]\n",
            "loss: 1.242672  [ 3200/ 4320]\n",
            "loss: 1.336417  [ 3360/ 4320]\n",
            "loss: 1.256354  [ 3520/ 4320]\n",
            "loss: 1.297338  [ 3680/ 4320]\n",
            "loss: 1.200716  [ 3840/ 4320]\n",
            "loss: 1.377306  [ 4000/ 4320]\n",
            "loss: 1.255174  [ 4160/ 4320]\n",
            "Validation loss after epoch 1: 1.257680\n",
            "loss: 1.283340  [    0/ 4320]\n",
            "loss: 1.071128  [  160/ 4320]\n",
            "loss: 1.129912  [  320/ 4320]\n",
            "loss: 1.259908  [  480/ 4320]\n",
            "loss: 1.112938  [  640/ 4320]\n",
            "loss: 1.122330  [  800/ 4320]\n",
            "loss: 1.355095  [  960/ 4320]\n",
            "loss: 0.990458  [ 1120/ 4320]\n",
            "loss: 1.104730  [ 1280/ 4320]\n",
            "loss: 1.165537  [ 1440/ 4320]\n",
            "loss: 1.245532  [ 1600/ 4320]\n",
            "loss: 1.364726  [ 1760/ 4320]\n",
            "loss: 1.124156  [ 1920/ 4320]\n",
            "loss: 1.078358  [ 2080/ 4320]\n",
            "loss: 1.112825  [ 2240/ 4320]\n",
            "loss: 0.990399  [ 2400/ 4320]\n",
            "loss: 1.089709  [ 2560/ 4320]\n",
            "loss: 1.053391  [ 2720/ 4320]\n",
            "loss: 0.944751  [ 2880/ 4320]\n",
            "loss: 1.145695  [ 3040/ 4320]\n",
            "loss: 0.970888  [ 3200/ 4320]\n",
            "loss: 1.173522  [ 3360/ 4320]\n",
            "loss: 1.269349  [ 3520/ 4320]\n",
            "loss: 1.170367  [ 3680/ 4320]\n",
            "loss: 1.017107  [ 3840/ 4320]\n",
            "loss: 1.234447  [ 4000/ 4320]\n",
            "loss: 0.944937  [ 4160/ 4320]\n",
            "Validation loss after epoch 2: 1.107012\n",
            "loss: 0.984832  [    0/ 4320]\n",
            "loss: 0.993710  [  160/ 4320]\n",
            "loss: 0.948469  [  320/ 4320]\n",
            "loss: 1.041243  [  480/ 4320]\n",
            "loss: 1.202889  [  640/ 4320]\n",
            "loss: 0.894275  [  800/ 4320]\n",
            "loss: 1.418252  [  960/ 4320]\n",
            "loss: 0.931174  [ 1120/ 4320]\n",
            "loss: 0.901502  [ 1280/ 4320]\n",
            "loss: 1.110670  [ 1440/ 4320]\n",
            "loss: 0.859111  [ 1600/ 4320]\n",
            "loss: 0.767447  [ 1760/ 4320]\n",
            "loss: 0.843221  [ 1920/ 4320]\n",
            "loss: 1.038732  [ 2080/ 4320]\n",
            "loss: 0.904726  [ 2240/ 4320]\n",
            "loss: 0.710157  [ 2400/ 4320]\n",
            "loss: 1.031137  [ 2560/ 4320]\n",
            "loss: 1.177805  [ 2720/ 4320]\n",
            "loss: 1.249129  [ 2880/ 4320]\n",
            "loss: 0.737714  [ 3040/ 4320]\n",
            "loss: 1.031361  [ 3200/ 4320]\n",
            "loss: 0.930054  [ 3360/ 4320]\n",
            "loss: 0.790015  [ 3520/ 4320]\n",
            "loss: 1.213298  [ 3680/ 4320]\n",
            "loss: 0.890441  [ 3840/ 4320]\n",
            "loss: 0.926413  [ 4000/ 4320]\n",
            "loss: 0.688424  [ 4160/ 4320]\n",
            "Validation loss after epoch 3: 1.167090\n",
            "loss: 0.889323  [    0/ 4320]\n",
            "loss: 0.819350  [  160/ 4320]\n",
            "loss: 0.907941  [  320/ 4320]\n",
            "loss: 1.126932  [  480/ 4320]\n",
            "loss: 1.050061  [  640/ 4320]\n",
            "loss: 1.019740  [  800/ 4320]\n",
            "loss: 0.894251  [  960/ 4320]\n",
            "loss: 0.628643  [ 1120/ 4320]\n",
            "loss: 0.911746  [ 1280/ 4320]\n",
            "loss: 0.656101  [ 1440/ 4320]\n",
            "loss: 0.934155  [ 1600/ 4320]\n",
            "loss: 0.603046  [ 1760/ 4320]\n",
            "loss: 0.974796  [ 1920/ 4320]\n",
            "loss: 0.799454  [ 2080/ 4320]\n",
            "loss: 0.706403  [ 2240/ 4320]\n",
            "loss: 0.690865  [ 2400/ 4320]\n",
            "loss: 0.874101  [ 2560/ 4320]\n",
            "loss: 0.499701  [ 2720/ 4320]\n",
            "loss: 0.863701  [ 2880/ 4320]\n",
            "loss: 0.765158  [ 3040/ 4320]\n",
            "loss: 0.956603  [ 3200/ 4320]\n",
            "loss: 0.802156  [ 3360/ 4320]\n",
            "loss: 0.740909  [ 3520/ 4320]\n",
            "loss: 0.593588  [ 3680/ 4320]\n",
            "loss: 0.499841  [ 3840/ 4320]\n",
            "loss: 0.712081  [ 4000/ 4320]\n",
            "loss: 0.625049  [ 4160/ 4320]\n",
            "Validation loss after epoch 4: 1.096709\n",
            "loss: 0.588309  [    0/ 4320]\n",
            "loss: 0.618656  [  160/ 4320]\n",
            "loss: 0.597771  [  320/ 4320]\n",
            "loss: 0.755272  [  480/ 4320]\n",
            "loss: 0.758608  [  640/ 4320]\n",
            "loss: 0.685144  [  800/ 4320]\n",
            "loss: 0.391957  [  960/ 4320]\n",
            "loss: 0.826142  [ 1120/ 4320]\n",
            "loss: 0.600843  [ 1280/ 4320]\n",
            "loss: 0.809926  [ 1440/ 4320]\n",
            "loss: 0.772199  [ 1600/ 4320]\n",
            "loss: 0.407353  [ 1760/ 4320]\n",
            "loss: 0.736327  [ 1920/ 4320]\n",
            "loss: 0.602833  [ 2080/ 4320]\n",
            "loss: 0.422823  [ 2240/ 4320]\n",
            "loss: 0.751873  [ 2400/ 4320]\n",
            "loss: 0.690375  [ 2560/ 4320]\n",
            "loss: 0.533849  [ 2720/ 4320]\n",
            "loss: 0.768057  [ 2880/ 4320]\n",
            "loss: 0.572041  [ 3040/ 4320]\n",
            "loss: 0.738317  [ 3200/ 4320]\n",
            "loss: 0.655205  [ 3360/ 4320]\n",
            "loss: 0.444207  [ 3520/ 4320]\n",
            "loss: 0.661974  [ 3680/ 4320]\n",
            "loss: 0.779200  [ 3840/ 4320]\n",
            "loss: 0.778312  [ 4000/ 4320]\n",
            "loss: 0.679957  [ 4160/ 4320]\n",
            "Validation loss after epoch 5: 1.195289\n",
            "loss: 0.709216  [    0/ 4320]\n",
            "loss: 0.487808  [  160/ 4320]\n",
            "loss: 0.543382  [  320/ 4320]\n",
            "loss: 0.675608  [  480/ 4320]\n",
            "loss: 0.507312  [  640/ 4320]\n",
            "loss: 0.485857  [  800/ 4320]\n",
            "loss: 0.778900  [  960/ 4320]\n",
            "loss: 0.602514  [ 1120/ 4320]\n",
            "loss: 0.536742  [ 1280/ 4320]\n",
            "loss: 0.414385  [ 1440/ 4320]\n",
            "loss: 0.446918  [ 1600/ 4320]\n",
            "loss: 0.316548  [ 1760/ 4320]\n",
            "loss: 0.556548  [ 1920/ 4320]\n",
            "loss: 0.402500  [ 2080/ 4320]\n",
            "loss: 0.351133  [ 2240/ 4320]\n",
            "loss: 0.318076  [ 2400/ 4320]\n",
            "loss: 0.568922  [ 2560/ 4320]\n",
            "loss: 0.416187  [ 2720/ 4320]\n",
            "loss: 0.849145  [ 2880/ 4320]\n",
            "loss: 0.539234  [ 3040/ 4320]\n",
            "loss: 0.442647  [ 3200/ 4320]\n",
            "loss: 0.252220  [ 3360/ 4320]\n",
            "loss: 0.586674  [ 3520/ 4320]\n",
            "loss: 0.244202  [ 3680/ 4320]\n",
            "loss: 0.374820  [ 3840/ 4320]\n",
            "loss: 0.580718  [ 4000/ 4320]\n",
            "loss: 0.681430  [ 4160/ 4320]\n",
            "Validation loss after epoch 6: 1.362038\n",
            "Early stopping at epoch 7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-05-20 18:42:25,922] Trial 3 finished with value: 53.541666666666664 and parameters: {'dropout_rate': 0.2386013777389532, 'learning_rate': 1.5646827945732724e-05, 'batch_size': 16, 'weight_decay': 0.017173157459675906, 'warmup_steps': 983}. Best is trial 1 with value: 56.458333333333336.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 1.765031  [    0/ 4320]\n",
            "loss: 1.738077  [   80/ 4320]\n",
            "loss: 1.758529  [  160/ 4320]\n",
            "loss: 1.737262  [  240/ 4320]\n",
            "loss: 1.665750  [  320/ 4320]\n",
            "loss: 1.715432  [  400/ 4320]\n",
            "loss: 1.691819  [  480/ 4320]\n",
            "loss: 1.516475  [  560/ 4320]\n",
            "loss: 1.511856  [  640/ 4320]\n",
            "loss: 1.409427  [  720/ 4320]\n",
            "loss: 1.569544  [  800/ 4320]\n",
            "loss: 1.277789  [  880/ 4320]\n",
            "loss: 1.672973  [  960/ 4320]\n",
            "loss: 1.377559  [ 1040/ 4320]\n",
            "loss: 1.221281  [ 1120/ 4320]\n",
            "loss: 1.316528  [ 1200/ 4320]\n",
            "loss: 1.503657  [ 1280/ 4320]\n",
            "loss: 1.482212  [ 1360/ 4320]\n",
            "loss: 1.273786  [ 1440/ 4320]\n",
            "loss: 1.237695  [ 1520/ 4320]\n",
            "loss: 1.569447  [ 1600/ 4320]\n",
            "loss: 1.362533  [ 1680/ 4320]\n",
            "loss: 1.354730  [ 1760/ 4320]\n",
            "loss: 1.492910  [ 1840/ 4320]\n",
            "loss: 1.194123  [ 1920/ 4320]\n",
            "loss: 1.036699  [ 2000/ 4320]\n",
            "loss: 1.376309  [ 2080/ 4320]\n",
            "loss: 1.187541  [ 2160/ 4320]\n",
            "loss: 1.135138  [ 2240/ 4320]\n",
            "loss: 1.073743  [ 2320/ 4320]\n",
            "loss: 1.267049  [ 2400/ 4320]\n",
            "loss: 0.986605  [ 2480/ 4320]\n",
            "loss: 1.148634  [ 2560/ 4320]\n",
            "loss: 1.291327  [ 2640/ 4320]\n",
            "loss: 0.909849  [ 2720/ 4320]\n",
            "loss: 0.832397  [ 2800/ 4320]\n",
            "loss: 0.757048  [ 2880/ 4320]\n",
            "loss: 0.968748  [ 2960/ 4320]\n",
            "loss: 1.121330  [ 3040/ 4320]\n",
            "loss: 0.877460  [ 3120/ 4320]\n",
            "loss: 1.059252  [ 3200/ 4320]\n",
            "loss: 0.800193  [ 3280/ 4320]\n",
            "loss: 1.168711  [ 3360/ 4320]\n",
            "loss: 1.121365  [ 3440/ 4320]\n",
            "loss: 1.002032  [ 3520/ 4320]\n",
            "loss: 1.480438  [ 3600/ 4320]\n",
            "loss: 1.096452  [ 3680/ 4320]\n",
            "loss: 1.221558  [ 3760/ 4320]\n",
            "loss: 0.943319  [ 3840/ 4320]\n",
            "loss: 1.096051  [ 3920/ 4320]\n",
            "loss: 1.054460  [ 4000/ 4320]\n",
            "loss: 1.133346  [ 4080/ 4320]\n",
            "loss: 1.347855  [ 4160/ 4320]\n",
            "loss: 0.802041  [ 4240/ 4320]\n",
            "Validation loss after epoch 1: 1.115947\n",
            "loss: 1.146967  [    0/ 4320]\n",
            "loss: 0.706833  [   80/ 4320]\n",
            "loss: 0.974606  [  160/ 4320]\n",
            "loss: 0.931723  [  240/ 4320]\n",
            "loss: 1.050753  [  320/ 4320]\n",
            "loss: 0.806362  [  400/ 4320]\n",
            "loss: 1.194902  [  480/ 4320]\n",
            "loss: 0.866198  [  560/ 4320]\n",
            "loss: 0.612937  [  640/ 4320]\n",
            "loss: 0.853377  [  720/ 4320]\n",
            "loss: 0.697059  [  800/ 4320]\n",
            "loss: 1.260611  [  880/ 4320]\n",
            "loss: 0.946876  [  960/ 4320]\n",
            "loss: 0.707738  [ 1040/ 4320]\n",
            "loss: 1.276575  [ 1120/ 4320]\n",
            "loss: 0.962115  [ 1200/ 4320]\n",
            "loss: 0.735740  [ 1280/ 4320]\n",
            "loss: 0.593651  [ 1360/ 4320]\n",
            "loss: 0.663220  [ 1440/ 4320]\n",
            "loss: 0.926531  [ 1520/ 4320]\n",
            "loss: 1.450360  [ 1600/ 4320]\n",
            "loss: 0.497815  [ 1680/ 4320]\n",
            "loss: 0.738222  [ 1760/ 4320]\n",
            "loss: 0.735880  [ 1840/ 4320]\n",
            "loss: 0.908651  [ 1920/ 4320]\n",
            "loss: 0.860481  [ 2000/ 4320]\n",
            "loss: 0.791723  [ 2080/ 4320]\n",
            "loss: 0.784412  [ 2160/ 4320]\n",
            "loss: 1.614877  [ 2240/ 4320]\n",
            "loss: 0.819451  [ 2320/ 4320]\n",
            "loss: 1.065589  [ 2400/ 4320]\n",
            "loss: 0.790052  [ 2480/ 4320]\n",
            "loss: 0.706314  [ 2560/ 4320]\n",
            "loss: 1.105672  [ 2640/ 4320]\n",
            "loss: 0.685207  [ 2720/ 4320]\n",
            "loss: 0.674707  [ 2800/ 4320]\n",
            "loss: 1.098023  [ 2880/ 4320]\n",
            "loss: 0.846651  [ 2960/ 4320]\n",
            "loss: 1.231114  [ 3040/ 4320]\n",
            "loss: 0.602425  [ 3120/ 4320]\n",
            "loss: 0.700754  [ 3200/ 4320]\n",
            "loss: 0.563418  [ 3280/ 4320]\n",
            "loss: 0.802607  [ 3360/ 4320]\n",
            "loss: 0.768355  [ 3440/ 4320]\n",
            "loss: 0.716924  [ 3520/ 4320]\n",
            "loss: 0.650810  [ 3600/ 4320]\n",
            "loss: 1.357379  [ 3680/ 4320]\n",
            "loss: 0.895635  [ 3760/ 4320]\n",
            "loss: 0.759931  [ 3840/ 4320]\n",
            "loss: 0.956267  [ 3920/ 4320]\n",
            "loss: 0.997448  [ 4000/ 4320]\n",
            "loss: 0.775703  [ 4080/ 4320]\n",
            "loss: 0.808946  [ 4160/ 4320]\n",
            "loss: 1.660390  [ 4240/ 4320]\n",
            "Validation loss after epoch 2: 1.023845\n",
            "loss: 0.408763  [    0/ 4320]\n",
            "loss: 0.485247  [   80/ 4320]\n",
            "loss: 0.574120  [  160/ 4320]\n",
            "loss: 0.833237  [  240/ 4320]\n",
            "loss: 0.551323  [  320/ 4320]\n",
            "loss: 0.699852  [  400/ 4320]\n",
            "loss: 0.492016  [  480/ 4320]\n",
            "loss: 0.671599  [  560/ 4320]\n",
            "loss: 0.514973  [  640/ 4320]\n",
            "loss: 0.681813  [  720/ 4320]\n",
            "loss: 0.579495  [  800/ 4320]\n",
            "loss: 0.988848  [  880/ 4320]\n",
            "loss: 0.398711  [  960/ 4320]\n",
            "loss: 0.612580  [ 1040/ 4320]\n",
            "loss: 0.512010  [ 1120/ 4320]\n",
            "loss: 1.122557  [ 1200/ 4320]\n",
            "loss: 0.226574  [ 1280/ 4320]\n",
            "loss: 0.597025  [ 1360/ 4320]\n",
            "loss: 1.069001  [ 1440/ 4320]\n",
            "loss: 0.637763  [ 1520/ 4320]\n",
            "loss: 0.837463  [ 1600/ 4320]\n",
            "loss: 0.967658  [ 1680/ 4320]\n",
            "loss: 0.730450  [ 1760/ 4320]\n",
            "loss: 0.673852  [ 1840/ 4320]\n",
            "loss: 0.541756  [ 1920/ 4320]\n",
            "loss: 0.376426  [ 2000/ 4320]\n",
            "loss: 1.105702  [ 2080/ 4320]\n",
            "loss: 0.709300  [ 2160/ 4320]\n",
            "loss: 0.653130  [ 2240/ 4320]\n",
            "loss: 1.000243  [ 2320/ 4320]\n",
            "loss: 0.755511  [ 2400/ 4320]\n",
            "loss: 0.376433  [ 2480/ 4320]\n",
            "loss: 0.719178  [ 2560/ 4320]\n",
            "loss: 0.686986  [ 2640/ 4320]\n",
            "loss: 0.913240  [ 2720/ 4320]\n",
            "loss: 1.204463  [ 2800/ 4320]\n",
            "loss: 0.607689  [ 2880/ 4320]\n",
            "loss: 0.893231  [ 2960/ 4320]\n",
            "loss: 0.957258  [ 3040/ 4320]\n",
            "loss: 1.393913  [ 3120/ 4320]\n",
            "loss: 1.050388  [ 3200/ 4320]\n",
            "loss: 0.565022  [ 3280/ 4320]\n",
            "loss: 0.567942  [ 3360/ 4320]\n",
            "loss: 0.793932  [ 3440/ 4320]\n",
            "loss: 0.796267  [ 3520/ 4320]\n",
            "loss: 0.322714  [ 3600/ 4320]\n",
            "loss: 0.705840  [ 3680/ 4320]\n",
            "loss: 0.767227  [ 3760/ 4320]\n",
            "loss: 0.679961  [ 3840/ 4320]\n",
            "loss: 0.772345  [ 3920/ 4320]\n",
            "loss: 0.690231  [ 4000/ 4320]\n",
            "loss: 0.590789  [ 4080/ 4320]\n",
            "loss: 0.447039  [ 4160/ 4320]\n",
            "loss: 0.386341  [ 4240/ 4320]\n",
            "Validation loss after epoch 3: 1.181056\n",
            "loss: 0.208462  [    0/ 4320]\n",
            "loss: 0.415783  [   80/ 4320]\n",
            "loss: 0.285048  [  160/ 4320]\n",
            "loss: 0.407916  [  240/ 4320]\n",
            "loss: 0.640989  [  320/ 4320]\n",
            "loss: 0.468162  [  400/ 4320]\n",
            "loss: 0.155134  [  480/ 4320]\n",
            "loss: 0.135249  [  560/ 4320]\n",
            "loss: 0.348933  [  640/ 4320]\n",
            "loss: 0.501175  [  720/ 4320]\n",
            "loss: 0.621603  [  800/ 4320]\n",
            "loss: 0.134689  [  880/ 4320]\n",
            "loss: 0.635556  [  960/ 4320]\n",
            "loss: 0.530710  [ 1040/ 4320]\n",
            "loss: 0.360784  [ 1120/ 4320]\n",
            "loss: 0.922008  [ 1200/ 4320]\n",
            "loss: 1.347099  [ 1280/ 4320]\n",
            "loss: 0.618328  [ 1360/ 4320]\n",
            "loss: 0.364424  [ 1440/ 4320]\n",
            "loss: 0.396970  [ 1520/ 4320]\n",
            "loss: 0.334799  [ 1600/ 4320]\n",
            "loss: 0.292095  [ 1680/ 4320]\n",
            "loss: 0.275085  [ 1760/ 4320]\n",
            "loss: 0.250870  [ 1840/ 4320]\n",
            "loss: 0.339893  [ 1920/ 4320]\n",
            "loss: 0.162780  [ 2000/ 4320]\n",
            "loss: 0.423625  [ 2080/ 4320]\n",
            "loss: 0.299942  [ 2160/ 4320]\n",
            "loss: 0.463152  [ 2240/ 4320]\n",
            "loss: 0.650144  [ 2320/ 4320]\n",
            "loss: 0.455586  [ 2400/ 4320]\n",
            "loss: 0.394976  [ 2480/ 4320]\n",
            "loss: 0.382811  [ 2560/ 4320]\n",
            "loss: 0.189693  [ 2640/ 4320]\n",
            "loss: 0.427526  [ 2720/ 4320]\n",
            "loss: 0.506206  [ 2800/ 4320]\n",
            "loss: 0.258477  [ 2880/ 4320]\n",
            "loss: 0.272258  [ 2960/ 4320]\n",
            "loss: 0.425029  [ 3040/ 4320]\n",
            "loss: 0.338417  [ 3120/ 4320]\n",
            "loss: 0.484379  [ 3200/ 4320]\n",
            "loss: 0.206659  [ 3280/ 4320]\n",
            "loss: 0.200398  [ 3360/ 4320]\n",
            "loss: 0.317026  [ 3440/ 4320]\n",
            "loss: 0.195490  [ 3520/ 4320]\n",
            "loss: 0.122371  [ 3600/ 4320]\n",
            "loss: 0.907097  [ 3680/ 4320]\n",
            "loss: 0.665661  [ 3760/ 4320]\n",
            "loss: 1.937538  [ 3840/ 4320]\n",
            "loss: 0.522266  [ 3920/ 4320]\n",
            "loss: 0.079951  [ 4000/ 4320]\n",
            "loss: 0.377289  [ 4080/ 4320]\n",
            "loss: 0.273875  [ 4160/ 4320]\n",
            "loss: 0.208024  [ 4240/ 4320]\n",
            "Validation loss after epoch 4: 1.407479\n",
            "Early stopping at epoch 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-05-20 18:52:40,426] Trial 4 finished with value: 52.291666666666664 and parameters: {'dropout_rate': 0.1488692218023682, 'learning_rate': 3.433337345214507e-05, 'batch_size': 8, 'weight_decay': 0.01931831034427832, 'warmup_steps': 550}. Best is trial 1 with value: 56.458333333333336.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 1.763241  [    0/ 4320]\n",
            "loss: 1.781573  [   80/ 4320]\n",
            "loss: 1.740962  [  160/ 4320]\n",
            "loss: 1.779508  [  240/ 4320]\n",
            "loss: 1.716906  [  320/ 4320]\n",
            "loss: 1.635084  [  400/ 4320]\n",
            "loss: 1.714244  [  480/ 4320]\n",
            "loss: 1.518795  [  560/ 4320]\n",
            "loss: 1.601787  [  640/ 4320]\n",
            "loss: 1.313006  [  720/ 4320]\n",
            "loss: 1.426766  [  800/ 4320]\n",
            "loss: 1.374263  [  880/ 4320]\n",
            "loss: 1.600331  [  960/ 4320]\n",
            "loss: 1.430050  [ 1040/ 4320]\n",
            "loss: 1.427869  [ 1120/ 4320]\n",
            "loss: 1.094309  [ 1200/ 4320]\n",
            "loss: 1.240790  [ 1280/ 4320]\n",
            "loss: 1.197086  [ 1360/ 4320]\n",
            "loss: 0.962763  [ 1440/ 4320]\n",
            "loss: 1.417878  [ 1520/ 4320]\n",
            "loss: 1.146443  [ 1600/ 4320]\n",
            "loss: 1.291636  [ 1680/ 4320]\n",
            "loss: 1.027286  [ 1760/ 4320]\n",
            "loss: 1.105490  [ 1840/ 4320]\n",
            "loss: 1.106200  [ 1920/ 4320]\n",
            "loss: 1.424825  [ 2000/ 4320]\n",
            "loss: 1.374760  [ 2080/ 4320]\n",
            "loss: 1.094722  [ 2160/ 4320]\n",
            "loss: 1.093053  [ 2240/ 4320]\n",
            "loss: 1.291978  [ 2320/ 4320]\n",
            "loss: 1.140568  [ 2400/ 4320]\n",
            "loss: 1.087718  [ 2480/ 4320]\n",
            "loss: 1.724061  [ 2560/ 4320]\n",
            "loss: 1.276877  [ 2640/ 4320]\n",
            "loss: 1.044238  [ 2720/ 4320]\n",
            "loss: 1.238215  [ 2800/ 4320]\n",
            "loss: 1.699383  [ 2880/ 4320]\n",
            "loss: 0.997587  [ 2960/ 4320]\n",
            "loss: 0.939526  [ 3040/ 4320]\n",
            "loss: 1.370660  [ 3120/ 4320]\n",
            "loss: 0.942187  [ 3200/ 4320]\n",
            "loss: 0.957884  [ 3280/ 4320]\n",
            "loss: 1.273747  [ 3360/ 4320]\n",
            "loss: 1.092155  [ 3440/ 4320]\n",
            "loss: 0.980757  [ 3520/ 4320]\n",
            "loss: 1.094133  [ 3600/ 4320]\n",
            "loss: 1.439739  [ 3680/ 4320]\n",
            "loss: 1.030421  [ 3760/ 4320]\n",
            "loss: 1.418060  [ 3840/ 4320]\n",
            "loss: 0.876979  [ 3920/ 4320]\n",
            "loss: 1.264774  [ 4000/ 4320]\n",
            "loss: 0.940120  [ 4080/ 4320]\n",
            "loss: 1.219002  [ 4160/ 4320]\n",
            "loss: 0.918806  [ 4240/ 4320]\n",
            "Validation loss after epoch 1: 1.263618\n",
            "loss: 1.173098  [    0/ 4320]\n",
            "loss: 0.794983  [   80/ 4320]\n",
            "loss: 0.646963  [  160/ 4320]\n",
            "loss: 0.983508  [  240/ 4320]\n",
            "loss: 1.362466  [  320/ 4320]\n",
            "loss: 1.019749  [  400/ 4320]\n",
            "loss: 0.765136  [  480/ 4320]\n",
            "loss: 1.293057  [  560/ 4320]\n",
            "loss: 0.752254  [  640/ 4320]\n",
            "loss: 1.152725  [  720/ 4320]\n",
            "loss: 1.361909  [  800/ 4320]\n",
            "loss: 0.922705  [  880/ 4320]\n",
            "loss: 1.166492  [  960/ 4320]\n",
            "loss: 1.052139  [ 1040/ 4320]\n",
            "loss: 0.704535  [ 1120/ 4320]\n",
            "loss: 0.896888  [ 1200/ 4320]\n",
            "loss: 1.134734  [ 1280/ 4320]\n",
            "loss: 0.966968  [ 1360/ 4320]\n",
            "loss: 0.908484  [ 1440/ 4320]\n",
            "loss: 0.674635  [ 1520/ 4320]\n",
            "loss: 1.185044  [ 1600/ 4320]\n",
            "loss: 1.031659  [ 1680/ 4320]\n",
            "loss: 0.999382  [ 1760/ 4320]\n",
            "loss: 0.756633  [ 1840/ 4320]\n",
            "loss: 0.695997  [ 1920/ 4320]\n",
            "loss: 1.010798  [ 2000/ 4320]\n",
            "loss: 1.085078  [ 2080/ 4320]\n",
            "loss: 0.750137  [ 2160/ 4320]\n",
            "loss: 0.769208  [ 2240/ 4320]\n",
            "loss: 0.584370  [ 2320/ 4320]\n",
            "loss: 1.341345  [ 2400/ 4320]\n",
            "loss: 0.717498  [ 2480/ 4320]\n",
            "loss: 0.851832  [ 2560/ 4320]\n",
            "loss: 1.093999  [ 2640/ 4320]\n",
            "loss: 0.934176  [ 2720/ 4320]\n",
            "loss: 0.796739  [ 2800/ 4320]\n",
            "loss: 0.939100  [ 2880/ 4320]\n",
            "loss: 1.436977  [ 2960/ 4320]\n",
            "loss: 0.609245  [ 3040/ 4320]\n",
            "loss: 0.806845  [ 3120/ 4320]\n",
            "loss: 1.470057  [ 3200/ 4320]\n",
            "loss: 1.069115  [ 3280/ 4320]\n",
            "loss: 1.195127  [ 3360/ 4320]\n",
            "loss: 0.849235  [ 3440/ 4320]\n",
            "loss: 0.716221  [ 3520/ 4320]\n",
            "loss: 0.979482  [ 3600/ 4320]\n",
            "loss: 0.993935  [ 3680/ 4320]\n",
            "loss: 1.237843  [ 3760/ 4320]\n",
            "loss: 0.993821  [ 3840/ 4320]\n",
            "loss: 0.925070  [ 3920/ 4320]\n",
            "loss: 0.578743  [ 4000/ 4320]\n",
            "loss: 1.521153  [ 4080/ 4320]\n",
            "loss: 0.678782  [ 4160/ 4320]\n",
            "loss: 0.961748  [ 4240/ 4320]\n",
            "Validation loss after epoch 2: 1.016781\n",
            "loss: 0.713251  [    0/ 4320]\n",
            "loss: 1.039092  [   80/ 4320]\n",
            "loss: 0.966178  [  160/ 4320]\n",
            "loss: 0.457005  [  240/ 4320]\n",
            "loss: 0.554658  [  320/ 4320]\n",
            "loss: 0.664434  [  400/ 4320]\n",
            "loss: 0.943154  [  480/ 4320]\n",
            "loss: 0.445185  [  560/ 4320]\n",
            "loss: 1.284504  [  640/ 4320]\n",
            "loss: 0.523609  [  720/ 4320]\n",
            "loss: 0.601188  [  800/ 4320]\n",
            "loss: 0.734527  [  880/ 4320]\n",
            "loss: 0.593418  [  960/ 4320]\n",
            "loss: 1.168795  [ 1040/ 4320]\n",
            "loss: 0.604478  [ 1120/ 4320]\n",
            "loss: 0.638373  [ 1200/ 4320]\n",
            "loss: 0.481043  [ 1280/ 4320]\n",
            "loss: 0.553558  [ 1360/ 4320]\n",
            "loss: 1.157554  [ 1440/ 4320]\n",
            "loss: 0.357234  [ 1520/ 4320]\n",
            "loss: 0.920154  [ 1600/ 4320]\n",
            "loss: 0.667230  [ 1680/ 4320]\n",
            "loss: 0.873655  [ 1760/ 4320]\n",
            "loss: 0.386479  [ 1840/ 4320]\n",
            "loss: 0.721118  [ 1920/ 4320]\n",
            "loss: 0.590481  [ 2000/ 4320]\n",
            "loss: 0.590087  [ 2080/ 4320]\n",
            "loss: 0.495413  [ 2160/ 4320]\n",
            "loss: 0.807338  [ 2240/ 4320]\n",
            "loss: 1.150192  [ 2320/ 4320]\n",
            "loss: 0.616187  [ 2400/ 4320]\n",
            "loss: 0.487218  [ 2480/ 4320]\n",
            "loss: 0.752034  [ 2560/ 4320]\n",
            "loss: 0.716703  [ 2640/ 4320]\n",
            "loss: 0.367634  [ 2720/ 4320]\n",
            "loss: 0.436173  [ 2800/ 4320]\n",
            "loss: 0.784007  [ 2880/ 4320]\n",
            "loss: 0.562255  [ 2960/ 4320]\n",
            "loss: 0.345002  [ 3040/ 4320]\n",
            "loss: 0.530469  [ 3120/ 4320]\n",
            "loss: 1.351148  [ 3200/ 4320]\n",
            "loss: 0.560407  [ 3280/ 4320]\n",
            "loss: 0.425624  [ 3360/ 4320]\n",
            "loss: 0.826101  [ 3440/ 4320]\n",
            "loss: 0.712567  [ 3520/ 4320]\n",
            "loss: 1.198393  [ 3600/ 4320]\n",
            "loss: 1.738637  [ 3680/ 4320]\n",
            "loss: 0.938069  [ 3760/ 4320]\n",
            "loss: 0.201793  [ 3840/ 4320]\n",
            "loss: 0.447670  [ 3920/ 4320]\n",
            "loss: 0.952799  [ 4000/ 4320]\n",
            "loss: 0.991323  [ 4080/ 4320]\n",
            "loss: 0.476916  [ 4160/ 4320]\n",
            "loss: 0.435236  [ 4240/ 4320]\n",
            "Validation loss after epoch 3: 1.113999\n",
            "loss: 0.374152  [    0/ 4320]\n",
            "loss: 0.282839  [   80/ 4320]\n",
            "loss: 0.860818  [  160/ 4320]\n",
            "loss: 0.455121  [  240/ 4320]\n",
            "loss: 0.868571  [  320/ 4320]\n",
            "loss: 1.217422  [  400/ 4320]\n",
            "loss: 1.010144  [  480/ 4320]\n",
            "loss: 0.508317  [  560/ 4320]\n",
            "loss: 0.303115  [  640/ 4320]\n",
            "loss: 0.597256  [  720/ 4320]\n",
            "loss: 0.561594  [  800/ 4320]\n",
            "loss: 0.536788  [  880/ 4320]\n",
            "loss: 0.430590  [  960/ 4320]\n",
            "loss: 0.415225  [ 1040/ 4320]\n",
            "loss: 0.500780  [ 1120/ 4320]\n",
            "loss: 0.351626  [ 1200/ 4320]\n",
            "loss: 0.414038  [ 1280/ 4320]\n",
            "loss: 0.518391  [ 1360/ 4320]\n",
            "loss: 0.432507  [ 1440/ 4320]\n",
            "loss: 0.978526  [ 1520/ 4320]\n",
            "loss: 1.058910  [ 1600/ 4320]\n",
            "loss: 0.903548  [ 1680/ 4320]\n",
            "loss: 0.266629  [ 1760/ 4320]\n",
            "loss: 0.478682  [ 1840/ 4320]\n",
            "loss: 0.543793  [ 1920/ 4320]\n",
            "loss: 0.560832  [ 2000/ 4320]\n",
            "loss: 0.276406  [ 2080/ 4320]\n",
            "loss: 0.659554  [ 2160/ 4320]\n",
            "loss: 0.558226  [ 2240/ 4320]\n",
            "loss: 0.391558  [ 2320/ 4320]\n",
            "loss: 0.309514  [ 2400/ 4320]\n",
            "loss: 0.274609  [ 2480/ 4320]\n",
            "loss: 0.406033  [ 2560/ 4320]\n",
            "loss: 0.292222  [ 2640/ 4320]\n",
            "loss: 0.290591  [ 2720/ 4320]\n",
            "loss: 0.417487  [ 2800/ 4320]\n",
            "loss: 1.010788  [ 2880/ 4320]\n",
            "loss: 0.278814  [ 2960/ 4320]\n",
            "loss: 0.458927  [ 3040/ 4320]\n",
            "loss: 0.295509  [ 3120/ 4320]\n",
            "loss: 0.215588  [ 3200/ 4320]\n",
            "loss: 0.861466  [ 3280/ 4320]\n",
            "loss: 1.025558  [ 3360/ 4320]\n",
            "loss: 0.306457  [ 3440/ 4320]\n",
            "loss: 0.547472  [ 3520/ 4320]\n",
            "loss: 0.476162  [ 3600/ 4320]\n",
            "loss: 0.408657  [ 3680/ 4320]\n",
            "loss: 0.504719  [ 3760/ 4320]\n",
            "loss: 0.373305  [ 3840/ 4320]\n",
            "loss: 0.328419  [ 3920/ 4320]\n",
            "loss: 0.383918  [ 4000/ 4320]\n",
            "loss: 0.210289  [ 4080/ 4320]\n",
            "loss: 0.923584  [ 4160/ 4320]\n",
            "loss: 0.417931  [ 4240/ 4320]\n",
            "Validation loss after epoch 4: 1.270834\n",
            "Early stopping at epoch 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-05-20 19:02:54,493] Trial 5 finished with value: 52.083333333333336 and parameters: {'dropout_rate': 0.11704219516598163, 'learning_rate': 2.624716219189803e-05, 'batch_size': 8, 'weight_decay': 0.00860543613305327, 'warmup_steps': 585}. Best is trial 1 with value: 56.458333333333336.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 1.812771  [    0/ 4320]\n",
            "loss: 1.797411  [   80/ 4320]\n",
            "loss: 1.723407  [  160/ 4320]\n",
            "loss: 1.736681  [  240/ 4320]\n",
            "loss: 1.699216  [  320/ 4320]\n",
            "loss: 1.718996  [  400/ 4320]\n",
            "loss: 1.712721  [  480/ 4320]\n",
            "loss: 1.669849  [  560/ 4320]\n",
            "loss: 1.576837  [  640/ 4320]\n",
            "loss: 1.681348  [  720/ 4320]\n",
            "loss: 1.438549  [  800/ 4320]\n",
            "loss: 1.600107  [  880/ 4320]\n",
            "loss: 1.638681  [  960/ 4320]\n",
            "loss: 1.301328  [ 1040/ 4320]\n",
            "loss: 1.344217  [ 1120/ 4320]\n",
            "loss: 1.298998  [ 1200/ 4320]\n",
            "loss: 1.465557  [ 1280/ 4320]\n",
            "loss: 1.326268  [ 1360/ 4320]\n",
            "loss: 1.522128  [ 1440/ 4320]\n",
            "loss: 1.361807  [ 1520/ 4320]\n",
            "loss: 1.523391  [ 1600/ 4320]\n",
            "loss: 1.208359  [ 1680/ 4320]\n",
            "loss: 1.152843  [ 1760/ 4320]\n",
            "loss: 1.471729  [ 1840/ 4320]\n",
            "loss: 0.977506  [ 1920/ 4320]\n",
            "loss: 1.099503  [ 2000/ 4320]\n",
            "loss: 1.101613  [ 2080/ 4320]\n",
            "loss: 1.205202  [ 2160/ 4320]\n",
            "loss: 1.269055  [ 2240/ 4320]\n",
            "loss: 1.467928  [ 2320/ 4320]\n",
            "loss: 1.136285  [ 2400/ 4320]\n",
            "loss: 1.514436  [ 2480/ 4320]\n",
            "loss: 0.863369  [ 2560/ 4320]\n",
            "loss: 1.244592  [ 2640/ 4320]\n",
            "loss: 1.243576  [ 2720/ 4320]\n",
            "loss: 1.020254  [ 2800/ 4320]\n",
            "loss: 1.124752  [ 2880/ 4320]\n",
            "loss: 0.933026  [ 2960/ 4320]\n",
            "loss: 1.056096  [ 3040/ 4320]\n",
            "loss: 1.483605  [ 3120/ 4320]\n",
            "loss: 0.873543  [ 3200/ 4320]\n",
            "loss: 1.523833  [ 3280/ 4320]\n",
            "loss: 1.143738  [ 3360/ 4320]\n",
            "loss: 1.224187  [ 3440/ 4320]\n",
            "loss: 1.208541  [ 3520/ 4320]\n",
            "loss: 0.954469  [ 3600/ 4320]\n",
            "loss: 1.291471  [ 3680/ 4320]\n",
            "loss: 1.191591  [ 3760/ 4320]\n",
            "loss: 1.021855  [ 3840/ 4320]\n",
            "loss: 1.018909  [ 3920/ 4320]\n",
            "loss: 0.953699  [ 4000/ 4320]\n",
            "loss: 1.156120  [ 4080/ 4320]\n",
            "loss: 0.968966  [ 4160/ 4320]\n",
            "loss: 0.960621  [ 4240/ 4320]\n",
            "Validation loss after epoch 1: 1.088363\n",
            "loss: 1.206687  [    0/ 4320]\n",
            "loss: 0.731406  [   80/ 4320]\n",
            "loss: 1.075192  [  160/ 4320]\n",
            "loss: 0.999320  [  240/ 4320]\n",
            "loss: 1.017604  [  320/ 4320]\n",
            "loss: 0.859648  [  400/ 4320]\n",
            "loss: 0.886083  [  480/ 4320]\n",
            "loss: 1.241350  [  560/ 4320]\n",
            "loss: 0.933491  [  640/ 4320]\n",
            "loss: 0.821261  [  720/ 4320]\n",
            "loss: 1.060989  [  800/ 4320]\n",
            "loss: 1.368207  [  880/ 4320]\n",
            "loss: 1.106425  [  960/ 4320]\n",
            "loss: 0.831791  [ 1040/ 4320]\n",
            "loss: 0.769058  [ 1120/ 4320]\n",
            "loss: 0.973779  [ 1200/ 4320]\n",
            "loss: 1.195575  [ 1280/ 4320]\n",
            "loss: 1.099300  [ 1360/ 4320]\n",
            "loss: 0.923206  [ 1440/ 4320]\n",
            "loss: 1.088512  [ 1520/ 4320]\n",
            "loss: 0.710426  [ 1600/ 4320]\n",
            "loss: 1.229381  [ 1680/ 4320]\n",
            "loss: 1.036796  [ 1760/ 4320]\n",
            "loss: 1.518678  [ 1840/ 4320]\n",
            "loss: 1.432468  [ 1920/ 4320]\n",
            "loss: 0.921096  [ 2000/ 4320]\n",
            "loss: 1.466340  [ 2080/ 4320]\n",
            "loss: 0.954316  [ 2160/ 4320]\n",
            "loss: 1.388450  [ 2240/ 4320]\n",
            "loss: 0.723217  [ 2320/ 4320]\n",
            "loss: 0.844483  [ 2400/ 4320]\n",
            "loss: 1.022843  [ 2480/ 4320]\n",
            "loss: 0.753679  [ 2560/ 4320]\n",
            "loss: 1.348014  [ 2640/ 4320]\n",
            "loss: 0.674233  [ 2720/ 4320]\n",
            "loss: 1.109010  [ 2800/ 4320]\n",
            "loss: 1.140334  [ 2880/ 4320]\n",
            "loss: 0.913886  [ 2960/ 4320]\n",
            "loss: 1.121069  [ 3040/ 4320]\n",
            "loss: 0.470516  [ 3120/ 4320]\n",
            "loss: 1.401212  [ 3200/ 4320]\n",
            "loss: 0.835316  [ 3280/ 4320]\n",
            "loss: 1.230559  [ 3360/ 4320]\n",
            "loss: 1.382477  [ 3440/ 4320]\n",
            "loss: 0.689431  [ 3520/ 4320]\n",
            "loss: 0.982634  [ 3600/ 4320]\n",
            "loss: 0.908181  [ 3680/ 4320]\n",
            "loss: 1.019221  [ 3760/ 4320]\n",
            "loss: 0.835097  [ 3840/ 4320]\n",
            "loss: 1.149985  [ 3920/ 4320]\n",
            "loss: 0.936462  [ 4000/ 4320]\n",
            "loss: 0.943499  [ 4080/ 4320]\n",
            "loss: 0.733100  [ 4160/ 4320]\n",
            "loss: 0.640926  [ 4240/ 4320]\n",
            "Validation loss after epoch 2: 1.116563\n",
            "loss: 0.886467  [    0/ 4320]\n",
            "loss: 1.169863  [   80/ 4320]\n",
            "loss: 0.594017  [  160/ 4320]\n",
            "loss: 0.927465  [  240/ 4320]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[W 2024-05-20 19:08:11,371] Trial 6 failed with parameters: {'dropout_rate': 0.13830806968014492, 'learning_rate': 2.3825994279570436e-05, 'batch_size': 8, 'weight_decay': 0.0008521233116552358, 'warmup_steps': 693} because of the following error: KeyboardInterrupt().\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"<ipython-input-13-b7e8d5179b74>\", line 166, in objective\n",
            "    train_loop_with_early_stopping(train_loader, model, criterion, optimizer, scheduler, test_loader)\n",
            "  File \"<ipython-input-13-b7e8d5179b74>\", line 119, in train_loop_with_early_stopping\n",
            "    loss, current = loss.item(), batch * len(inputs['input_ids'])\n",
            "KeyboardInterrupt\n",
            "[W 2024-05-20 19:08:11,372] Trial 6 failed with value None.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-b7e8d5179b74>\u001b[0m in \u001b[0;36m<cell line: 184>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;31m# Set up and run the study\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Number of trials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;31m# Print the best hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    449\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \"\"\"\n\u001b[0;32m--> 451\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    452\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     63\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     ):\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-b7e8d5179b74>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;31m# Training loop with early stopping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mtrain_loop_with_early_stopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;31m# Compute validation accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-b7e8d5179b74>\u001b[0m in \u001b[0;36mtrain_loop_with_early_stopping\u001b[0;34m(dataloader, model, loss_fn, optimizer, scheduler, val_loader, patience)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import CamembertTokenizer, CamembertModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load your data\n",
        "data = df_train\n",
        "sentences = data['sentence'].tolist()\n",
        "difficulties = data['difficulty'].tolist()\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(difficulties)\n",
        "\n",
        "# Load CamemBERT tokenizer and model\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
        "\n",
        "# Tokenize sentences and convert to tensor\n",
        "def tokenize_and_encode(sentences):\n",
        "    return tokenizer(sentences, padding=True, truncation=True, max_length=600, return_tensors='pt')\n",
        "\n",
        "# Custom Dataset class\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.encodings = tokenize_and_encode(texts)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: self.encodings[key][idx] for key in self.encodings}, self.labels[idx]\n",
        "\n",
        "# Data preparation\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    sentences, encoded_labels, test_size=0.1, random_state=42, stratify=encoded_labels\n",
        ")\n",
        "\n",
        "train_dataset = TextDataset(X_train, y_train)\n",
        "test_dataset = TextDataset(X_test, y_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# Neural network model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes, dropout_rate):\n",
        "        super(Net, self).__init__()\n",
        "        self.camembert = CamembertModel.from_pretrained('camembert-base')\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.fc = nn.Linear(self.camembert.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        outputs = self.camembert(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.fc(pooled_output)\n",
        "        return logits\n",
        "\n",
        "# Function to compute accuracy\n",
        "def compute_accuracy(dataloader, model):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            inputs, labels = batch\n",
        "            inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
        "            labels = labels.to('cuda')\n",
        "            outputs = model(**inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "# Function to compute validation loss\n",
        "def compute_validation_loss(dataloader, model, loss_fn):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            inputs, labels = batch\n",
        "            inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
        "            labels = labels.to('cuda')\n",
        "            outputs = model(**inputs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "# Training loop with early stopping\n",
        "def train_loop_with_early_stopping(dataloader, model, loss_fn, optimizer, scheduler, val_loader, patience=2):\n",
        "    size = len(dataloader.dataset)\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_no_improve = 0\n",
        "    early_stop = False\n",
        "\n",
        "    for epoch in range(10):  # Set a high number of epochs\n",
        "        if early_stop:\n",
        "            print(f\"Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "        model.train()  # Set model to training mode\n",
        "        for batch, (inputs, labels) in enumerate(dataloader):\n",
        "            inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
        "            labels = labels.to('cuda')\n",
        "            pred = model(**inputs)\n",
        "            loss = loss_fn(pred, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            if batch % 10 == 0:\n",
        "                loss, current = loss.item(), batch * len(inputs['input_ids'])\n",
        "                print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "        # Compute validation loss\n",
        "        val_loss = compute_validation_loss(val_loader, model, loss_fn)\n",
        "        print(f\"Validation loss after epoch {epoch+1}: {val_loss:>7f}\")\n",
        "\n",
        "        # Check for early stopping\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve == patience:\n",
        "                early_stop = True\n",
        "\n",
        "# Objective function for Optuna\n",
        "def objective(trial):\n",
        "    # Hyperparameters to tune\n",
        "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.3)\n",
        "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 8e-5)\n",
        "    batch_size = trial.suggest_categorical('batch_size', [8, 16])\n",
        "    weight_decay = trial.suggest_loguniform('weight_decay', 1e-4, 0.2)\n",
        "    warmup_steps = trial.suggest_int('warmup_steps', 500, 1000)\n",
        "\n",
        "    # Re-create the DataLoader with the new batch size\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Instantiate the model, loss, and optimizer with the suggested hyperparameters\n",
        "    model = Net(len(label_encoder.classes_), dropout_rate).to('cuda')\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "    # Create a scheduler\n",
        "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "        optimizer,\n",
        "        max_lr=learning_rate,\n",
        "        steps_per_epoch=len(train_loader),\n",
        "        epochs=10,\n",
        "        anneal_strategy='linear',\n",
        "        div_factor=1.0,\n",
        "        final_div_factor=1.0,\n",
        "        pct_start=warmup_steps / (len(train_loader) * 10)\n",
        "    )\n",
        "\n",
        "    # Training loop with early stopping\n",
        "    train_loop_with_early_stopping(train_loader, model, criterion, optimizer, scheduler, test_loader)\n",
        "\n",
        "    # Compute validation accuracy\n",
        "    accuracy = compute_accuracy(test_loader, model)\n",
        "\n",
        "    # Save model if it is one of the top 3 best\n",
        "    top_models.append((accuracy, model.state_dict()))\n",
        "    top_models.sort(key=lambda x: x[0], reverse=True)\n",
        "    if len(top_models) > 3:\n",
        "        top_models.pop()\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# List to keep track of the top 3 models\n",
        "top_models = []\n",
        "\n",
        "# Set up and run the study\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=15)  # Number of trials\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(f\"Best hyperparameters: {study.best_params}\")\n",
        "print(f\"Best validation accuracy: {study.best_value:.2f}%\")\n",
        "\n",
        "# Save the top 3 models and their submission samples\n",
        "for i, (accuracy, state_dict) in enumerate(top_models):\n",
        "    model_path = f\"model_top_{i+1}.pth\"\n",
        "    torch.save(state_dict, model_path)\n",
        "    print(f\"Model with accuracy {accuracy:.2f}% saved as {model_path}\")\n",
        "\n",
        "    # Load the best model state_dict\n",
        "    model = Net(len(label_encoder.classes_), 0.1).to('cuda')  # Use an arbitrary dropout rate for initialization\n",
        "    model.load_state_dict(state_dict)\n",
        "    model.eval()\n",
        "\n",
        "    # Prepare test data and predict\n",
        "    test_dataset = TextDataset(test_data['sentence'].tolist())\n",
        "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "    test_outputs = []\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            inputs = {key: value.to('cuda') for key, value in batch[0].items()}\n",
        "            outputs = model(**inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            test_outputs.extend(predicted.cpu().numpy())\n",
        "\n",
        "    # Convert numeric predictions back to labels\n",
        "    inv_label_dict = {v: k for k, v in label_dict.items()}\n",
        "    test_difficulties = [inv_label_dict[pred] for pred in test_outputs]\n",
        "\n",
        "    # Prepare the submission file\n",
        "    submission = pd.DataFrame({\n",
        "        'id': test_data['id'],\n",
        "        'difficulty': test_difficulties\n",
        "    })\n",
        "    submission_path = f'submission_top_{i+1}.csv'\n",
        "    submission.to_csv(submission_path, index=False)\n",
        "    print(f\"Submission for model_top_{i+1} saved as {submission_path}\")\n",
        "\n",
        "# If using Google Colab, download the models and submission files\n",
        "from google.colab import files\n",
        "for i in range(3):\n",
        "    files.download(f\"model_top_{i+1}.pth\")\n",
        "    files.download(f\"submission_top_{i+1}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Best model\n",
        "\n",
        "Based on the best hyperparameters of the optuna (I also runned in other pages), I achieved my best accuracy: **0.604**.\n",
        "\n",
        "Here the code below:"
      ],
      "metadata": {
        "id": "8XqS1EoGE5HC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "98afc151-de16-4cb6-a602-b792758cf786",
        "id": "8bzcWX7qFPv4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 1.812540  [    0/ 8640]\n",
            "loss: 1.792373  [   80/ 8640]\n",
            "loss: 1.768942  [  160/ 8640]\n",
            "loss: 1.789834  [  240/ 8640]\n",
            "loss: 1.760698  [  320/ 8640]\n",
            "loss: 1.805588  [  400/ 8640]\n",
            "loss: 1.728761  [  480/ 8640]\n",
            "loss: 1.698526  [  560/ 8640]\n",
            "loss: 1.780606  [  640/ 8640]\n",
            "loss: 1.670511  [  720/ 8640]\n",
            "loss: 1.675855  [  800/ 8640]\n",
            "loss: 1.719842  [  880/ 8640]\n",
            "loss: 1.552509  [  960/ 8640]\n",
            "loss: 1.611227  [ 1040/ 8640]\n",
            "loss: 1.465091  [ 1120/ 8640]\n",
            "loss: 1.471157  [ 1200/ 8640]\n",
            "loss: 1.499789  [ 1280/ 8640]\n",
            "loss: 1.414754  [ 1360/ 8640]\n",
            "loss: 1.930340  [ 1440/ 8640]\n",
            "loss: 1.450998  [ 1520/ 8640]\n",
            "loss: 1.235415  [ 1600/ 8640]\n",
            "loss: 1.319008  [ 1680/ 8640]\n",
            "loss: 1.427784  [ 1760/ 8640]\n",
            "loss: 1.534316  [ 1840/ 8640]\n",
            "loss: 1.496436  [ 1920/ 8640]\n",
            "loss: 1.538229  [ 2000/ 8640]\n",
            "loss: 1.220909  [ 2080/ 8640]\n",
            "loss: 1.213867  [ 2160/ 8640]\n",
            "loss: 1.214661  [ 2240/ 8640]\n",
            "loss: 1.216570  [ 2320/ 8640]\n",
            "loss: 1.618491  [ 2400/ 8640]\n",
            "loss: 1.345122  [ 2480/ 8640]\n",
            "loss: 1.200644  [ 2560/ 8640]\n",
            "loss: 1.334107  [ 2640/ 8640]\n",
            "loss: 1.385386  [ 2720/ 8640]\n",
            "loss: 1.294872  [ 2800/ 8640]\n",
            "loss: 1.313225  [ 2880/ 8640]\n",
            "loss: 1.167663  [ 2960/ 8640]\n",
            "loss: 1.038708  [ 3040/ 8640]\n",
            "loss: 1.588439  [ 3120/ 8640]\n",
            "loss: 1.213405  [ 3200/ 8640]\n",
            "loss: 0.907928  [ 3280/ 8640]\n",
            "loss: 1.018451  [ 3360/ 8640]\n",
            "loss: 1.019043  [ 3440/ 8640]\n",
            "loss: 1.160505  [ 3520/ 8640]\n",
            "loss: 0.968708  [ 3600/ 8640]\n",
            "loss: 1.069904  [ 3680/ 8640]\n",
            "loss: 1.640405  [ 3760/ 8640]\n",
            "loss: 1.371258  [ 3840/ 8640]\n",
            "loss: 1.042897  [ 3920/ 8640]\n",
            "loss: 1.372269  [ 4000/ 8640]\n",
            "loss: 1.013313  [ 4080/ 8640]\n",
            "loss: 1.337116  [ 4160/ 8640]\n",
            "loss: 1.262738  [ 4240/ 8640]\n",
            "loss: 1.146806  [ 4320/ 8640]\n",
            "loss: 1.237204  [ 4400/ 8640]\n",
            "loss: 1.210115  [ 4480/ 8640]\n",
            "loss: 1.271011  [ 4560/ 8640]\n",
            "loss: 1.298538  [ 4640/ 8640]\n",
            "loss: 1.660277  [ 4720/ 8640]\n",
            "loss: 1.504240  [ 4800/ 8640]\n",
            "loss: 1.962186  [ 4880/ 8640]\n",
            "loss: 1.789736  [ 4960/ 8640]\n",
            "loss: 1.911574  [ 5040/ 8640]\n",
            "loss: 1.561641  [ 5120/ 8640]\n",
            "loss: 1.344810  [ 5200/ 8640]\n",
            "loss: 1.901953  [ 5280/ 8640]\n",
            "loss: 1.515456  [ 5360/ 8640]\n",
            "loss: 1.575630  [ 5440/ 8640]\n",
            "loss: 1.856682  [ 5520/ 8640]\n",
            "loss: 1.776702  [ 5600/ 8640]\n",
            "loss: 1.957423  [ 5680/ 8640]\n",
            "loss: 1.602303  [ 5760/ 8640]\n",
            "loss: 1.629143  [ 5840/ 8640]\n",
            "loss: 1.605707  [ 5920/ 8640]\n",
            "loss: 1.402632  [ 6000/ 8640]\n",
            "loss: 1.366865  [ 6080/ 8640]\n",
            "loss: 1.192574  [ 6160/ 8640]\n",
            "loss: 1.480644  [ 6240/ 8640]\n",
            "loss: 1.686145  [ 6320/ 8640]\n",
            "loss: 1.374533  [ 6400/ 8640]\n",
            "loss: 1.431105  [ 6480/ 8640]\n",
            "loss: 1.608894  [ 6560/ 8640]\n",
            "loss: 1.395752  [ 6640/ 8640]\n",
            "loss: 1.237648  [ 6720/ 8640]\n",
            "loss: 1.092237  [ 6800/ 8640]\n",
            "loss: 0.935934  [ 6880/ 8640]\n",
            "loss: 0.975200  [ 6960/ 8640]\n",
            "loss: 1.237804  [ 7040/ 8640]\n",
            "loss: 1.168940  [ 7120/ 8640]\n",
            "loss: 1.157654  [ 7200/ 8640]\n",
            "loss: 0.883163  [ 7280/ 8640]\n",
            "loss: 0.915642  [ 7360/ 8640]\n",
            "loss: 0.954595  [ 7440/ 8640]\n",
            "loss: 1.114438  [ 7520/ 8640]\n",
            "loss: 0.978077  [ 7600/ 8640]\n",
            "loss: 1.443103  [ 7680/ 8640]\n",
            "loss: 1.101109  [ 7760/ 8640]\n",
            "loss: 0.921696  [ 7840/ 8640]\n",
            "loss: 1.476718  [ 7920/ 8640]\n",
            "loss: 0.997257  [ 8000/ 8640]\n",
            "loss: 1.068618  [ 8080/ 8640]\n",
            "loss: 1.540907  [ 8160/ 8640]\n",
            "loss: 1.194686  [ 8240/ 8640]\n",
            "loss: 1.056718  [ 8320/ 8640]\n",
            "loss: 1.206017  [ 8400/ 8640]\n",
            "loss: 0.758769  [ 8480/ 8640]\n",
            "loss: 1.387310  [ 8560/ 8640]\n",
            "Training done\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.832517  [    0/ 8640]\n",
            "loss: 0.899295  [   80/ 8640]\n",
            "loss: 1.198065  [  160/ 8640]\n",
            "loss: 1.114133  [  240/ 8640]\n",
            "loss: 0.886807  [  320/ 8640]\n",
            "loss: 0.691636  [  400/ 8640]\n",
            "loss: 1.032547  [  480/ 8640]\n",
            "loss: 0.859716  [  560/ 8640]\n",
            "loss: 1.254292  [  640/ 8640]\n",
            "loss: 0.991352  [  720/ 8640]\n",
            "loss: 0.873123  [  800/ 8640]\n",
            "loss: 0.786609  [  880/ 8640]\n",
            "loss: 1.431482  [  960/ 8640]\n",
            "loss: 0.903936  [ 1040/ 8640]\n",
            "loss: 0.938979  [ 1120/ 8640]\n",
            "loss: 0.962164  [ 1200/ 8640]\n",
            "loss: 1.054223  [ 1280/ 8640]\n",
            "loss: 0.945390  [ 1360/ 8640]\n",
            "loss: 1.051670  [ 1440/ 8640]\n",
            "loss: 0.832379  [ 1520/ 8640]\n",
            "loss: 0.999842  [ 1600/ 8640]\n",
            "loss: 1.385735  [ 1680/ 8640]\n",
            "loss: 0.836355  [ 1760/ 8640]\n",
            "loss: 0.622162  [ 1840/ 8640]\n",
            "loss: 1.062052  [ 1920/ 8640]\n",
            "loss: 0.719565  [ 2000/ 8640]\n",
            "loss: 0.735846  [ 2080/ 8640]\n",
            "loss: 0.871696  [ 2160/ 8640]\n",
            "loss: 0.631393  [ 2240/ 8640]\n",
            "loss: 1.047400  [ 2320/ 8640]\n",
            "loss: 1.098523  [ 2400/ 8640]\n",
            "loss: 0.938039  [ 2480/ 8640]\n",
            "loss: 0.923579  [ 2560/ 8640]\n",
            "loss: 0.879894  [ 2640/ 8640]\n",
            "loss: 0.830340  [ 2720/ 8640]\n",
            "loss: 1.252477  [ 2800/ 8640]\n",
            "loss: 0.924427  [ 2880/ 8640]\n",
            "loss: 0.934801  [ 2960/ 8640]\n",
            "loss: 1.018886  [ 3040/ 8640]\n",
            "loss: 1.153529  [ 3120/ 8640]\n",
            "loss: 0.933215  [ 3200/ 8640]\n",
            "loss: 1.074838  [ 3280/ 8640]\n",
            "loss: 0.991986  [ 3360/ 8640]\n",
            "loss: 0.965457  [ 3440/ 8640]\n",
            "loss: 0.885467  [ 3520/ 8640]\n",
            "loss: 1.167695  [ 3600/ 8640]\n",
            "loss: 0.735822  [ 3680/ 8640]\n",
            "loss: 1.059136  [ 3760/ 8640]\n",
            "loss: 0.535366  [ 3840/ 8640]\n",
            "loss: 1.356823  [ 3920/ 8640]\n",
            "loss: 0.729066  [ 4000/ 8640]\n",
            "loss: 1.057180  [ 4080/ 8640]\n",
            "loss: 0.937956  [ 4160/ 8640]\n",
            "loss: 0.749095  [ 4240/ 8640]\n",
            "loss: 1.236560  [ 4320/ 8640]\n",
            "loss: 0.941382  [ 4400/ 8640]\n",
            "loss: 0.925978  [ 4480/ 8640]\n",
            "loss: 1.280366  [ 4560/ 8640]\n",
            "loss: 0.761770  [ 4640/ 8640]\n",
            "loss: 1.152177  [ 4720/ 8640]\n",
            "loss: 0.897093  [ 4800/ 8640]\n",
            "loss: 0.937877  [ 4880/ 8640]\n",
            "loss: 1.164587  [ 4960/ 8640]\n",
            "loss: 0.823552  [ 5040/ 8640]\n",
            "loss: 1.087910  [ 5120/ 8640]\n",
            "loss: 0.817346  [ 5200/ 8640]\n",
            "loss: 0.631808  [ 5280/ 8640]\n",
            "loss: 0.880104  [ 5360/ 8640]\n",
            "loss: 0.796093  [ 5440/ 8640]\n",
            "loss: 1.436491  [ 5520/ 8640]\n",
            "loss: 1.112643  [ 5600/ 8640]\n",
            "loss: 0.729832  [ 5680/ 8640]\n",
            "loss: 1.081443  [ 5760/ 8640]\n",
            "loss: 1.223396  [ 5840/ 8640]\n",
            "loss: 0.741264  [ 5920/ 8640]\n",
            "loss: 0.879328  [ 6000/ 8640]\n",
            "loss: 0.860282  [ 6080/ 8640]\n",
            "loss: 1.034064  [ 6160/ 8640]\n",
            "loss: 0.472058  [ 6240/ 8640]\n",
            "loss: 0.794095  [ 6320/ 8640]\n",
            "loss: 0.972858  [ 6400/ 8640]\n",
            "loss: 1.088364  [ 6480/ 8640]\n",
            "loss: 0.564976  [ 6560/ 8640]\n",
            "loss: 0.544973  [ 6640/ 8640]\n",
            "loss: 0.750673  [ 6720/ 8640]\n",
            "loss: 0.667496  [ 6800/ 8640]\n",
            "loss: 0.925272  [ 6880/ 8640]\n",
            "loss: 0.651972  [ 6960/ 8640]\n",
            "loss: 0.725301  [ 7040/ 8640]\n",
            "loss: 0.690641  [ 7120/ 8640]\n",
            "loss: 0.929420  [ 7200/ 8640]\n",
            "loss: 0.929493  [ 7280/ 8640]\n",
            "loss: 0.676450  [ 7360/ 8640]\n",
            "loss: 1.091838  [ 7440/ 8640]\n",
            "loss: 0.841182  [ 7520/ 8640]\n",
            "loss: 1.569034  [ 7600/ 8640]\n",
            "loss: 0.797477  [ 7680/ 8640]\n",
            "loss: 0.599770  [ 7760/ 8640]\n",
            "loss: 0.960491  [ 7840/ 8640]\n",
            "loss: 1.271757  [ 7920/ 8640]\n",
            "loss: 1.114190  [ 8000/ 8640]\n",
            "loss: 0.951912  [ 8080/ 8640]\n",
            "loss: 0.898055  [ 8160/ 8640]\n",
            "loss: 0.969935  [ 8240/ 8640]\n",
            "loss: 1.066077  [ 8320/ 8640]\n",
            "loss: 0.793251  [ 8400/ 8640]\n",
            "loss: 0.635322  [ 8480/ 8640]\n",
            "loss: 0.533235  [ 8560/ 8640]\n",
            "Training done\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.747802  [    0/ 8640]\n",
            "loss: 1.125092  [   80/ 8640]\n",
            "loss: 0.760645  [  160/ 8640]\n",
            "loss: 0.873856  [  240/ 8640]\n",
            "loss: 0.722335  [  320/ 8640]\n",
            "loss: 0.586521  [  400/ 8640]\n",
            "loss: 0.548434  [  480/ 8640]\n",
            "loss: 1.103685  [  560/ 8640]\n",
            "loss: 0.613973  [  640/ 8640]\n",
            "loss: 0.970740  [  720/ 8640]\n",
            "loss: 0.596265  [  800/ 8640]\n",
            "loss: 0.828070  [  880/ 8640]\n",
            "loss: 0.984079  [  960/ 8640]\n",
            "loss: 1.092264  [ 1040/ 8640]\n",
            "loss: 0.852514  [ 1120/ 8640]\n",
            "loss: 0.705472  [ 1200/ 8640]\n",
            "loss: 0.637497  [ 1280/ 8640]\n",
            "loss: 0.615686  [ 1360/ 8640]\n",
            "loss: 0.552017  [ 1440/ 8640]\n",
            "loss: 0.426606  [ 1520/ 8640]\n",
            "loss: 1.466936  [ 1600/ 8640]\n",
            "loss: 1.030237  [ 1680/ 8640]\n",
            "loss: 0.817024  [ 1760/ 8640]\n",
            "loss: 0.619679  [ 1840/ 8640]\n",
            "loss: 0.655051  [ 1920/ 8640]\n",
            "loss: 0.915240  [ 2000/ 8640]\n",
            "loss: 0.489670  [ 2080/ 8640]\n",
            "loss: 0.361733  [ 2160/ 8640]\n",
            "loss: 0.874726  [ 2240/ 8640]\n",
            "loss: 1.267215  [ 2320/ 8640]\n",
            "loss: 0.287807  [ 2400/ 8640]\n",
            "loss: 0.451119  [ 2480/ 8640]\n",
            "loss: 0.448057  [ 2560/ 8640]\n",
            "loss: 0.674046  [ 2640/ 8640]\n",
            "loss: 0.587544  [ 2720/ 8640]\n",
            "loss: 0.706357  [ 2800/ 8640]\n",
            "loss: 0.328002  [ 2880/ 8640]\n",
            "loss: 1.007556  [ 2960/ 8640]\n",
            "loss: 0.953658  [ 3040/ 8640]\n",
            "loss: 0.694035  [ 3120/ 8640]\n",
            "loss: 0.598509  [ 3200/ 8640]\n",
            "loss: 0.636324  [ 3280/ 8640]\n",
            "loss: 0.506586  [ 3360/ 8640]\n",
            "loss: 0.765939  [ 3440/ 8640]\n",
            "loss: 0.509330  [ 3520/ 8640]\n",
            "loss: 0.705781  [ 3600/ 8640]\n",
            "loss: 0.442962  [ 3680/ 8640]\n",
            "loss: 0.561625  [ 3760/ 8640]\n",
            "loss: 0.393483  [ 3840/ 8640]\n",
            "loss: 0.729202  [ 3920/ 8640]\n",
            "loss: 1.082199  [ 4000/ 8640]\n",
            "loss: 0.449335  [ 4080/ 8640]\n",
            "loss: 0.614461  [ 4160/ 8640]\n",
            "loss: 0.750025  [ 4240/ 8640]\n",
            "loss: 1.097012  [ 4320/ 8640]\n",
            "loss: 0.619606  [ 4400/ 8640]\n",
            "loss: 0.461253  [ 4480/ 8640]\n",
            "loss: 0.370261  [ 4560/ 8640]\n",
            "loss: 0.579649  [ 4640/ 8640]\n",
            "loss: 0.886795  [ 4720/ 8640]\n",
            "loss: 0.203830  [ 4800/ 8640]\n",
            "loss: 0.355927  [ 4880/ 8640]\n",
            "loss: 1.216530  [ 4960/ 8640]\n",
            "loss: 0.665891  [ 5040/ 8640]\n",
            "loss: 0.663561  [ 5120/ 8640]\n",
            "loss: 0.654433  [ 5200/ 8640]\n",
            "loss: 0.410196  [ 5280/ 8640]\n",
            "loss: 0.303540  [ 5360/ 8640]\n",
            "loss: 0.480203  [ 5440/ 8640]\n",
            "loss: 0.873463  [ 5520/ 8640]\n",
            "loss: 0.930893  [ 5600/ 8640]\n",
            "loss: 0.584471  [ 5680/ 8640]\n",
            "loss: 0.475242  [ 5760/ 8640]\n",
            "loss: 1.180521  [ 5840/ 8640]\n",
            "loss: 0.495384  [ 5920/ 8640]\n",
            "loss: 0.987495  [ 6000/ 8640]\n",
            "loss: 0.639139  [ 6080/ 8640]\n",
            "loss: 0.909436  [ 6160/ 8640]\n",
            "loss: 0.340077  [ 6240/ 8640]\n",
            "loss: 0.575651  [ 6320/ 8640]\n",
            "loss: 0.580096  [ 6400/ 8640]\n",
            "loss: 0.392067  [ 6480/ 8640]\n",
            "loss: 0.474204  [ 6560/ 8640]\n",
            "loss: 0.815298  [ 6640/ 8640]\n",
            "loss: 0.401185  [ 6720/ 8640]\n",
            "loss: 1.127548  [ 6800/ 8640]\n",
            "loss: 0.622617  [ 6880/ 8640]\n",
            "loss: 0.682327  [ 6960/ 8640]\n",
            "loss: 0.907893  [ 7040/ 8640]\n",
            "loss: 0.283140  [ 7120/ 8640]\n",
            "loss: 0.188950  [ 7200/ 8640]\n",
            "loss: 0.527047  [ 7280/ 8640]\n",
            "loss: 0.275322  [ 7360/ 8640]\n",
            "loss: 0.538688  [ 7440/ 8640]\n",
            "loss: 0.910188  [ 7520/ 8640]\n",
            "loss: 1.350120  [ 7600/ 8640]\n",
            "loss: 0.520276  [ 7680/ 8640]\n",
            "loss: 0.766180  [ 7760/ 8640]\n",
            "loss: 0.538516  [ 7840/ 8640]\n",
            "loss: 1.405501  [ 7920/ 8640]\n",
            "loss: 0.515638  [ 8000/ 8640]\n",
            "loss: 1.085067  [ 8080/ 8640]\n",
            "loss: 0.584532  [ 8160/ 8640]\n",
            "loss: 0.918897  [ 8240/ 8640]\n",
            "loss: 0.298123  [ 8320/ 8640]\n",
            "loss: 0.944413  [ 8400/ 8640]\n",
            "loss: 0.585425  [ 8480/ 8640]\n",
            "loss: 1.826079  [ 8560/ 8640]\n",
            "Training done\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.657607  [    0/ 8640]\n",
            "loss: 0.475309  [   80/ 8640]\n",
            "loss: 0.605762  [  160/ 8640]\n",
            "loss: 0.247848  [  240/ 8640]\n",
            "loss: 0.587717  [  320/ 8640]\n",
            "loss: 0.354042  [  400/ 8640]\n",
            "loss: 0.275365  [  480/ 8640]\n",
            "loss: 0.832089  [  560/ 8640]\n",
            "loss: 0.241663  [  640/ 8640]\n",
            "loss: 0.375476  [  720/ 8640]\n",
            "loss: 0.194873  [  800/ 8640]\n",
            "loss: 0.255336  [  880/ 8640]\n",
            "loss: 0.480410  [  960/ 8640]\n",
            "loss: 0.147758  [ 1040/ 8640]\n",
            "loss: 0.980201  [ 1120/ 8640]\n",
            "loss: 0.354508  [ 1200/ 8640]\n",
            "loss: 0.334271  [ 1280/ 8640]\n",
            "loss: 0.408169  [ 1360/ 8640]\n",
            "loss: 0.342217  [ 1440/ 8640]\n",
            "loss: 0.774238  [ 1520/ 8640]\n",
            "loss: 0.763451  [ 1600/ 8640]\n",
            "loss: 0.325906  [ 1680/ 8640]\n",
            "loss: 0.303867  [ 1760/ 8640]\n",
            "loss: 0.826964  [ 1840/ 8640]\n",
            "loss: 0.340667  [ 1920/ 8640]\n",
            "loss: 0.238371  [ 2000/ 8640]\n",
            "loss: 0.272487  [ 2080/ 8640]\n",
            "loss: 0.642625  [ 2160/ 8640]\n",
            "loss: 0.125039  [ 2240/ 8640]\n",
            "loss: 0.320673  [ 2320/ 8640]\n",
            "loss: 0.349565  [ 2400/ 8640]\n",
            "loss: 0.909344  [ 2480/ 8640]\n",
            "loss: 0.282845  [ 2560/ 8640]\n",
            "loss: 0.605436  [ 2640/ 8640]\n",
            "loss: 0.589326  [ 2720/ 8640]\n",
            "loss: 0.140576  [ 2800/ 8640]\n",
            "loss: 0.278903  [ 2880/ 8640]\n",
            "loss: 0.170503  [ 2960/ 8640]\n",
            "loss: 0.592513  [ 3040/ 8640]\n",
            "loss: 0.517486  [ 3120/ 8640]\n",
            "loss: 0.261743  [ 3200/ 8640]\n",
            "loss: 0.713862  [ 3280/ 8640]\n",
            "loss: 0.245912  [ 3360/ 8640]\n",
            "loss: 1.058263  [ 3440/ 8640]\n",
            "loss: 0.520019  [ 3520/ 8640]\n",
            "loss: 0.589375  [ 3600/ 8640]\n",
            "loss: 0.190805  [ 3680/ 8640]\n",
            "loss: 0.424144  [ 3760/ 8640]\n",
            "loss: 0.333187  [ 3840/ 8640]\n",
            "loss: 0.424874  [ 3920/ 8640]\n",
            "loss: 0.098180  [ 4000/ 8640]\n",
            "loss: 0.151268  [ 4080/ 8640]\n",
            "loss: 0.434011  [ 4160/ 8640]\n",
            "loss: 0.178595  [ 4240/ 8640]\n",
            "loss: 0.167617  [ 4320/ 8640]\n",
            "loss: 0.361371  [ 4400/ 8640]\n",
            "loss: 0.820176  [ 4480/ 8640]\n",
            "loss: 0.305886  [ 4560/ 8640]\n",
            "loss: 0.459045  [ 4640/ 8640]\n",
            "loss: 0.648703  [ 4720/ 8640]\n",
            "loss: 0.479721  [ 4800/ 8640]\n",
            "loss: 0.556718  [ 4880/ 8640]\n",
            "loss: 0.154287  [ 4960/ 8640]\n",
            "loss: 0.428314  [ 5040/ 8640]\n",
            "loss: 0.222871  [ 5120/ 8640]\n",
            "loss: 0.903122  [ 5200/ 8640]\n",
            "loss: 0.140405  [ 5280/ 8640]\n",
            "loss: 1.066808  [ 5360/ 8640]\n",
            "loss: 0.707217  [ 5440/ 8640]\n",
            "loss: 0.365985  [ 5520/ 8640]\n",
            "loss: 0.727479  [ 5600/ 8640]\n",
            "loss: 0.340475  [ 5680/ 8640]\n",
            "loss: 0.499192  [ 5760/ 8640]\n",
            "loss: 0.574406  [ 5840/ 8640]\n",
            "loss: 0.993125  [ 5920/ 8640]\n",
            "loss: 0.482105  [ 6000/ 8640]\n",
            "loss: 0.316617  [ 6080/ 8640]\n",
            "loss: 0.100376  [ 6160/ 8640]\n",
            "loss: 0.871756  [ 6240/ 8640]\n",
            "loss: 0.982788  [ 6320/ 8640]\n",
            "loss: 0.600565  [ 6400/ 8640]\n",
            "loss: 0.112482  [ 6480/ 8640]\n",
            "loss: 0.405043  [ 6560/ 8640]\n",
            "loss: 0.172298  [ 6640/ 8640]\n",
            "loss: 0.544186  [ 6720/ 8640]\n",
            "loss: 0.901955  [ 6800/ 8640]\n",
            "loss: 0.098189  [ 6880/ 8640]\n",
            "loss: 0.163678  [ 6960/ 8640]\n",
            "loss: 0.124537  [ 7040/ 8640]\n",
            "loss: 0.187790  [ 7120/ 8640]\n",
            "loss: 0.277632  [ 7200/ 8640]\n",
            "loss: 1.019371  [ 7280/ 8640]\n",
            "loss: 0.258506  [ 7360/ 8640]\n",
            "loss: 0.684436  [ 7440/ 8640]\n",
            "loss: 0.514749  [ 7520/ 8640]\n",
            "loss: 0.248642  [ 7600/ 8640]\n",
            "loss: 0.157026  [ 7680/ 8640]\n",
            "loss: 0.608166  [ 7760/ 8640]\n",
            "loss: 0.499212  [ 7840/ 8640]\n",
            "loss: 0.143609  [ 7920/ 8640]\n",
            "loss: 0.630879  [ 8000/ 8640]\n",
            "loss: 0.314175  [ 8080/ 8640]\n",
            "loss: 0.105194  [ 8160/ 8640]\n",
            "loss: 0.361581  [ 8240/ 8640]\n",
            "loss: 0.297517  [ 8320/ 8640]\n",
            "loss: 0.340744  [ 8400/ 8640]\n",
            "loss: 1.267568  [ 8480/ 8640]\n",
            "loss: 0.380036  [ 8560/ 8640]\n",
            "Training done\n",
            "Test Accuracy: 79.38%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_a8b4fb83-2f39-4819-8dd3-ed6f94e577e2\", \"sample_text_add_b8_lr175e5_drop01.csv\", 8504)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def synonym_replacement(sentence, n):\n",
        "    words = sentence.split()\n",
        "    new_words = words.copy()\n",
        "    french_stopwords = set(nltk.corpus.stopwords.words('french'))\n",
        "    random_word_list = list(set([word for word in words if word not in french_stopwords]))\n",
        "    random.shuffle(random_word_list)\n",
        "    num_replaced = 0\n",
        "    for random_word in random_word_list:\n",
        "        synonyms = get_synonyms(random_word)\n",
        "        if len(synonyms) > 0:\n",
        "            synonym = random.choice(synonyms)\n",
        "            new_words = [synonym if word == random_word else word for word in new_words]\n",
        "            num_replaced += 1\n",
        "        if num_replaced >= n:  # Only replace up to n words\n",
        "            break\n",
        "    return ' '.join(new_words)\n",
        "\n",
        "def get_synonyms(word):\n",
        "    synonyms = set()\n",
        "    for syn in wordnet.synsets(word, lang='fra'):\n",
        "        for lemma in syn.lemmas(lang='fra'):\n",
        "            synonym = lemma.name().replace(\"_\", \" \").replace(\"-\", \" \").lower()\n",
        "            synonym = \"\".join([char for char in synonym if char.isalnum() or char.isspace()])\n",
        "            synonyms.add(synonym)\n",
        "    if word in synonyms:\n",
        "        synonyms.remove(word)\n",
        "    return list(synonyms)\n",
        "\n",
        "# Generate augmented sentences\n",
        "new_sentences = []\n",
        "new_difficulties = []\n",
        "for _, row in df_train.iterrows():\n",
        "    original_sentence = row['sentence']\n",
        "    difficulty = row['difficulty']\n",
        "    augmented_sentence = synonym_replacement(original_sentence, 2)\n",
        "    new_sentences.append(augmented_sentence)\n",
        "    new_difficulties.append(difficulty)\n",
        "\n",
        "# Create a new DataFrame for the augmented sentences\n",
        "df_augmented = pd.DataFrame({'sentence': new_sentences, 'difficulty': new_difficulties})\n",
        "\n",
        "# Concatenate the original and augmented DataFrames\n",
        "df_combined = pd.concat([df_train, df_augmented], ignore_index=True)\n",
        "\n",
        "# Load your data\n",
        "data = df_combined\n",
        "sentences = data['sentence'].tolist()\n",
        "difficulties = data['difficulty'].tolist()\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(difficulties)\n",
        "\n",
        "# Load CamemBERT tokenizer and model\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
        "camembert = CamembertModel.from_pretrained('camembert-base')\n",
        "\n",
        "# Tokenize sentences and convert to tensor\n",
        "def tokenize_and_encode(sentences):\n",
        "    return tokenizer(sentences, padding=True, truncation=True, max_length=600, return_tensors='pt')\n",
        "\n",
        "# Custom Dataset class\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.encodings = tokenize_and_encode(texts)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: self.encodings[key][idx] for key in self.encodings}, self.labels[idx]\n",
        "\n",
        "# Data preparation\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    sentences, encoded_labels, test_size=0.1, random_state=42, stratify=encoded_labels\n",
        ")\n",
        "\n",
        "train_dataset = TextDataset(X_train, y_train)\n",
        "test_dataset = TextDataset(X_test, y_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# Neural network model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Net, self).__init__()\n",
        "        self.camembert = camembert\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        self.fc = nn.Linear(self.camembert.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        outputs = self.camembert(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.fc(pooled_output)\n",
        "        return logits\n",
        "\n",
        "# Instantiate the model, loss, and optimizer\n",
        "model = Net(len(label_encoder.classes_)).to('cuda')\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1.75e-5)\n",
        "\n",
        "# Function to compute accuracy\n",
        "def compute_accuracy(dataloader, model):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            inputs, labels = batch\n",
        "            inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
        "            labels = labels.to('cuda')\n",
        "            outputs = model(**inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "# Training loop\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()  # Set model to training mode\n",
        "    for batch, (inputs, labels) in enumerate(dataloader):\n",
        "        inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
        "        labels = labels.to('cuda')\n",
        "        pred = model(**inputs)\n",
        "        loss = loss_fn(pred, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 10 == 0:\n",
        "            loss, current = loss.item(), batch * len(inputs['input_ids'])\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "# Execute training\n",
        "for epoch in range(4):  # Number of epochs\n",
        "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
        "    train_loop(train_loader, model, criterion, optimizer)\n",
        "    print(\"Training done\")\n",
        "\n",
        "# Test the model\n",
        "accuracy = compute_accuracy(test_loader, model)\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import CamembertTokenizer\n",
        "\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
        "\n",
        "# Tokenize and encode the test data\n",
        "def tokenize_and_encode(sentences):\n",
        "    return tokenizer(sentences, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
        "\n",
        "# Custom Dataset class for test data\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, texts):\n",
        "        self.encodings = tokenize_and_encode(texts)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings['input_ids'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: self.encodings[key][idx] for key in self.encodings}\n",
        "\n",
        "# Create the dataset and dataloader for df_test\n",
        "test_dataset = TestDataset(df_test['sentence'].tolist())\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# Define the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Generate predictions for df_test\n",
        "model.eval()  # Make sure the model is in evaluation mode\n",
        "all_predictions = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        inputs = {key: value.to(device) for key, value in batch.items()}\n",
        "        outputs = model(**inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "# Convert numeric predictions back to labels\n",
        "predicted_labels = label_encoder.inverse_transform(all_predictions)\n",
        "\n",
        "# Prepare and save the submission file\n",
        "submission_df = pd.DataFrame({\n",
        "    'id': df_test['id'],  # Ensure df_test includes an 'id' column\n",
        "    'difficulty': predicted_labels\n",
        "})\n",
        "\n",
        "submission_df.to_csv('sample_text_add_b8_lr175e5_drop01.csv', index=False)\n",
        "from google.colab import files\n",
        "files.download('sample_text_add_b8_lr175e5_drop01.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68aa1790-dc7c-4e9b-964f-3632a68f6abb",
        "id": "GopgFuQDFcJy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to C:/Users/User/Desktop/1-Учеба/For_python/trained_model.pth\n",
            "Model loaded from C:/Users/User/Desktop/1-Учеба/For_python/trained_model.pth\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Path to save the model\n",
        "model_save_path = 'C:/Users/User/Desktop/1-Учеба/For_python/trained_model.pth'\n",
        "\n",
        "# Ensure the directory exists\n",
        "os.makedirs(os.path.dirname(model_save_path), exist_ok=True)\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "print(f\"Model saved to {model_save_path}\")\n",
        "\n",
        "# Load the saved model\n",
        "model_load_path = model_save_path\n",
        "loaded_model = Net(len(label_encoder.classes_)).to('cuda')\n",
        "loaded_model.load_state_dict(torch.load(model_load_path))\n",
        "loaded_model.eval()\n",
        "print(f\"Model loaded from {model_load_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ba0821e-580e-4d90-bf04-64abe20ae5d9",
        "id": "SasDKV11FzRs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to trained_model.pth\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_e55cbcdb-5f09-462a-ba20-0ae14c84ddbf\", \"trained_model.pth\", 442591214)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "from google.colab import files\n",
        "\n",
        "# Path to save the model in Colab\n",
        "model_save_path = 'trained_model.pth'\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "print(f\"Model saved to {model_save_path}\")\n",
        "\n",
        "# Download the file to your local machine\n",
        "files.download(model_save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhU9cp6rTGlH"
      },
      "source": [
        "### Other requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "Lekk0csWkPzn",
        "outputId": "a5405a7e-c6e0-4314-d067-f897c7322c29"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxQAAAK9CAYAAAC95yoDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABeLUlEQVR4nO3deZyNdf/H8feZMceMGYZZyL5mxm4sYSIVKqKyJ0vZsoTSYksisqXNUrlzpylliRBxt6sUUilZQkb2mAVjNrP+/vBzOifbXFdmrmvM63k/zuPhXNf3XNfnnE/c53M+3+91ObKzs7MFAAAAACZ4WR0AAAAAgPyLggIAAACAaRQUAAAAAEyjoAAAAABgGgUFAAAAANMoKAAAAACYRkEBAAAAwDQKCgAAAACmUVAAAAAAMI2CAgAu4c8//1S/fv3UsGFDhYWF6fPPP7+mxz9y5IjCwsL04YcfXtPj5me9e/dW7969rQ4DAGAQBQUA2zp06JAmTJigVq1aqU6dOmrQoIHuv/9+RUVFKTU1NVfPPWbMGO3du1cjR47UzJkzVbt27Vw9X14aM2aMwsLC1KBBg0t+jn/++afCwsIUFham//73v4aPf+LECc2ZM0e7d+++FuECAGyukNUBAMClbNiwQY8++qicTqfuvfdeVa9eXenp6frpp5/0wgsv6I8//tDkyZNz5dypqanatm2bBg8erF69euXKOcqWLavt27erUCFr/hkuVKiQUlNT9eWXX6pdu3Ye+9asWaPChQvr3Llzpo598uRJzZ07V2XLllWNGjVy/DozxQsAwHoUFABs5/Dhwxo5cqTKlCmjqKgolSxZ0rWvZ8+eOnjwoDZs2JBr54+Pj5ckFStWLNfO4XA4VLhw4Vw7/tU4nU41aNBAH3/88UUFxdq1a3Xrrbfqk08+yZNYUlJS5OfnJ6fTmSfnAwBcW0x5AmA7CxYsUHJysp5//nmPYuKCihUr6sEHH3Q9z8jI0Lx589S6dWvVrl1bt99+u1566SWlpaV5vO7222/XoEGD9OOPP6pLly6qU6eOWrVqpVWrVrnGzJkzR7fddpskaebMmQoLC9Ptt98u6fxUoQt/djdnzhyFhYV5bPvuu+/Uo0cPNWrUSBEREbrzzjv10ksvufZfbg3Fpk2b9MADD6h+/fpq1KiRhgwZov3791/yfAcPHtSYMWPUqFEjNWzYUGPHjlVKSsqVPloP7du31zfffKOEhATXtu3bt+vPP/9U+/btLxp/+vRpzZgxQx06dFBERIQaNGigAQMG6Pfff3eN2bJli7p06SJJGjt2rGvq1IX32bt3b7Vv3147duxQz549Va9ePdfn8s81FKNHj1adOnUuev/9+/dX48aNdeLEiRy/VwBA7qGgAGA7X331lcqXL68GDRrkaPz48eM1e/Zs1axZU2PHjlXjxo01f/58jRw58qKxBw8e1KOPPqqbb75ZY8aMUWBgoMaMGaN9+/ZJktq0aaOxY8dKOv+Fe+bMmRo3bpyh+Pft26dBgwYpLS1NI0aM0OjRo3X77bfr559/vuLrvv/+ew0YMEBxcXEaNmyYHnroIW3btk09evTQkSNHLhr/2GOPKSkpSY8//rjatm2rDz/8UHPnzs1xnG3atJHD4dCnn37q2rZ27VpVqVJFNWvWvGj84cOH9fnnn+vWW2/VmDFj1L9/f+3du1e9evVyfbmvWrWqRowYIUnq3r27Zs6cqZkzZ6px48au45w+fVoDBw5UjRo1NG7cODVp0uSS8T399NMKCgrS6NGjlZmZKUlasmSJNm7cqPHjx6tUqVI5fq8AgNzDlCcAtpKYmKgTJ06oVatWORr/+++/a+XKlerataumTJki6fy0qKCgIL311lvavHmzmjZt6hp/4MABvffee2rUqJEkqW3btmrZsqU+/PBDjR49WuHh4QoICNC0adNUs2ZN3XvvvYbfw3fffaf09HS9+eabCgoKyvHrZs6cqcDAQC1dulTFixeXJLVu3VodO3bUnDlzNGPGDI/xNWrU0NSpU13PT58+reXLl+upp57K0fkCAgJ06623au3aterSpYuysrK0bt063X///ZccHxYWpk8++UReXn//FnXvvfeqbdu2Wr58uR555BGFhITolltu0ezZs1W/fv1Lfn4xMTGaNGnSZc9zQbFixfT888+rf//++s9//qP27dtrxowZat26tam8AAByBx0KALaSmJgoSfL398/R+K+//lqS1LdvX4/t/fr189h/QbVq1VzFhCQFBQWpcuXKOnz4sOmY/+nC2osvvvhCWVlZOXrNyZMntXv3bnXs2NFVTEhSeHi4IiMjL3ofki76Qt6oUSOdPn3a9RnmRIcOHfTDDz8oJiZGmzdvVkxMjDp06HDJsU6n01VMZGZm6tSpUypSpIgqV66sXbt25ficTqdTnTp1ytHY5s2bq3v37po3b56GDx+uwoUL67nnnsvxuQAAuY+CAoCtBAQESJKSkpJyNP7o0aPy8vJShQoVPLaHhoaqWLFiOnr0qMf20qVLX3SMwMBAnTlzxmTEF2vXrp0aNGig8ePHKzIyUiNHjtS6deuuWFwcO3ZMklS5cuWL9lWtWlWnTp1ScnKyx/YyZcp4PL9QyBh5Ly1btpS/v7/WrVunNWvWqE6dOqpYseIlx2ZlZentt9/WHXfcoTp16qhp06Zq1qyZ9uzZo7Nnz+b4nKVKlTK0AHv06NEqXry4du/erfHjxys4ODjHrwUA5D6mPAGwlYCAAJUsWdK1piGnHA5HjsZ5e3ubCeuK57gwv/8CX19fvffee9qyZYs2bNigb7/9VuvWrdPSpUv11ltv/asY3LlPPXKXnZ2d42M4nU61adNGq1at0uHDhzVs2LDLjn3jjTf06quvqnPnznr00UcVGBgoLy8vTZ061dA5fX19czxWknbv3q24uDhJ0t69ew29FgCQ++hQALCd2267TYcOHdK2bduuOrZs2bLKysrSwYMHPbbHxsYqISFBZcuWvWZxFStWzOOKSBdc6C648/LyUrNmzTR27FitW7dOI0eO1ObNm7Vly5ZLHvtCt+HAgQMX7YuOjlaJEiVUpEiRf/kOLq1Dhw7atWuXkpKSdPfdd1923CeffKImTZpo6tSpuvvuu9W8eXNFRkZe9JnktLjLieTkZI0dO1bVqlVT9+7dtWDBAm3fvv2aHR8A8O9RUACwnQEDBqhIkSIaP368YmNjL9p/6NAhRUVFSTo/ZUeS6/kFCxcu9Nh/LVSoUEFnz571uEzqyZMn9dlnn3mMO3369EWvvXCDt39eyvaCkiVLqkaNGlq1apXHF/S9e/fqu+++u6bv45+aNGmiRx99VM8884xCQ0MvO87b2/uiTsT69esvunyrn5+fJF2y+DJq1qxZOn78uKZPn64xY8aobNmyGjNmzGU/RwBA3mPKEwDbqVChgmbNmqWRI0eqXbt2rjtlp6Wladu2bfrf//7nWtQbHh6ujh07aunSpUpISFDjxo3122+/aeXKlWrdurXHFZ7+rXbt2mnWrFkaNmyYevfurdTUVC1evFiVK1fWzp07XePmzZunH3/8US1btlTZsmUVFxen999/XzfccIMaNmx42eOPGjVKAwcOVPfu3dWlSxelpqZq0aJFKlq06BWnIv1bXl5eGjp06FXH3XrrrZo3b57Gjh2riIgI7d27V2vWrFH58uU9xlWoUEHFihXTkiVL5O/vryJFiqhu3boXjbuaTZs26f3339ewYcNUq1YtSdK0adPUu3dvvfLKKxo1apSh4wEAcgcFBQBbatWqlT766CP997//1RdffKHFixfL6XQqLCxMY8aMUbdu3Vxjp0yZonLlymnlypX6/PPPFRISokGDBl3zL+ElSpTQ3LlzNX36dL3wwgsqV66cHn/8cR08eNCjoLj99tt19OhRrVixQqdOnVKJEiV00003afjw4SpatOhljx8ZGakFCxZo9uzZmj17tgoVKqTGjRvrqaeeMvxlPDcMHjxYKSkpWrNmjdatW6eaNWtq/vz5evHFFz3G+fj4aPr06XrppZc0ceJEZWRkaNq0aYbeQ2Jiop5++mnVrFlTgwcPdm1v1KiR+vTpo4ULF+qOO+5Q/fr1r9XbAwCY5Mg2spIOAAAAANywhgIAAACAaRQUAAAAAEyjoAAAAABgGgUFAAAAANMoKAAAAACYRkEBAAAAwDQKCgAAAACmXZc3tuu16FerQ8AVbNp2zOoQcBnHvvzY6hBwOf4lrI4AV+BbKdzqEHAZQx5obHUIuIyp7apbHcJl+UVc2xujGpGyba5l5zaLDgUAAAAA067LDgUAAABgmoPf3I3g0wIAAABgGgUFAAAAANOY8gQAAAC4czisjiBfoUMBAAAAwDQ6FAAAAIA7FmUbwqcFAAAAwDQ6FAAAAIA71lAYQocCAAAAgGkUFAAAAABMY8oTAAAA4I5F2YbwaQEAAAAwjQ4FAAAA4I5F2YbQoQAAAABgGgUFAAAAANOY8gQAAAC4Y1G2IXxaAAAAAEyjQwEAAAC4Y1G2IXQoAAAAAJhGhwIAAABwxxoKQ/i0AAAAAJhGQQEAAADANKY8AQAAAO5YlG0IHQoAAAAAptGhAAAAANyxKNsQPi0AAAAAplFQAAAAAPnQ/Pnz1blzZ0VERKhZs2YaOnSooqOjPcb07t1bYWFhHo8JEyZ4jDl27Jgefvhh1atXT82aNdOMGTOUkZGR4ziY8gQAAAC4yyeLsn/44Qf17NlTderUUWZmpl566SX1799fH3/8sYoUKeIa161bN40YMcL13M/Pz/XnzMxMDRo0SCEhIVqyZIlOnjyp0aNHy8fHR48//niO4qCgAAAAAPKh//73vx7Pp0+frmbNmmnnzp1q3Lixa7uvr69CQ0MveYyNGzfqjz/+0MKFCxUSEqIaNWro0Ucf1axZszRs2DA5nc6rxsGUJwAAAMCdw8uyR1pamhITEz0eaWlpOQr77NmzkqTAwECP7WvWrFGTJk3Uvn17vfjii0pJSXHt++WXX1S9enWFhIS4tjVv3lyJiYn6448/cnReOhQAAACATcyfP19z58712DZs2DANHz78iq/LysrS1KlT1aBBA1WvXt21vX379ipTpoxKliypPXv2aNasWTpw4IDrHLGxsR7FhCTX85iYmBzFTEEBAAAAuLPwsrGDBg1S3759PbblZNrRpEmTtG/fPr3//vse27t37+76c1hYmEJDQ/XQQw/p0KFDqlChwjWJmSlPAAAAgE04nU4FBAR4PK5WUDz33HPasGGDoqKidMMNN1xxbL169SRJBw8elHS+GxEbG+sx5sLzy627+CcKCgAAACAfys7O1nPPPafPPvtMUVFRKl++/FVfs3v3bkl/Fwv169fX3r17FRcX5xrz/fffKyAgQNWqVctRHEx5AgAAANx55Y/Lxk6aNElr167Va6+9Jn9/f9eah6JFi8rX11eHDh3SmjVr1LJlSxUvXlx79uzRtGnT1LhxY4WHh0s6vwC7WrVqGjVqlJ566inFxMTolVdeUc+ePXM01UqioAAAAADypcWLF0s6f/M6d9OmTVOnTp3k4+OjTZs26Z133lFycrJKly6tO+64Q0OHDnWN9fb21htvvKGJEyeqe/fu8vPzU8eOHT3uW3E1FBQAAACAOwsXZRuxZ8+eK+4vXbq0Fi1adNXjlC1bVm+++abpOPLHpwUAAADAligoAAAAAJjGlCcAAADAnSN/LMq2CzoUAAAAAEyjQwEAAAC4yyeLsu2CTwsAAACAabYtKDIyMnTs2DGrwwAAAEBB43BY98iHbDvl6Y8//lDHjh1dtwe/noSV9NfdNUNVOaiIShTx0csbDuinIwmXHNv3prJqVT1E7/54VJ/8Huva/vJ9NRQa4Hn3wqXbjmvNzpO5GntB0LhKCQ28tYpqlyumUoG+GrzwJ3224+/PNTjAqdHtw9S8eoiK+floa3S8Jq3cpT9jkz2OE1GxuJ5oW131KgQqM1vafTRBD/1nq85lZOX1W7ouPNnvDt13ez1Vr1RKKefSteXXaD396mrtO+j533yTupU18ZH2alynkjIzs7R971F1GDpPqefSPcY5fQrpm3efVL2wcmrSfZq27z2al2/nuvNkr1t0X8saql4x9Hx+fjusp1//VPsO//3v1idz+umWiMoer3tz1Q8aMWuNJKlOtRv0ZK8WiqxTUcHFi+jg8dNasPoHzftgc56+l+vNyA611L5xed1YuphS0zL1w74YTVy6TX8cPytJKu7v1NjOdXVbndIqF1xEcQnn9PFPhzV1+XYlpPz996ZccBG92PcmNa9RSkmpGVqyMVqTlv6izKxsq97adSFm/w7t/fJDnT6yX6kJ8Wrab5zK1mkmScrKzNDOdYv01+4flRT3l3x8/VWyej3Vbv+g/AKDXcf4fsFknT4arXOJZ+T0Czg/psNDHmOA3GTbguJ6VriQlw6dStU3++P1WMvKlx3XqHwxVQvxV3xy+iX3L//1uL7aF+96nprOF9VroYjTW78fS9DyH47o9b4NLtr/Rt8GysjM1qCFPysxNUP9W1bSO4Nu0p0vfKuUtExJ54uJhQMb6fUvozVp5S5lZGWrRpmiyub/d01r0aCa3lj6jX7aeVCFCnlr0rAOWvv6MEV0mqLk1DRJ54uJ1XOHatbCT/X4jA+UkZmlutXLKusSX3imPnavjsecUb2wcnn9Vq5LLSIq6Y0Pf9BPvx9VIW8vTXq4tda+/KAies1Wcurf/4b996OtmrzgS9dz930RYWUUcypJfScv15GTZ9S0dgXNG3WPMjOz9caHW/L0/VxPImuU1ILP9mpbdJwKeTv0TLf6+nB0KzUdvUbJ5zJVuoSfbijupwnv/6zfj55R+RB/vdT3Jt1Qoogemv2tJMnL4dDSJ2/TidMpunPSp7qhuJ9eH9xM6ZlZmrzsV4vfYf6WmZaq4mUrq1KTNtq8cOo/9p3T6SP7VaNNdwWWray05ET9uvJNfb9gilo98bJrXGi1Ogpr3VW+xYKUeiZO2z96S5vfnq7bHn0hr98OCijLCoqOHTtecX9qamoeRZL3th87q+3Hzl5xTAm/QurTqKxmfBmtJ2+rcskxKelZOpOakRshFmhf/x6rr926Qe4qhRRRg0oldNfMb7XvRKIk6ZkVO7Xl2dvVIaK0lm05Ikl6+t4aitp4UPO/jHa99kBMUu4Hfx27d9hrHs8ffnaRDn85XRE1y+u7n/dLkmY+0UmvLdmgWQs/c437ZwdDku64uaZaNa2hHk8t0F3Na+Vu4AXEvU+84/H84akf6vDasYoIK6Pvfj3o2p6Smq4T8YmXPMY7H//s8fzPY6fUpHZ53duyJgXFv9B15lcez4fO36Q/Xu+i+pWC9f2ek9p95Iwe/P/CQZL+PJmoKR/8qvlDIuXt5VBmVrZur1NaYWWL6b5pXygmIVU7Dp3S1OXbNfH++pq+4jelZ/KDllk31GikG2o0uuQ+Hz9/tRgy2WNb/c6D9NXLTyj51EkVKVFSknTjrfe59vsHlVRYqy7a9NbzysrMkJc3vx2bwqJsQyz7r+yPP/7Q3XffrXLlLv3r4MmTJ/Xnn3/mbVA24ZA0+OYK+nhXjI6eOXfZcR1qldR9dUopLildm/48pfW7Y0TnOXc5C53/B8Z92lJ2tpSWmaVGlUto2ZYjCg5wKqJicX308zF9MLypKgQX0f6TSXpx/V79dOCUVaFfd4oF+EqSTp05P9UstESAbqpbWUvW/6iv3n5clcuFaO+fJzRx7hp9/8vfhV3JoKJ67Zke6vb4m0pOSbMk9oKgmP//5ychxWN79zb1dP8d9XQiPlHrvtujaW9vUMq5S3dhJSnQ3/eiY+DfKVbER5J0Kuny//9SrIiPzqaku6YzNb4xRLsOn1ZMwt8/9n3x2zG91O8mhZcL1G8H+bctr6SnJEsOh3z8Ai65Py3prA7/tEHBlcIpJpBnLPsv7cYbb1TdunX1wAMPXHL/7t279cEHH+RxVPbQvlZJZWVJn+y59K/kkvTpnhj9GZ+ixHOZujHUX93r36Difj567ycWsuem6JNJOhqfoifbVdf45TuUkpapvrdUVunifgotVliSVD6oiCRpxB3VNG3N79p97Kw6NiyjdwffpHYvfHvRWgsY53A49MKTXfT9tv3atf+4JKlyuRBJ0tOD2mnsyyu1fc8R9Wx/k9bNH66GXadq/6EYSdJ/nuulN5dv1M+7DqlC6SDL3sP1zOFw6IUR7fT99oPadeDvDtHSz7br0F+ndTz2rOpULaUpQ+5Q9Qohuv/pxZc8TtPa5dWlVW11fOrdvAr9uudwSNN6NdLm/+9MXEpQQGE9dV8dRX31h2tbyUBfnTzjOXMg5v+flwr002+ioMgLmelp2rH2bZWPuEU+vkU89v225m3t37hWmWnnFFQxTJEDJ1gU5XUiny6OtoplBUWDBg104MCBy+739/dXo0aXbgFezyoF+enO8BCNX7f3iuPW7/672Dh8OlUZWdnq16Sclm47rgzaFLkmIytbQ6N+1rRudbRtShtlZGbp+31x2rD7pBw6/4+P1/93SRdvOqwVW88v9N11NEGRNwary03lNOsqucXVvTK2m2pVK61Wff+eQ+zldf7z/++KjXr3o/OLeH/dc0S33hSmB+9tpglzPtLQHi1VtIivXnjrU0viLiheeby9alUpqVZDF3hsf+ujH11/3hl9Qsfjzup/s/upcpkSOnDM8wtpzcoltWxaTz2/8Ct9sXV/nsRdEMx6sLFqlAtU28mX/jtQ1K+Qlj55q/YcPaPpH27P4+hwJVmZGdoSNUPKzlZE16EX7a9+W0dVatJGyadOavcni/Xjey8rcuAEOfhijDxgWUExfvz4K+6vUKGCnnnmmTyKxj7CSvqrmG8hvdqxpmubt5dDPRuU0V3hoRq56tJXvdofm6RCXg6FBjh1POHybWz8ezuOJKjDS98pwLeQnN5eik9K04oRzfTb///ad/L/P/8/TnjOE99/MkllSvjlebzXm5dHd1W7FrXVuv8rOnrytGv78ZjzV0rbHf2Xx/g9B/5S+RtKSJJubVxdTepW1pktr3iM+e69UVqy/kcNnMAv4f/WyyPvVrvIMLUetkBHYy599boLtu46v+aoarlgj4IivFKo1r3aV2+t+VEzor7O1XgLkpl9GunOiLJqN+UzHYu/eBpZgG8hLX/qdiWmpqvXK18rI/PvH6dOnklVw6qeVwwKDTw/re3EGaak5bYLxUTyqZNqMfT5i7oTklQ4IFCFAwJVtGRZFS1VXusn9VX8wT0KrhRuQcQoaGw3uS4xMVEff/yxPvjgA+3cufO6vGzslXwXfUo7j3t+ER3Vqoq+iz6lb6LjL/MqqWIJP2VlZbNIOw8l/v9nXSmkiOqUD9TL/9snSToSn6K/zqSqSkl/j/GVQv319e6YPI/zevLy6K665/Z6umPgqzp4LM5j38FjcTp28rSqVyrpsb1axZL69LtdkqQnZi7XxHlrXftKhwZq7evD1HvMQm397c9cj/969/LIu3XPLTV1x/D/6uDx01cdX+/G0pKkv+L+vkhFjcoltf7Vvnpv/TZN/M/nuRVqgTOzTyPd3ai8Ojz/uQ5d4gIRRf0Kafmo25WWkaUHXvpa5/5x1cCt+2L1xL21FFKssGL//0eT22qXVkJymvYcvfTUKVwbF4qJxJhjuuWRqSrsX+zqL8o+n7+sjMuvT8JVsCjbENsUFFu3btXy5cv16aefqmTJkmrTpo0mTLg+5/8VLuSlUkX/vodEaIBTFUr4KulcpuKS05X4/5cevSAzK1unU9NdnYdqIUVUNaSIdv+VqJSMLN0YUkQ9G5XRdwdOKfkfr4VxRZzeqhjy968/5YKKqEaZojqdnK7jp1PVtu4Nik9K07FTKQorXVTP3FdDn+04oY17/56G9uZXB/TYndW0+9hZ7T6aoE6Ny6pqSX8Ni9pmxVu6Lrwytpu6t22kriP/o8SkVJUKLipJOpOY6rrHxMtRn2v84Lv1296j+nXPEfXq0ERhlUrpgaf+K0k6/JfntJrE5PN/p6IPx3h0O2DcK0+0V/fWddV17PtKTE5TqaDzC0bPJKYqNS1DlcuUUPc29fTJ5r2KO5OsOlVv0MwRbfXttgPasf+EpPPTnNbP7qvPt/yh2Uu/dx0jMytLsadZe2TWrIcaq0uzSnrg5a+VmJqukv/fWUhITldqeqaK+hXSitGtVMTprUGvf6Oifj4q6nd+4XZswjllZWfry9+Oa8/RBL0xOFITl2xTyUA/Pd2lnhZ8vldp3FvnX8k4l6LE2OOu58lxJ3T6aLScRQLkWyxIm9+ertNH9itywARlZ2UpNeH8v2POIgHyKuSj+IN7FH9on0Kq1JSPX4CS4o5r17r35B9SWkF0J5BHLC0oYmJitHLlSi1fvlyJiYlq27at0tLSNG/ePFWrVs3K0HJVlWA/Pd3m7/fXq1FZSdI3++P1n02Hr/r6jKxsNatYXJ3q3iAfL4diEtP0v92xWs+v39dEnfKBen9oE9fz8ffWkCSt2HpEo5b8ppLFCuvpe8MVHFBYMQnntPKno5r72R8ex3j72z9V2MdL4+8NV6Cfj34/flZ95m/VoTi+FJk1qNstkqTPFjzmsX3ghHe1aM35S4rOfX+DfAv7aOYTnVUisIh+23tU7YfM1YEjl7/AAa6NQR3P/535bG5/j+0Dn/9Qi9ZvU3pGpm5vVEXDujWTv6+PjpxM0KoNOzXdbUpTx9tqqWSJAD1wV309cFd91/aDx08pvOtLefI+rkf9W1eXJH08vo3H9qHzN2nxt9GqWylIjaudv6jBtpfu9RhT97FVOhybpKzsbN0/a4Ne7NtYnzx7p5LPZWjxt9Gaupx1Fv/WqcN/6Jt541zPt68+/wNIxca3q8ZdD+j4jvP/vn0xa4TH6255ZKpCq9WRt09hHdu+Sbv/974y0lLlW6yESoU3VJM23eVdyCfv3sj1hrUnhjiys6251dbgwYO1detW3XrrrerQoYNatGghb29v1apVS6tXr/5XBUWvRdxkx842beNKVHZ17MuPrQ4Bl+NfwuoIcAW+/BJsW0MeaGx1CLiMqe2qWx3CZfm1ffnqg3JJyvqRlp3bLMs6FN9884169+6tHj16qFKlSlaFAQAAAHhiDYUhln1a77//vpKSktSpUyd17dpVixYtUnz85RcdAwAAALAfywqK+vXra8qUKdq4caO6d++ujz/+WLfccouysrL03XffKTEx8eoHAQAAAGApy/s5RYoUUZcuXbR48WJ99NFH6tu3r958801FRkZq8ODBVocHAACAgsbhsO6RD1leULirUqWKRo0apa+//lovvcQVPQAAAAC7s819KNx5e3urdevWat26tdWhAAAAoKBhUbYhfFoAAAAATKOgAAAAAGCaLac8AQAAAJZhypMhfFoAAAAATKNDAQAAALjLp5dvtQodCgAAAACmUVAAAAAAMI0pTwAAAIA7FmUbwqcFAAAAwDQ6FAAAAIA7FmUbQocCAAAAgGl0KAAAAAB3rKEwhE8LAAAAgGkUFAAAAABMY8oTAAAA4I5F2YbQoQAAAABgGh0KAAAAwI2DDoUhdCgAAAAAmEZBAQAAAMA0pjwBAAAAbpjyZAwdCgAAAACm0aEAAAAA3NGgMIQOBQAAAADT6FAAAAAAblhDYQwdCgAAAACmUVAAAAAAMI0pTwAAAIAbpjwZQ4cCAAAAgGl0KAAAAAA3dCiMoUMBAAAAwDQKCgAAAACmMeUJAAAAcMOUJ2PoUAAAAAAwjQ4FAAAA4I4GhSF0KAAAAACYRocCAAAAcMMaCmPoUAAAAAAwjYICAAAAgGlMeQIAAADcMOXJGEd2dna21UFca6kZVkcAAACAK/G18c/aJXq9Z9m5Ty3qadm5zbJxKgEAAIC8R4fCGNZQAAAAADCNggIAAACAaUx5AgAAANww5ckYOhQAAAAATKNDAQAAALijQWEIHQoAAAAAptGhAAAAANywhsIYOhQAAAAATKOgAAAAAGAaU54AAAAAN0x5MoYOBQAAAADT6FAAAAAAbuhQGEOHAgAAAIBpFBQAAAAATGPKEwAAAOCOGU+G0KEAAAAAYBodCgAAAMANi7KNoUMBAAAAwDQ6FAAAAIAbOhTG0KEAAAAAYBoFBQAAAADTmPIEAAAAuGHKkzF0KAAAAACYRocCAAAAcEOHwhg6FAAAAABMo6AAAAAAYBpTngAAAAB3zHgyhA4FAAAAANPoUAAAAABuWJRtDB0KAAAAAKbRoQAAAADc0KEwhg4FAAAAANMoKAAAAACYxpQnAAAAwA1TnoyhQwEAAADANDoUAAAAgDsaFIbQoQAAAABgGgUFAAAAANOY8gQAAAC4YVG2MXQoAAAAAJhGhwIAAABwQ4fCGDoUAAAAQD40f/58de7cWREREWrWrJmGDh2q6OhojzHnzp3TpEmT1KRJE0VERGj48OGKjY31GHPs2DE9/PDDqlevnpo1a6YZM2YoIyMjx3FQUAAAAAD50A8//KCePXtq2bJlWrhwoTIyMtS/f38lJye7xkydOlVfffWVXnnlFb377rs6efKkhg0b5tqfmZmpQYMGKT09XUuWLNH06dO1cuVKzZ49O8dxOLKzs7Ov6TuzgdScF1QAAACwgK+NJ95XenStZef+89X2pl8bHx+vZs2aadGiRWrcuLHOnj2rZs2aadasWbrrrrskSfv371e7du20dOlS1a9fX19//bUGDx6sb7/9ViEhIZKkxYsXa9asWdq0aZOcTudVz2tph+K9997TQw89pEcffVSbNm3y2BcfH69WrVpZFJk9LHn/PbVtc7saR9RRz/u76rft260OCW7Ij32RG/siN/ZGfuyL3BQcaWlpSkxM9HikpaXl6LVnz56VJAUGBkqSduzYofT0dEVGRrrGVK1aVWXKlNEvv/wiSfrll19UvXp1VzEhSc2bN1diYqL++OOPHJ3XsoLinXfe0QsvvKAqVarI6XRq4MCBmj9/vmt/VlaWjh07ZlV4lvvf+nWaNXOaBg19REs+WKmwsHANGdRfcXFxVocGkR87Izf2RW7sjfzYF7nJew6Hw7LH/Pnz1bBhQ4+H+3fky8nKytLUqVPVoEEDVa9eXZIUGxsrHx8fFStWzGNscHCwYmJiXGPciwlJrucXxlyNZQXF0qVLNXnyZE2YMEEvvPCC3nnnHb399tt69dVXrQrJVt6NWqhOXbrpvo6dVbVaNY1/dpJ8fX216sMVVocGkR87Izf2RW7sjfzYF7kpWAYNGqSffvrJ4zFo0KCrvm7SpEnat2+fXn755TyI0pNlBcWRI0cUERHhet6gQQNFRUVp2bJlevHFF60KyxbS09K0e9dONW32d3vKy8tLTZtGavuv2yyMDBL5sTNyY1/kxt7Ij32RG4s4rHs4nU4FBAR4PK62juG5557Thg0bFBUVpRtuuMG1PSQkROnp6UpISPAYHxcXp9DQUNeYf1716cLzC2OuxrKCokSJEvrrr788tlWvXl1RUVH68MMP9cILL1gUmfVOnT6lzMxMBQcHe2wPDg6+KOHIe+THvsiNfZEbeyM/9kVucCXZ2dl67rnn9NlnnykqKkrly5f32F+7dm35+Ph4rFWOjo7WsWPHVL9+fUlS/fr1tXfvXo8pdN9//70CAgJUrVq1HMVhWUHRsGFDffrppxdtr1atmt5++2198803FkQFAAAA5A+TJk3SRx99pBdffFH+/v6KiYlRTEyMUlNTJUlFixZV586dNX36dG3evFk7duzQuHHjFBER4SoomjdvrmrVqmnUqFH6/fff9e233+qVV15Rz549c3SFJ8nCO2UPHDhQO3fuvOS+G2+8Ue+8847mzJmTx1HZQ4niJeTt7X3RYqu4uLiLFs0g75Ef+yI39kVu7I382Be5sUZ+uVP24sWLJUm9e/f22D5t2jR16tRJkjRu3Dh5eXlpxIgRSktLU/PmzfXss8+6xnp7e+uNN97QxIkT1b17d/n5+aljx44aMWJEjuOwrKAIDw9XeHj4RdsTExP18ccf64MPPrhswXG983E6VaNmLW3ZvEm3t2ot6fzK/S1bNun+Hr0sjg7kx77IjX2RG3sjP/ZFbnAle/bsueqYwoUL69lnn/UoIv6pbNmyevPNN03HYZtbimzdulXLly/Xp59+qpIlS6pNmzaaMGGC1WFZpveDffXMuNGqVau2atepq0XvRiklJUX3dexkdWgQ+bEzcmNf5MbeyI99kZu8l186FHZhaUERExOjlStXavny5UpMTFTbtm2VlpamefPm5XgRyPXqrrbtdCo+Xq/Nna3Y2BiFhdfQa/MXKJj2pi2QH/siN/ZFbuyN/NgXuYHdObKzs7OtOPHgwYO1detW3XrrrerQoYNatGghb29v1apVS6tXr/5XBUVqxjUMFAAAANecr23myVys6hPrLTv3/hfbWnZusyxL5TfffKPevXurR48eqlSpklVhAAAAAB6Y8WSMZZeNff/995WUlKROnTqpa9euWrRokeLj460KBwAAAIAJlhUU9evX15QpU7Rx40Z1795dH3/8sW655RZlZWXpu+++U2JiolWhAQAAoABzOByWPfIjy9ZQXEp0dLSWL1+ujz76SAkJCYqMjNQbb7xh+DisoQAAALA3O6+huPGp/1l27n0v3GXZuc2yrENxKVWqVNGoUaP09ddf66WXXrI6HAAAABRADod1j/zIlrWht7e3WrdurdatW1sdCgAAAIArsFWHAgAAAED+YssOBQAAAGCV/Lo42ip0KAAAAACYRocCAAAAcEODwhg6FAAAAABMo6AAAAAAYBpTngAAAAA3Xl7MeTKCDgUAAAAA0+hQAAAAAG5YlG0MHQoAAAAAptGhAAAAANxwYztj6FAAAAAAMI2CAgAAAIBpTHkCAAAA3DDjyRg6FAAAAABMo0MBAAAAuGFRtjF0KAAAAACYRkEBAAAAwDSmPAEAAABumPJkDB0KAAAAAKbRoQAAAADc0KAwhg4FAAAAANPoUAAAAABuWENhDB0KAAAAAKZRUAAAAAAwjSlPAAAAgBtmPBlDhwIAAACAaXQoAAAAADcsyjaGDgUAAAAA0ygoAAAAAJjGlCcAAADADTOejKFDAQAAAMA0OhQAAACAGxZlG0OHAgAAAIBpdCgAAAAANzQojKFDAQAAAMA0CgoAAAAApjHlCQAAAHDDomxj6FAAAAAAMI0OBQAAAOCGBoUxdCgAAAAAmEZBAQAAAMA0pjwBAAAAbliUbQwdCgAAAACm0aEAAAAA3NCgMIYOBQAAAADT6FAAAAAAblhDYQwdCgAAAACmUVAAAAAAMI0pTwAAAIAbZjwZQ4cCAAAAgGl0KAAAAAA3LMo2hg4FAAAAANMoKAAAAACYxpQnAAAAwA1TnoyhQwEAAADANDoUAAAAgBsaFMbQoQAAAABgGgUFAAAAANOY8gQAAAC4YVG2MXQoAAAAAJhGhwIAAABwQ4PCGDoUAAAAAEyjQwEAAAC4YQ2FMXQoAAAAAJhGQQEAAADANKY8AQAAAG6Y8WQMHQoAAAAAptGhAAAAANx40aIwhA4FAAAAANMoKAAAAACYxpQnAAAAwA0znoyhQwEAAADANDoUAAAAgBvulG0MHQoAAAAAptGhAAAAANx40aAwhA4FAAAAANMoKAAAAACYxpQnAAAAwA2Lso2hQwEAAADANDoUAAAAgBsaFMbQoQAAAABgGgUFAAAAANOY8gQAAAC4cYg5T0bQoQAAAABgGh0KAAAAwA13yjbG1h2K5ORkbd261eowLLPk/ffUts3tahxRRz3v76rftm+3OiS4IT/2RW7si9zYG/mxL3IDO7N1QXHo0CH16dPH6jAs8b/16zRr5jQNGvqIlnywUmFh4RoyqL/i4uKsDg0iP3ZGbuyL3Ngb+bEvcpP3HA6HZY/8yNYFRUH2btRCderSTfd17Kyq1app/LOT5Ovrq1UfrrA6NIj82Bm5sS9yY2/kx77IDezO0jUUN9100xX3Z2Zm5lEk9pKelqbdu3aq/8BBrm1eXl5q2jRS23/dZmFkkMiPnZEb+yI39kZ+7IvcID+wtKBIS0tTjx49VL169UvuP3r0qObNm5fHUVnv1OlTyszMVHBwsMf24OBgHTgQbVFUuID82Be5sS9yY2/kx77IjTXy6cwjy1haUISHh+uGG25Qx44dL7n/999/L5AFBQAAAJBfWFpQ3HrrrTp79uxl9wcGBuq+++7Lu4BsokTxEvL29r5osVVcXJxCQkIsigoXkB/7Ijf2RW7sjfzYF7mxhhctCkMsXZQ9ePBgDRs27LL7S5curWnTpuVhRPbg43SqRs1a2rJ5k2tbVlaWtmzZpLr1IiyMDBL5sTNyY1/kxt7Ij32RG+QHtrix3alTp1SiRAlJ0vHjx7Vs2TKlpqaqVatWatSokcXRWaP3g331zLjRqlWrtmrXqatF70YpJSVF93XsZHVoEPmxM3JjX+TG3siPfZEb2J2lBcWePXs0ZMgQHT9+XBUrVtTLL7+sAQMGKDk5WV5eXoqKitLs2bPVunVrK8O0xF1t2+lUfLxemztbsbExCguvodfmL1Aw7U1bID/2RW7si9zYG/mxL3KT95jxZIwjOzs726qTDxgwQIUKFdLAgQO1evVqbdiwQc2bN9eUKVMkSZMnT9bOnTu1bNkyQ8dNzciNaAEAAHCt+NpinsyldX7rJ8vOvaJfQ8vObZalayh+++03PfbYY2rYsKFGjx6tkydP6oEHHpCXl5e8vLzUq1cvRUdzSTQAAADknfxyp+ytW7dq8ODBat68ucLCwvT555977B8zZozCwsI8Hv379/cYc/r0aT3xxBNq0KCBGjVqpHHjxikpKclQHJbWhmfOnFFoaKgkyd/fX35+fgoMDHTtDwwMNPyGAAAAgIIgOTlZYWFh6ty582UvdNSiRQuPixw5nU6P/U8++aRiYmK0cOFCpaena9y4cZowYYJefPHFHMdhebPJaCUGAAAA5Kb88vW0ZcuWatmy5RXHOJ1O1w/4/7R//359++23Wr58uerUqSNJGj9+vB5++GGNGjVKpUqVylEclhcUY8aMcVVKaWlpmjhxovz8/FzPAQAAgIIiLS3tou/ATqfzos5CTv3www9q1qyZihUrpqZNm+qxxx5zXV1127ZtKlasmKuYkKTIyEh5eXlp+/btatOmTY7OYWlB8c87ZN9zzz0XjSmIN7YDAABAwTR//nzNnTvXY9uwYcM0fPhww8dq0aKF2rRpo3Llyunw4cN66aWXNHDgQC1dulTe3t6KjY1VUFCQx2sKFSqkwMBAxcTE5Pg8lhYUBfGmdQAAALA3K++UPWjQIPXt29djm9nuxN133+3684VF2a1bt3Z1La4VS6/yBAAAAOBvTqdTAQEBHg+zBcU/lS9fXiVKlNDBgwclSSEhIYqPj/cYk5GR4XHhpJygoAAAAADcOCx85Ka//vpLp0+fdhULERERSkhI0I4dO1xjNm/erKysLNWtWzfHx7V8UTYAAAAA45KSknTo0CHX8yNHjmj37t0KDAxUYGCg5s6dqzvvvFMhISE6fPiwXnjhBVWsWFEtWrSQJFWtWlUtWrTQM888o0mTJik9PV2TJ0/W3XffneMrPEkW3yk7t3CnbAAAAHuz852y74/aZtm5lzwYkeOxW7ZsUZ8+fS7a3rFjR02cOFGPPPKIdu3apbNnz6pkyZK6+eab9eijjyokJMQ19vTp05o8ebK+/PJLeXl56Y477tD48ePl7++f4zgoKAAAAJDn7FxQ9HjnF8vOvbhPfcvObRZrKAAAAACYZuPaEAAAAMh7XvnkTtl2QYcCAAAAgGl0KAAAAAA3DgtvbJcf0aEAAAAAYBoFBQAAAADTmPIEAAAAuGHGkzF0KAAAAACYRocCAAAAcMOibGPoUAAAAAAwjYICAAAAgGlMeQIAAADccKdsY+hQAAAAADCNDgUAAADghkXZxtChAAAAAGAaHQoAAADADf0JY+hQAAAAADCNggIAAACAaUx5AgAAANx4sSjbEDoUAAAAAEyjQwEAAAC4oUFhDB0KAAAAAKaZKih+/PFHPfnkk+revbtOnDghSVq1apV+/PHHaxocAAAAAHszXFB88skn6t+/v3x9fbVr1y6lpaVJkhITEzV//vxrHiAAAACQlxwOh2WP/MhwQfH6669r0qRJmjJligoV+nsJRoMGDbRr165rGhwAAAAAezO8KPvAgQNq1KjRRduLFi2qhISEaxIUAAAAYJV82iiwjOEORUhIiA4dOnTR9p9++knly5e/JkEBAAAAyB8MFxTdunXT888/r19//VUOh0MnTpzQRx99pBkzZqhHjx65ESMAAAAAmzI85enhhx9WVlaWHnroIaWkpKhXr15yOp3q16+fevfunRsxAgAAAHmGO2Ub48jOzs4288K0tDQdOnRIycnJqlq1qvz9/a91bKalZlgdAQAAAK7E18a3Vx6ywroLDb3euaZl5zbLdCqdTqeqVat2LWMBAAAALEeDwhjDBUXv3r2veI3cd955518FBAAAACD/MFxQ1KhRw+N5RkaGdu/erX379um+++67VnEBAAAAlsivN5iziuGCYty4cZfcPmfOHCUnJ//rgAAAAADkH4YvG3s599xzj1asWHGtDgcAAAAgH7hm6+u3bdsmp9N5rQ4HAAAAWOKa/eJeQBguKIYNG+bxPDs7WzExMdqxY4eGDh16zQIDAAAAYH+GC4qiRYt6PHc4HKpcubJGjBih5s2bX7PAAAAAACuwKNsYQwVFZmamOnXqpOrVqyswMDC3YgIAAACQTxiaIubt7a1+/fopISEht+IBAAAAkI8YnvJ044036siRIypfvnxuxAMAAABYyosZT4YYXsT+2GOPacaMGfrqq6908uRJJSYmejwAAAAAFBw57lDMnTtX/fr108MPPyxJGjJkiMeClezsbDkcDu3evfvaRwkAAADkEToUxuS4oJg3b5569Oihd955JzfjAQAAAJCP5LigyM7OliTddNNNuRYMAAAAYDUuG2uMoTUUfLgAAAAA3Bm6ytOdd9551aLihx9++FcBAQAAAMg/DBUUw4cPv+hO2QAAAMD1hEXZxhgqKO6++24FBwfnViwAAAAA8pkcFxSsnwAAAEBBwNdeY3K8KPvCVZ4AAAAA4IIcdyh+//333IwDAAAAQD5kaA0FAAAAcL3zYs6TIYbuQwEAAAAA7uhQAAAAAG74xd0YPi8AAAAAptGhAAAAANywhMIYOhQAAAAATKOgAAAAAGAaU54AAAAAN1w21hg6FAAAAABMo0MBAAAAuKFBYQwdCgAAAACmUVAAAAAAMI0pTwAAAIAbL6Y8GUKHAgAAAIBpdCgAAAAAN1w21hg6FAAAAABMo0MBAAAAuKFBYQwdCgAAAACmUVAAAAAAMI0pTwAAAIAbLhtrDB0KAAAAAKbRoQAAAADcOESLwgg6FAAAAABMo6AAAAAAYBpTngAAAAA3LMo2hg4FAAAAANPoUAAAAABu6FAYQ4cCAAAAgGl0KAAAAAA3DgctCiPoUNjYkvffU9s2t6txRB31vL+rftu+3eqQ4Ib82Be5sS9yY2/kx77IDezM0oIiPT1dM2fOVJs2bdSlSxctX77cY39sbKxq1KhhUXTW+t/6dZo1c5oGDX1ESz5YqbCwcA0Z1F9xcXFWhwaRHzsjN/ZFbuyN/NgXuYHdWVpQvPHGG1q9erXuv/9+3XzzzZo+fbomTJjgMSY7O9ui6Kz1btRCderSTfd17Kyq1app/LOT5Ovrq1UfrrA6NIj82Bm5sS9yY2/kx77ITd7zclj3yI8sLSjWrFmjKVOmqH///ho5cqRWrFihzZs3a+zYsa5CoiDOYUtPS9PuXTvVtFmka5uXl5eaNo3U9l+3WRgZJPJjZ+TGvsiNvZEf+yI3yA8sLShOnDihG2+80fW8YsWKevfdd/Xzzz/rqaeeUmZmpoXRWefU6VPKzMxUcHCwx/bg4GDFxsZaFBUuID/2RW7si9zYG/mxL3JjDYfDukd+ZGlBERISosOHD3tsK1WqlN555x399ttvGjt2rEWRAQAAAMgJSwuKpk2bas2aNRdtv1BUHDlyxIKorFeieAl5e3tftNgqLi5OISEhFkWFC8iPfZEb+yI39kZ+7IvcID+wtKAYOnSo2rZte8l9pUqV0rvvvqupU6fmcVTW83E6VaNmLW3ZvMm1LSsrS1u2bFLdehEWRgaJ/NgZubEvcmNv5Me+yI01vBwOyx75kaU3titbtqzKli2rU6dOqUSJEpKk48ePa9myZUpNTVWrVq3UsWNHK0O0TO8H++qZcaNVq1Zt1a5TV4vejVJKSoru69jJ6tAg8mNn5Ma+yI29kR/7IjewO0sLij179mjIkCE6fvy4KlasqJdfflkDBgxQcnKyvLy8FBUVpdmzZ6t169ZWhmmJu9q206n4eL02d7ZiY2MUFl5Dr81foGDam7ZAfuyL3NgXubE38mNf5Cbv5dfLt1rFkW3hjR4GDBigQoUKaeDAgVq9erU2bNig5s2ba8qUKZKkyZMna+fOnVq2bJmh46Zm5Ea0AAAAuFZ8Lf1Z+8pmbzxg2blHNK9s2bnNsjSVv/32m6KiohQeHq7w8HAtW7ZMDzzwgLy8zi/t6NWrl7p3725liAAAAChg8ulSBstYuij7zJkzCg0NlST5+/vLz89PgYGBrv2BgYFKSkqyKjwAAAAAV2FpQSEVzDthAwAAANcLy2evjRkzRk6nU5KUlpamiRMnys/Pz/UcAAAAyEte4gdvIywtKP55Sdh77rnnojH33XdfHkUDAAAAwChLC4pp06ZZeXoAAADgIszIN8byNRQAAAAA8i8KCgAAAACmWb4oGwAAALAT7pRtDB0KAAAAAKbRoQAAAADceLEq2xA6FAAAAABMo6AAAAAAYBoFBQAAAODG4bDuYcTWrVs1ePBgNW/eXGFhYfr888899mdnZ+vVV19V8+bNVbduXT300EP6888/PcacPn1aTzzxhBo0aKBGjRpp3LhxSkpKMhQHBQUAAACQDyUnJyssLEzPPvvsJfe/+eabevfddzVx4kQtW7ZMfn5+6t+/v86dO+ca8+STT+qPP/7QwoUL9cYbb+jHH3/UhAkTDMXBomwAAADATX5ZlN2yZUu1bNnykvuys7P1zjvvaMiQIWrdurUkaebMmYqMjNTnn3+uu+++W/v379e3336r5cuXq06dOpKk8ePH6+GHH9aoUaNUqlSpHMVBhwIAAACwibS0NCUmJno80tLSDB/nyJEjiomJUWRkpGtb0aJFVa9ePW3btk2StG3bNhUrVsxVTEhSZGSkvLy8tH379hyfiw4FAAAA4MbKBsX8+fM1d+5cj23Dhg3T8OHDDR0nJiZGkhQcHOyxPTg4WLGxsZKk2NhYBQUFeewvVKiQAgMDXa/PCQoKAAAAwCYGDRqkvn37emxzOp0WRZMzFBQAAACATTidzmtSQISGhkqS4uLiVLJkSdf2uLg4hYeHS5JCQkIUHx/v8bqMjAydOXPG9fqcYA0FAAAA4MbLwse1Uq5cOYWGhmrTpk2ubYmJifr1118VEREhSYqIiFBCQoJ27NjhGrN582ZlZWWpbt26OT4XHQoAAAAgH0pKStKhQ4dcz48cOaLdu3crMDBQZcqUUZ8+ffT666+rYsWKKleunF599VWVLFnSddWnqlWrqkWLFnrmmWc0adIkpaena/Lkybr77rtzfIUnSXJkZ2dnX/N3Z7HUDKsjAAAAwJX42vhn7agfD1t27gcblc/x2C1btqhPnz4Xbe/YsaOmT5+u7OxszZ49W8uWLVNCQoIaNmyoZ599VpUrV3aNPX36tCZPnqwvv/xSXl5euuOOOzR+/Hj5+/vnOA4KCgAAAOQ5CopLM1JQ2AVrKAAAAACYZuPaEAAAAMh7+eM+2fZBhwIAAACAaXQoAAAAADdeVt4qOx+iQwEAAADANDoUAAAAgBv6E8bQoQAAAABgGgUFAAAAANOY8gQAAAC4YU22MXQoAAAAAJhGhwIAAABw46BFYQgdCgAAAACmUVAAAAAAMI0pTwAAAIAbfnE3hs8LAAAAgGl0KAAAAAA3LMo2hg4FAAAAANPoUAAAAABu6E8YQ4cCAAAAgGkUFAAAAABMY8oTAAAA4IZF2cbQoQAAAABgGh0KAAAAwA2/uBvD5wUAAADANAoKAAAAAKYx5QkAAABww6JsY+hQAAAAADCNDgUAAADghv6EMXQoAAAAAJhGhwIAAABwwxIKY+hQAAAAADCNggIAAACAaUx5AgAAANx4sSzbEDoUAAAAAEyjQwEAAAC4YVG2MXQoAAAAAJhGQQEAAADANKY8AQAAAG4cLMo2hA4FAAAAANPoUAAAAABuWJRtDB0KAAAAAKbRoQAAAADccGM7Y+hQAAAAADCNggIAAACAaUx5AgAAANywKNsYOhQAAAAATKNDAQAAALihQ2EMHQoAAAAAplFQAAAAADCNKU8AAACAGwf3oTCEDgUAAAAA0+hQAAAAAG68aFAYQocCAAAAgGl0KAAAAAA3rKEwhg4FAAAAANMoKAAAAACYxpQnAAAAwA13yjaGDgUAAAAA0+hQAAAAAG5YlG0MHQoAAAAAplFQAAAAADCNKU8AAACAG+6UbQwdCgAAAACm0aEAAAAA3LAo2xg6FAAAAABMo6AAAAAAYBpTngAAAAA33CnbGNt2KM6cOaNVq1ZZHYallrz/ntq2uV2NI+qo5/1d9dv27VaHBDfkx77IjX2RG3sjP/ZFbmBnti0ojh8/rrFjx1odhmX+t36dZs2cpkFDH9GSD1YqLCxcQwb1V1xcnNWhQeTHzsiNfZEbeyM/9kVu8p7Dwkd+ZFlBkZiYeNVHQfZu1EJ16tJN93XsrKrVqmn8s5Pk6+urVR+usDo0iPzYGbmxL3Jjb+THvsgN7M6yNRSNGjWS4woT1LKzs6+4/3qWnpam3bt2qv/AQa5tXl5eato0Utt/3WZhZJDIj52RG/siN/ZGfuyL3FjDq4B+BzXLsoLC399fgwcPVr169S65/+DBg5owYUIeR2UPp06fUmZmpoKDgz22BwcH68CBaIuiwgXkx77IjX2RG3sjP/ZFbpAfWFZQ1KxZU5J00003XXJ/sWLFlJ2dnZchAQAAADDIsoKiQ4cOSklJuez+kJAQDRs2LA8jso8SxUvI29v7osVWcXFxCgkJsSgqXEB+7Ivc2Be5sTfyY1/kxhpMeDLGskXZ3bp104MPPnjZ/QW5oPBxOlWjZi1t2bzJtS0rK0tbtmxS3XoRFkYGifzYGbmxL3Jjb+THvsgN8gPLCopNmzapXbt2l7ya09mzZ3X33Xfrxx9/tCAye+j9YF99uHyZPlq1UtH792vKcxOVkpKi+zp2sjo0iPzYGbmxL3Jjb+THvsiNBbhurCGWTXmKiopSt27dFBAQcNG+okWLqnv37lq4cKEaNWpkQXTWu6ttO52Kj9drc2crNjZGYeE19Nr8BQqmvWkL5Me+yI19kRt7Iz/2RW5gd45si1Y+33bbbVqwYIGqVq16yf379+9X//79tWHDBsPHTs34l8EBAAAgV/la9rP21W3ef9qyczetWtyyc5tlWSpjY2NVqNDlT1+oUCHFx8fnYUQAAACA5Mivc48sYtkailKlSmnfvn2X3b9nzx6FhobmYUQAAAAAjLKsoGjZsqVeffVVnTt37qJ9qampmjNnjm677TYLIgMAAEBB5nBY98iPLFtDERsbq44dO8rb21s9e/ZU5cqVJUnR0dF6//33lZmZqZUrV5q6xjJrKAAAAOzNzmsofog+Y9m5b6oSaNm5zbKsoJCko0ePauLEidq4caPrrtgOh0PNmzfXhAkTVL58eVPHpaAAAACwNzsXFFstLCgaU1CYc+bMGR08eFCSVLFiRQUG/rsPkoICAADA3igoLi0/FhS2SGVgYKDq1q1rdRgAAAAADLJFQQEAAADYRj5dHG0Vy67yBAAAACD/o0MBAAAAuOHGdsbQoQAAAABgGgUFAAAAANOY8gQAAAC4ya93rLYKHQoAAAAAptGhAAAAANzQoDCGDgUAAAAA0+hQAAAAAO5oURhChwIAAACAaRQUAAAAAExjyhMAAADghjtlG0OHAgAAAIBpdCgAAAAAN9zYzhg6FAAAAABMo6AAAAAAYBpTngAAAAA3zHgyhg4FAAAAANPoUAAAAADuaFEYQocCAAAAgGkUFAAAAIAbh4X/M2LOnDkKCwvzeNx1112u/efOndOkSZPUpEkTRUREaPjw4YqNjb3WHxdTngAAAID86sYbb9TChQtdz729vV1/njp1qr7++mu98sorKlq0qCZPnqxhw4ZpyZIl1zQGCgoAAAAgn/L29lZoaOhF28+ePasVK1Zo1qxZatasmaTzBUa7du30yy+/qH79+tcsBgoKAAAAwI2Vd8pOS0tTWlqaxzan0ymn03nJ8QcPHlTz5s1VuHBh1a9fX0888YTKlCmjHTt2KD09XZGRka6xVatWVZkyZSgoAAAAgOvV/PnzNXfuXI9tw4YN0/Dhwy8aW7duXU2bNk2VK1dWTEyM5s2bp549e2rNmjWKjY2Vj4+PihUr5vGa4OBgxcTEXNOYKSgAAAAAN1ZeNXbQoEHq27evx7bLdSdatmzp+nN4eLjq1aun2267TevXr5evr2+uxumOqzwBAAAANuF0OhUQEODxuFxB8U/FihVTpUqVdOjQIYWEhCg9PV0JCQkeY+Li4i655uLfoKAAAAAArgNJSUk6fPiwQkNDVbt2bfn4+GjTpk2u/dHR0Tp27Ng1XT8hMeUJAAAA8JRP7pQ9Y8YM3XbbbSpTpoxOnjypOXPmyMvLS+3bt1fRokXVuXNnTZ8+XYGBgQoICNCUKVMUERFBQQEAAABA+uuvv/T444/r9OnTCgoKUsOGDbVs2TIFBQVJksaNGycvLy+NGDFCaWlpat68uZ599tlrHocjOzs7+5of1WKpGVZHAAAAgCvxtfHP2juPJll27lpl/S07t1msoQAAAABgmo1rQwAAACDvWXlju/yIDgUAAAAA0ygoAAAAAJjGlCcAAADADTOejKFDAQAAAMA0OhQAAACAO1oUhtChAAAAAGAaBQUAAAAA05jyBAAAALhxMOfJEDoUAAAAAEyjQwEAAAC44U7ZxtChAAAAAGAaHQoAAADADQ0KY+hQAAAAADCNggIAAACAaUx5AgAAANwx58kQOhQAAAAATKNDAQAAALjhxnbG0KEAAAAAYBoFBQAAAADTmPIEAAAAuOFO2cbQoQAAAABgGh0KAAAAwA0NCmPoUAAAAAAwjYICAAAAgGlMeQIAAADcMefJEDoUAAAAAEyjQwEAAAC44U7ZxtChAAAAAGAaHQoAAADADTe2M4YOBQAAAADTKCgAAAAAmMaUJwAAAMANM56MoUMBAAAAwDQ6FAAAAIA7WhSG0KEAAAAAYBoFBQAAAADTmPIEAAAAuOFO2cbQoQAAAABgGh0KAAAAwA13yjaGDgUAAAAA0+hQAAAAAG5oUBhDhwIAAACAaRQUAAAAAExjyhMAAADghkXZxtChAAAAAGAaHQoAAADAAy0KI+hQAAAAADCNggIAAACAaUx5AgAAANywKNsYOhQAAAAATLO8oMjKyrrs9mPHjuVxNAAAACjoHBY+8iPLCorExEQ9+uijql+/viIjI/Xqq68qMzPTtT8+Pl6tWrWyKjxbWPL+e2rb5nY1jqijnvd31W/bt1sdEtyQH/siN/ZFbuyN/NgXuYGdWVZQvPLKK/r99981c+ZMjRw5UqtXr9bQoUOVlpbmGpOdnW1VeJb73/p1mjVzmgYNfURLPlipsLBwDRnUX3FxcVaHBpEfOyM39kVu7I382Be5yXsOh3WP/MiyguKLL77Qc889p7vuuktdu3bV8uXLFR8fryFDhriKCkd+/VSvgXejFqpTl266r2NnVa1WTeOfnSRfX1+t+nCF1aFB5MfOyI19kRt7Iz/2RW5gd5YVFPHx8SpTpozreVBQkBYuXKikpCQNHDhQKSkpVoVmufS0NO3etVNNm0W6tnl5ealp00ht/3WbhZFBIj92Rm7si9zYG/mxL3KD/MCygqJ06dKKjo722BYQEKD//ve/OnfunIYNG2ZRZNY7dfqUMjMzFRwc7LE9ODhYsbGxFkWFC8iPfZEb+yI39kZ+7IvcWMNh4f/yI8sKiptvvlkrVlzcqvP399eCBQtUuHBhC6ICAAAAYIRlN7YbMWKEYmJiLrkvICBAb731lnbt2pXHUdlDieIl5O3tfdFiq7i4OIWEhFgUFS4gP/ZFbuyL3Ngb+bEvcmOR/NkosIxlHYpdu3ZpxIgRSkxMvGjf2bNn1b179wK7KNvH6VSNmrW0ZfMm17asrCxt2bJJdetFWBgZJPJjZ+TGvsiNvZEf+yI3yA8s61BERUWpW7duCggIuGhf0aJF1b17d7399ttq3LixBdFZr/eDffXMuNGqVau2atepq0XvRiklJUX3dexkdWgQ+bEzcmNf5MbeyI99kRvYnWUFxZ49e/TUU09ddv/NN9+st956Kw8jspe72rbTqfh4vTZ3tmJjYxQWXkOvzV+gYNqbtkB+7Ivc2Be5sTfyY1/kJu8VzDky5jmyLbp7XJ06dbR27VpVrFjxkvsPHjyoDh06aLuJO0GmZvzb6AAAAJCbfC37WfvqTiSkW3buUsV8LDu3WZatoShVqpT27dt32f179uxRaGhoHkYEAAAAcKdsoywrKFq2bKlXX31V586du2hfamqq5syZo9tuu82CyAAAAADklGVTnmJjY9WxY0d5e3urZ8+eqly5siQpOjpa77//vjIzM7Vy5UpTl0RjyhMAAIC92XnKU8xZ675Mhha18QdzGZYVFJJ09OhRTZw4URs3btSFMBwOh5o3b64JEyaofPnypo5LQQEAAGBvFBSXRkFh0pkzZ3Tw4EFJUsWKFRUYGPivjkdBAQAAYG8UFJdGQWETFBQAAAD2ZuuCItHCgiLAxh/MZVi2KBsAAABA/pf/SiAAAAAgF+XTq7dahg4FAAAAANMoKAAAAACYxpQnAAAAwE1+vWO1VehQAAAAADCNDgUAAADgxsGybEPoUAAAAAAwjQ4FAAAA4IY1FMbQoQAAAABgGgUFAAAAANMoKAAAAACYRkEBAAAAwDQWZQMAAABuWJRtDB0KAAAAAKZRUAAAAAAwjSlPAAAAgBvulG0MHQoAAAAAptGhAAAAANywKNsYOhQAAAAATKNDAQAAALihQWEMHQoAAAAAplFQAAAAADCNKU8AAACAO+Y8GUKHAgAAAIBpdCgAAAAAN9zYzhg6FAAAAABMo6AAAAAAYBpTngAAAAA33CnbGDoUAAAAAEyjQwEAAAC4oUFhDB0KAAAAAKZRUAAAAAAwjSlPAAAAgDvmPBlChwIAAACAaXQoAAAAADfcKdsYOhQAAABAPvXee+/p9ttvV506ddS1a1dt3749z2OgoAAAAADcOBzWPYxYt26dpk2bpkceeUQrV65UeHi4+vfvr7i4uNz5YC6DggIAAADIhxYuXKhu3bqpc+fOqlatmiZNmiRfX1+tWLEiT+OgoAAAAABsIi0tTYmJiR6PtLS0S47buXOnIiMjXdu8vLwUGRmpbdu25WXI1+eibN/r8l0BAAAgL1j5XXLOnPmaO3eux7Zhw4Zp+PDhHttOnTqlzMxMBQcHe2wPDg5WdHR0rsfpjq/eAAAAgE0MGjRIffv29djmdDotiiZnKCgAAAAAm3A6nTkqIEqUKCFvb++LFmDHxcUpJCQkt8K7JNZQAAAAAPmM0+lUrVq1tGnTJte2rKwsbdq0SREREXkaCx0KAAAAIB/q27evRo8erdq1a6tu3bqKiopSSkqKOnXqlKdxUFAAAAAA+VC7du0UHx+v2bNnKyYmRjVq1NCCBQvyfMqTIzs7OztPzwgAAADgusEaCgAAAACmUVAAAAAAMI2CAgAAAIBpFBQAAAAATOMqTzaybds2PfDAA2rRooX+85//eOybMmWKfv75Z+3du1dVq1bV6tWrLYqyYLpcbn7//Xf95z//0U8//aRTp06pbNmyuv/++/Xggw9aGG3BMWbMGK1cudL1vHjx4qpdu7aeeuophYeHS5Jef/11ff3119q9e7d8fHz0448/WhVugXK13Bw5ckSvvfaaNm/erNjYWJUsWVL33HOPBg8ebPs7wl4vYmJi9MYbb2jDhg06ceKEgoODVaNGDT344INq1qyZli5dqrVr12rnzp1KSkrS1q1bVaxYMavDLhCulJsaNWpozpw52rhxo44fP66goCC1bt1ajz76qIoWLWp16Cig6FDYyPLly9WrVy9t3bpVJ06cuGh/586d1a5dOwsiw+Vys2PHDgUFBemFF17Qxx9/rMGDB+ull17SokWLLIy2YGnRooU2btyojRs36u2331ahQoU0ePBg1/709HTddddd6tGjh4VRFkxXyk10dLSys7P13HPP6eOPP9bYsWO1ZMkSvfzyyxZHXTAcOXJEnTp10ubNmzVq1CitWbNGCxYsUJMmTTRp0iRJUkpKilq0aOHx9wm572q5OXnypE6ePKnRo0dr7dq1mjZtmr799ls9/fTTVoeOAowOhU0kJSVp3bp1WrFihWJjY7Vy5UqPf8THjx8vSYqPj9eePXusCrNAulJuunTp4jG2fPny+uWXX/Tpp5+qV69eVoRb4DidToWGhkqSQkNDNXDgQPXs2VPx8fEKCgrSiBEjJEkffvihlWEWSFfKzS233KJbbrnFNbZ8+fI6cOCAFi9erNGjR1sVcoExadIkORwOffDBBypSpIhr+4033qjOnTtLkh566CFJ0pYtW6wIscC6Wm6KFSumOXPmuLZXqFBBjz32mJ566illZGSoUCG+2iHv0aGwifXr16tKlSqqUqWK7rnnHq1YsULcIsQejObm7NmzKl68eN4FCJekpCR99NFHqlixIjmwmZzk5uzZswoMDMzbwAqg06dP69tvv1XPnj09vrBewLQm65jNTWJiogICAigmYBn+y7OJ5cuX65577pF0fprA2bNn9cMPP6hJkyYWRwYjufn555+1fv16zZ8/P6/DLLA2bNigiIgISVJycrJCQ0M1f/58eXnxe4nVjOTm4MGDWrRoEd2JPHDo0CFlZ2erSpUqVoeCfzCTm/j4eL322mvq3r17LkYGXBn/j2sD0dHR+u2339S+fXtJUqFChdSuXTstX77c4shgJDd79+7V0KFD9cgjj6h58+Z5HWqB1aRJE61atUqrVq3SBx98oBYtWmjgwIE6evSo1aEVeDnNzYkTJzRgwADddddd6tatm0XRFhx0v+3LaG4SExM1aNAgVa1aVcOGDculqICro0NhA8uXL1dGRoZatGjh2padnS2n06kJEyZw1QYL5TQ3f/zxhx566CF1795dQ4cOtSrcAsnPz08VK1Z0Pa9Vq5YaNWqkZcuWaeTIkRZGhpzk5sSJE+rTp48iIiI0efJkq0ItUCpWrCiHw6Ho6GirQ8E/GMlNYmKiBgwYIH9/f82bN08+Pj55ECFwaXQoLJaRkaHVq1drzJgxrl/yVq1apdWrV6tkyZJau3at1SEWWDnNzb59+9SnTx/dd999fIG1AYfDIYfDoXPnzlkdCv7hn7m5UEzUqlVL06ZNY5paHilevLiaN2+u9957T8nJyRftT0hIsCAqSDnPTWJiovr37y8fHx+9/vrrKly4cF6HCnigQ2GxDRs26MyZM+rSpctFnYg77rhDy5cvV48ePXTw4EElJycrJiZGqamp2r17tySpatWqXLM9l+QkNw0bNtSDDz6o5s2bq2/fvoqJiZEkeXt7KygoyIqwC5y0tDTX556QkKBFixYpOTlZt912myTp2LFjOnPmjI4dO6bMzEzX350KFSrI39/fsrgLgivl5sSJE+rdu7fKlCmj0aNHKz4+3vW6C1eGQu559tln1aNHD3Xt2lUjRoxQWFiYMjMz9d1332nx4sVav369YmJiFBsbq0OHDkk6P63T399fpUuX5qIHuehqufnggw/Ur18/paSk6IUXXlBiYqISExMlSUFBQfL29rb4HaAgcmQzmdJSgwcPVlZW1kU3spOk7du3q2vXrlq9erWef/55/fDDDxeN+eKLL1SuXLm8CLXAyUlu2rRpo88+++yi/WXLltWXX36ZF2EWaP+8eZq/v7+qVKmigQMH6s4777zkmAveeecdLnqQi66Wmw8//FBjx4695Gu5NHbeOHnypOvmaSdPnlRQUJBq1aqlhx56SE2aNNGcOXM0d+7ci143bdo0derUyYKIC44r5UaS+vTpc8nX8Z0AVqGgAAAAAGAaE1YBAAAAmEZBAQAAAMA0CgoAAAAAplFQAAAAADCNggIAAACAaRQUAAAAAEyjoAAAAABgGgUFAAAAANMoKADAZsaMGaOhQ4e6nvfu3VvPP/98nsexZcsWhYWFKSEhIc/PDQDIPwpZHQAA5BdjxozRypUrJUk+Pj4qXbq07r33Xg0ePFiFCuXeP6dz5szJ8fG3bNmiPn36aOvWrSpWrFiuxQQAwAUUFABgQIsWLTRt2jSlpaXp66+/1nPPPScfHx8NGjTIY1xaWpqcTuc1OWfx4sWvyXEAAMgNFBQAYIDT6VRoaKgk6YEHHtDnn3+uL7/8UgcOHFBCQoLq1Kmj9957T06nU19++aWOHz+u6dOn67vvvpOXl5caNmyop59+WuXKlZMkZWZmaubMmVqxYoW8vb3VuXNnZWdne5yzd+/eCg8P19NPPy3pfLHy6quvau3atYqLi1Pp0qX18MMPq1mzZurTp48kqXHjxpKkjh07avr06crKytKbb76ppUuXKjY2VpUqVdLQoUN11113uc7z9ddfa+rUqTp+/Ljq1aunjh075vrnCQDI/ygoAOBfKFy4sE6fPi1J2rRpkwICArRw4UJJUnp6uvr376/69evrvffeU6FChfTaa69pwIAB+uijj+R0OvXWW29p5cqVmjp1qqpWraq33npLn332mZo2bXrZc44aNUq//PKLxo8fr/DwcB05ckSnTp1S6dKlNWfOHA0fPlz/+9//FBAQIF9fX0nS/Pnz9dFHH2nSpEmqVKmStm7dqqeeekpBQUG66aabdPz4cQ0bNkw9e/ZUt27dtGPHDs2YMSPXPz8AQP5HQQEAJmRnZ2vTpk3auHGjevXqpVOnTqlIkSKaMmWKa6rT6tWrlZWVpeeff14Oh0OSNG3aNDVu3Fg//PCDmjdvrqioKD388MO64447JEmTJk3Sxo0bL3veAwcOaP369Vq4cKEiIyMlSeXLl3ftDwwMlCQFBwe71lCkpaVp/vz5WrhwoSIiIlyv+emnn7R06VLddNNNWrx4sSpUqKAxY8ZIkqpUqaK9e/fqzTffvJYfGwDgOkRBAQAGbNiwQREREUpPT1d2drbat2+v4cOH67nnnlP16tU91k38/vvvOnTokBo0aOBxjHPnzunQoUM6e/asYmJiVK9ePde+QoUKqXbt2hdNe7pg9+7d8vb2dk1pyomDBw8qJSVF/fr189ienp6uGjVqSJL279+vunXreuyvX79+js8BACi4KCgAwIAmTZpo4sSJ8vHxUcmSJT2uvuTn5+cxNjk5WbVq1dKsWbMuOk5QUJCp81+YwmREcnKypPPTnkqVKuWx71otHAcAFFwUFABggJ+fnypWrJijsbVq1dL69esVHBysgICAS44JDQ3Vr7/+6uo4ZGRkaOfOnapZs+Ylx1evXl1ZWVnaunWra8qTOx8fH0nnF3tfULVqVTmdTh07dkw33XTTJY9btWpVffnllx7bfv3116u/SQBAgceN7QAgl3To0EElSpTQkCFD9OOPP+rw4cPasmWLpkyZor/++kuS1KdPH7355pv6/PPPtX//fk2aNOmKN5IrV66cOnbsqHHjxunzzz93HXPdunWSpLJly8rhcGjDhg2Kj49XUlKSAgIC1K9fP02bNk0rV67UoUOHtHPnTr377ruu+2rcf//9+vPPPzVjxgxFR0drzZo1rn0AAFwJBQUA5BI/Pz8tWrRIZcqU0bBhw9SuXTs9/fTTOnfunKtj0a9fP91zzz0aPXq07r//fvn7+6tNmzZXPO7EiRN15513auLEiWrbtq2eeeYZpaSkSJJKlSql4cOH68UXX1RkZKQmT54sSXrsscc0dOhQzZ8/X+3atdOAAQO0YcMG1+Vry5Qpozlz5uiLL77QvffeqyVLlmjkyJG5+OkAAK4XjuzLrfwDAAAAgKugQwEAAADANAoKAAAAAKZRUAAAAAAwjYICAAAAgGkUFAAAAABMo6AAAAAAYBoFBQAAAADTKCgAAAAAmEZBAQAAAMA0CgoAAAAAplFQAAAAADDt/wCfMT9im/nAiAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate predictions for the test set\n",
        "final_model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        inputs, labels = batch\n",
        "        inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
        "        labels = labels.to('cuda')\n",
        "        outputs = final_model(**inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "label_names = label_encoder.classes_\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_names, yticklabels=label_names)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZU8JfNLkW3J"
      },
      "outputs": [],
      "source": [
        "# Find indices of incorrect predictions\n",
        "incorrect_indices = [i for i in range(len(all_preds)) if all_preds[i] != all_labels[i]]\n",
        "\n",
        "# Show some examples of erroneous predictions\n",
        "num_examples = 10  # Number of examples to show\n",
        "print(\"Examples of erroneous predictions:\")\n",
        "for i in incorrect_indices[:num_examples]:\n",
        "    print(f\"Sentence: {X_test[i]}\")\n",
        "    print(f\"Predicted: {label_encoder.inverse_transform([all_preds[i]])[0]}\")\n",
        "    print(f\"True: {label_encoder.inverse_transform([all_labels[i]])[0]}\")\n",
        "    print(\"----------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqqVw1Qakabw"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(all_labels, all_preds, target_names=label_names)\n",
        "print(report)\n",
        "\n",
        "# Plot distribution of true labels vs predicted labels\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(all_labels, bins=len(label_names), alpha=0.7, label='True Labels')\n",
        "plt.xticks(ticks=np.arange(len(label_names)), labels=label_names, rotation=90)\n",
        "plt.title('Distribution of True Labels')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(all_preds, bins=len(label_names), alpha=0.7, label='Predicted Labels', color='orange')\n",
        "plt.xticks(ticks=np.arange(len(label_names)), labels=label_names, rotation=90)\n",
        "plt.title('Distribution of Predicted Labels')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pfppq7C2OFyV"
      },
      "source": [
        "Let's try to build a **streamlit application**. It's better to adjust, based on the best model above. (I am not sure if it will work.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfAQPW2rkdV8"
      },
      "outputs": [],
      "source": [
        "pip install streamlit transformers torch sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqJCp9nPkkMa"
      },
      "outputs": [],
      "source": [
        "import streamlit as st\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import CamembertTokenizer, CamembertModel\n",
        "from torch.nn import functional as F\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import joblib  # Use joblib to save and load label encoder\n",
        "\n",
        "# Load the trained model and tokenizer\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes, dropout_rate):\n",
        "        super(Net, self).__init__()\n",
        "        self.camembert = CamembertModel.from_pretrained('camembert-base')\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.fc = nn.Linear(self.camembert.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        outputs = self.camembert(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.fc(pooled_output)\n",
        "        return logits\n",
        "\n",
        "# Load the model\n",
        "model = Net(num_classes=3, dropout_rate=0.25)  # Adjust num_classes as needed\n",
        "# model.load_state_dict(torch.load('path_to_your_model.pth', map_location=torch.device('cpu')))\n",
        "model.eval()\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
        "\n",
        "# Load the label encoder\n",
        "label_encoder = joblib.load('path_to_your_label_encoder.joblib')\n",
        "\n",
        "def predict_difficulty(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=600)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        probabilities = F.softmax(outputs, dim=1)\n",
        "        predicted_class = torch.argmax(probabilities, dim=1).item()\n",
        "        confidence = probabilities[0][predicted_class].item()\n",
        "    return label_encoder.inverse_transform([predicted_class])[0], confidence\n",
        "\n",
        "# Streamlit application\n",
        "st.title(\"Text Difficulty Prediction\")\n",
        "st.write(\"Enter a text and get its predicted difficulty level.\")\n",
        "\n",
        "text_input = st.text_area(\"Enter Text\", \"\")\n",
        "\n",
        "if st.button(\"Predict\"):\n",
        "    if text_input.strip():\n",
        "        predicted_label, confidence = predict_difficulty(text_input)\n",
        "        st.write(f\"**Predicted Difficulty:** {predicted_label}\")\n",
        "        st.write(f\"**Confidence:** {confidence:.2f}\")\n",
        "\n",
        "        st.write(\"### Additional Analysis\")\n",
        "        st.write(\"Here you could add more insights or visualizations based on the model's predictions.\")\n",
        "    else:\n",
        "        st.write(\"Please enter some text to predict its difficulty.\")\n",
        "\n",
        "# Optional: Visualizations\n",
        "st.write(\"### Distribution of Predictions\")\n",
        "# Add your code here to visualize predictions if you have a batch of texts to analyze"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwEJm23ekubV"
      },
      "outputs": [],
      "source": [
        "streamlit run app.py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Starting from scratch\n",
        "\n",
        "Having reached 60%+ accuracy, I decided to spend some time trying to completely change the methodology."
      ],
      "metadata": {
        "id": "MfglFPRBjcCZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a first, I decided to calculate the number of the words in the total corpus, then spreading them between different levels of difficulty. To create a final list of the words, I put two main conditions:\n",
        "1. At least 70% of a specific word belongs to a certain level;\n",
        "2. Removing Top-150 most popular words (usually it is stop words).\n",
        "\n",
        "I was also thinking about lemmatization but decided that it can partially spoil results as the verb can be both in present simple and subjonctif but it will have the same root.\n",
        "\n",
        "*Below the main pieces of the code.*"
      ],
      "metadata": {
        "id": "pXPPGYCdj0xg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import string\n",
        "\n",
        "# Load the dataset\n",
        "data = df_train.copy()\n",
        "\n",
        "# List of French stop words (a small subset for demonstration purposes)\n",
        "french_stop_words = set([\n",
        "    'au', 'aux', 'avec', 'ce', 'ces', 'dans', 'de', 'des', 'du', 'elle', 'en', 'et', 'eux', 'il', 'je', 'la', 'le',\n",
        "    'leur', 'lui', 'ma', 'mais', 'me', 'même', 'mes', 'moi', 'mon', 'ne', 'nos', 'notre', 'nous', 'on', 'ou', 'par',\n",
        "    'pas', 'pour', 'qu', 'que', 'qui', 'sa', 'se', 'ses', 'son', 'sur', 'ta', 'te', 'tes', 'toi', 'ton', 'tu', 'un',\n",
        "    'une', 'vos', 'votre', 'vous', 'c', 'd', 'j', 'l', 'à', 'm', 'n', 's', 't', 'y', 'été', 'étée', 'étées', 'étés',\n",
        "    'étant', 'suis', 'es', 'est', 'sommes', 'êtes', 'sont', 'serai', 'seras', 'sera', 'serons', 'serez', 'seront',\n",
        "    'serais', 'serait', 'serions', 'seriez', 'seraient', 'étais', 'était', 'étions', 'étiez', 'étaient', 'fus', 'fut',\n",
        "    'fûmes', 'fûtes', 'furent', 'sois', 'soit', 'soyons', 'soyez', 'soient', 'fusse', 'fusses', 'fût', 'fussions',\n",
        "    'fussiez', 'fussent', 'ayant', 'ayante', 'ayantes', 'ayants', 'eu', 'eue', 'eues', 'eus', 'ai', 'as', 'avons',\n",
        "    'avez', 'ont', 'aurai', 'auras', 'aura', 'aurons', 'aurez', 'auront', 'aurais', 'aurait', 'aurions', 'auriez',\n",
        "    'auraient', 'avais', 'avait', 'avions', 'aviez', 'avaient', 'eut', 'eûmes', 'eûtes', 'eurent', 'aie', 'aies',\n",
        "    'ait', 'ayons', 'ayez', 'aient', 'eusse', 'eusses', 'eût', 'eussions', 'eussiez', 'eussent'\n",
        "])\n",
        "\n",
        "# Function to preprocess and count word frequency\n",
        "def preprocess_and_count(sentences, stop_words):\n",
        "    word_counts = Counter()\n",
        "\n",
        "    for sentence in sentences:\n",
        "        # Tokenize the sentence\n",
        "        tokens = sentence.split()\n",
        "        # Remove punctuation and stop words, and convert to lower case\n",
        "        filtered_tokens = [\n",
        "            word.lower().strip(string.punctuation)\n",
        "            for word in tokens\n",
        "            if word.lower().strip(string.punctuation) not in stop_words\n",
        "        ]\n",
        "        # Update word counts\n",
        "        word_counts.update(filtered_tokens)\n",
        "\n",
        "    return word_counts\n",
        "\n",
        "# Apply the function to the dataset\n",
        "word_counts_no_stopwords = preprocess_and_count(data['sentence'], french_stop_words)\n",
        "\n",
        "# Convert to a DataFrame for better visualization\n",
        "word_freq_df_no_stopwords = pd.DataFrame(word_counts_no_stopwords.items(), columns=['Word', 'Frequency']).sort_values(by='Frequency', ascending=False)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(word_freq_df_no_stopwords.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3A7I0AnEPkZ",
        "outputId": "d5691022-2cd9-441f-e33f-e6f74f465269"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Word  Frequency\n",
            "0      les       2027\n",
            "140              1051\n",
            "182      a        540\n",
            "195   plus        424\n",
            "24   c'est        299\n",
            "88   comme        288\n",
            "310  cette        269\n",
            "477     si        218\n",
            "331   tout        209\n",
            "512    ils        188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = word_freq_df_no_stopwords.iloc[150:].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "rnQlBxwGj0Or"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "s3gFfhzQM-Rc",
        "outputId": "fc0bd136-6eaf-4a36-e8c8-765ce460e6cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Word  Frequency\n",
              "0  effet         33\n",
              "1  point         33\n",
              "2  livre         32"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e9d0ef79-e26f-400f-ac55-1837df69e636\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Frequency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>effet</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>point</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>livre</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e9d0ef79-e26f-400f-ac55-1837df69e636')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e9d0ef79-e26f-400f-ac55-1837df69e636 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e9d0ef79-e26f-400f-ac55-1837df69e636');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3636b5f5-8735-4d99-b22f-c478ad0260a6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3636b5f5-8735-4d99-b22f-c478ad0260a6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3636b5f5-8735-4d99-b22f-c478ad0260a6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "words",
              "summary": "{\n  \"name\": \"words\",\n  \"rows\": 15525,\n  \"fields\": [\n    {\n      \"column\": \"Word\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15525,\n        \"samples\": [\n          \"instantan\\u00e9ment\",\n          \"vives\",\n          \"h\\u00f4te\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Frequency\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 33,\n        \"num_unique_values\": 33,\n        \"samples\": [\n          2,\n          18,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "\n",
        "words_df = words\n",
        "\n",
        "# Initialize the new columns for levels A1 to C2\n",
        "levels = ['A1', 'A2', 'B1', 'B2', 'C1', 'C2']\n",
        "for level in levels:\n",
        "    words_df[level] = 0\n",
        "\n",
        "# Function to count word occurrences per level\n",
        "def count_words_per_level(sentences, levels, word):\n",
        "    level_counts = {level: 0 for level in levels}\n",
        "\n",
        "    for level, sentence in sentences.itertuples(index=False):\n",
        "        tokens = sentence.split()\n",
        "        filtered_tokens = [w.lower().strip(string.punctuation) for w in tokens]\n",
        "        level_counts[level] += filtered_tokens.count(word.lower())\n",
        "\n",
        "    return level_counts\n",
        "\n",
        "# Apply the counting function to each word in the words_df\n",
        "for index, row in words_df.iterrows():\n",
        "    word = row['Word']\n",
        "    level_counts = count_words_per_level(df_train[['difficulty', 'sentence']], levels, word)\n",
        "    for level in levels:\n",
        "        words_df.at[index, level] = level_counts[level]\n",
        "\n",
        "# Display the updated DataFrame\n",
        "print(words_df.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mU0pjfVORAO",
        "outputId": "93658a3a-f6a4-4c36-82a5-3b5e7eceff95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Word  Frequency  A1  A2  B1  B2  C1  C2\n",
            "0     effet         33   0   1   3   6  11  12\n",
            "1     point         33   0   0   3   3  13  14\n",
            "2     livre         32   5   5   3   9   6   4\n",
            "3      père         32   2   5   6   4   1  14\n",
            "4       cas         32   0   6   5   7   6   8\n",
            "5  nouvelle         32   2  13   5   6   6   0\n",
            "6    milieu         32   0   1   2   6   9  14\n",
            "7      fête         32   3  12   7   8   1   1\n",
            "8    partie         32   3   2   8   7   5   7\n",
            "9       ici         32   7   7   6   1   4   7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Levels\n",
        "levels = ['A1', 'A2', 'B1', 'B2', 'C1', 'C2']\n",
        "\n",
        "# Calculate the total occurrences for each word\n",
        "words_df['Total'] = words_df[levels].sum(axis=1)\n",
        "\n",
        "# Create a new list \"meaningful_words\" with dictionaries\n",
        "meaningful_words = []\n",
        "\n",
        "# Determine the words that belong to a certain level more than 70% of the time\n",
        "threshold = 0.7\n",
        "\n",
        "for index, row in words_df.iterrows():\n",
        "    for level in levels:\n",
        "        if row[level] / row['Total'] > threshold:\n",
        "            meaningful_words.append({'Word': row['Word'], 'Level': level})\n",
        "            break\n",
        "\n",
        "# Convert the list of dictionaries to a DataFrame\n",
        "meaningful_words_df = pd.DataFrame(meaningful_words)\n",
        "\n",
        "# Display the new DataFrame\n",
        "print(meaningful_words_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VLPJeWYU2vz",
        "outputId": "ab649c93-dfa0-4a74-86d9-b924b76d1b6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 Word Level\n",
            "0              j'aime    A1\n",
            "1             déchets    B2\n",
            "2             marquis    C1\n",
            "3               sorte    C2\n",
            "4            ellénore    C2\n",
            "...               ...   ...\n",
            "10965       éternelle    C1\n",
            "10966      inévitable    C1\n",
            "10967  d'arrache-pied    B2\n",
            "10968          gratté    A1\n",
            "10969        étouffée    C2\n",
            "\n",
            "[10970 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although, there are some exceptions for some words (like gratté), mainly it produced interesting results."
      ],
      "metadata": {
        "id": "Xn9OtyyFliyU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of words per level\n",
        "word_counts_per_level = meaningful_words_df['Level'].value_counts()\n",
        "print(word_counts_per_level)"
      ],
      "metadata": {
        "id": "qKfjvm8SUnOg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe10e0fa-80ee-41d9-ffb4-0bcbf73f2549"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Level\n",
            "C2    4297\n",
            "C1    3015\n",
            "B2    2011\n",
            "B1     882\n",
            "A2     470\n",
            "A1     295\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "meaningful_words_df.to_csv('meaningful_words_df.csv', index=False)\n",
        "from google.colab import files\n",
        "files.download('meaningful_words_df.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "idA7q0MWiWVn",
        "outputId": "6cf6f68c-aca4-45ba-c312-f8507a0da4a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_605b5dc7-9e71-40c1-9bd9-fe1b07d34ea2\", \"meaningful_words_df.csv\", 141222)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a next step. I decided to check different quantitative characteristics:\n",
        "1. The average length of the sentence for each difficulty level;\n",
        "2. The average number of words in the sentence for each difficulty level;\n",
        "3. The average number of apostrophes in the sentence for each difficulty level;\n",
        "4. The average number of punctuation marks in the sentence for each difficulty level.\n",
        "\n",
        "In the future this list can be continued and include different words and features of the words/sentences/levels."
      ],
      "metadata": {
        "id": "d7t0E3Xnmt2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = df_train.copy()\n",
        "\n",
        "# Calculate the length of each sentence\n",
        "data['sentence_length'] = data['sentence'].apply(len)\n",
        "\n",
        "# Calculate the average length of the sentence for each difficulty level\n",
        "average_length_by_difficulty = data.groupby('difficulty')['sentence_length'].mean().reset_index()\n",
        "\n",
        "# Display the results\n",
        "import ace_tools as tools; tools.display_dataframe_to_user(name=\"Average Sentence Length by Difficulty\", dataframe=average_length_by_difficulty)\n",
        "\n",
        "average_length_by_difficulty"
      ],
      "metadata": {
        "id": "eEfmXOqonfKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the number of words in each sentence\n",
        "data['word_count'] = data['sentence'].apply(lambda x: len(x.split()))\n",
        "\n",
        "# Calculate the average number of words in the sentence for each difficulty level\n",
        "average_word_count_by_difficulty = data.groupby('difficulty')['word_count'].mean().reset_index()\n",
        "\n",
        "# Display the results\n",
        "tools.display_dataframe_to_user(name=\"Average Word Count by Difficulty\", dataframe=average_word_count_by_difficulty)\n",
        "\n",
        "average_word_count_by_difficulty"
      ],
      "metadata": {
        "id": "k0VoGYLxnf7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the number of apostrophes in each sentence\n",
        "data['apostrophe_count'] = data['sentence'].apply(lambda x: x.count(\"'\"))\n",
        "\n",
        "# Calculate the average number of apostrophes in the sentence for each difficulty level\n",
        "average_apostrophe_count_by_difficulty = data.groupby('difficulty')['apostrophe_count'].mean().reset_index()\n",
        "\n",
        "# Display the results\n",
        "tools.display_dataframe_to_user(name=\"Average Apostrophe Count by Difficulty\", dataframe=average_apostrophe_count_by_difficulty)\n",
        "\n",
        "average_apostrophe_count_by_difficulty"
      ],
      "metadata": {
        "id": "KnPECFUiniYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "# Define the punctuation marks\n",
        "punctuation_marks = string.punctuation\n",
        "\n",
        "# Calculate the number of punctuation marks in each sentence\n",
        "data['punctuation_count'] = data['sentence'].apply(lambda x: sum(1 for char in x if char in punctuation_marks))\n",
        "\n",
        "# Calculate the average number of punctuation marks in the sentence for each difficulty level\n",
        "average_punctuation_count_by_difficulty = data.groupby('difficulty')['punctuation_count'].mean().reset_index()\n",
        "\n",
        "# Display the results\n",
        "tools.display_dataframe_to_user(name=\"Average Punctuation Count by Difficulty\", dataframe=average_punctuation_count_by_difficulty)\n",
        "\n",
        "average_punctuation_count_by_difficulty"
      ],
      "metadata": {
        "id": "uB3ykj52nkfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge the datasets based on the difficulty level\n",
        "combined_data = average_length_by_difficulty.merge(\n",
        "    average_word_count_by_difficulty, on='difficulty').merge(\n",
        "    average_apostrophe_count_by_difficulty, on='difficulty').merge(\n",
        "    average_punctuation_count_by_difficulty, on='difficulty')\n",
        "\n",
        "# Display the combined results\n",
        "tools.display_dataframe_to_user(name=\"Combined Indicators by Difficulty\", dataframe=combined_data)\n",
        "\n",
        "combined_data"
      ],
      "metadata": {
        "id": "gmrVWDoInozL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's time to test some models, based on these characteristics.\n",
        "\n",
        "However, the results were quite modest: around 28-30%, based on the words, and around 42%, adding quantitative characteristics."
      ],
      "metadata": {
        "id": "WeywBE1Fn0_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import re\n",
        "\n",
        "# Load datasets\n",
        "training_data = df_train.copy()\n",
        "indicators_by_difficulty = comb_dif.copy()\n",
        "meaningful_words_df = minif_words.copy()\n",
        "unlabelled_test_data = df_test.copy()\n",
        "\n",
        "# Function to extract features from sentences\n",
        "def extract_features(df):\n",
        "    df['sentence_length'] = df['sentence'].apply(len)\n",
        "    df['word_count'] = df['sentence'].apply(lambda x: len(x.split()))\n",
        "    df['apostrophe_count'] = df['sentence'].apply(lambda x: x.count(\"'\"))\n",
        "    df['punctuation_count'] = df['sentence'].apply(lambda x: len(re.findall(r'[^\\w\\s]', x)))\n",
        "    return df\n",
        "\n",
        "# Extract features for training data\n",
        "training_data = extract_features(training_data)\n",
        "\n",
        "# Map word difficulties to their levels\n",
        "word_difficulty_map = meaningful_words_df.set_index('Word')['Level'].to_dict()\n",
        "\n",
        "def word_difficulty_features(sentence):\n",
        "    words = sentence.split()\n",
        "    levels = [word_difficulty_map.get(word, 'unknown') for word in words]\n",
        "    level_counts = pd.Series(levels).value_counts().to_dict()\n",
        "    return level_counts\n",
        "\n",
        "# Add word difficulty features to training data\n",
        "difficulty_levels = meaningful_words_df['Level'].unique()\n",
        "for level in difficulty_levels:\n",
        "    training_data[level] = training_data['sentence'].apply(lambda x: word_difficulty_features(x).get(level, 0))\n",
        "\n",
        "# Encode target variable\n",
        "difficulty_mapping = {'A1': 1, 'A2': 2, 'B1': 3, 'B2': 4, 'C1': 5, 'C2': 6}\n",
        "training_data['difficulty'] = training_data['difficulty'].map(difficulty_mapping)\n",
        "\n",
        "# Prepare feature set and target variable\n",
        "X = training_data.drop(columns=['id', 'sentence', 'difficulty'])\n",
        "y = training_data['difficulty']\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a RandomForest Classifier\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = clf.predict(X_val)\n",
        "print(classification_report(y_val, y_pred, target_names=difficulty_mapping.keys()))\n",
        "\n",
        "# Extract features for unlabelled test data\n",
        "unlabelled_test_data = extract_features(unlabelled_test_data)\n",
        "for level in difficulty_levels:\n",
        "    unlabelled_test_data[level] = unlabelled_test_data['sentence'].apply(lambda x: word_difficulty_features(x).get(level, 0))\n",
        "\n",
        "# Predict difficulty levels for the unlabelled test data\n",
        "X_test = unlabelled_test_data.drop(columns=['id', 'sentence'])\n",
        "unlabelled_test_data['predicted_difficulty'] = clf.predict(X_test)\n",
        "\n",
        "# Map predicted difficulty levels back to labels\n",
        "inverse_difficulty_mapping = {v: k for k, v in difficulty_mapping.items()}\n",
        "unlabelled_test_data['predicted_difficulty'] = unlabelled_test_data['predicted_difficulty'].map(inverse_difficulty_mapping)\n",
        "\n",
        "# Show a sample of the predictions\n",
        "unlabelled_test_sample = unlabelled_test_data[['id', 'sentence', 'predicted_difficulty']].head()\n",
        "unlabelled_test_sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "ORTlOrzToA8z",
        "outputId": "9dd03c3b-2f7c-44d4-c54c-1aa9d12613c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          A1       0.67      0.73      0.70       166\n",
            "          A2       0.63      0.62      0.63       158\n",
            "          B1       0.79      0.71      0.75       166\n",
            "          B2       0.84      0.88      0.86       153\n",
            "          C1       0.91      0.91      0.91       152\n",
            "          C2       0.94      0.93      0.94       165\n",
            "\n",
            "    accuracy                           0.80       960\n",
            "   macro avg       0.80      0.80      0.80       960\n",
            "weighted avg       0.80      0.80      0.80       960\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                                           sentence predicted_difficulty\n",
              "0   0  Nous dûmes nous excuser des propos que nous eû...                   C2\n",
              "1   1  Vous ne pouvez pas savoir le plaisir que j'ai ...                   A2\n",
              "2   2  Et, paradoxalement, boire froid n'est pas la b...                   B1\n",
              "3   3  Ce n'est pas étonnant, car c'est une saison my...                   B2\n",
              "4   4  Le corps de Golo lui-même, d'une essence aussi...                   C2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5e8cedf8-dda8-4085-9c35-b82c9b44a48e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>predicted_difficulty</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Nous dûmes nous excuser des propos que nous eû...</td>\n",
              "      <td>C2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Vous ne pouvez pas savoir le plaisir que j'ai ...</td>\n",
              "      <td>A2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Et, paradoxalement, boire froid n'est pas la b...</td>\n",
              "      <td>B1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Ce n'est pas étonnant, car c'est une saison my...</td>\n",
              "      <td>B2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Le corps de Golo lui-même, d'une essence aussi...</td>\n",
              "      <td>C2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5e8cedf8-dda8-4085-9c35-b82c9b44a48e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5e8cedf8-dda8-4085-9c35-b82c9b44a48e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5e8cedf8-dda8-4085-9c35-b82c9b44a48e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2e66655e-4346-4b51-ad54-28609e3b92a3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2e66655e-4346-4b51-ad54-28609e3b92a3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2e66655e-4346-4b51-ad54-28609e3b92a3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "unlabelled_test_sample",
              "summary": "{\n  \"name\": \"unlabelled_test_sample\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1,\n          4,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Vous ne pouvez pas savoir le plaisir que j'ai de recevoir cette bonne nouvelle.\",\n          \"Le corps de Golo lui-m\\u00eame, d'une essence aussi surnaturelle que celui de sa monture, s'arrangeait de tout obstacle mat\\u00e9riel, de tout objet g\\u00eanant qu'il rencontrait en le prenant comme ossature et en se le rendant int\\u00e9rieur, f\\u00fbt-ce le bouton de la porte sur lequel s'adaptait aussit\\u00f4t et surnageait invinciblement sa robe rouge ou sa figure p\\u00e2le toujours aussi noble et aussi m\\u00e9lancolique, mais qui ne laissait para\\u00eetre aucun trouble de cette transvert\\u00e9bration.\",\n          \"Et, paradoxalement, boire froid n'est pas la bonne parade.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted_difficulty\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"A2\",\n          \"B2\",\n          \"C2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.metrics import classification_report\n",
        "import torch\n",
        "from transformers import CamembertTokenizer, CamembertForSequenceClassification, Trainer, TrainingArguments\n",
        "from torch.utils.data import Dataset\n",
        "from datasets import Dataset as HFDataset, ClassLabel\n",
        "\n",
        "# Load datasets\n",
        "training_data = df_train.copy()\n",
        "indicators_by_difficulty = comb_dif.copy()\n",
        "meaningful_words_df = minif_words.copy()\n",
        "unlabelled_test_data = df_test.copy()\n",
        "\n",
        "# Define difficulty mapping\n",
        "difficulty_mapping = {'A1': 0, 'A2': 1, 'B1': 2, 'B2': 3, 'C1': 4, 'C2': 5}\n",
        "inverse_difficulty_mapping = {v: k for k, v in difficulty_mapping.items()}\n",
        "\n",
        "# Function to extract features from sentences\n",
        "def extract_features(df):\n",
        "    df['sentence_length'] = df['sentence'].apply(len)\n",
        "    df['word_count'] = df['sentence'].apply(lambda x: len(x.split()))\n",
        "    df['apostrophe_count'] = df['sentence'].apply(lambda x: x.count(\"'\"))\n",
        "    df['punctuation_count'] = df['sentence'].apply(lambda x: len(re.findall(r'[^\\w\\s]', x)))\n",
        "    return df\n",
        "\n",
        "# Extract features for training data\n",
        "training_data = extract_features(training_data)\n",
        "\n",
        "# Map word difficulties to their levels\n",
        "word_difficulty_map = meaningful_words_df.set_index('Word')['Level'].to_dict()\n",
        "\n",
        "def word_difficulty_features(sentence):\n",
        "    words = sentence.split()\n",
        "    levels = [word_difficulty_map.get(word, 'unknown') for word in words]\n",
        "    level_counts = pd.Series(levels).value_counts().to_dict()\n",
        "    return level_counts\n",
        "\n",
        "# Add word difficulty features to training data\n",
        "difficulty_levels = meaningful_words_df['Level'].unique()\n",
        "for level in difficulty_levels:\n",
        "    training_data[level] = training_data['sentence'].apply(lambda x: word_difficulty_features(x).get(level, 0))\n",
        "\n",
        "# Encode target variable\n",
        "training_data['difficulty'] = training_data['difficulty'].map(difficulty_mapping)\n",
        "\n",
        "# Convert data to Hugging Face Dataset\n",
        "dataset = HFDataset.from_pandas(training_data[['sentence', 'difficulty']])\n",
        "\n",
        "# Convert difficulty back to string\n",
        "dataset = dataset.map(lambda example: {'difficulty': inverse_difficulty_mapping[example['difficulty']]})\n",
        "\n",
        "# Convert difficulty to ClassLabel\n",
        "class_label = ClassLabel(num_classes=len(difficulty_mapping), names=list(difficulty_mapping.keys()))\n",
        "dataset = dataset.map(lambda example: {'label': class_label.str2int(example['difficulty'])})\n",
        "dataset = dataset.remove_columns(['difficulty'])\n",
        "dataset = dataset.rename_column('label', 'labels')\n",
        "\n",
        "# Split dataset\n",
        "dataset = dataset.train_test_split(test_size=0.1)\n",
        "\n",
        "# Tokenize data\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['sentence'], padding='max_length', truncation=True)\n",
        "\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "tokenized_datasets = tokenized_datasets.remove_columns(['sentence'])\n",
        "tokenized_datasets.set_format('torch')\n",
        "\n",
        "# Load model\n",
        "model = CamembertForSequenceClassification.from_pretrained('camembert-base', num_labels=len(difficulty_mapping))\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    evaluation_strategy='epoch',\n",
        "    learning_rate=1.75e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=5,\n",
        "    #weight_decay=0.01,\n",
        ")\n",
        "\n",
        "# Define trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['test'],\n",
        ")\n",
        "\n",
        "# Train model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate model\n",
        "predictions = trainer.predict(tokenized_datasets['test'])\n",
        "preds = np.argmax(predictions.predictions, axis=1)\n",
        "print(classification_report(tokenized_datasets['test']['labels'], preds, target_names=[inverse_difficulty_mapping[i] for i in range(len(difficulty_mapping))]))\n",
        "\n",
        "# Process unlabelled test data\n",
        "unlabelled_test_data = extract_features(unlabelled_test_data)\n",
        "for level in difficulty_levels:\n",
        "    unlabelled_test_data[level] = unlabelled_test_data['sentence'].apply(lambda x: word_difficulty_features(x).get(level, 0))\n",
        "\n",
        "# Tokenize unlabelled test data\n",
        "unlabelled_dataset = HFDataset.from_pandas(unlabelled_test_data)\n",
        "unlabelled_tokenized_dataset = unlabelled_dataset.map(tokenize_function, batched=True)\n",
        "unlabelled_tokenized_dataset = unlabelled_tokenized_dataset.remove_columns(['sentence'])\n",
        "unlabelled_tokenized_dataset.set_format('torch')\n",
        "\n",
        "# Predict difficulty levels for the unlabelled test data\n",
        "test_predictions = trainer.predict(unlabelled_tokenized_dataset)\n",
        "test_preds = np.argmax(test_predictions.predictions, axis=1)\n",
        "unlabelled_test_data['predicted_difficulty'] = [inverse_difficulty_mapping[i] for i in test_preds]\n",
        "\n",
        "# Show a sample of the predictions\n",
        "unlabelled_test_sample = unlabelled_test_data[['id', 'sentence', 'predicted_difficulty']].head()\n",
        "unlabelled_test_sample\n",
        "\n",
        "submission2 = unlabelled_test_data[['id', 'predicted_difficulty']]\n",
        "submission2.to_csv('know_how2.csv', index=False)\n",
        "from google.colab import files\n",
        "files.download('know_how2.csv')"
      ],
      "metadata": {
        "id": "00-65f-Xo4PD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After this fail, I tried to add the camembert - the result became better (52-53%), but still not good enough."
      ],
      "metadata": {
        "id": "iAuYCulApBWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.metrics import classification_report\n",
        "import torch\n",
        "from transformers import CamembertTokenizer, CamembertForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback\n",
        "from torch.utils.data import Dataset\n",
        "from datasets import Dataset as HFDataset, ClassLabel\n",
        "\n",
        "# Load datasets\n",
        "training_data = df_train.copy()\n",
        "indicators_by_difficulty = comb_dif.copy()\n",
        "meaningful_words_df = minif_words.copy()\n",
        "unlabelled_test_data = df_test.copy()\n",
        "\n",
        "# Define difficulty mapping\n",
        "difficulty_mapping = {'A1': 0, 'A2': 1, 'B1': 2, 'B2': 3, 'C1': 4, 'C2': 5}\n",
        "inverse_difficulty_mapping = {v: k for k, v in difficulty_mapping.items()}\n",
        "\n",
        "# Function to extract features from sentences\n",
        "def extract_features(df):\n",
        "    df['sentence_length'] = df['sentence'].apply(len)\n",
        "    df['word_count'] = df['sentence'].apply(lambda x: len(x.split()))\n",
        "    df['apostrophe_count'] = df['sentence'].apply(lambda x: x.count(\"'\"))\n",
        "    df['punctuation_count'] = df['sentence'].apply(lambda x: len(re.findall(r'[^\\w\\s]', x)))\n",
        "    return df\n",
        "\n",
        "# Extract features for training data\n",
        "training_data = extract_features(training_data)\n",
        "\n",
        "# Map word difficulties to their levels\n",
        "word_difficulty_map = meaningful_words_df.set_index('Word')['Level'].to_dict()\n",
        "\n",
        "def word_difficulty_features(sentence):\n",
        "    words = sentence.split()\n",
        "    levels = [word_difficulty_map.get(word, 'unknown') for word in words]\n",
        "    level_counts = pd.Series(levels).value_counts().to_dict()\n",
        "    return level_counts\n",
        "\n",
        "# Add word difficulty features to training data\n",
        "difficulty_levels = meaningful_words_df['Level'].unique()\n",
        "for level in difficulty_levels:\n",
        "    training_data[level] = training_data['sentence'].apply(lambda x: word_difficulty_features(x).get(level, 0))\n",
        "\n",
        "# Encode target variable\n",
        "training_data['difficulty'] = training_data['difficulty'].map(difficulty_mapping)\n",
        "\n",
        "# Convert data to Hugging Face Dataset\n",
        "dataset = HFDataset.from_pandas(training_data[['sentence', 'difficulty']])\n",
        "\n",
        "# Convert difficulty back to string\n",
        "dataset = dataset.map(lambda example: {'difficulty': inverse_difficulty_mapping[example['difficulty']]})\n",
        "\n",
        "# Convert difficulty to ClassLabel\n",
        "class_label = ClassLabel(num_classes=len(difficulty_mapping), names=list(difficulty_mapping.keys()))\n",
        "dataset = dataset.map(lambda example: {'label': class_label.str2int(example['difficulty'])})\n",
        "dataset = dataset.remove_columns(['difficulty'])\n",
        "dataset = dataset.rename_column('label', 'labels')\n",
        "\n",
        "# Split dataset\n",
        "dataset = dataset.train_test_split(test_size=0.1)\n",
        "\n",
        "# Tokenize data\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['sentence'], padding='max_length', truncation=True)\n",
        "\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "tokenized_datasets = tokenized_datasets.remove_columns(['sentence'])\n",
        "tokenized_datasets.set_format('torch')\n",
        "\n",
        "# Load model\n",
        "model = CamembertForSequenceClassification.from_pretrained('camembert-base', num_labels=len(difficulty_mapping))\n",
        "\n",
        "# Define training arguments with early stopping\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    evaluation_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    learning_rate=1.75e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=10,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='eval_loss',\n",
        "    greater_is_better=False,\n",
        ")\n",
        "\n",
        "# Define early stopping callback\n",
        "early_stopping_callback = EarlyStoppingCallback(early_stopping_patience=1)\n",
        "\n",
        "# Define trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['test'],\n",
        "    callbacks=[early_stopping_callback]\n",
        ")\n",
        "\n",
        "# Train model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate model\n",
        "predictions = trainer.predict(tokenized_datasets['test'])\n",
        "preds = np.argmax(predictions.predictions, axis=1)\n",
        "print(classification_report(tokenized_datasets['test']['labels'], preds, target_names=[inverse_difficulty_mapping[i] for i in range(len(difficulty_mapping))]))\n",
        "\n",
        "# Process unlabelled test data\n",
        "unlabelled_test_data = extract_features(unlabelled_test_data)\n",
        "for level in difficulty_levels:\n",
        "    unlabelled_test_data[level] = unlabelled_test_data['sentence'].apply(lambda x: word_difficulty_features(x).get(level, 0))\n",
        "\n",
        "# Tokenize unlabelled test data\n",
        "unlabelled_dataset = HFDataset.from_pandas(unlabelled_test_data)\n",
        "unlabelled_tokenized_dataset = unlabelled_dataset.map(tokenize_function, batched=True)\n",
        "unlabelled_tokenized_dataset = unlabelled_tokenized_dataset.remove_columns(['sentence'])\n",
        "unlabelled_tokenized_dataset.set_format('torch')\n",
        "\n",
        "# Predict difficulty levels for the unlabelled test data\n",
        "test_predictions = trainer.predict(unlabelled_tokenized_dataset)\n",
        "test_preds = np.argmax(test_predictions.predictions, axis=1)\n",
        "unlabelled_test_data['predicted_difficulty'] = [inverse_difficulty_mapping[i] for i in test_preds]\n",
        "\n",
        "# Show a sample of the predictions\n",
        "unlabelled_test_sample = unlabelled_test_data[['id', 'sentence', 'predicted_difficulty']].head()\n",
        "unlabelled_test_sample"
      ],
      "metadata": {
        "id": "0dl6dGyvrJph",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850,
          "referenced_widgets": [
            "1b6bb1a3c80345a8999d9ef2033d8753",
            "a4299f8e63dd4a7ab23b02210bd6c732",
            "6ca122a1bd004ce28befbeddbaf16269",
            "4479b84206b2488383dfb9560c6e9152",
            "610a7b3bf9754d99908266ca012b14eb",
            "b267a88ebcaf425b8805621cd03e547d",
            "c3bd23b6d23a4b2e968b28185744da12",
            "95b9bf99076b4fc88470f2c2fd902d05",
            "9b5a96f99ca74466ac763d510ca7c28b",
            "d7413cced8c24619be2d673557f7c228",
            "72f17258944641d2bbbbe28afd691673",
            "77b19f2c5e8e40d1972367b82ca833da",
            "b060e6c408074705ba3db3a2b5593d8d",
            "105b0ef6bb4b4cadacd6e5323dab6c4b",
            "086219d27cd840c3a4e107129a2ff333",
            "4463e7d34206410ca8322a4335c3a2a9",
            "eab63a08a0c94fa0accb6990dea734f3",
            "af1015d756b644a5a9f8f1ea4fa35704",
            "f9810cc0a4144173beabaf1941e95711",
            "e16a36d491a24ef7829d36dcdcf433c8",
            "ecc370c31dd741c08b29c6ed170d1539",
            "05c3872e52f54704bb01e56596283918",
            "b3cb1b6f24ab42fab5e5ab33cd19fcb3",
            "2dbd2db9fc854317ad9a04d7de15f845",
            "409f78447ab74455a63a10a4b2f4d222",
            "0a1ea39e530b400197e0b7de8f6988d9",
            "1ad77fc99b7a4d898936276c0bba210b",
            "d9b87f643ec5465d8b793c603b81b871",
            "243ba28adf6d470d8079d953dc150ca0",
            "5ad1eb75cd934edab7bb3f3c2215a027",
            "32df99e4c65b4f7d9ddb79b945c29051",
            "f69282b8538348839ee1bfb41328268c",
            "fdf50fbf89534ff1ae0a0cae031407e0",
            "c5140cc200064d108030ae0c50386bf7",
            "ca8eaf002f8a47cab48f1d707e5a24e0",
            "ddaa4542209a4f5684393b7b2b46e749",
            "6f46c3263bf744e0bdc590fb07659fa5",
            "45b24245e2e0401da8b6469f6191c68d",
            "e52f02b2045849c18c26ca49df7c3fa8",
            "3b01c3cefac34aef992d29f5672b1159",
            "e77f21aa4fb943759632eab857a6abe1",
            "29e9600d9e1742bfa6012dcfd6b69341",
            "89c6e5d7406d4bd5a56910704ddea311",
            "5eeb876700e946eb813df30f9ef5c685",
            "6d76717556ea4ef5b69edc20e6bd5dc5",
            "46298e6f58424c68b236e6a6c4ff3943",
            "8e51fc8db16149538093872a4e42ea38",
            "c16e0ec19eb44e6cb867f39702876a78",
            "748024d08cb840cb9598f1d77ae89e70",
            "88c60584478f4074a12141c17903246d",
            "56557fba37a54c59bfdd8042f0b7cfc2",
            "235d12b308a04b16adfed3818ed7158a",
            "91908ad836104f91aa9c3ac5f7512ab7",
            "57ac53e51a5549dc94ac9ef3920d5894",
            "c107cadc48bc457683006ec88cb057e2"
          ]
        },
        "outputId": "ef7ec59b-fe53-4198-a034-f8fc9d2d6d15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/4800 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b6bb1a3c80345a8999d9ef2033d8753"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/4800 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "77b19f2c5e8e40d1972367b82ca833da"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/4320 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b3cb1b6f24ab42fab5e5ab33cd19fcb3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c5140cc200064d108030ae0c50386bf7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1620' max='5400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1620/5400 11:38 < 27:12, 2.32 it/s, Epoch 3/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.411700</td>\n",
              "      <td>1.256848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.043900</td>\n",
              "      <td>1.137318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.853300</td>\n",
              "      <td>1.271539</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          A1       0.64      0.74      0.69        73\n",
            "          A2       0.49      0.60      0.54        78\n",
            "          B1       0.58      0.39      0.47        94\n",
            "          B2       0.40      0.60      0.48        72\n",
            "          C1       0.45      0.23      0.30        92\n",
            "          C2       0.57      0.65      0.61        71\n",
            "\n",
            "    accuracy                           0.52       480\n",
            "   macro avg       0.52      0.53      0.51       480\n",
            "weighted avg       0.52      0.52      0.50       480\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1200 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d76717556ea4ef5b69edc20e6bd5dc5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                                           sentence predicted_difficulty\n",
              "0   0  Nous dûmes nous excuser des propos que nous eû...                   C2\n",
              "1   1  Vous ne pouvez pas savoir le plaisir que j'ai ...                   A2\n",
              "2   2  Et, paradoxalement, boire froid n'est pas la b...                   B1\n",
              "3   3  Ce n'est pas étonnant, car c'est une saison my...                   A2\n",
              "4   4  Le corps de Golo lui-même, d'une essence aussi...                   C2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-301939da-5f5b-453e-8550-dad50ec8e29c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>predicted_difficulty</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Nous dûmes nous excuser des propos que nous eû...</td>\n",
              "      <td>C2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Vous ne pouvez pas savoir le plaisir que j'ai ...</td>\n",
              "      <td>A2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Et, paradoxalement, boire froid n'est pas la b...</td>\n",
              "      <td>B1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Ce n'est pas étonnant, car c'est une saison my...</td>\n",
              "      <td>A2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Le corps de Golo lui-même, d'une essence aussi...</td>\n",
              "      <td>C2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-301939da-5f5b-453e-8550-dad50ec8e29c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-301939da-5f5b-453e-8550-dad50ec8e29c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-301939da-5f5b-453e-8550-dad50ec8e29c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3865ec3c-8796-46a8-b39c-0cff3a338ae0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3865ec3c-8796-46a8-b39c-0cff3a338ae0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3865ec3c-8796-46a8-b39c-0cff3a338ae0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "unlabelled_test_sample",
              "summary": "{\n  \"name\": \"unlabelled_test_sample\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1,\n          4,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Vous ne pouvez pas savoir le plaisir que j'ai de recevoir cette bonne nouvelle.\",\n          \"Le corps de Golo lui-m\\u00eame, d'une essence aussi surnaturelle que celui de sa monture, s'arrangeait de tout obstacle mat\\u00e9riel, de tout objet g\\u00eanant qu'il rencontrait en le prenant comme ossature et en se le rendant int\\u00e9rieur, f\\u00fbt-ce le bouton de la porte sur lequel s'adaptait aussit\\u00f4t et surnageait invinciblement sa robe rouge ou sa figure p\\u00e2le toujours aussi noble et aussi m\\u00e9lancolique, mais qui ne laissait para\\u00eetre aucun trouble de cette transvert\\u00e9bration.\",\n          \"Et, paradoxalement, boire froid n'est pas la bonne parade.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted_difficulty\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"C2\",\n          \"A2\",\n          \"B1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission2 = unlabelled_test_data[['id', 'predicted_difficulty']]\n",
        "submission2.to_csv('know_how2_b8.csv', index=False)\n",
        "from google.colab import files\n",
        "files.download('know_how2_b8.csv')"
      ],
      "metadata": {
        "id": "nrYhFSmoo4a3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FCDxtr9X8tq"
      },
      "source": [
        "# Appendix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKlT2Bq7YBfI"
      },
      "source": [
        "## Appendix - Full Bert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AqDDOoDYHg_"
      },
      "source": [
        "**Model 1.** Accuracy: 0.562\n",
        "\n",
        "Key parameters:\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=6,\n",
        "    per_device_eval_batch_size=12,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568,
          "referenced_widgets": [
            "54950539d41c43bc95edad341ec518bb",
            "d723ab718844430a9831cbb894e82651",
            "d73320f9e8a54cf5809d476654fc433b",
            "8ad049105cff4df0827de0e80025f559",
            "7f96f5ef71b14c848900943d3cef587e"
          ]
        },
        "id": "mYkll4l1W_86",
        "outputId": "82f4ee17-ef45-416c-9058-e6cb99603f18"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "54950539d41c43bc95edad341ec518bb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d723ab718844430a9831cbb894e82651",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d73320f9e8a54cf5809d476654fc433b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ad049105cff4df0827de0e80025f559",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7f96f5ef71b14c848900943d3cef587e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3200' max='3200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3200/3200 07:27, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.267100</td>\n",
              "      <td>1.374169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.070300</td>\n",
              "      <td>1.230954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.711700</td>\n",
              "      <td>1.169585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.464900</td>\n",
              "      <td>1.659990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.033800</td>\n",
              "      <td>2.051420</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.5645833333333333\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# Load data\n",
        "training_data = df_train\n",
        "test_data = df_test\n",
        "\n",
        "# Initialize tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "\n",
        "# Tokenization and dataset preparation\n",
        "class FrenchTextDataset(Dataset):\n",
        "    def __init__(self, texts, labels=None, max_length=128):\n",
        "        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=max_length)\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.labels:\n",
        "            item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)\n",
        "\n",
        "# Encoding the labels\n",
        "label_dict = {label: i for i, label in enumerate(training_data['difficulty'].unique())}\n",
        "training_data['encoded_labels'] = training_data['difficulty'].map(label_dict)\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    training_data['sentence'],\n",
        "    training_data['encoded_labels'],\n",
        "    test_size=0.2\n",
        ")\n",
        "\n",
        "# Prepare datasets\n",
        "train_dataset = FrenchTextDataset(train_texts.tolist(), train_labels.tolist())\n",
        "val_dataset = FrenchTextDataset(val_texts.tolist(), val_labels.tolist())\n",
        "\n",
        "# Load pretrained BERT model\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=len(label_dict))\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=6,\n",
        "    per_device_eval_batch_size=12,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\"\n",
        ")\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Prediction on validation data for evaluation\n",
        "outputs = trainer.predict(val_dataset)\n",
        "val_preds = np.argmax(outputs.predictions, axis=-1)\n",
        "val_accuracy = accuracy_score(val_labels, val_preds)\n",
        "print(\"Validation Accuracy:\", val_accuracy)\n",
        "\n",
        "# Prepare test data and predict\n",
        "test_dataset = FrenchTextDataset(test_data['sentence'].tolist())\n",
        "test_outputs = trainer.predict(test_dataset)\n",
        "test_preds = np.argmax(test_outputs.predictions, axis=-1)\n",
        "\n",
        "# Convert numeric predictions back to labels\n",
        "inv_label_dict = {v: k for k, v in label_dict.items()}\n",
        "test_difficulties = [inv_label_dict[pred] for pred in test_preds]\n",
        "\n",
        "# Prepare the submission file\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_data['id'],\n",
        "    'difficulty': test_difficulties\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMJSCWCcTNyT"
      },
      "outputs": [],
      "source": [
        "submission.to_csv('sample_B.csv', index=False)\n",
        "from google.colab import files\n",
        "files.download('sample_B.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBgPCh0TYhOF"
      },
      "source": [
        "**Model 2**\n",
        "\n",
        "Key parameters:\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=6,\n",
        "    per_device_eval_batch_size=12,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.001,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568,
          "referenced_widgets": [
            "5dd747fdeffe4d5d8e27176ad1482726",
            "b5de94ee25294ae3bfdba4588db6653d",
            "9566328126dc4283a752f7e8d619a1b2",
            "bcea35890bcf4ed7915e9d8a43ffa4c9",
            "5735185234c1488d8bcd10f1956208d6"
          ]
        },
        "id": "TE_qxYAfEHsc",
        "outputId": "ddd3cff7-ae63-4988-e690-d27c3f02324a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5dd747fdeffe4d5d8e27176ad1482726",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b5de94ee25294ae3bfdba4588db6653d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9566328126dc4283a752f7e8d619a1b2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bcea35890bcf4ed7915e9d8a43ffa4c9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5735185234c1488d8bcd10f1956208d6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3200' max='3200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3200/3200 07:23, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.313300</td>\n",
              "      <td>1.238763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.000600</td>\n",
              "      <td>1.176991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.947300</td>\n",
              "      <td>1.135223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.493400</td>\n",
              "      <td>1.289233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.486400</td>\n",
              "      <td>1.745724</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.5447916666666667\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# Load data\n",
        "training_data = df_train\n",
        "test_data = df_test\n",
        "\n",
        "# Initialize tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "\n",
        "# Tokenization and dataset preparation\n",
        "class FrenchTextDataset(Dataset):\n",
        "    def __init__(self, texts, labels=None, max_length=128):\n",
        "        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=max_length)\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.labels:\n",
        "            item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)\n",
        "\n",
        "# Encoding the labels\n",
        "label_dict = {label: i for i, label in enumerate(training_data['difficulty'].unique())}\n",
        "training_data['encoded_labels'] = training_data['difficulty'].map(label_dict)\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    training_data['sentence'],\n",
        "    training_data['encoded_labels'],\n",
        "    test_size=0.2\n",
        ")\n",
        "\n",
        "# Prepare datasets\n",
        "train_dataset = FrenchTextDataset(train_texts.tolist(), train_labels.tolist())\n",
        "val_dataset = FrenchTextDataset(val_texts.tolist(), val_labels.tolist())\n",
        "\n",
        "# Load pretrained BERT model\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=len(label_dict))\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=6,\n",
        "    per_device_eval_batch_size=12,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.001,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\"\n",
        ")\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Prediction on validation data for evaluation\n",
        "outputs = trainer.predict(val_dataset)\n",
        "val_preds = np.argmax(outputs.predictions, axis=-1)\n",
        "val_accuracy = accuracy_score(val_labels, val_preds)\n",
        "print(\"Validation Accuracy:\", val_accuracy)\n",
        "\n",
        "# Prepare test data and predict\n",
        "test_dataset = FrenchTextDataset(test_data['sentence'].tolist())\n",
        "test_outputs = trainer.predict(test_dataset)\n",
        "test_preds = np.argmax(test_outputs.predictions, axis=-1)\n",
        "\n",
        "# Convert numeric predictions back to labels\n",
        "inv_label_dict = {v: k for k, v in label_dict.items()}\n",
        "test_difficulties = [inv_label_dict[pred] for pred in test_preds]\n",
        "\n",
        "# Prepare the submission file\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_data['id'],\n",
        "    'difficulty': test_difficulties\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUC8cmnUc3QE"
      },
      "source": [
        "**Model 3**\n",
        "\n",
        "Key parameters:\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=4,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    learning_rate = 2e-5,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537,
          "referenced_widgets": [
            "5a9fbf48949b4c7a81ac431e36bd0536",
            "578bb5a6f30e40b89baa2bb0de4b09a2",
            "00b42491f4874a9c8ecc7a0731ff71f6",
            "29d5f76c80f34da8b76d2154e477a42c",
            "b892fdc138ff4ec5a0e93a910772db60",
            "849ce637a0f64025a1339ef9d0b48466",
            "72e5f7fae28048f0ab030fdc55f35544",
            "f89ba3c6e424402bb86432af3336a344",
            "7ce028bf6abf4c3c931a6b5e5d495c21",
            "7d986eb5036e458aaa9f4e49a4992031",
            "8f8595c3cc654402bf82202b19482010",
            "abc29061ec0d4e3d86067f54883113a0",
            "2c4f90a5b4c6431989d94e668b313706",
            "56fcea3c78ee427daf57f10bfe879a64",
            "6f1e3fecc7754a289affb11874e84f84",
            "b031c7275bc64c8fa22aa0a1ac8c9421",
            "4052d33a69cb47e18c8d60d57332c4a9",
            "e37e996517794c8092bd48622c3abb5d",
            "028481c4bda74a7280205b85607cef0b",
            "564d52f9e7f84d0bb01047d1b6122f0a",
            "20308d0c810d4ca088cd3a2ca81e62e4",
            "2249e3b13960470e93ae2a6defe61921",
            "f29d4e9c22144860bfc51775a8331ea7",
            "d22992858d2145da90a4a2650476100e",
            "450ba73092c7406ab649703a1a79d7bd",
            "3b90e766e3de4de681af63d313102329",
            "a90693ce3adf414ba5a4850a59708db0",
            "2e6ab4e304b64f24b63f3ad1f32ddd87",
            "bd1c33d4719d4caf9070c59b6f1cea45",
            "db73637221c8473cbced109994759c92",
            "cb6fc0d1e65a4099ac0bd38edbeda90f",
            "e90526d4b9e749f68a30363580a2f3c5",
            "117d626f10c543c6b3bfe1af9f056d0b",
            "14d3ae72e40840188233db05b65630c4",
            "519fe5b6e8444644bcfdbf4166e4edb3",
            "7082c620549a4fc68033f31693396ac5",
            "49896401ae9348c6ab7135a0d5b952bf",
            "e7ae1a52cc97461797ed17465774837f",
            "e787f0154dfb40cd84ed2a3c442a4afb",
            "dbb7704e3df142d19a0eb254062ee895",
            "c0665233909c4eaa8269e68337ace1d8",
            "b5dd3b86a0324936a657cd2614e43cbc",
            "0479589e2aba47ef929237d770561c2f",
            "19ca3426bf69495f8d67e19fdbd5b17e",
            "52b478d3a29b4af69ccb21b6a8c1fb75",
            "3f5f5aca0a34471f88e4b729015a78b1",
            "47f319f363b64f0d90d3bf1e348be474",
            "93b4c007f19b4d6996e38333fccb9a4e",
            "79e3f40d1fc64e408c897f06bc24d303",
            "b8d0e6919cf24b54b27831c0a494dbe2",
            "bcb0d278d0db428e953766f078fa60c9",
            "23154509673847f4888e6342615ea9ec",
            "5fa30489cc254748962ede4d3024e37b",
            "3aac719891f84df384e10741d6c74761",
            "2c50e03eacc8464f99df9d541956a128"
          ]
        },
        "id": "4ixSO4M1cl3X",
        "outputId": "0b77f41d-13df-426e-8a78-c0f26d28b8b3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a9fbf48949b4c7a81ac431e36bd0536",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "abc29061ec0d4e3d86067f54883113a0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f29d4e9c22144860bfc51775a8331ea7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "14d3ae72e40840188233db05b65630c4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "52b478d3a29b4af69ccb21b6a8c1fb75",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2160' max='2160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2160/2160 05:53, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.305400</td>\n",
              "      <td>1.150795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.044300</td>\n",
              "      <td>1.081923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.582200</td>\n",
              "      <td>1.060861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.554500</td>\n",
              "      <td>1.224713</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.5645833333333333\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_8b2d75a8-9941-4ecc-8b58-73db50b3efda\", \"sample_FB_b8_wd001_lr2e5.csv\", 8504)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# Load data\n",
        "training_data = df_train\n",
        "test_data = df_test\n",
        "\n",
        "# Initialize tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "\n",
        "# Tokenization and dataset preparation\n",
        "class FrenchTextDataset(Dataset):\n",
        "    def __init__(self, texts, labels=None, max_length=150):\n",
        "        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=max_length)\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.labels:\n",
        "            item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)\n",
        "\n",
        "# Encoding the labels\n",
        "label_dict = {label: i for i, label in enumerate(training_data['difficulty'].unique())}\n",
        "training_data['encoded_labels'] = training_data['difficulty'].map(label_dict)\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    training_data['sentence'],\n",
        "    training_data['encoded_labels'],\n",
        "    test_size=0.1\n",
        ")\n",
        "\n",
        "# Prepare datasets\n",
        "train_dataset = FrenchTextDataset(train_texts.tolist(), train_labels.tolist())\n",
        "val_dataset = FrenchTextDataset(val_texts.tolist(), val_labels.tolist())\n",
        "\n",
        "# Load pretrained BERT model\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=len(label_dict))\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=4,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    learning_rate = 2e-5,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\"\n",
        ")\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Prediction on validation data for evaluation\n",
        "outputs = trainer.predict(val_dataset)\n",
        "val_preds = np.argmax(outputs.predictions, axis=-1)\n",
        "val_accuracy = accuracy_score(val_labels, val_preds)\n",
        "print(\"Validation Accuracy:\", val_accuracy)\n",
        "\n",
        "# Prepare test data and predict\n",
        "test_dataset = FrenchTextDataset(test_data['sentence'].tolist())\n",
        "test_outputs = trainer.predict(test_dataset)\n",
        "test_preds = np.argmax(test_outputs.predictions, axis=-1)\n",
        "\n",
        "# Convert numeric predictions back to labels\n",
        "inv_label_dict = {v: k for k, v in label_dict.items()}\n",
        "test_difficulties = [inv_label_dict[pred] for pred in test_preds]\n",
        "\n",
        "# Prepare the submission file\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_data['id'],\n",
        "    'difficulty': test_difficulties\n",
        "})\n",
        "\n",
        "submission.to_csv('sample_FB_b8_wd001_lr2e5.csv', index=False)\n",
        "from google.colab import files\n",
        "files.download('sample_FB_b8_wd001_lr2e5.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNN9wMKzgMdG"
      },
      "source": [
        "**Other models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "0c4ESq4JcpNE",
        "outputId": "317790a9-d11b-4032-ea6e-72986535ea37"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2700' max='2700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2700/2700 07:47, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.249100</td>\n",
              "      <td>1.204081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.041000</td>\n",
              "      <td>1.077007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.899200</td>\n",
              "      <td>1.184270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.638100</td>\n",
              "      <td>1.349510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.341100</td>\n",
              "      <td>1.482497</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.5541666666666667\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_3632babc-16f0-4702-ac23-536bf2f9bb6c\", \"sample_FB_b8_wd01_lr2e5.csv\", 8504)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# Load data\n",
        "training_data = df_train\n",
        "test_data = df_test\n",
        "\n",
        "# Initialize tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "\n",
        "# Tokenization and dataset preparation\n",
        "class FrenchTextDataset(Dataset):\n",
        "    def __init__(self, texts, labels=None, max_length=150):\n",
        "        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=max_length)\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.labels:\n",
        "            item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)\n",
        "\n",
        "# Encoding the labels\n",
        "label_dict = {label: i for i, label in enumerate(training_data['difficulty'].unique())}\n",
        "training_data['encoded_labels'] = training_data['difficulty'].map(label_dict)\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    training_data['sentence'],\n",
        "    training_data['encoded_labels'],\n",
        "    test_size=0.1\n",
        ")\n",
        "\n",
        "# Prepare datasets\n",
        "train_dataset = FrenchTextDataset(train_texts.tolist(), train_labels.tolist())\n",
        "val_dataset = FrenchTextDataset(val_texts.tolist(), val_labels.tolist())\n",
        "\n",
        "# Load pretrained BERT model\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=len(label_dict))\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.1,\n",
        "    learning_rate = 2e-5,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\"\n",
        ")\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Prediction on validation data for evaluation\n",
        "outputs = trainer.predict(val_dataset)\n",
        "val_preds = np.argmax(outputs.predictions, axis=-1)\n",
        "val_accuracy = accuracy_score(val_labels, val_preds)\n",
        "print(\"Validation Accuracy:\", val_accuracy)\n",
        "\n",
        "# Prepare test data and predict\n",
        "test_dataset = FrenchTextDataset(test_data['sentence'].tolist())\n",
        "test_outputs = trainer.predict(test_dataset)\n",
        "test_preds = np.argmax(test_outputs.predictions, axis=-1)\n",
        "\n",
        "# Convert numeric predictions back to labels\n",
        "inv_label_dict = {v: k for k, v in label_dict.items()}\n",
        "test_difficulties = [inv_label_dict[pred] for pred in test_preds]\n",
        "\n",
        "# Prepare the submission file\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_data['id'],\n",
        "    'difficulty': test_difficulties\n",
        "})\n",
        "\n",
        "submission.to_csv('sample_FB_b8_wd01_lr2e5.csv', index=False)\n",
        "from google.colab import files\n",
        "files.download('sample_FB_b8_wd01_lr2e5.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "id": "jf-7xowKc0yj",
        "outputId": "5c0c5b79-983a-49f8-e6a1-785b40672e84"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2183' max='2700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2183/2700 06:10 < 01:27, 5.89 it/s, Epoch 4.04/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>1.247621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.070300</td>\n",
              "      <td>1.098368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.904100</td>\n",
              "      <td>1.182353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.629800</td>\n",
              "      <td>1.358626</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-f19edacf148c>\u001b[0m in \u001b[0;36m<cell line: 70>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;31m# Prediction on validation data for evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1857\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1858\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1859\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1860\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1861\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2164\u001b[0m             \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2165\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2166\u001b[0m                 \u001b[0mtotal_batched_samples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/data_loader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    461\u001b[0m                 \u001b[0;31m# But we still move it to the device so it is done before `StopIteration` is reached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m                     \u001b[0mcurrent_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msend_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_non_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m                 \u001b[0mnext_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_batches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mskip_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         return type(tensor)(\n\u001b[0;32m--> 186\u001b[0;31m             {\n\u001b[0m\u001b[1;32m    187\u001b[0m                 \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskip_keys\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msend_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    185\u001b[0m         return type(tensor)(\n\u001b[1;32m    186\u001b[0m             {\n\u001b[0;32m--> 187\u001b[0;31m                 \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskip_keys\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msend_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             }\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# .to() doesn't accept non_blocking as kwarg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# Load data\n",
        "training_data = df_train\n",
        "test_data = df_test\n",
        "\n",
        "# Initialize tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "\n",
        "# Tokenization and dataset preparation\n",
        "class FrenchTextDataset(Dataset):\n",
        "    def __init__(self, texts, labels=None, max_length=150):\n",
        "        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=max_length)\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.labels:\n",
        "            item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)\n",
        "\n",
        "# Encoding the labels\n",
        "label_dict = {label: i for i, label in enumerate(training_data['difficulty'].unique())}\n",
        "training_data['encoded_labels'] = training_data['difficulty'].map(label_dict)\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    training_data['sentence'],\n",
        "    training_data['encoded_labels'],\n",
        "    test_size=0.1\n",
        ")\n",
        "\n",
        "# Prepare datasets\n",
        "train_dataset = FrenchTextDataset(train_texts.tolist(), train_labels.tolist())\n",
        "val_dataset = FrenchTextDataset(val_texts.tolist(), val_labels.tolist())\n",
        "\n",
        "# Load pretrained BERT model\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=len(label_dict))\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.005,\n",
        "    learning_rate = 2e-5,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\"\n",
        ")\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Prediction on validation data for evaluation\n",
        "outputs = trainer.predict(val_dataset)\n",
        "val_preds = np.argmax(outputs.predictions, axis=-1)\n",
        "val_accuracy = accuracy_score(val_labels, val_preds)\n",
        "print(\"Validation Accuracy:\", val_accuracy)\n",
        "\n",
        "# Prepare test data and predict\n",
        "test_dataset = FrenchTextDataset(test_data['sentence'].tolist())\n",
        "test_outputs = trainer.predict(test_dataset)\n",
        "test_preds = np.argmax(test_outputs.predictions, axis=-1)\n",
        "\n",
        "# Convert numeric predictions back to labels\n",
        "inv_label_dict = {v: k for k, v in label_dict.items()}\n",
        "test_difficulties = [inv_label_dict[pred] for pred in test_preds]\n",
        "\n",
        "# Prepare the submission file\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_data['id'],\n",
        "    'difficulty': test_difficulties\n",
        "})\n",
        "\n",
        "submission.to_csv('sample_FB_b8_wd0005_lr2e5.csv', index=False)\n",
        "from google.colab import files\n",
        "files.download('sample_FB_b8_wd0005_lr2e5.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "LbWkgFZVgVsK",
        "outputId": "1a8809c0-1ace-4fa4-eb2d-96acaa0f007b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3600' max='3600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3600/3600 09:19, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.127800</td>\n",
              "      <td>1.163018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.958200</td>\n",
              "      <td>1.060712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.773700</td>\n",
              "      <td>1.269080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.611500</td>\n",
              "      <td>1.482649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.400200</td>\n",
              "      <td>1.739673</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.5833333333333334\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_d3cf1fa1-f509-42df-b329-8e5a22f97b20\", \"sample_FB_b6_wd001_lr2e5.csv\", 8504)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# Load data\n",
        "training_data = df_train\n",
        "test_data = df_test\n",
        "\n",
        "# Initialize tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "\n",
        "# Tokenization and dataset preparation\n",
        "class FrenchTextDataset(Dataset):\n",
        "    def __init__(self, texts, labels=None, max_length=150):\n",
        "        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=max_length)\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.labels:\n",
        "            item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)\n",
        "\n",
        "# Encoding the labels\n",
        "label_dict = {label: i for i, label in enumerate(training_data['difficulty'].unique())}\n",
        "training_data['encoded_labels'] = training_data['difficulty'].map(label_dict)\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    training_data['sentence'],\n",
        "    training_data['encoded_labels'],\n",
        "    test_size=0.1\n",
        ")\n",
        "\n",
        "# Prepare datasets\n",
        "train_dataset = FrenchTextDataset(train_texts.tolist(), train_labels.tolist())\n",
        "val_dataset = FrenchTextDataset(val_texts.tolist(), val_labels.tolist())\n",
        "\n",
        "# Load pretrained BERT model\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=len(label_dict))\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=6,\n",
        "    per_device_eval_batch_size=6,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    learning_rate = 2e-5,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\"\n",
        ")\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Prediction on validation data for evaluation\n",
        "outputs = trainer.predict(val_dataset)\n",
        "val_preds = np.argmax(outputs.predictions, axis=-1)\n",
        "val_accuracy = accuracy_score(val_labels, val_preds)\n",
        "print(\"Validation Accuracy:\", val_accuracy)\n",
        "\n",
        "# Prepare test data and predict\n",
        "test_dataset = FrenchTextDataset(test_data['sentence'].tolist())\n",
        "test_outputs = trainer.predict(test_dataset)\n",
        "test_preds = np.argmax(test_outputs.predictions, axis=-1)\n",
        "\n",
        "# Convert numeric predictions back to labels\n",
        "inv_label_dict = {v: k for k, v in label_dict.items()}\n",
        "test_difficulties = [inv_label_dict[pred] for pred in test_preds]\n",
        "\n",
        "# Prepare the submission file\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_data['id'],\n",
        "    'difficulty': test_difficulties\n",
        "})\n",
        "\n",
        "submission.to_csv('sample_FB_b6_wd001_lr2e5.csv', index=False)\n",
        "from google.colab import files\n",
        "files.download('sample_FB_b6_wd001_lr2e5.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "W1Bntah9g_-j",
        "outputId": "1e109cc3-e898-46d4-e244-b02e56dc466c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "Net.forward() got an unexpected keyword argument 'token_type_ids'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-511f16ab7f44>\u001b[0m in \u001b[0;36m<cell line: 103>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Number of epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch+1}\\n-------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training done\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-511f16ab7f44>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Net.forward() got an unexpected keyword argument 'token_type_ids'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load your data\n",
        "data = df_train\n",
        "sentences = data['sentence'].tolist()\n",
        "difficulties = data['difficulty'].tolist()\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(difficulties)\n",
        "\n",
        "# Load BERT tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "bert_model = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
        "\n",
        "# Tokenize sentences and convert to tensor\n",
        "def tokenize_and_encode(sentences):\n",
        "    return tokenizer(sentences, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
        "\n",
        "# Custom Dataset class\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.encodings = tokenize_and_encode(texts)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: self.encodings[key][idx] for key in self.encodings}, self.labels[idx]\n",
        "\n",
        "# Data preparation\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    sentences, encoded_labels, test_size=0.1, random_state=42, stratify=encoded_labels\n",
        ")\n",
        "\n",
        "train_dataset = TextDataset(X_train, y_train)\n",
        "test_dataset = TextDataset(X_test, y_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# Neural network model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Net, self).__init__()\n",
        "        self.bert = bert_model\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.fc = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs[1]\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.fc(pooled_output)\n",
        "        return logits\n",
        "\n",
        "# Instantiate the model, loss, and optimizer\n",
        "model = Net(len(label_encoder.classes_)).to('cuda')\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
        "\n",
        "# Function to compute accuracy\n",
        "def compute_accuracy(dataloader, model):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            inputs, labels = batch\n",
        "            inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
        "            labels = labels.to('cuda')\n",
        "            outputs = model(**inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "# Training loop\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()  # Set model to training mode\n",
        "    for batch, (inputs, labels) in enumerate(dataloader):\n",
        "        inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
        "        labels = labels.to('cuda')\n",
        "        pred = model(**inputs)\n",
        "        loss = loss_fn(pred, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 10 == 0:\n",
        "            loss, current = loss.item(), batch * len(inputs['input_ids'])\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "# Execute training\n",
        "for epoch in range(5):  # Number of epochs\n",
        "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
        "    train_loop(train_loader, model, criterion, optimizer)\n",
        "    print(\"Training done\")\n",
        "\n",
        "# Test the model\n",
        "accuracy = compute_accuracy(test_loader, model)\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import CamembertTokenizer\n",
        "\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
        "\n",
        "# Tokenize and encode the test data\n",
        "def tokenize_and_encode(sentences):\n",
        "    return tokenizer(sentences, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
        "\n",
        "# Custom Dataset class for test data\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, texts):\n",
        "        self.encodings = tokenize_and_encode(texts)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings['input_ids'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: self.encodings[key][idx] for key in self.encodings}\n",
        "\n",
        "# Create the dataset and dataloader for df_test\n",
        "test_dataset = TestDataset(df_test['sentence'].tolist())\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# Define the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Generate predictions for df_test\n",
        "model.eval()  # Make sure the model is in evaluation mode\n",
        "all_predictions = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        inputs = {key: value.to(device) for key, value in batch.items()}\n",
        "        outputs = model(**inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "# Convert numeric predictions back to labels\n",
        "predicted_labels = label_encoder.inverse_transform(all_predictions)\n",
        "\n",
        "# Prepare and save the submission file\n",
        "submission_df = pd.DataFrame({\n",
        "    'id': df_test['id'],  # Ensure df_test includes an 'id' column\n",
        "    'difficulty': predicted_labels\n",
        "})\n",
        "\n",
        "submission_df.to_csv('sample_fromDC_sameAScamerbert.csv', index=False)\n",
        "from google.colab import files\n",
        "files.download('sample_fromDC_sameAScamerbert.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YR489jO6FDmM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# Load data\n",
        "training_data = df_train\n",
        "test_data = df_test\n",
        "\n",
        "# Initialize tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "\n",
        "# Tokenization and dataset preparation\n",
        "class FrenchTextDataset(Dataset):\n",
        "    def __init__(self, texts, labels=None, max_length=512):\n",
        "        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=max_length)\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.labels:\n",
        "            item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)\n",
        "\n",
        "# Encoding the labels\n",
        "label_dict = {label: i for i, label in enumerate(training_data['difficulty'].unique())}\n",
        "training_data['encoded_labels'] = training_data['difficulty'].map(label_dict)\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    training_data['sentence'],\n",
        "    training_data['encoded_labels'],\n",
        "    test_size=0.1\n",
        ")\n",
        "\n",
        "# Prepare datasets\n",
        "train_dataset = FrenchTextDataset(train_texts.tolist(), train_labels.tolist())\n",
        "val_dataset = FrenchTextDataset(val_texts.tolist(), val_labels.tolist())\n",
        "\n",
        "# Load pretrained BERT model\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=len(label_dict))\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=6,\n",
        "    per_device_eval_batch_size=12,\n",
        "    warmup_steps=800,\n",
        "    weight_decay=0.1,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\"\n",
        ")\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Prediction on validation data for evaluation\n",
        "outputs = trainer.predict(val_dataset)\n",
        "val_preds = np.argmax(outputs.predictions, axis=-1)\n",
        "val_accuracy = accuracy_score(val_labels, val_preds)\n",
        "print(\"Validation Accuracy:\", val_accuracy)\n",
        "\n",
        "# Prepare test data and predict\n",
        "test_dataset = FrenchTextDataset(test_data['sentence'].tolist())\n",
        "test_outputs = trainer.predict(test_dataset)\n",
        "test_preds = np.argmax(test_outputs.predictions, axis=-1)\n",
        "\n",
        "# Convert numeric predictions back to labels\n",
        "inv_label_dict = {v: k for k, v in label_dict.items()}\n",
        "test_difficulties = [inv_label_dict[pred] for pred in test_preds]\n",
        "\n",
        "# Prepare the submission file\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_data['id'],\n",
        "    'difficulty': test_difficulties\n",
        "})\n",
        "\n",
        "submission.to_csv('sample_FB_wc800_wd01.csv', index=False)\n",
        "from google.colab import files\n",
        "files.download('sample_FB_wc800_wd01.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c6fb23b24ef34f479b8207756e7c2fc4",
            "cfe20b1f39dd467eaedbf46fa47de826",
            "b69ba8fc455d45b49934405030b6d4f6",
            "edf58e56404c46c1ad786738d3203705",
            "428bb56d6e0043bf84001674096e7a74",
            "9c6ec5d73f0344039e7aed059a23c4ad",
            "2521d9c52112458f98c0ecfc72515c07",
            "a8371995491645cc9b4a70495ba2fec4",
            "58a6dee75512466f959e1c63d5dde5d9",
            "38c036ce3e864f56a4e4c4082edd56f4",
            "246f403d7227470dab948e25aeb52d76",
            "c489c2aaa0b14f709e5af68e103abb47",
            "15fe3e21451f48d9b55c810e53f492bd",
            "06c3b38b34b74557965a5d3375af6988",
            "18cb6d3a1d274f2e98ce466cc29f66b9",
            "2f4bd19638694fe09a070bd9c94baab6",
            "b3bf28038bca43f0bda96355362a2497",
            "55901e6a3f064b199d7026c8c40fca1f",
            "e1ad3750865249b2b8cff9207f9f31eb",
            "f2170cf01f0d4dbf8b629ed7077b3ddc",
            "d5aa05a77f8f4e978eb3b2964f4ff9a1",
            "5a2fa119b8d24e04a10d2194e3f1623d",
            "73a425f8b2374ad3904cb0d299bf554d",
            "c1ea6112c5064b568ea64981f78aa72b",
            "27d059e1b3b5417092017c57b201afad",
            "792b9fadded045ed9f59bb30bef7e56a",
            "61365492dcb34eba86a47724baf81fca",
            "d56af21f3dc54dde8ca208249591c196",
            "e9e93c8339f84085be06c6bbe7d9e28f",
            "a45b7227a9464f518c5072beadf83ba8",
            "f95aaf44f1294c24a849f16fcacfb598",
            "39d58cd0398b481e8dcb6f1363694f2e",
            "615b32bc3a9b4a88bad394596866bd87",
            "d6d7cffc7909465fad4767f0b6a71b05",
            "34a7060692d3465a9ce48b0c9cf5da25",
            "b4f87c27fc6343d18b71adc829c1ae4b",
            "ed03f3f878894478abd01dc396e6188b",
            "14d2eb31a64347a3a90bf7169bcda0d7",
            "057dbe930e0a4cee8a0f045a95a38792",
            "3091dda380e141eb84e05577da6b4f45",
            "1787a7547d60489c9b9a31bfdda86d42",
            "ac1ab4a39a0b47c488109cccaa4028c5",
            "3376e11e43df4d08bb96331f09afa7d7",
            "a3ce64d8a56e43a78358452e7da8c3fe",
            "37ed2172611940d086bcc085733c5886",
            "869322f910994dfeb7bfa9a40f2a8643",
            "a36834daea9e41608dc85778132f9bfe",
            "a17d73c0392c4e07b2d3fff7ca773c0b",
            "2499e308249a4d99bea3a08dc0ed3a29",
            "fa2036691ef14b1d92ffba863d4917f1",
            "16d07f9b06b84ae0a0fb7acb1aeaab29",
            "0fe1a474db1e418daf1aa30382f2a0c5",
            "e3193ebeec5842539d4af3f8335241ee",
            "b299692b07c645cb8f5d1aa0f341b0a5",
            "f18d53f2b04549d7ac4ed3faf4dd10bf",
            "9271015749c941fb83cb95f1a84c1948",
            "442d1021dbcf43d3a034eb2630033781",
            "ab76fd5397034320bec56b5dbe07ab66",
            "b7edc3ca5a544a9db4c180bc1cbe2238",
            "a81398fa32b642569a62ec41ad082d76",
            "93f2b91d76084556b0da56866ceba7d0",
            "77e5ee20cb8948c78cfd3b65c6395f9b",
            "69621f20d31d4e91a647b8027519cd57",
            "50c55f07006048588ad9473625a3b43d",
            "1f4bc8f9fc7e468e8d47d9dd54eb9c4c",
            "3e21ca738a5e42a295c58bd8f5febf83",
            "45bd53997eec46799b01790396581881",
            "b0b44e138e524b77b6dc379d3c1c2494",
            "18069acb3863421b8ba614b4f1fcebd1",
            "e8343a0f28974f19a1f6032ad63574d3",
            "29475d1918994a93a1d7469475281f19",
            "c8ac6b820be442568d35ebc0d7f39432",
            "0c100b1cb0434c59a01559933bdca8a3",
            "7c934d421b0c4174b752c0b07f8f5905",
            "535e8a26e58e4b599a01014f6875be21",
            "240034f8394d4a46975a9a352f4cad4a",
            "15694bd160124faa9eb30a0aeb02814b",
            "cf24c9a510354af5a2cac21e1697432b",
            "bfc4fe88a5e74775ad858d13cafd8acb",
            "0b1fc2176c5a484399eab063c0bd8ce6",
            "639d22a637754f558ff0701d0921ccb4",
            "2569e46aee614620bda857a6f8c9238d",
            "6ea5ac60df5c4f74b42cddf86780dc5e",
            "2608a62f05b5468b931f92146acf78b3",
            "3ecbd800a7fb4f2b877e844a4adfba51",
            "da2cbcf72a104d8e856df39892c1c5ee",
            "2203950bfbb24db698311e4e1834cfe7",
            "aa1f0ee78ad24b72990e75a3563ff081",
            "b10c15429c3f427c9f8b047b4e366ac8",
            "6c71b891e62e4beb99ac75683b1277d2",
            "3f59e6c6861b4cdf98c0793fbe074c87",
            "2b92ae8d24ca414e8936c1513b2dd0a1",
            "02b3f3ec396b4d9fb83e7f7ab71a152e",
            "6c4f20d4b4d44690b34fea75bfe79b92",
            "8841989b4b45491b909f8dec565b326f",
            "7d91964e9b594ddcbb92182bfb7fbd34",
            "bb69938a62454f2d84cfcc2bdd101ef3",
            "f8d2a14f795c40c9a6884f7d49536d6f",
            "12c6f2f9686447b298976e84e42889e3",
            "d4402f0782f34a02a89ff41f16fa78d2",
            "f938a61a322d4609ad25202c67e1c9e5",
            "24c0f46a606b4782ba7b02ec6ef4f362",
            "b32f918873454449bb1c5f2dd754512f",
            "ae5792751cfd494d8247f8e294011c9a",
            "23f14973b04a48a19d26ac12bd621e97",
            "6e0f7d8592dd4e858b2a48e55eb11152",
            "fd266b4f83154b6d872dde6ea7509e5e",
            "8c141d6676734e0db79b529daef2ce0a",
            "d120a4af777640b9b4791f13262b7e20",
            "2edfafd89835485482b9997c0a8ab664",
            "4eef5874d04b4e259b77d11972ac1c97",
            "e190e6fec4f54cb8a569fad79691b31f",
            "2cea345d24bf45e6b20e68a43dacd97a",
            "960919cf9bb74641b28051fc356617ee",
            "65354227bdd34a73ac09d86e91628bc9",
            "0efa9e0210044ff89d86b7067c7948c0",
            "add9dcb5a4b34c0c960cc22032881dfb",
            "b6b7cd0cf19842cdb7f97d6ab790f87b",
            "aebc5e8f1dbd450bae21d9fb6b61b008",
            "633afddd380a401088af5580a2068aa0",
            "218514e1177a43b78fd77d7c0336bc3e",
            "c5447064cf004b8691b51d72dfe4387e",
            "2bcbd5c7edec4d4ea2802449bcf8d10a",
            "bea349bb1ce640c0b9520c4947400d88",
            "ce77b7d5debe4e779ff1f4c25829c3fa",
            "f994cfba62f34088b9a04e4104e4e713",
            "fe15371c1ae8470cbe8e460201caba4a",
            "57700dc2c7bd4dd18c686cbb7f4777b0",
            "a63997fc448e44968c7193a90b086c3c",
            "70eb7399947943b4a98c68832abd5974",
            "21ce2b1bab4542979184c77d9a016900",
            "ab1d5a31230449bda7e527c6e6458bed",
            "91cb7aa53be044d4a7e4d4c5fa8bb718",
            "8eedf2034fe74614a70cf7b41966f998",
            "5cf21325905243b6b12b9926965c4954",
            "b71b066eef32495abe841df9a887d5f5",
            "649255caee1c4cfa91d2658cb1c843d7",
            "6a15d394c8b44d308b372260d0ddba6c",
            "0e31839ec3434ec0a01fabf1f8b736d8",
            "6621f0fba8ed4fada476021607f61d4e",
            "fa8603735825495683c9864e9b2b386a",
            "e478945824b1482abd980721967c2444",
            "49d9dfa8f98340dea6b73c7e4ae77b4f",
            "cf576f998f25435dbe5eb8b2cd92acf9",
            "aac7c9859dbe405b8caa9b3842ee6ab4",
            "d04974052992476eb09ad74e4a2c692f",
            "f5b2e3b82a4342e0884cb84ecc4a41e5",
            "c2041fe52c854dd581b1cb83ad478382",
            "351e2d7494d54e648d1e317eb621deae",
            "e0442cf2921f4a588c140d5ae4d1ab99",
            "4f843ee40d7b43e0afd215fde18d76a0",
            "89d9aa8acd7c4aedbdbd4b9e14c8777f",
            "73918b48058743aa9fb6dc0ce84599ef",
            "309a5e254dce4d4f8e050bcef9dc34cb",
            "8a3588d837dc4464aa63d322404b3c7e",
            "e99ac145af504eff8d93aff9cf069804",
            "4a68543a6e5b4287b958f7f00a4faade",
            "d6c059eb91c243659aa7792ae6a891d3",
            "0741703d2f9b47499c10dcb799d72018",
            "51a3901b53a2400f8f20486de44a0674",
            "d01c0222af9e4c62adafd7a8318626f7",
            "5767cd3738d54b8c8219b0bb67baa0f2",
            "7b68962035b2411891b6bdff1bc0aa4e",
            "94e6df7f5e38417ebc0849ce8b264740",
            "c0777279eac94647bbc7e83b83d2b53a",
            "81fb36edca0440ca975a20c5f40d25fa",
            "602f28ba1fd34221a661e44f0aca6c72",
            "047f5fd326c6414f96534d2c97b62f49",
            "c991cd32e3dc457481510ef439e423f9",
            "2bf90794afd6486882e36d8d3153afd9",
            "9bc6c3f266ac449dba4951e12fa24860",
            "6d2ce9499fe64d4998ae36279967e820",
            "ff751d73142a474f9492d39405fade5a",
            "69dd0ab2f5d74b9680a959f1b0337a00",
            "ac730df0bcb14d5aacb7801b05a0b7c9",
            "039d9d0079474cb899b534691772e6a6",
            "7f778c47be514a6e933fd81495993fae",
            "bdbd74c403fc41e6aa868b18616ea561",
            "6e250655f9cb41bd91a93a781dab3a79",
            "04e003b0f12e49098a395b4260e9ec0a",
            "9c728bfad6514ce5ad1fbd157b88703b",
            "9b65f4101c804dc2976447e49673815e",
            "8cc41d5ee8664be7adfc6b73364d9267",
            "18d7b41b5fec41d185aeaebb0db970a2",
            "21809437c894423db07fc234828352f8",
            "6071e861d2874599bbb1b5fd846f2de9",
            "f771564397d14268ada62260c8fdb988",
            "ae3f511422f54645aeb6e07b77b395c6",
            "87ea1f911a3649e3b3e86a0f06512447",
            "29f2a5738dc24d54aa34b067c7efb21e",
            "1bae5abd6768461184549f532662d159",
            "f63374756893458d84c3e3176e030bf5",
            "d12838d898aa4d489433da4ff14c628f",
            "e47fabb291b249cd986eec928e8adbb2",
            "8f77add20ab84acd81fbf7d24d1f128e",
            "3a28c86be0d848f98e254305d14c5314",
            "b462f2effb9b429bb9365e86c35da020",
            "9f55ed964e924124bacf1707d6f4ea10"
          ]
        },
        "id": "KeEjjKFLRhKv",
        "outputId": "de9e7195-b336-4fee-87df-5bf771179013"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c6fb23b24ef34f479b8207756e7c2fc4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c489c2aaa0b14f709e5af68e103abb47",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "73a425f8b2374ad3904cb0d299bf554d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d6d7cffc7909465fad4767f0b6a71b05",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "37ed2172611940d086bcc085733c5886",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9271015749c941fb83cb95f1a84c1948",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "source.spm:   0%|          | 0.00/778k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "45bd53997eec46799b01790396581881",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "target.spm:   0%|          | 0.00/802k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cf24c9a510354af5a2cac21e1697432b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.34M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b10c15429c3f427c9f8b047b4e366ac8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.42k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d4402f0782f34a02a89ff41f16fa78d2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4eef5874d04b4e259b77d11972ac1c97",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "source.spm:   0%|          | 0.00/802k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c5447064cf004b8691b51d72dfe4387e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "target.spm:   0%|          | 0.00/778k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "91cb7aa53be044d4a7e4d4c5fa8bb718",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.34M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cf576f998f25435dbe5eb8b2cd92acf9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.42k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a3588d837dc4464aa63d322404b3c7e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/301M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "81fb36edca0440ca975a20c5f40d25fa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7f778c47be514a6e933fd81495993fae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/301M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae3f511422f54645aeb6e07b77b395c6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-1430a835b8e9>\u001b[0m in \u001b[0;36m<cell line: 40>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# Perform back translation on the training sentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0maugmented_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mback_translate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0maugmented_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'difficulty'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-1430a835b8e9>\u001b[0m in \u001b[0;36mback_translate\u001b[0;34m(sentences, src_lang, tgt_lang)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Translate to target language\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mtranslated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mtgt_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1653\u001b[0m             )\n\u001b[1;32m   1654\u001b[0m             \u001b[0;31m# 13. run beam search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1655\u001b[0;31m             result = self._beam_search(\n\u001b[0m\u001b[1;32m   1656\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, output_logits, return_dict_in_generate, synced_gpus, sequential, **model_kwargs)\u001b[0m\n\u001b[1;32m   3169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3170\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Unchanged original behavior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3171\u001b[0;31m                 outputs = self(\n\u001b[0m\u001b[1;32m   3172\u001b[0m                     \u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3173\u001b[0m                     \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/marian/modeling_marian.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1415\u001b[0m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1416\u001b[0m         )\n\u001b[0;32m-> 1417\u001b[0;31m         \u001b[0mlm_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_logits_bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1419\u001b[0m         \u001b[0mmasked_lm_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, MarianMTModel, MarianTokenizer\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# Load data\n",
        "training_data = df_train\n",
        "test_data = df_test\n",
        "\n",
        "# Initialize tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "\n",
        "# Back translation for data augmentation\n",
        "def back_translate(sentences, src_lang=\"en\", tgt_lang=\"fr\"):\n",
        "    src_tokenizer = MarianTokenizer.from_pretrained(f'Helsinki-NLP/opus-mt-{src_lang}-{tgt_lang}')\n",
        "    tgt_tokenizer = MarianTokenizer.from_pretrained(f'Helsinki-NLP/opus-mt-{tgt_lang}-{src_lang}')\n",
        "    src_model = MarianMTModel.from_pretrained(f'Helsinki-NLP/opus-mt-{src_lang}-{tgt_lang}')\n",
        "    tgt_model = MarianMTModel.from_pretrained(f'Helsinki-NLP/opus-mt-{tgt_lang}-{src_lang}')\n",
        "\n",
        "    augmented_sentences = []\n",
        "    for sentence in sentences:\n",
        "        # Translate to target language\n",
        "        encoded = src_tokenizer(sentence, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
        "        translated = src_model.generate(**encoded)\n",
        "        tgt_sentence = src_tokenizer.batch_decode(translated, skip_special_tokens=True)[0]\n",
        "\n",
        "        # Translate back to source language\n",
        "        encoded = tgt_tokenizer(tgt_sentence, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
        "        back_translated = tgt_model.generate(**encoded)\n",
        "        src_sentence = tgt_tokenizer.batch_decode(back_translated, skip_special_tokens=True)[0]\n",
        "\n",
        "        augmented_sentences.append(src_sentence)\n",
        "\n",
        "    return augmented_sentences\n",
        "\n",
        "# Perform back translation on the training sentences\n",
        "augmented_sentences = back_translate(training_data['sentence'].tolist())\n",
        "augmented_labels = training_data['difficulty'].tolist()\n",
        "\n",
        "# Append the augmented data to the original data\n",
        "training_data_augmented = training_data.copy()\n",
        "training_data_augmented = training_data_augmented.append(pd.DataFrame({'sentence': augmented_sentences, 'difficulty': augmented_labels}), ignore_index=True)\n",
        "\n",
        "# Encoding the labels\n",
        "label_dict = {label: i for i, label in enumerate(training_data_augmented['difficulty'].unique())}\n",
        "training_data_augmented['encoded_labels'] = training_data_augmented['difficulty'].map(label_dict)\n",
        "\n",
        "# Split data into training and validation sets\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    training_data_augmented['sentence'],\n",
        "    training_data_augmented['encoded_labels'],\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Tokenization and dataset preparation\n",
        "class FrenchTextDataset(Dataset):\n",
        "    def __init__(self, texts, labels=None, max_length=128):\n",
        "        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=max_length)\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.labels is not None:\n",
        "            item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings['input_ids'])\n",
        "\n",
        "# Prepare datasets\n",
        "train_dataset = FrenchTextDataset(train_texts.tolist(), train_labels.tolist())\n",
        "val_dataset = FrenchTextDataset(val_texts.tolist(), val_labels.tolist())\n",
        "\n",
        "# Load pretrained BERT model\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=len(label_dict))\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=6,\n",
        "    per_device_eval_batch_size=12,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\"\n",
        ")\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Prediction on validation data for evaluation\n",
        "outputs = trainer.predict(val_dataset)\n",
        "val_preds = np.argmax(outputs.predictions, axis=-1)\n",
        "val_accuracy = accuracy_score(val_labels, val_preds)\n",
        "print(\"Validation Accuracy:\", val_accuracy)\n",
        "\n",
        "# Prepare test data and predict\n",
        "test_dataset = FrenchTextDataset(test_data['sentence'].tolist())\n",
        "test_outputs = trainer.predict(test_dataset)\n",
        "test_preds = np.argmax(test_outputs.predictions, axis=-1)\n",
        "\n",
        "# Convert numeric predictions back to labels\n",
        "inv_label_dict = {v: k for k, v in label_dict.items()}\n",
        "test_difficulties = [inv_label_dict[pred] for pred in test_preds]\n",
        "\n",
        "# Prepare the submission file\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_data['id'],\n",
        "    'difficulty': test_difficulties\n",
        "})\n",
        "\n",
        "# Save the submission file\n",
        "submission.to_csv('sample_b_tr.csv', index=False)\n",
        "from google.colab import files\n",
        "files.download('sample_b_tr.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyoEDXKwngt4"
      },
      "source": [
        "## Appendix - French Bert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCFOEfR-qWEF"
      },
      "source": [
        "**Model 1.** Accuracy - 57.9\n",
        "\n",
        "It is the same model from the best Camembert result but with nn.Dropout - 0.2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jYJQVsyOkuxf",
        "outputId": "9183b3d3-e350-4133-cabc-9c0cc4ae0f1c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 1.768519  [    0/ 8640]\n",
            "loss: 1.777880  [   80/ 8640]\n",
            "loss: 1.803201  [  160/ 8640]\n",
            "loss: 1.749476  [  240/ 8640]\n",
            "loss: 1.717174  [  320/ 8640]\n",
            "loss: 1.757003  [  400/ 8640]\n",
            "loss: 1.700055  [  480/ 8640]\n",
            "loss: 1.604457  [  560/ 8640]\n",
            "loss: 1.489173  [  640/ 8640]\n",
            "loss: 1.650767  [  720/ 8640]\n",
            "loss: 1.559480  [  800/ 8640]\n",
            "loss: 1.668092  [  880/ 8640]\n",
            "loss: 1.417057  [  960/ 8640]\n",
            "loss: 1.497578  [ 1040/ 8640]\n",
            "loss: 1.345356  [ 1120/ 8640]\n",
            "loss: 1.195809  [ 1200/ 8640]\n",
            "loss: 1.222228  [ 1280/ 8640]\n",
            "loss: 1.297692  [ 1360/ 8640]\n",
            "loss: 1.425284  [ 1440/ 8640]\n",
            "loss: 1.387073  [ 1520/ 8640]\n",
            "loss: 1.333253  [ 1600/ 8640]\n",
            "loss: 1.411439  [ 1680/ 8640]\n",
            "loss: 1.251545  [ 1760/ 8640]\n",
            "loss: 1.269686  [ 1840/ 8640]\n",
            "loss: 1.402421  [ 1920/ 8640]\n",
            "loss: 1.117135  [ 2000/ 8640]\n",
            "loss: 1.172135  [ 2080/ 8640]\n",
            "loss: 1.179394  [ 2160/ 8640]\n",
            "loss: 1.420729  [ 2240/ 8640]\n",
            "loss: 1.257098  [ 2320/ 8640]\n",
            "loss: 1.291638  [ 2400/ 8640]\n",
            "loss: 1.044386  [ 2480/ 8640]\n",
            "loss: 0.916338  [ 2560/ 8640]\n",
            "loss: 0.720821  [ 2640/ 8640]\n",
            "loss: 1.309410  [ 2720/ 8640]\n",
            "loss: 1.068861  [ 2800/ 8640]\n",
            "loss: 1.454478  [ 2880/ 8640]\n",
            "loss: 1.153750  [ 2960/ 8640]\n",
            "loss: 1.034105  [ 3040/ 8640]\n",
            "loss: 1.130459  [ 3120/ 8640]\n",
            "loss: 1.356678  [ 3200/ 8640]\n",
            "loss: 1.121907  [ 3280/ 8640]\n",
            "loss: 1.180036  [ 3360/ 8640]\n",
            "loss: 1.132083  [ 3440/ 8640]\n",
            "loss: 0.938239  [ 3520/ 8640]\n",
            "loss: 1.293630  [ 3600/ 8640]\n",
            "loss: 0.756995  [ 3680/ 8640]\n",
            "loss: 1.063500  [ 3760/ 8640]\n",
            "loss: 1.226688  [ 3840/ 8640]\n",
            "loss: 0.819609  [ 3920/ 8640]\n",
            "loss: 1.300459  [ 4000/ 8640]\n",
            "loss: 1.165258  [ 4080/ 8640]\n",
            "loss: 0.853211  [ 4160/ 8640]\n",
            "loss: 1.275976  [ 4240/ 8640]\n",
            "loss: 1.771695  [ 4320/ 8640]\n",
            "loss: 1.171957  [ 4400/ 8640]\n",
            "loss: 0.904006  [ 4480/ 8640]\n",
            "loss: 1.029183  [ 4560/ 8640]\n",
            "loss: 1.103205  [ 4640/ 8640]\n",
            "loss: 1.038623  [ 4720/ 8640]\n",
            "loss: 1.493185  [ 4800/ 8640]\n",
            "loss: 1.199961  [ 4880/ 8640]\n",
            "loss: 1.133821  [ 4960/ 8640]\n",
            "loss: 1.065624  [ 5040/ 8640]\n",
            "loss: 1.210057  [ 5120/ 8640]\n",
            "loss: 0.779103  [ 5200/ 8640]\n",
            "loss: 1.460435  [ 5280/ 8640]\n",
            "loss: 1.260869  [ 5360/ 8640]\n",
            "loss: 0.754317  [ 5440/ 8640]\n",
            "loss: 1.016280  [ 5520/ 8640]\n",
            "loss: 0.758038  [ 5600/ 8640]\n",
            "loss: 1.358537  [ 5680/ 8640]\n",
            "loss: 0.936286  [ 5760/ 8640]\n",
            "loss: 1.296655  [ 5840/ 8640]\n",
            "loss: 0.671011  [ 5920/ 8640]\n",
            "loss: 0.852663  [ 6000/ 8640]\n",
            "loss: 1.094943  [ 6080/ 8640]\n",
            "loss: 1.326622  [ 6160/ 8640]\n",
            "loss: 0.658102  [ 6240/ 8640]\n",
            "loss: 1.122284  [ 6320/ 8640]\n",
            "loss: 0.998044  [ 6400/ 8640]\n",
            "loss: 1.156617  [ 6480/ 8640]\n",
            "loss: 1.293521  [ 6560/ 8640]\n",
            "loss: 0.702967  [ 6640/ 8640]\n",
            "loss: 0.958979  [ 6720/ 8640]\n",
            "loss: 0.986833  [ 6800/ 8640]\n",
            "loss: 0.970116  [ 6880/ 8640]\n",
            "loss: 1.653078  [ 6960/ 8640]\n",
            "loss: 0.890651  [ 7040/ 8640]\n",
            "loss: 1.365303  [ 7120/ 8640]\n",
            "loss: 1.361717  [ 7200/ 8640]\n",
            "loss: 1.116721  [ 7280/ 8640]\n",
            "loss: 1.433293  [ 7360/ 8640]\n",
            "loss: 0.915274  [ 7440/ 8640]\n",
            "loss: 0.765348  [ 7520/ 8640]\n",
            "loss: 0.872261  [ 7600/ 8640]\n",
            "loss: 1.400513  [ 7680/ 8640]\n",
            "loss: 0.403185  [ 7760/ 8640]\n",
            "loss: 0.940116  [ 7840/ 8640]\n",
            "loss: 0.896435  [ 7920/ 8640]\n",
            "loss: 0.904878  [ 8000/ 8640]\n",
            "loss: 0.900359  [ 8080/ 8640]\n",
            "loss: 1.282585  [ 8160/ 8640]\n",
            "loss: 0.746986  [ 8240/ 8640]\n",
            "loss: 1.088802  [ 8320/ 8640]\n",
            "loss: 1.464249  [ 8400/ 8640]\n",
            "loss: 0.462081  [ 8480/ 8640]\n",
            "loss: 0.613312  [ 8560/ 8640]\n",
            "Training done\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.786681  [    0/ 8640]\n",
            "loss: 0.657767  [   80/ 8640]\n",
            "loss: 0.562751  [  160/ 8640]\n",
            "loss: 0.656285  [  240/ 8640]\n",
            "loss: 0.731633  [  320/ 8640]\n",
            "loss: 0.568916  [  400/ 8640]\n",
            "loss: 1.222726  [  480/ 8640]\n",
            "loss: 1.170799  [  560/ 8640]\n",
            "loss: 0.878438  [  640/ 8640]\n",
            "loss: 0.492298  [  720/ 8640]\n",
            "loss: 0.906090  [  800/ 8640]\n",
            "loss: 0.813371  [  880/ 8640]\n",
            "loss: 0.550657  [  960/ 8640]\n",
            "loss: 1.395335  [ 1040/ 8640]\n",
            "loss: 1.176760  [ 1120/ 8640]\n",
            "loss: 1.027304  [ 1200/ 8640]\n",
            "loss: 0.472310  [ 1280/ 8640]\n",
            "loss: 0.515959  [ 1360/ 8640]\n",
            "loss: 0.741052  [ 1440/ 8640]\n",
            "loss: 1.170966  [ 1520/ 8640]\n",
            "loss: 0.651729  [ 1600/ 8640]\n",
            "loss: 0.696982  [ 1680/ 8640]\n",
            "loss: 0.525225  [ 1760/ 8640]\n",
            "loss: 0.656823  [ 1840/ 8640]\n",
            "loss: 1.140294  [ 1920/ 8640]\n",
            "loss: 0.829765  [ 2000/ 8640]\n",
            "loss: 1.126919  [ 2080/ 8640]\n",
            "loss: 1.077768  [ 2160/ 8640]\n",
            "loss: 0.505898  [ 2240/ 8640]\n",
            "loss: 0.631603  [ 2320/ 8640]\n",
            "loss: 0.590441  [ 2400/ 8640]\n",
            "loss: 0.968887  [ 2480/ 8640]\n",
            "loss: 0.797412  [ 2560/ 8640]\n",
            "loss: 0.598548  [ 2640/ 8640]\n",
            "loss: 0.452923  [ 2720/ 8640]\n",
            "loss: 0.514191  [ 2800/ 8640]\n",
            "loss: 0.668356  [ 2880/ 8640]\n",
            "loss: 0.231948  [ 2960/ 8640]\n",
            "loss: 0.425173  [ 3040/ 8640]\n",
            "loss: 0.774461  [ 3120/ 8640]\n",
            "loss: 0.627263  [ 3200/ 8640]\n",
            "loss: 0.386830  [ 3280/ 8640]\n",
            "loss: 0.595642  [ 3360/ 8640]\n",
            "loss: 0.901249  [ 3440/ 8640]\n",
            "loss: 0.270032  [ 3520/ 8640]\n",
            "loss: 0.685146  [ 3600/ 8640]\n",
            "loss: 0.373591  [ 3680/ 8640]\n",
            "loss: 0.898953  [ 3760/ 8640]\n",
            "loss: 0.400485  [ 3840/ 8640]\n",
            "loss: 1.751872  [ 3920/ 8640]\n",
            "loss: 0.931055  [ 4000/ 8640]\n",
            "loss: 0.878800  [ 4080/ 8640]\n",
            "loss: 1.493749  [ 4160/ 8640]\n",
            "loss: 1.482334  [ 4240/ 8640]\n",
            "loss: 0.327916  [ 4320/ 8640]\n",
            "loss: 0.597091  [ 4400/ 8640]\n",
            "loss: 1.185695  [ 4480/ 8640]\n",
            "loss: 0.692545  [ 4560/ 8640]\n",
            "loss: 0.569529  [ 4640/ 8640]\n",
            "loss: 1.300110  [ 4720/ 8640]\n",
            "loss: 0.530115  [ 4800/ 8640]\n",
            "loss: 0.387232  [ 4880/ 8640]\n",
            "loss: 0.508346  [ 4960/ 8640]\n",
            "loss: 0.497444  [ 5040/ 8640]\n",
            "loss: 1.198894  [ 5120/ 8640]\n",
            "loss: 0.595745  [ 5200/ 8640]\n",
            "loss: 0.512505  [ 5280/ 8640]\n",
            "loss: 0.402953  [ 5360/ 8640]\n",
            "loss: 0.345020  [ 5440/ 8640]\n",
            "loss: 1.063328  [ 5520/ 8640]\n",
            "loss: 0.583772  [ 5600/ 8640]\n",
            "loss: 0.571427  [ 5680/ 8640]\n",
            "loss: 0.249534  [ 5760/ 8640]\n",
            "loss: 0.640652  [ 5840/ 8640]\n",
            "loss: 0.309584  [ 5920/ 8640]\n",
            "loss: 0.882937  [ 6000/ 8640]\n",
            "loss: 0.543084  [ 6080/ 8640]\n",
            "loss: 0.286893  [ 6160/ 8640]\n",
            "loss: 0.531648  [ 6240/ 8640]\n",
            "loss: 0.897306  [ 6320/ 8640]\n",
            "loss: 0.300756  [ 6400/ 8640]\n",
            "loss: 0.563752  [ 6480/ 8640]\n",
            "loss: 0.596854  [ 6560/ 8640]\n",
            "loss: 0.682947  [ 6640/ 8640]\n",
            "loss: 0.402212  [ 6720/ 8640]\n",
            "loss: 1.151317  [ 6800/ 8640]\n",
            "loss: 1.213513  [ 6880/ 8640]\n",
            "loss: 0.570068  [ 6960/ 8640]\n",
            "loss: 0.346039  [ 7040/ 8640]\n",
            "loss: 0.713976  [ 7120/ 8640]\n",
            "loss: 0.362278  [ 7200/ 8640]\n",
            "loss: 0.519813  [ 7280/ 8640]\n",
            "loss: 0.484873  [ 7360/ 8640]\n",
            "loss: 0.439680  [ 7440/ 8640]\n",
            "loss: 0.587013  [ 7520/ 8640]\n",
            "loss: 0.561453  [ 7600/ 8640]\n",
            "loss: 0.918028  [ 7680/ 8640]\n",
            "loss: 0.541593  [ 7760/ 8640]\n",
            "loss: 0.439541  [ 7840/ 8640]\n",
            "loss: 0.512492  [ 7920/ 8640]\n",
            "loss: 0.201150  [ 8000/ 8640]\n",
            "loss: 0.379176  [ 8080/ 8640]\n",
            "loss: 0.861942  [ 8160/ 8640]\n",
            "loss: 0.866972  [ 8240/ 8640]\n",
            "loss: 0.470282  [ 8320/ 8640]\n",
            "loss: 1.317333  [ 8400/ 8640]\n",
            "loss: 0.563442  [ 8480/ 8640]\n",
            "loss: 0.414853  [ 8560/ 8640]\n",
            "Training done\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.248563  [    0/ 8640]\n",
            "loss: 0.716225  [   80/ 8640]\n",
            "loss: 0.340639  [  160/ 8640]\n",
            "loss: 0.254158  [  240/ 8640]\n",
            "loss: 0.145049  [  320/ 8640]\n",
            "loss: 0.479617  [  400/ 8640]\n",
            "loss: 0.099715  [  480/ 8640]\n",
            "loss: 0.383303  [  560/ 8640]\n",
            "loss: 0.140567  [  640/ 8640]\n",
            "loss: 0.590332  [  720/ 8640]\n",
            "loss: 0.554683  [  800/ 8640]\n",
            "loss: 0.447101  [  880/ 8640]\n",
            "loss: 0.209397  [  960/ 8640]\n",
            "loss: 0.962412  [ 1040/ 8640]\n",
            "loss: 0.884673  [ 1120/ 8640]\n",
            "loss: 0.180596  [ 1200/ 8640]\n",
            "loss: 0.231804  [ 1280/ 8640]\n",
            "loss: 0.078546  [ 1360/ 8640]\n",
            "loss: 0.283332  [ 1440/ 8640]\n",
            "loss: 0.227177  [ 1520/ 8640]\n",
            "loss: 0.191702  [ 1600/ 8640]\n",
            "loss: 0.401066  [ 1680/ 8640]\n",
            "loss: 0.604293  [ 1760/ 8640]\n",
            "loss: 0.334918  [ 1840/ 8640]\n",
            "loss: 0.197314  [ 1920/ 8640]\n",
            "loss: 0.704823  [ 2000/ 8640]\n",
            "loss: 0.303331  [ 2080/ 8640]\n",
            "loss: 0.614783  [ 2160/ 8640]\n",
            "loss: 0.168315  [ 2240/ 8640]\n",
            "loss: 0.446030  [ 2320/ 8640]\n",
            "loss: 0.541374  [ 2400/ 8640]\n",
            "loss: 0.104891  [ 2480/ 8640]\n",
            "loss: 0.405938  [ 2560/ 8640]\n",
            "loss: 0.072235  [ 2640/ 8640]\n",
            "loss: 0.420654  [ 2720/ 8640]\n",
            "loss: 0.252824  [ 2800/ 8640]\n",
            "loss: 0.555278  [ 2880/ 8640]\n",
            "loss: 0.176499  [ 2960/ 8640]\n",
            "loss: 0.329306  [ 3040/ 8640]\n",
            "loss: 0.618387  [ 3120/ 8640]\n",
            "loss: 0.460987  [ 3200/ 8640]\n",
            "loss: 0.531146  [ 3280/ 8640]\n",
            "loss: 0.350458  [ 3360/ 8640]\n",
            "loss: 0.519633  [ 3440/ 8640]\n",
            "loss: 0.112829  [ 3520/ 8640]\n",
            "loss: 0.127700  [ 3600/ 8640]\n",
            "loss: 0.794430  [ 3680/ 8640]\n",
            "loss: 0.160526  [ 3760/ 8640]\n",
            "loss: 1.046813  [ 3840/ 8640]\n",
            "loss: 0.229654  [ 3920/ 8640]\n",
            "loss: 0.260910  [ 4000/ 8640]\n",
            "loss: 0.445187  [ 4080/ 8640]\n",
            "loss: 0.291887  [ 4160/ 8640]\n",
            "loss: 0.093270  [ 4240/ 8640]\n",
            "loss: 0.198803  [ 4320/ 8640]\n",
            "loss: 0.484674  [ 4400/ 8640]\n",
            "loss: 0.157228  [ 4480/ 8640]\n",
            "loss: 0.443120  [ 4560/ 8640]\n",
            "loss: 0.235702  [ 4640/ 8640]\n",
            "loss: 0.608858  [ 4720/ 8640]\n",
            "loss: 0.072335  [ 4800/ 8640]\n",
            "loss: 0.242473  [ 4880/ 8640]\n",
            "loss: 0.133011  [ 4960/ 8640]\n",
            "loss: 1.439971  [ 5040/ 8640]\n",
            "loss: 0.217317  [ 5120/ 8640]\n",
            "loss: 0.464016  [ 5200/ 8640]\n",
            "loss: 0.133516  [ 5280/ 8640]\n",
            "loss: 0.377924  [ 5360/ 8640]\n",
            "loss: 0.731204  [ 5440/ 8640]\n",
            "loss: 0.299074  [ 5520/ 8640]\n",
            "loss: 0.667870  [ 5600/ 8640]\n",
            "loss: 0.249782  [ 5680/ 8640]\n",
            "loss: 0.848742  [ 5760/ 8640]\n",
            "loss: 0.141751  [ 5840/ 8640]\n",
            "loss: 0.586718  [ 5920/ 8640]\n",
            "loss: 0.310548  [ 6000/ 8640]\n",
            "loss: 0.179890  [ 6080/ 8640]\n",
            "loss: 0.070643  [ 6160/ 8640]\n",
            "loss: 0.164308  [ 6240/ 8640]\n",
            "loss: 0.512890  [ 6320/ 8640]\n",
            "loss: 0.359087  [ 6400/ 8640]\n",
            "loss: 0.222565  [ 6480/ 8640]\n",
            "loss: 0.058015  [ 6560/ 8640]\n",
            "loss: 0.448600  [ 6640/ 8640]\n",
            "loss: 0.582123  [ 6720/ 8640]\n",
            "loss: 0.874660  [ 6800/ 8640]\n",
            "loss: 0.363423  [ 6880/ 8640]\n",
            "loss: 0.264827  [ 6960/ 8640]\n",
            "loss: 0.594833  [ 7040/ 8640]\n",
            "loss: 0.076685  [ 7120/ 8640]\n",
            "loss: 0.062990  [ 7200/ 8640]\n",
            "loss: 0.806676  [ 7280/ 8640]\n",
            "loss: 1.157486  [ 7360/ 8640]\n",
            "loss: 0.213560  [ 7440/ 8640]\n",
            "loss: 0.335776  [ 7520/ 8640]\n",
            "loss: 0.661300  [ 7600/ 8640]\n",
            "loss: 0.088913  [ 7680/ 8640]\n",
            "loss: 0.246485  [ 7760/ 8640]\n",
            "loss: 0.848103  [ 7840/ 8640]\n",
            "loss: 0.563342  [ 7920/ 8640]\n",
            "loss: 0.141607  [ 8000/ 8640]\n",
            "loss: 0.110395  [ 8080/ 8640]\n",
            "loss: 0.355576  [ 8160/ 8640]\n",
            "loss: 0.077476  [ 8240/ 8640]\n",
            "loss: 0.850207  [ 8320/ 8640]\n",
            "loss: 0.231893  [ 8400/ 8640]\n",
            "loss: 0.159591  [ 8480/ 8640]\n",
            "loss: 0.300916  [ 8560/ 8640]\n",
            "Training done\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.348977  [    0/ 8640]\n",
            "loss: 0.139137  [   80/ 8640]\n",
            "loss: 0.056024  [  160/ 8640]\n",
            "loss: 0.091266  [  240/ 8640]\n",
            "loss: 0.195588  [  320/ 8640]\n",
            "loss: 0.086911  [  400/ 8640]\n",
            "loss: 0.036310  [  480/ 8640]\n",
            "loss: 0.029649  [  560/ 8640]\n",
            "loss: 0.040329  [  640/ 8640]\n",
            "loss: 0.220569  [  720/ 8640]\n",
            "loss: 0.261679  [  800/ 8640]\n",
            "loss: 0.333027  [  880/ 8640]\n",
            "loss: 0.452418  [  960/ 8640]\n",
            "loss: 0.046195  [ 1040/ 8640]\n",
            "loss: 0.113618  [ 1120/ 8640]\n",
            "loss: 0.228693  [ 1200/ 8640]\n",
            "loss: 0.037056  [ 1280/ 8640]\n",
            "loss: 0.289985  [ 1360/ 8640]\n",
            "loss: 0.138351  [ 1440/ 8640]\n",
            "loss: 0.091630  [ 1520/ 8640]\n",
            "loss: 0.034548  [ 1600/ 8640]\n",
            "loss: 0.075344  [ 1680/ 8640]\n",
            "loss: 0.054582  [ 1760/ 8640]\n",
            "loss: 0.032880  [ 1840/ 8640]\n",
            "loss: 0.048732  [ 1920/ 8640]\n",
            "loss: 0.346041  [ 2000/ 8640]\n",
            "loss: 0.051998  [ 2080/ 8640]\n",
            "loss: 0.039515  [ 2160/ 8640]\n",
            "loss: 0.104132  [ 2240/ 8640]\n",
            "loss: 0.051559  [ 2320/ 8640]\n",
            "loss: 0.257900  [ 2400/ 8640]\n",
            "loss: 0.020986  [ 2480/ 8640]\n",
            "loss: 0.054856  [ 2560/ 8640]\n",
            "loss: 0.400924  [ 2640/ 8640]\n",
            "loss: 0.151240  [ 2720/ 8640]\n",
            "loss: 0.397224  [ 2800/ 8640]\n",
            "loss: 0.248170  [ 2880/ 8640]\n",
            "loss: 0.427640  [ 2960/ 8640]\n",
            "loss: 0.066884  [ 3040/ 8640]\n",
            "loss: 0.049363  [ 3120/ 8640]\n",
            "loss: 0.018735  [ 3200/ 8640]\n",
            "loss: 0.061897  [ 3280/ 8640]\n",
            "loss: 0.322202  [ 3360/ 8640]\n",
            "loss: 0.028746  [ 3440/ 8640]\n",
            "loss: 0.028970  [ 3520/ 8640]\n",
            "loss: 0.038794  [ 3600/ 8640]\n",
            "loss: 0.119753  [ 3680/ 8640]\n",
            "loss: 0.022366  [ 3760/ 8640]\n",
            "loss: 0.763968  [ 3840/ 8640]\n",
            "loss: 0.386686  [ 3920/ 8640]\n",
            "loss: 0.098686  [ 4000/ 8640]\n",
            "loss: 0.147672  [ 4080/ 8640]\n",
            "loss: 0.041050  [ 4160/ 8640]\n",
            "loss: 0.359220  [ 4240/ 8640]\n",
            "loss: 0.327022  [ 4320/ 8640]\n",
            "loss: 0.070375  [ 4400/ 8640]\n",
            "loss: 0.104183  [ 4480/ 8640]\n",
            "loss: 0.686947  [ 4560/ 8640]\n",
            "loss: 0.064239  [ 4640/ 8640]\n",
            "loss: 0.061054  [ 4720/ 8640]\n",
            "loss: 0.100489  [ 4800/ 8640]\n",
            "loss: 0.314194  [ 4880/ 8640]\n",
            "loss: 0.020876  [ 4960/ 8640]\n",
            "loss: 0.069168  [ 5040/ 8640]\n",
            "loss: 0.224953  [ 5120/ 8640]\n",
            "loss: 0.237721  [ 5200/ 8640]\n",
            "loss: 0.399935  [ 5280/ 8640]\n",
            "loss: 0.409353  [ 5360/ 8640]\n",
            "loss: 0.030758  [ 5440/ 8640]\n",
            "loss: 0.143886  [ 5520/ 8640]\n",
            "loss: 0.350016  [ 5600/ 8640]\n",
            "loss: 0.020992  [ 5680/ 8640]\n",
            "loss: 0.137264  [ 5760/ 8640]\n",
            "loss: 0.239475  [ 5840/ 8640]\n",
            "loss: 0.014736  [ 5920/ 8640]\n",
            "loss: 0.413391  [ 6000/ 8640]\n",
            "loss: 0.306759  [ 6080/ 8640]\n",
            "loss: 0.076204  [ 6160/ 8640]\n",
            "loss: 0.209201  [ 6240/ 8640]\n",
            "loss: 0.021819  [ 6320/ 8640]\n",
            "loss: 1.275242  [ 6400/ 8640]\n",
            "loss: 0.111042  [ 6480/ 8640]\n",
            "loss: 0.036973  [ 6560/ 8640]\n",
            "loss: 0.231590  [ 6640/ 8640]\n",
            "loss: 0.161955  [ 6720/ 8640]\n",
            "loss: 0.259794  [ 6800/ 8640]\n",
            "loss: 0.315053  [ 6880/ 8640]\n",
            "loss: 0.172655  [ 6960/ 8640]\n",
            "loss: 0.090585  [ 7040/ 8640]\n",
            "loss: 0.079083  [ 7120/ 8640]\n",
            "loss: 0.098709  [ 7200/ 8640]\n",
            "loss: 0.017415  [ 7280/ 8640]\n",
            "loss: 0.653108  [ 7360/ 8640]\n",
            "loss: 0.199404  [ 7440/ 8640]\n",
            "loss: 0.655774  [ 7520/ 8640]\n",
            "loss: 0.113929  [ 7600/ 8640]\n",
            "loss: 0.062771  [ 7680/ 8640]\n",
            "loss: 0.015831  [ 7760/ 8640]\n",
            "loss: 0.418862  [ 7840/ 8640]\n",
            "loss: 0.043111  [ 7920/ 8640]\n",
            "loss: 0.260634  [ 8000/ 8640]\n",
            "loss: 0.033166  [ 8080/ 8640]\n",
            "loss: 0.033427  [ 8160/ 8640]\n",
            "loss: 0.042703  [ 8240/ 8640]\n",
            "loss: 0.079739  [ 8320/ 8640]\n",
            "loss: 0.213056  [ 8400/ 8640]\n",
            "loss: 0.112791  [ 8480/ 8640]\n",
            "loss: 0.024034  [ 8560/ 8640]\n",
            "Training done\n",
            "Test Accuracy: 83.75%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_a02c16c6-eb07-4108-8504-da58b7bc4835\", \"sample_text_add_b8_lr3e5_e4_drop02.csv\", 8504)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def synonym_replacement(sentence, n):\n",
        "    words = sentence.split()\n",
        "    new_words = words.copy()\n",
        "    french_stopwords = set(nltk.corpus.stopwords.words('french'))\n",
        "    random_word_list = list(set([word for word in words if word not in french_stopwords]))\n",
        "    random.shuffle(random_word_list)\n",
        "    num_replaced = 0\n",
        "    for random_word in random_word_list:\n",
        "        synonyms = get_synonyms(random_word)\n",
        "        if len(synonyms) > 0:\n",
        "            synonym = random.choice(synonyms)\n",
        "            new_words = [synonym if word == random_word else word for word in new_words]\n",
        "            num_replaced += 1\n",
        "        if num_replaced >= n:  # Only replace up to n words\n",
        "            break\n",
        "    return ' '.join(new_words)\n",
        "\n",
        "def get_synonyms(word):\n",
        "    synonyms = set()\n",
        "    for syn in wordnet.synsets(word, lang='fra'):\n",
        "        for lemma in syn.lemmas(lang='fra'):\n",
        "            synonym = lemma.name().replace(\"_\", \" \").replace(\"-\", \" \").lower()\n",
        "            synonym = \"\".join([char for char in synonym if char.isalnum() or char.isspace()])\n",
        "            synonyms.add(synonym)\n",
        "    if word in synonyms:\n",
        "        synonyms.remove(word)\n",
        "    return list(synonyms)\n",
        "\n",
        "# Generate augmented sentences\n",
        "new_sentences = []\n",
        "new_difficulties = []\n",
        "for _, row in df_train.iterrows():\n",
        "    original_sentence = row['sentence']\n",
        "    difficulty = row['difficulty']\n",
        "    augmented_sentence = synonym_replacement(original_sentence, 2)\n",
        "    new_sentences.append(augmented_sentence)\n",
        "    new_difficulties.append(difficulty)\n",
        "\n",
        "# Create a new DataFrame for the augmented sentences\n",
        "df_augmented = pd.DataFrame({'sentence': new_sentences, 'difficulty': new_difficulties})\n",
        "\n",
        "# Concatenate the original and augmented DataFrames\n",
        "df_combined = pd.concat([df_train, df_augmented], ignore_index=True)\n",
        "\n",
        "# Load your data\n",
        "data = df_combined\n",
        "sentences = data['sentence'].tolist()\n",
        "difficulties = data['difficulty'].tolist()\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(difficulties)\n",
        "\n",
        "# Load CamemBERT tokenizer and model\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
        "camembert = CamembertModel.from_pretrained('camembert-base')\n",
        "\n",
        "# Tokenize sentences and convert to tensor\n",
        "def tokenize_and_encode(sentences):\n",
        "    return tokenizer(sentences, padding=True, truncation=True, max_length=600, return_tensors='pt')\n",
        "\n",
        "# Custom Dataset class\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.encodings = tokenize_and_encode(texts)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: self.encodings[key][idx] for key in self.encodings}, self.labels[idx]\n",
        "\n",
        "# Data preparation\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    sentences, encoded_labels, test_size=0.1, random_state=42, stratify=encoded_labels\n",
        ")\n",
        "\n",
        "train_dataset = TextDataset(X_train, y_train)\n",
        "test_dataset = TextDataset(X_test, y_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# Neural network model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Net, self).__init__()\n",
        "        self.camembert = camembert\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.fc = nn.Linear(self.camembert.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        outputs = self.camembert(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.fc(pooled_output)\n",
        "        return logits\n",
        "\n",
        "# Instantiate the model, loss, and optimizer\n",
        "model = Net(len(label_encoder.classes_)).to('cuda')\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-5)\n",
        "\n",
        "# Function to compute accuracy\n",
        "def compute_accuracy(dataloader, model):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            inputs, labels = batch\n",
        "            inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
        "            labels = labels.to('cuda')\n",
        "            outputs = model(**inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "# Training loop\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()  # Set model to training mode\n",
        "    for batch, (inputs, labels) in enumerate(dataloader):\n",
        "        inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
        "        labels = labels.to('cuda')\n",
        "        pred = model(**inputs)\n",
        "        loss = loss_fn(pred, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 10 == 0:\n",
        "            loss, current = loss.item(), batch * len(inputs['input_ids'])\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "# Execute training\n",
        "for epoch in range(4):  # Number of epochs\n",
        "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
        "    train_loop(train_loader, model, criterion, optimizer)\n",
        "    print(\"Training done\")\n",
        "\n",
        "# Test the model\n",
        "accuracy = compute_accuracy(test_loader, model)\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import CamembertTokenizer\n",
        "\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
        "\n",
        "# Tokenize and encode the test data\n",
        "def tokenize_and_encode(sentences):\n",
        "    return tokenizer(sentences, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
        "\n",
        "# Custom Dataset class for test data\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, texts):\n",
        "        self.encodings = tokenize_and_encode(texts)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings['input_ids'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: self.encodings[key][idx] for key in self.encodings}\n",
        "\n",
        "# Create the dataset and dataloader for df_test\n",
        "test_dataset = TestDataset(df_test['sentence'].tolist())\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# Define the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Generate predictions for df_test\n",
        "model.eval()  # Make sure the model is in evaluation mode\n",
        "all_predictions = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        inputs = {key: value.to(device) for key, value in batch.items()}\n",
        "        outputs = model(**inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "# Convert numeric predictions back to labels\n",
        "predicted_labels = label_encoder.inverse_transform(all_predictions)\n",
        "\n",
        "# Prepare and save the submission file\n",
        "submission_df = pd.DataFrame({\n",
        "    'id': df_test['id'],  # Ensure df_test includes an 'id' column\n",
        "    'difficulty': predicted_labels\n",
        "})\n",
        "\n",
        "submission_df.to_csv('sample_text_add_b8_lr3e5_e4_drop02.csv', index=False)\n",
        "from google.colab import files\n",
        "files.download('sample_text_add_b8_lr3e5_e4_drop02.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obGkSqzp-rCS"
      },
      "source": [
        "**Other models**\n",
        "\n",
        "*(Their real accuracy can be checked on the Kaggle.)* Mainly, I focus with **nltk**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "424abf6ce1e64c59a2116a2d20dd550e",
            "be7832305adc466a9a02d09819f2e250",
            "6b1d4be047954999b55514b680a2fbda",
            "2465f1f8b12e41139d23abb12dbf4b7d",
            "ac1e94d8a5fb485dbbfc754596ee8986",
            "e30da31ab6eb4560ba7a674ad3e8aa25",
            "5721cdbe865d44dc8c0c81c83230d70f",
            "4ad9feb9ce8443f79948cf934304c17e",
            "38d6dcb350d441e89fde65659be5af80",
            "9d420e46be3c4899a70fa2313c05bbd2",
            "050800caa8014720af48cdb1de2671ec",
            "a8aeb7e9805c47a79b9e160c505b804b",
            "c2c3af897eb4407a81f0be34616fb76f",
            "aaa1153086dc46b9b4bd9cc8eefb9a01",
            "f0551774a16441b79e5fead5f07c2677",
            "1fa9b3101d7f4f31a1dae7fe0fd23c42",
            "2872e30171c84ed0b84cd7ab1291eb86",
            "b353b163ea324e29ac11b05e7a35d997",
            "16ac0aaf191a4ad5a24479afd8d37e31",
            "4d218f659c5c44f8adb585545c345a82",
            "a344e0188fc84435a1ee41eb322a0f78",
            "f472d1be6bdb46ddbf8adc2b44686919",
            "8204179b49f640a69c38bcfd71b4f118",
            "27aa70f4dc8644d8b9ed174714775034",
            "dfebd435f93a4525a1303dbcf45ab479",
            "13f3530bada04e50a50644afc933748b",
            "d4e6b7e32fa847b8827ad176b78c7385",
            "aa6e9998b0e14b26b49df2205b678e62",
            "71363cfce17249688c2877847f25dcc6",
            "7281536743ae46868819e1ce5607f172",
            "2366427b387d4cf6973a0683a235ef46",
            "1dee23b3f9eb4f4ba878f518320f4fee",
            "73efcbc4b2894ee980eca7d5f24e7713",
            "ca7a5c1ff379425fba78ad7049a2a5bb",
            "636f68e313284fd1aca6dc1fcdf0f2b8",
            "81b2d289ee0349dfb7ff05c8b571db95",
            "800ef3027cbb451a9fb11e2673ace0aa",
            "54d6bff4f2c04110bb3079cfc3f50b69",
            "49cb86fd7de14fbebb80df731983954f",
            "f6e93cda2ab04dd3a2e730d540407bb7",
            "3ab36bfbda27453cbbde4c3458efc38f",
            "3e9d8ffb1f674bd6a4f78154c498a6e7",
            "14c875b5b2de45e0af89707288046a7b",
            "110a1dfd0b34463b843f2f54c6bacc38",
            "49056a1aed1249719285c61683189b2d",
            "68750d3063634f4b82efabf29a564d8e",
            "e1b42517261f4584aff2e2be818b7cf8",
            "ee1f2384bd2b4059a5d5df7feaeede87",
            "828da0e1d5c340c5b6e34aba7c0bd1e9",
            "5ce537839ff74df1abc99aa05ccdf5a1",
            "e256643bd7ac497bb72cdcfeaede545d",
            "8863cbd44cc74ac1b82cb9f2f21305cb",
            "c7100dcf5f744f65afb159533579e953",
            "ac730faf81e843b6bb66909f505cb567",
            "50b72575a341423296027982812af8c1"
          ]
        },
        "id": "vfHtPDJ79glL",
        "outputId": "bc181a4a-34cd-40a4-8760-eba1d87f4ec4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "424abf6ce1e64c59a2116a2d20dd550e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a8aeb7e9805c47a79b9e160c505b804b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/811k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8204179b49f640a69c38bcfd71b4f118",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.40M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca7a5c1ff379425fba78ad7049a2a5bb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/508 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "49056a1aed1249719285c61683189b2d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 1.806043  [    0/ 8640]\n",
            "loss: 1.804136  [   80/ 8640]\n",
            "loss: 1.762988  [  160/ 8640]\n",
            "loss: 1.821134  [  240/ 8640]\n",
            "loss: 1.768228  [  320/ 8640]\n",
            "loss: 1.756873  [  400/ 8640]\n",
            "loss: 1.748500  [  480/ 8640]\n",
            "loss: 1.699681  [  560/ 8640]\n",
            "loss: 1.646486  [  640/ 8640]\n",
            "loss: 1.692441  [  720/ 8640]\n",
            "loss: 1.576208  [  800/ 8640]\n",
            "loss: 1.631260  [  880/ 8640]\n",
            "loss: 1.418647  [  960/ 8640]\n",
            "loss: 1.607756  [ 1040/ 8640]\n",
            "loss: 1.476603  [ 1120/ 8640]\n",
            "loss: 1.633927  [ 1200/ 8640]\n",
            "loss: 1.547223  [ 1280/ 8640]\n",
            "loss: 1.538892  [ 1360/ 8640]\n",
            "loss: 1.598789  [ 1440/ 8640]\n",
            "loss: 1.305871  [ 1520/ 8640]\n",
            "loss: 1.214934  [ 1600/ 8640]\n",
            "loss: 1.470122  [ 1680/ 8640]\n",
            "loss: 1.497276  [ 1760/ 8640]\n",
            "loss: 1.596928  [ 1840/ 8640]\n",
            "loss: 1.367312  [ 1920/ 8640]\n",
            "loss: 1.259271  [ 2000/ 8640]\n",
            "loss: 1.382690  [ 2080/ 8640]\n",
            "loss: 1.375529  [ 2160/ 8640]\n",
            "loss: 1.107187  [ 2240/ 8640]\n",
            "loss: 1.474723  [ 2320/ 8640]\n",
            "loss: 1.186127  [ 2400/ 8640]\n",
            "loss: 1.325468  [ 2480/ 8640]\n",
            "loss: 1.313946  [ 2560/ 8640]\n",
            "loss: 1.315507  [ 2640/ 8640]\n",
            "loss: 1.323593  [ 2720/ 8640]\n",
            "loss: 1.384965  [ 2800/ 8640]\n",
            "loss: 0.938093  [ 2880/ 8640]\n",
            "loss: 1.110429  [ 2960/ 8640]\n",
            "loss: 1.173072  [ 3040/ 8640]\n",
            "loss: 1.170092  [ 3120/ 8640]\n",
            "loss: 1.305143  [ 3200/ 8640]\n",
            "loss: 1.252110  [ 3280/ 8640]\n",
            "loss: 1.099140  [ 3360/ 8640]\n",
            "loss: 1.337066  [ 3440/ 8640]\n",
            "loss: 1.087947  [ 3520/ 8640]\n",
            "loss: 1.422765  [ 3600/ 8640]\n",
            "loss: 1.173463  [ 3680/ 8640]\n",
            "loss: 1.136960  [ 3760/ 8640]\n",
            "loss: 1.705052  [ 3840/ 8640]\n",
            "loss: 0.946172  [ 3920/ 8640]\n",
            "loss: 1.052535  [ 4000/ 8640]\n",
            "loss: 1.275975  [ 4080/ 8640]\n",
            "loss: 1.294468  [ 4160/ 8640]\n",
            "loss: 1.166207  [ 4240/ 8640]\n",
            "loss: 1.218201  [ 4320/ 8640]\n",
            "loss: 1.171890  [ 4400/ 8640]\n",
            "loss: 1.200642  [ 4480/ 8640]\n",
            "loss: 0.985716  [ 4560/ 8640]\n",
            "loss: 1.160630  [ 4640/ 8640]\n",
            "loss: 1.062901  [ 4720/ 8640]\n",
            "loss: 1.218778  [ 4800/ 8640]\n",
            "loss: 0.980611  [ 4880/ 8640]\n",
            "loss: 1.497164  [ 4960/ 8640]\n",
            "loss: 1.017378  [ 5040/ 8640]\n",
            "loss: 1.086165  [ 5120/ 8640]\n",
            "loss: 1.096938  [ 5200/ 8640]\n",
            "loss: 0.939537  [ 5280/ 8640]\n",
            "loss: 1.161442  [ 5360/ 8640]\n",
            "loss: 0.864354  [ 5440/ 8640]\n",
            "loss: 1.227019  [ 5520/ 8640]\n",
            "loss: 0.949602  [ 5600/ 8640]\n",
            "loss: 0.898678  [ 5680/ 8640]\n",
            "loss: 1.057842  [ 5760/ 8640]\n",
            "loss: 0.703897  [ 5840/ 8640]\n",
            "loss: 0.843824  [ 5920/ 8640]\n",
            "loss: 1.055072  [ 6000/ 8640]\n",
            "loss: 0.896402  [ 6080/ 8640]\n",
            "loss: 0.699686  [ 6160/ 8640]\n",
            "loss: 0.798227  [ 6240/ 8640]\n",
            "loss: 1.257350  [ 6320/ 8640]\n",
            "loss: 1.326587  [ 6400/ 8640]\n",
            "loss: 1.118079  [ 6480/ 8640]\n",
            "loss: 0.983249  [ 6560/ 8640]\n",
            "loss: 0.654372  [ 6640/ 8640]\n",
            "loss: 0.971593  [ 6720/ 8640]\n",
            "loss: 0.880817  [ 6800/ 8640]\n",
            "loss: 0.925292  [ 6880/ 8640]\n",
            "loss: 1.125978  [ 6960/ 8640]\n",
            "loss: 1.370980  [ 7040/ 8640]\n",
            "loss: 0.779144  [ 7120/ 8640]\n",
            "loss: 1.019099  [ 7200/ 8640]\n",
            "loss: 2.157720  [ 7280/ 8640]\n",
            "loss: 0.704599  [ 7360/ 8640]\n",
            "loss: 1.006570  [ 7440/ 8640]\n",
            "loss: 1.329371  [ 7520/ 8640]\n",
            "loss: 0.985852  [ 7600/ 8640]\n",
            "loss: 1.137457  [ 7680/ 8640]\n",
            "loss: 1.237847  [ 7760/ 8640]\n",
            "loss: 1.152690  [ 7840/ 8640]\n",
            "loss: 0.875386  [ 7920/ 8640]\n",
            "loss: 1.264249  [ 8000/ 8640]\n",
            "loss: 1.228754  [ 8080/ 8640]\n",
            "loss: 1.061466  [ 8160/ 8640]\n",
            "loss: 0.532861  [ 8240/ 8640]\n",
            "loss: 1.072425  [ 8320/ 8640]\n",
            "loss: 1.395428  [ 8400/ 8640]\n",
            "loss: 1.118426  [ 8480/ 8640]\n",
            "loss: 0.811509  [ 8560/ 8640]\n",
            "Validation loss: 57.81\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.986272  [    0/ 8640]\n",
            "loss: 0.842624  [   80/ 8640]\n",
            "loss: 0.727263  [  160/ 8640]\n",
            "loss: 1.011672  [  240/ 8640]\n",
            "loss: 1.446656  [  320/ 8640]\n",
            "loss: 0.984003  [  400/ 8640]\n",
            "loss: 0.943272  [  480/ 8640]\n",
            "loss: 0.704776  [  560/ 8640]\n",
            "loss: 0.906932  [  640/ 8640]\n",
            "loss: 0.791227  [  720/ 8640]\n",
            "loss: 0.855591  [  800/ 8640]\n",
            "loss: 0.728527  [  880/ 8640]\n",
            "loss: 0.947649  [  960/ 8640]\n",
            "loss: 1.009373  [ 1040/ 8640]\n",
            "loss: 1.149416  [ 1120/ 8640]\n",
            "loss: 0.625707  [ 1200/ 8640]\n",
            "loss: 0.974762  [ 1280/ 8640]\n",
            "loss: 0.908098  [ 1360/ 8640]\n",
            "loss: 0.486568  [ 1440/ 8640]\n",
            "loss: 0.893610  [ 1520/ 8640]\n",
            "loss: 0.739086  [ 1600/ 8640]\n",
            "loss: 1.094687  [ 1680/ 8640]\n",
            "loss: 0.703693  [ 1760/ 8640]\n",
            "loss: 0.784926  [ 1840/ 8640]\n",
            "loss: 1.630239  [ 1920/ 8640]\n",
            "loss: 0.847876  [ 2000/ 8640]\n",
            "loss: 0.644422  [ 2080/ 8640]\n",
            "loss: 0.943398  [ 2160/ 8640]\n",
            "loss: 0.756499  [ 2240/ 8640]\n",
            "loss: 1.194889  [ 2320/ 8640]\n",
            "loss: 0.942934  [ 2400/ 8640]\n",
            "loss: 0.678979  [ 2480/ 8640]\n",
            "loss: 0.752553  [ 2560/ 8640]\n",
            "loss: 0.571026  [ 2640/ 8640]\n",
            "loss: 0.906679  [ 2720/ 8640]\n",
            "loss: 0.999766  [ 2800/ 8640]\n",
            "loss: 0.640668  [ 2880/ 8640]\n",
            "loss: 0.847239  [ 2960/ 8640]\n",
            "loss: 0.508729  [ 3040/ 8640]\n",
            "loss: 0.830621  [ 3120/ 8640]\n",
            "loss: 0.875249  [ 3200/ 8640]\n",
            "loss: 0.674746  [ 3280/ 8640]\n",
            "loss: 0.691717  [ 3360/ 8640]\n",
            "loss: 0.634904  [ 3440/ 8640]\n",
            "loss: 1.400063  [ 3520/ 8640]\n",
            "loss: 0.835726  [ 3600/ 8640]\n",
            "loss: 1.189127  [ 3680/ 8640]\n",
            "loss: 0.867234  [ 3760/ 8640]\n",
            "loss: 0.760416  [ 3840/ 8640]\n",
            "loss: 0.691527  [ 3920/ 8640]\n",
            "loss: 1.060645  [ 4000/ 8640]\n",
            "loss: 1.157604  [ 4080/ 8640]\n",
            "loss: 0.553958  [ 4160/ 8640]\n",
            "loss: 0.815423  [ 4240/ 8640]\n",
            "loss: 0.980817  [ 4320/ 8640]\n",
            "loss: 0.750750  [ 4400/ 8640]\n",
            "loss: 0.756574  [ 4480/ 8640]\n",
            "loss: 0.742558  [ 4560/ 8640]\n",
            "loss: 0.468838  [ 4640/ 8640]\n",
            "loss: 0.801820  [ 4720/ 8640]\n",
            "loss: 0.701203  [ 4800/ 8640]\n",
            "loss: 1.101233  [ 4880/ 8640]\n",
            "loss: 0.661879  [ 4960/ 8640]\n",
            "loss: 0.704683  [ 5040/ 8640]\n",
            "loss: 0.637966  [ 5120/ 8640]\n",
            "loss: 0.337948  [ 5200/ 8640]\n",
            "loss: 0.315532  [ 5280/ 8640]\n",
            "loss: 0.867619  [ 5360/ 8640]\n",
            "loss: 1.422502  [ 5440/ 8640]\n",
            "loss: 0.967373  [ 5520/ 8640]\n",
            "loss: 0.489331  [ 5600/ 8640]\n",
            "loss: 0.538818  [ 5680/ 8640]\n",
            "loss: 0.746683  [ 5760/ 8640]\n",
            "loss: 0.711618  [ 5840/ 8640]\n",
            "loss: 0.817321  [ 5920/ 8640]\n",
            "loss: 1.464643  [ 6000/ 8640]\n",
            "loss: 0.435414  [ 6080/ 8640]\n",
            "loss: 0.565003  [ 6160/ 8640]\n",
            "loss: 0.448507  [ 6240/ 8640]\n",
            "loss: 0.571510  [ 6320/ 8640]\n",
            "loss: 0.304824  [ 6400/ 8640]\n",
            "loss: 1.174858  [ 6480/ 8640]\n",
            "loss: 0.613432  [ 6560/ 8640]\n",
            "loss: 0.875902  [ 6640/ 8640]\n",
            "loss: 0.484536  [ 6720/ 8640]\n",
            "loss: 0.589246  [ 6800/ 8640]\n",
            "loss: 0.522712  [ 6880/ 8640]\n",
            "loss: 0.937457  [ 6960/ 8640]\n",
            "loss: 1.080058  [ 7040/ 8640]\n",
            "loss: 0.691518  [ 7120/ 8640]\n",
            "loss: 0.793405  [ 7200/ 8640]\n",
            "loss: 0.807853  [ 7280/ 8640]\n",
            "loss: 0.740960  [ 7360/ 8640]\n",
            "loss: 1.042059  [ 7440/ 8640]\n",
            "loss: 0.459211  [ 7520/ 8640]\n",
            "loss: 0.494517  [ 7600/ 8640]\n",
            "loss: 0.526556  [ 7680/ 8640]\n",
            "loss: 0.719500  [ 7760/ 8640]\n",
            "loss: 0.795784  [ 7840/ 8640]\n",
            "loss: 0.698537  [ 7920/ 8640]\n",
            "loss: 1.061863  [ 8000/ 8640]\n",
            "loss: 0.659624  [ 8080/ 8640]\n",
            "loss: 0.590191  [ 8160/ 8640]\n",
            "loss: 0.541433  [ 8240/ 8640]\n",
            "loss: 0.802810  [ 8320/ 8640]\n",
            "loss: 0.375667  [ 8400/ 8640]\n",
            "loss: 0.828170  [ 8480/ 8640]\n",
            "loss: 0.657754  [ 8560/ 8640]\n",
            "Validation loss: 67.92\n",
            "Early stopping triggered\n",
            "Test Accuracy: 67.92%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_50dfe27e-2e75-4208-9110-7b574e30bd99\", \"sample_text_add_b8_lr175e5_drop01_wd01.csv\", 8504)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "import random\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import CamembertTokenizer, CamembertModel\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def synonym_replacement(sentence, n):\n",
        "    words = sentence.split()\n",
        "    new_words = words.copy()\n",
        "    french_stopwords = set(nltk.corpus.stopwords.words('french'))\n",
        "    random_word_list = list(set([word for word in words if word not in french_stopwords]))\n",
        "    random.shuffle(random_word_list)\n",
        "    num_replaced = 0\n",
        "    for random_word in random_word_list:\n",
        "        synonyms = get_synonyms(random_word)\n",
        "        if len(synonyms) > 0:\n",
        "            synonym = random.choice(synonyms)\n",
        "            new_words = [synonym if word == random_word else word for word in new_words]\n",
        "            num_replaced += 1\n",
        "        if num_replaced >= n:  # Only replace up to n words\n",
        "            break\n",
        "    return ' '.join(new_words)\n",
        "\n",
        "def get_synonyms(word):\n",
        "    synonyms = set()\n",
        "    for syn in wordnet.synsets(word, lang='fra'):\n",
        "        for lemma in syn.lemmas(lang='fra'):\n",
        "            synonym = lemma.name().replace(\"_\", \" \").replace(\"-\", \" \").lower()\n",
        "            synonym = \"\".join([char for char in synonym if char.isalnum() or char.isspace()])\n",
        "            synonyms.add(synonym)\n",
        "    if word in synonyms:\n",
        "        synonyms.remove(word)\n",
        "    return list(synonyms)\n",
        "\n",
        "# Generate augmented sentences\n",
        "new_sentences = []\n",
        "new_difficulties = []\n",
        "for _, row in df_train.iterrows():\n",
        "    original_sentence = row['sentence']\n",
        "    difficulty = row['difficulty']\n",
        "    augmented_sentence = synonym_replacement(original_sentence, 2)\n",
        "    new_sentences.append(augmented_sentence)\n",
        "    new_difficulties.append(difficulty)\n",
        "\n",
        "# Create a new DataFrame for the augmented sentences\n",
        "df_augmented = pd.DataFrame({'sentence': new_sentences, 'difficulty': new_difficulties})\n",
        "\n",
        "# Concatenate the original and augmented DataFrames\n",
        "df_combined = pd.concat([df_train, df_augmented], ignore_index=True)\n",
        "\n",
        "# Load your data\n",
        "data = df_combined\n",
        "sentences = data['sentence'].tolist()\n",
        "difficulties = data['difficulty'].tolist()\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(difficulties)\n",
        "\n",
        "# Load CamemBERT tokenizer and model\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
        "camembert = CamembertModel.from_pretrained('camembert-base')\n",
        "\n",
        "# Tokenize sentences and convert to tensor\n",
        "def tokenize_and_encode(sentences):\n",
        "    return tokenizer(sentences, padding=True, truncation=True, max_length=600, return_tensors='pt')\n",
        "\n",
        "# Custom Dataset class\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.encodings = tokenize_and_encode(texts)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: self.encodings[key][idx] for key in self.encodings}, self.labels[idx]\n",
        "\n",
        "# Data preparation\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    sentences, encoded_labels, test_size=0.1, random_state=42, stratify=encoded_labels\n",
        ")\n",
        "\n",
        "train_dataset = TextDataset(X_train, y_train)\n",
        "test_dataset = TextDataset(X_test, y_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# Neural network model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Net, self).__init__()\n",
        "        self.camembert = camembert\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        self.fc = nn.Linear(self.camembert.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        outputs = self.camembert(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.fc(pooled_output)\n",
        "        return logits\n",
        "\n",
        "# Instantiate the model, loss, and optimizer\n",
        "model = Net(len(label_encoder.classes_)).to('cuda')\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1.75e-5, weight_decay=0.1)\n",
        "\n",
        "# Early stopping parameters\n",
        "early_stopping_patience = 1\n",
        "best_loss = float('inf')\n",
        "patience_counter = 0\n",
        "\n",
        "# Function to compute accuracy\n",
        "def compute_accuracy(dataloader, model):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            inputs, labels = batch\n",
        "            inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
        "            labels = labels.to('cuda')\n",
        "            outputs = model(**inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "# Training loop\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()  # Set model to training mode\n",
        "    for batch, (inputs, labels) in enumerate(dataloader):\n",
        "        inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
        "        labels = labels.to('cuda')\n",
        "        pred = model(**inputs)\n",
        "        loss = loss_fn(pred, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 10 == 0:\n",
        "            loss, current = loss.item(), batch * len(inputs['input_ids'])\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "# Execute training\n",
        "for epoch in range(10):  # Number of epochs\n",
        "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
        "    train_loop(train_loader, model, criterion, optimizer)\n",
        "    val_loss = compute_accuracy(test_loader, model)\n",
        "    print(f\"Validation loss: {val_loss:.2f}\")\n",
        "\n",
        "    # Check for early stopping\n",
        "    if val_loss < best_loss:\n",
        "        best_loss = val_loss\n",
        "        patience_counter = 0\n",
        "        # Save the model\n",
        "        torch.save(model.state_dict(), 'best_model.pth')\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= early_stopping_patience:\n",
        "            print(\"Early stopping triggered\")\n",
        "            break\n",
        "\n",
        "# Load the best model\n",
        "#model.load_state_dict(torch.load('best_model.pth'))\n",
        "\n",
        "# Test the model\n",
        "accuracy = compute_accuracy(test_loader, model)\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "# Further processing for generating predictions and submission remains the same...\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import CamembertTokenizer\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
        "\n",
        "# Tokenize and encode the test data\n",
        "def tokenize_and_encode(sentences):\n",
        "    return tokenizer(sentences, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
        "\n",
        "# Custom Dataset class for test data\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, texts):\n",
        "        self.encodings = tokenize_and_encode(texts)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings['input_ids'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: self.encodings[key][idx] for key in self.encodings}\n",
        "\n",
        "# Create the dataset and dataloader for df_test\n",
        "test_dataset = TestDataset(df_test['sentence'].tolist())\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# Define the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Generate predictions for df_test\n",
        "model.eval()  # Make sure the model is in evaluation mode\n",
        "all_predictions = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        inputs = {key: value.to(device) for key, value in batch.items()}\n",
        "        outputs = model(**inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "# Convert numeric predictions back to labels\n",
        "predicted_labels = label_encoder.inverse_transform(all_predictions)\n",
        "\n",
        "# Prepare and save the submission file\n",
        "submission_df = pd.DataFrame({\n",
        "    'id': df_test['id'],  # Ensure df_test includes an 'id' column\n",
        "    'difficulty': predicted_labels\n",
        "})\n",
        "\n",
        "submission_df.to_csv('sample_text_add_b8_lr175e5_drop01_wd01.csv', index=False)\n",
        "from google.colab import files\n",
        "files.download('sample_text_add_b8_lr175e5_drop01_wd01.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OZidCFoQBZMB",
        "outputId": "d99406b7-a317-43ca-ca41-5b46bcc13b3e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 1.784604  [    0/ 8640]\n",
            "loss: 1.783562  [   80/ 8640]\n",
            "loss: 1.782790  [  160/ 8640]\n",
            "loss: 1.791610  [  240/ 8640]\n",
            "loss: 1.737871  [  320/ 8640]\n",
            "loss: 1.794748  [  400/ 8640]\n",
            "loss: 1.759478  [  480/ 8640]\n",
            "loss: 1.708128  [  560/ 8640]\n",
            "loss: 1.709434  [  640/ 8640]\n",
            "loss: 1.703352  [  720/ 8640]\n",
            "loss: 1.648378  [  800/ 8640]\n",
            "loss: 1.637098  [  880/ 8640]\n",
            "loss: 1.668722  [  960/ 8640]\n",
            "loss: 1.471904  [ 1040/ 8640]\n",
            "loss: 1.524548  [ 1120/ 8640]\n",
            "loss: 1.542871  [ 1200/ 8640]\n",
            "loss: 1.490619  [ 1280/ 8640]\n",
            "loss: 1.386975  [ 1360/ 8640]\n",
            "loss: 1.389264  [ 1440/ 8640]\n",
            "loss: 1.563174  [ 1520/ 8640]\n",
            "loss: 1.457448  [ 1600/ 8640]\n",
            "loss: 1.595213  [ 1680/ 8640]\n",
            "loss: 1.287173  [ 1760/ 8640]\n",
            "loss: 1.390197  [ 1840/ 8640]\n",
            "loss: 1.600583  [ 1920/ 8640]\n",
            "loss: 1.347261  [ 2000/ 8640]\n",
            "loss: 1.258888  [ 2080/ 8640]\n",
            "loss: 1.322496  [ 2160/ 8640]\n",
            "loss: 1.269006  [ 2240/ 8640]\n",
            "loss: 1.250496  [ 2320/ 8640]\n",
            "loss: 1.841937  [ 2400/ 8640]\n",
            "loss: 1.247155  [ 2480/ 8640]\n",
            "loss: 1.311186  [ 2560/ 8640]\n",
            "loss: 1.410153  [ 2640/ 8640]\n",
            "loss: 1.115618  [ 2720/ 8640]\n",
            "loss: 1.065127  [ 2800/ 8640]\n",
            "loss: 1.073190  [ 2880/ 8640]\n",
            "loss: 1.283115  [ 2960/ 8640]\n",
            "loss: 1.142235  [ 3040/ 8640]\n",
            "loss: 0.982461  [ 3120/ 8640]\n",
            "loss: 1.401359  [ 3200/ 8640]\n",
            "loss: 0.989080  [ 3280/ 8640]\n",
            "loss: 1.074760  [ 3360/ 8640]\n",
            "loss: 1.059883  [ 3440/ 8640]\n",
            "loss: 1.114369  [ 3520/ 8640]\n",
            "loss: 1.092331  [ 3600/ 8640]\n",
            "loss: 1.067098  [ 3680/ 8640]\n",
            "loss: 1.101071  [ 3760/ 8640]\n",
            "loss: 1.065593  [ 3840/ 8640]\n",
            "loss: 1.287895  [ 3920/ 8640]\n",
            "loss: 0.798363  [ 4000/ 8640]\n",
            "loss: 0.923153  [ 4080/ 8640]\n",
            "loss: 1.174455  [ 4160/ 8640]\n",
            "loss: 0.773746  [ 4240/ 8640]\n",
            "loss: 1.540314  [ 4320/ 8640]\n",
            "loss: 1.292539  [ 4400/ 8640]\n",
            "loss: 1.121947  [ 4480/ 8640]\n",
            "loss: 1.088848  [ 4560/ 8640]\n",
            "loss: 1.264319  [ 4640/ 8640]\n",
            "loss: 0.972096  [ 4720/ 8640]\n",
            "loss: 1.076801  [ 4800/ 8640]\n",
            "loss: 1.221672  [ 4880/ 8640]\n",
            "loss: 1.519215  [ 4960/ 8640]\n",
            "loss: 1.299945  [ 5040/ 8640]\n",
            "loss: 0.904143  [ 5120/ 8640]\n",
            "loss: 0.706911  [ 5200/ 8640]\n",
            "loss: 0.928612  [ 5280/ 8640]\n",
            "loss: 1.371708  [ 5360/ 8640]\n",
            "loss: 0.907486  [ 5440/ 8640]\n",
            "loss: 0.866967  [ 5520/ 8640]\n",
            "loss: 1.279595  [ 5600/ 8640]\n",
            "loss: 0.942728  [ 5680/ 8640]\n",
            "loss: 1.069275  [ 5760/ 8640]\n",
            "loss: 0.905822  [ 5840/ 8640]\n",
            "loss: 1.314869  [ 5920/ 8640]\n",
            "loss: 1.115255  [ 6000/ 8640]\n",
            "loss: 1.126971  [ 6080/ 8640]\n",
            "loss: 1.023197  [ 6160/ 8640]\n",
            "loss: 0.790353  [ 6240/ 8640]\n",
            "loss: 0.784515  [ 6320/ 8640]\n",
            "loss: 0.960714  [ 6400/ 8640]\n",
            "loss: 1.154474  [ 6480/ 8640]\n",
            "loss: 0.905945  [ 6560/ 8640]\n",
            "loss: 1.221481  [ 6640/ 8640]\n",
            "loss: 0.885839  [ 6720/ 8640]\n",
            "loss: 1.318762  [ 6800/ 8640]\n",
            "loss: 1.010040  [ 6880/ 8640]\n",
            "loss: 1.133978  [ 6960/ 8640]\n",
            "loss: 0.922698  [ 7040/ 8640]\n",
            "loss: 0.642907  [ 7120/ 8640]\n",
            "loss: 1.029989  [ 7200/ 8640]\n",
            "loss: 1.232007  [ 7280/ 8640]\n",
            "loss: 0.689985  [ 7360/ 8640]\n",
            "loss: 1.302975  [ 7440/ 8640]\n",
            "loss: 0.822543  [ 7520/ 8640]\n",
            "loss: 0.668608  [ 7600/ 8640]\n",
            "loss: 1.686181  [ 7680/ 8640]\n",
            "loss: 1.118031  [ 7760/ 8640]\n",
            "loss: 0.866929  [ 7840/ 8640]\n",
            "loss: 1.278832  [ 7920/ 8640]\n",
            "loss: 1.697736  [ 8000/ 8640]\n",
            "loss: 0.887785  [ 8080/ 8640]\n",
            "loss: 0.998591  [ 8160/ 8640]\n",
            "loss: 0.716703  [ 8240/ 8640]\n",
            "loss: 0.931187  [ 8320/ 8640]\n",
            "loss: 0.731886  [ 8400/ 8640]\n",
            "loss: 0.980635  [ 8480/ 8640]\n",
            "loss: 1.124107  [ 8560/ 8640]\n",
            "Validation loss: 58.23\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.792940  [    0/ 8640]\n",
            "loss: 1.006399  [   80/ 8640]\n",
            "loss: 0.932572  [  160/ 8640]\n",
            "loss: 0.896669  [  240/ 8640]\n",
            "loss: 0.744018  [  320/ 8640]\n",
            "loss: 0.591225  [  400/ 8640]\n",
            "loss: 0.861753  [  480/ 8640]\n",
            "loss: 0.699971  [  560/ 8640]\n",
            "loss: 0.721364  [  640/ 8640]\n",
            "loss: 0.714307  [  720/ 8640]\n",
            "loss: 0.790406  [  800/ 8640]\n",
            "loss: 1.082686  [  880/ 8640]\n",
            "loss: 0.756706  [  960/ 8640]\n",
            "loss: 0.904435  [ 1040/ 8640]\n",
            "loss: 0.715404  [ 1120/ 8640]\n",
            "loss: 0.527764  [ 1200/ 8640]\n",
            "loss: 0.762521  [ 1280/ 8640]\n",
            "loss: 0.558663  [ 1360/ 8640]\n",
            "loss: 1.641860  [ 1440/ 8640]\n",
            "loss: 0.993971  [ 1520/ 8640]\n",
            "loss: 0.741072  [ 1600/ 8640]\n",
            "loss: 0.753161  [ 1680/ 8640]\n",
            "loss: 1.310724  [ 1760/ 8640]\n",
            "loss: 0.973583  [ 1840/ 8640]\n",
            "loss: 0.702503  [ 1920/ 8640]\n",
            "loss: 0.759477  [ 2000/ 8640]\n",
            "loss: 1.064707  [ 2080/ 8640]\n",
            "loss: 1.073192  [ 2160/ 8640]\n",
            "loss: 0.728307  [ 2240/ 8640]\n",
            "loss: 1.062506  [ 2320/ 8640]\n",
            "loss: 0.750449  [ 2400/ 8640]\n",
            "loss: 0.750029  [ 2480/ 8640]\n",
            "loss: 0.770104  [ 2560/ 8640]\n",
            "loss: 0.485640  [ 2640/ 8640]\n",
            "loss: 1.405404  [ 2720/ 8640]\n",
            "loss: 0.944870  [ 2800/ 8640]\n",
            "loss: 0.643476  [ 2880/ 8640]\n",
            "loss: 0.803793  [ 2960/ 8640]\n",
            "loss: 1.313799  [ 3040/ 8640]\n",
            "loss: 0.701936  [ 3120/ 8640]\n",
            "loss: 0.983712  [ 3200/ 8640]\n",
            "loss: 0.717048  [ 3280/ 8640]\n",
            "loss: 0.832218  [ 3360/ 8640]\n",
            "loss: 0.435207  [ 3440/ 8640]\n",
            "loss: 1.181881  [ 3520/ 8640]\n",
            "loss: 0.568548  [ 3600/ 8640]\n",
            "loss: 0.940755  [ 3680/ 8640]\n",
            "loss: 1.450594  [ 3760/ 8640]\n",
            "loss: 0.764377  [ 3840/ 8640]\n",
            "loss: 0.796679  [ 3920/ 8640]\n",
            "loss: 1.097912  [ 4000/ 8640]\n",
            "loss: 1.730010  [ 4080/ 8640]\n",
            "loss: 1.016306  [ 4160/ 8640]\n",
            "loss: 0.698944  [ 4240/ 8640]\n",
            "loss: 1.222730  [ 4320/ 8640]\n",
            "loss: 0.832606  [ 4400/ 8640]\n",
            "loss: 0.586400  [ 4480/ 8640]\n",
            "loss: 0.820845  [ 4560/ 8640]\n",
            "loss: 1.553836  [ 4640/ 8640]\n",
            "loss: 0.686331  [ 4720/ 8640]\n",
            "loss: 1.122221  [ 4800/ 8640]\n",
            "loss: 0.750076  [ 4880/ 8640]\n",
            "loss: 0.561050  [ 4960/ 8640]\n",
            "loss: 0.311760  [ 5040/ 8640]\n",
            "loss: 0.452756  [ 5120/ 8640]\n",
            "loss: 0.585963  [ 5200/ 8640]\n",
            "loss: 0.972551  [ 5280/ 8640]\n",
            "loss: 1.056074  [ 5360/ 8640]\n",
            "loss: 0.360344  [ 5440/ 8640]\n",
            "loss: 0.694793  [ 5520/ 8640]\n",
            "loss: 0.864331  [ 5600/ 8640]\n",
            "loss: 1.476787  [ 5680/ 8640]\n",
            "loss: 0.523655  [ 5760/ 8640]\n",
            "loss: 0.932816  [ 5840/ 8640]\n",
            "loss: 1.000282  [ 5920/ 8640]\n",
            "loss: 1.087542  [ 6000/ 8640]\n",
            "loss: 0.757956  [ 6080/ 8640]\n",
            "loss: 0.711075  [ 6160/ 8640]\n",
            "loss: 1.056774  [ 6240/ 8640]\n",
            "loss: 1.027801  [ 6320/ 8640]\n",
            "loss: 0.570998  [ 6400/ 8640]\n",
            "loss: 0.742035  [ 6480/ 8640]\n",
            "loss: 0.790051  [ 6560/ 8640]\n",
            "loss: 0.878609  [ 6640/ 8640]\n",
            "loss: 0.736549  [ 6720/ 8640]\n",
            "loss: 1.077160  [ 6800/ 8640]\n",
            "loss: 0.466715  [ 6880/ 8640]\n",
            "loss: 0.597640  [ 6960/ 8640]\n",
            "loss: 0.566575  [ 7040/ 8640]\n",
            "loss: 0.796791  [ 7120/ 8640]\n",
            "loss: 0.824976  [ 7200/ 8640]\n",
            "loss: 0.814228  [ 7280/ 8640]\n",
            "loss: 0.713822  [ 7360/ 8640]\n",
            "loss: 0.767576  [ 7440/ 8640]\n",
            "loss: 0.745045  [ 7520/ 8640]\n",
            "loss: 0.338408  [ 7600/ 8640]\n",
            "loss: 0.746210  [ 7680/ 8640]\n",
            "loss: 0.493020  [ 7760/ 8640]\n",
            "loss: 0.422479  [ 7840/ 8640]\n",
            "loss: 1.016418  [ 7920/ 8640]\n",
            "loss: 0.638490  [ 8000/ 8640]\n",
            "loss: 0.958486  [ 8080/ 8640]\n",
            "loss: 0.502744  [ 8160/ 8640]\n",
            "loss: 0.862080  [ 8240/ 8640]\n",
            "loss: 1.220577  [ 8320/ 8640]\n",
            "loss: 0.945643  [ 8400/ 8640]\n",
            "loss: 0.532565  [ 8480/ 8640]\n",
            "loss: 0.570543  [ 8560/ 8640]\n",
            "Validation loss: 65.62\n",
            "Early stopping triggered\n",
            "Test Accuracy: 65.62%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_8efa1be3-f252-4fe5-a07c-e00dbe6b21ec\", \"sample_text_add_b8_lr175e5_drop01_wd005.csv\", 8504)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "import random\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import CamembertTokenizer, CamembertModel\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def synonym_replacement(sentence, n):\n",
        "    words = sentence.split()\n",
        "    new_words = words.copy()\n",
        "    french_stopwords = set(nltk.corpus.stopwords.words('french'))\n",
        "    random_word_list = list(set([word for word in words if word not in french_stopwords]))\n",
        "    random.shuffle(random_word_list)\n",
        "    num_replaced = 0\n",
        "    for random_word in random_word_list:\n",
        "        synonyms = get_synonyms(random_word)\n",
        "        if len(synonyms) > 0:\n",
        "            synonym = random.choice(synonyms)\n",
        "            new_words = [synonym if word == random_word else word for word in new_words]\n",
        "            num_replaced += 1\n",
        "        if num_replaced >= n:  # Only replace up to n words\n",
        "            break\n",
        "    return ' '.join(new_words)\n",
        "\n",
        "def get_synonyms(word):\n",
        "    synonyms = set()\n",
        "    for syn in wordnet.synsets(word, lang='fra'):\n",
        "        for lemma in syn.lemmas(lang='fra'):\n",
        "            synonym = lemma.name().replace(\"_\", \" \").replace(\"-\", \" \").lower()\n",
        "            synonym = \"\".join([char for char in synonym if char.isalnum() or char.isspace()])\n",
        "            synonyms.add(synonym)\n",
        "    if word in synonyms:\n",
        "        synonyms.remove(word)\n",
        "    return list(synonyms)\n",
        "\n",
        "# Generate augmented sentences\n",
        "new_sentences = []\n",
        "new_difficulties = []\n",
        "for _, row in df_train.iterrows():\n",
        "    original_sentence = row['sentence']\n",
        "    difficulty = row['difficulty']\n",
        "    augmented_sentence = synonym_replacement(original_sentence, 2)\n",
        "    new_sentences.append(augmented_sentence)\n",
        "    new_difficulties.append(difficulty)\n",
        "\n",
        "# Create a new DataFrame for the augmented sentences\n",
        "df_augmented = pd.DataFrame({'sentence': new_sentences, 'difficulty': new_difficulties})\n",
        "\n",
        "# Concatenate the original and augmented DataFrames\n",
        "df_combined = pd.concat([df_train, df_augmented], ignore_index=True)\n",
        "\n",
        "# Load your data\n",
        "data = df_combined\n",
        "sentences = data['sentence'].tolist()\n",
        "difficulties = data['difficulty'].tolist()\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(difficulties)\n",
        "\n",
        "# Load CamemBERT tokenizer and model\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
        "camembert = CamembertModel.from_pretrained('camembert-base')\n",
        "\n",
        "# Tokenize sentences and convert to tensor\n",
        "def tokenize_and_encode(sentences):\n",
        "    return tokenizer(sentences, padding=True, truncation=True, max_length=600, return_tensors='pt')\n",
        "\n",
        "# Custom Dataset class\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.encodings = tokenize_and_encode(texts)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: self.encodings[key][idx] for key in self.encodings}, self.labels[idx]\n",
        "\n",
        "# Data preparation\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    sentences, encoded_labels, test_size=0.1, random_state=42, stratify=encoded_labels\n",
        ")\n",
        "\n",
        "train_dataset = TextDataset(X_train, y_train)\n",
        "test_dataset = TextDataset(X_test, y_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# Neural network model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Net, self).__init__()\n",
        "        self.camembert = camembert\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        self.fc = nn.Linear(self.camembert.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        outputs = self.camembert(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.fc(pooled_output)\n",
        "        return logits\n",
        "\n",
        "# Instantiate the model, loss, and optimizer\n",
        "model = Net(len(label_encoder.classes_)).to('cuda')\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1.75e-5, weight_decay=0.05)\n",
        "\n",
        "# Early stopping parameters\n",
        "early_stopping_patience = 1\n",
        "best_loss = float('inf')\n",
        "patience_counter = 0\n",
        "\n",
        "# Function to compute accuracy\n",
        "def compute_accuracy(dataloader, model):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            inputs, labels = batch\n",
        "            inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
        "            labels = labels.to('cuda')\n",
        "            outputs = model(**inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "# Training loop\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()  # Set model to training mode\n",
        "    for batch, (inputs, labels) in enumerate(dataloader):\n",
        "        inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
        "        labels = labels.to('cuda')\n",
        "        pred = model(**inputs)\n",
        "        loss = loss_fn(pred, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 10 == 0:\n",
        "            loss, current = loss.item(), batch * len(inputs['input_ids'])\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "# Execute training\n",
        "for epoch in range(10):  # Number of epochs\n",
        "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
        "    train_loop(train_loader, model, criterion, optimizer)\n",
        "    val_loss = compute_accuracy(test_loader, model)\n",
        "    print(f\"Validation loss: {val_loss:.2f}\")\n",
        "\n",
        "    # Check for early stopping\n",
        "    if val_loss < best_loss:\n",
        "        best_loss = val_loss\n",
        "        patience_counter = 0\n",
        "        # Save the model\n",
        "        torch.save(model.state_dict(), 'best_model.pth')\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= early_stopping_patience:\n",
        "            print(\"Early stopping triggered\")\n",
        "            break\n",
        "\n",
        "# Load the best model\n",
        "#model.load_state_dict(torch.load('best_model.pth'))\n",
        "\n",
        "# Test the model\n",
        "accuracy = compute_accuracy(test_loader, model)\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "# Further processing for generating predictions and submission remains the same...\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import CamembertTokenizer\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
        "\n",
        "# Tokenize and encode the test data\n",
        "def tokenize_and_encode(sentences):\n",
        "    return tokenizer(sentences, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
        "\n",
        "# Custom Dataset class for test data\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, texts):\n",
        "        self.encodings = tokenize_and_encode(texts)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings['input_ids'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: self.encodings[key][idx] for key in self.encodings}\n",
        "\n",
        "# Create the dataset and dataloader for df_test\n",
        "test_dataset = TestDataset(df_test['sentence'].tolist())\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# Define the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Generate predictions for df_test\n",
        "model.eval()  # Make sure the model is in evaluation mode\n",
        "all_predictions = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        inputs = {key: value.to(device) for key, value in batch.items()}\n",
        "        outputs = model(**inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "# Convert numeric predictions back to labels\n",
        "predicted_labels = label_encoder.inverse_transform(all_predictions)\n",
        "\n",
        "# Prepare and save the submission file\n",
        "submission_df = pd.DataFrame({\n",
        "    'id': df_test['id'],  # Ensure df_test includes an 'id' column\n",
        "    'difficulty': predicted_labels\n",
        "})\n",
        "\n",
        "submission_df.to_csv('sample_text_add_b8_lr175e5_drop01_wd005.csv', index=False)\n",
        "from google.colab import files\n",
        "files.download('sample_text_add_b8_lr175e5_drop01_wd005.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "i9P-NkRCHLeo",
        "outputId": "c8ae6b4b-1003-4c3e-8401-200cb1c2581a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 1.798753  [    0/ 8640]\n",
            "loss: 1.747671  [   80/ 8640]\n",
            "loss: 1.749572  [  160/ 8640]\n",
            "loss: 1.733417  [  240/ 8640]\n",
            "loss: 1.800035  [  320/ 8640]\n",
            "loss: 1.789371  [  400/ 8640]\n",
            "loss: 1.718962  [  480/ 8640]\n",
            "loss: 1.686798  [  560/ 8640]\n",
            "loss: 1.642476  [  640/ 8640]\n",
            "loss: 1.639246  [  720/ 8640]\n",
            "loss: 1.652835  [  800/ 8640]\n",
            "loss: 1.665615  [  880/ 8640]\n",
            "loss: 1.588026  [  960/ 8640]\n",
            "loss: 1.440770  [ 1040/ 8640]\n",
            "loss: 1.342685  [ 1120/ 8640]\n",
            "loss: 1.487931  [ 1200/ 8640]\n",
            "loss: 1.434970  [ 1280/ 8640]\n",
            "loss: 1.629258  [ 1360/ 8640]\n",
            "loss: 1.273824  [ 1440/ 8640]\n",
            "loss: 1.372522  [ 1520/ 8640]\n",
            "loss: 1.150522  [ 1600/ 8640]\n",
            "loss: 1.369034  [ 1680/ 8640]\n",
            "loss: 1.531774  [ 1760/ 8640]\n",
            "loss: 1.754651  [ 1840/ 8640]\n",
            "loss: 1.164102  [ 1920/ 8640]\n",
            "loss: 1.445399  [ 2000/ 8640]\n",
            "loss: 1.292204  [ 2080/ 8640]\n",
            "loss: 1.528812  [ 2160/ 8640]\n",
            "loss: 1.291221  [ 2240/ 8640]\n",
            "loss: 1.054811  [ 2320/ 8640]\n",
            "loss: 1.016702  [ 2400/ 8640]\n",
            "loss: 1.098799  [ 2480/ 8640]\n",
            "loss: 0.984117  [ 2560/ 8640]\n",
            "loss: 1.558531  [ 2640/ 8640]\n",
            "loss: 1.077175  [ 2720/ 8640]\n",
            "loss: 1.208067  [ 2800/ 8640]\n",
            "loss: 1.271573  [ 2880/ 8640]\n",
            "loss: 1.572734  [ 2960/ 8640]\n",
            "loss: 1.255024  [ 3040/ 8640]\n",
            "loss: 1.414444  [ 3120/ 8640]\n",
            "loss: 1.119382  [ 3200/ 8640]\n",
            "loss: 1.325234  [ 3280/ 8640]\n",
            "loss: 1.121046  [ 3360/ 8640]\n",
            "loss: 1.043973  [ 3440/ 8640]\n",
            "loss: 1.583422  [ 3520/ 8640]\n",
            "loss: 1.015765  [ 3600/ 8640]\n",
            "loss: 1.176999  [ 3680/ 8640]\n",
            "loss: 1.115621  [ 3760/ 8640]\n",
            "loss: 1.101785  [ 3840/ 8640]\n",
            "loss: 1.023130  [ 3920/ 8640]\n",
            "loss: 1.307823  [ 4000/ 8640]\n",
            "loss: 1.549695  [ 4080/ 8640]\n",
            "loss: 1.018865  [ 4160/ 8640]\n",
            "loss: 1.020015  [ 4240/ 8640]\n",
            "loss: 1.352098  [ 4320/ 8640]\n",
            "loss: 0.938182  [ 4400/ 8640]\n",
            "loss: 1.025533  [ 4480/ 8640]\n",
            "loss: 1.141817  [ 4560/ 8640]\n",
            "loss: 1.061708  [ 4640/ 8640]\n",
            "loss: 1.677800  [ 4720/ 8640]\n",
            "loss: 1.663181  [ 4800/ 8640]\n",
            "loss: 1.033607  [ 4880/ 8640]\n",
            "loss: 1.125943  [ 4960/ 8640]\n",
            "loss: 1.182557  [ 5040/ 8640]\n",
            "loss: 0.961853  [ 5120/ 8640]\n",
            "loss: 0.939302  [ 5200/ 8640]\n",
            "loss: 0.843151  [ 5280/ 8640]\n",
            "loss: 1.770741  [ 5360/ 8640]\n",
            "loss: 1.005294  [ 5440/ 8640]\n",
            "loss: 0.994257  [ 5520/ 8640]\n",
            "loss: 1.276842  [ 5600/ 8640]\n",
            "loss: 1.086587  [ 5680/ 8640]\n",
            "loss: 1.256743  [ 5760/ 8640]\n",
            "loss: 1.002161  [ 5840/ 8640]\n",
            "loss: 1.101348  [ 5920/ 8640]\n",
            "loss: 1.139842  [ 6000/ 8640]\n",
            "loss: 1.344475  [ 6080/ 8640]\n",
            "loss: 1.351498  [ 6160/ 8640]\n",
            "loss: 1.062128  [ 6240/ 8640]\n",
            "loss: 0.752784  [ 6320/ 8640]\n",
            "loss: 1.398250  [ 6400/ 8640]\n",
            "loss: 0.911656  [ 6480/ 8640]\n",
            "loss: 1.639263  [ 6560/ 8640]\n",
            "loss: 1.428945  [ 6640/ 8640]\n",
            "loss: 0.863036  [ 6720/ 8640]\n",
            "loss: 0.828030  [ 6800/ 8640]\n",
            "loss: 1.131197  [ 6880/ 8640]\n",
            "loss: 1.192111  [ 6960/ 8640]\n",
            "loss: 0.992170  [ 7040/ 8640]\n",
            "loss: 0.878921  [ 7120/ 8640]\n",
            "loss: 0.716079  [ 7200/ 8640]\n",
            "loss: 1.153145  [ 7280/ 8640]\n",
            "loss: 1.035433  [ 7360/ 8640]\n",
            "loss: 0.850303  [ 7440/ 8640]\n",
            "loss: 0.997496  [ 7520/ 8640]\n",
            "loss: 1.142724  [ 7600/ 8640]\n",
            "loss: 0.704585  [ 7680/ 8640]\n",
            "loss: 0.875769  [ 7760/ 8640]\n",
            "loss: 1.374050  [ 7840/ 8640]\n",
            "loss: 1.170154  [ 7920/ 8640]\n",
            "loss: 0.807109  [ 8000/ 8640]\n",
            "loss: 0.997729  [ 8080/ 8640]\n",
            "loss: 1.104270  [ 8160/ 8640]\n",
            "loss: 0.872724  [ 8240/ 8640]\n",
            "loss: 0.990176  [ 8320/ 8640]\n",
            "loss: 1.257920  [ 8400/ 8640]\n",
            "loss: 0.900022  [ 8480/ 8640]\n",
            "loss: 0.774514  [ 8560/ 8640]\n",
            "Validation loss: 55.52\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 1.255459  [    0/ 8640]\n",
            "loss: 0.776742  [   80/ 8640]\n",
            "loss: 0.751754  [  160/ 8640]\n",
            "loss: 0.857037  [  240/ 8640]\n",
            "loss: 1.108645  [  320/ 8640]\n",
            "loss: 0.732997  [  400/ 8640]\n",
            "loss: 0.751322  [  480/ 8640]\n",
            "loss: 0.838695  [  560/ 8640]\n",
            "loss: 0.628638  [  640/ 8640]\n",
            "loss: 0.952083  [  720/ 8640]\n",
            "loss: 1.292302  [  800/ 8640]\n",
            "loss: 0.678059  [  880/ 8640]\n",
            "loss: 0.909126  [  960/ 8640]\n",
            "loss: 0.925614  [ 1040/ 8640]\n",
            "loss: 1.067948  [ 1120/ 8640]\n",
            "loss: 1.110368  [ 1200/ 8640]\n",
            "loss: 0.811772  [ 1280/ 8640]\n",
            "loss: 0.512569  [ 1360/ 8640]\n",
            "loss: 0.863663  [ 1440/ 8640]\n",
            "loss: 0.887342  [ 1520/ 8640]\n",
            "loss: 0.702717  [ 1600/ 8640]\n",
            "loss: 0.982771  [ 1680/ 8640]\n",
            "loss: 1.031647  [ 1760/ 8640]\n",
            "loss: 1.020086  [ 1840/ 8640]\n",
            "loss: 0.927599  [ 1920/ 8640]\n",
            "loss: 1.174481  [ 2000/ 8640]\n",
            "loss: 0.563655  [ 2080/ 8640]\n",
            "loss: 1.189512  [ 2160/ 8640]\n",
            "loss: 1.065822  [ 2240/ 8640]\n",
            "loss: 0.929318  [ 2320/ 8640]\n",
            "loss: 0.930797  [ 2400/ 8640]\n",
            "loss: 0.531683  [ 2480/ 8640]\n",
            "loss: 1.426355  [ 2560/ 8640]\n",
            "loss: 0.813056  [ 2640/ 8640]\n",
            "loss: 0.593366  [ 2720/ 8640]\n",
            "loss: 1.103006  [ 2800/ 8640]\n",
            "loss: 0.459713  [ 2880/ 8640]\n",
            "loss: 0.669403  [ 2960/ 8640]\n",
            "loss: 0.529469  [ 3040/ 8640]\n",
            "loss: 0.561534  [ 3120/ 8640]\n",
            "loss: 0.627139  [ 3200/ 8640]\n",
            "loss: 1.054068  [ 3280/ 8640]\n",
            "loss: 0.773418  [ 3360/ 8640]\n",
            "loss: 0.968095  [ 3440/ 8640]\n",
            "loss: 1.003755  [ 3520/ 8640]\n",
            "loss: 1.229613  [ 3600/ 8640]\n",
            "loss: 0.874179  [ 3680/ 8640]\n",
            "loss: 0.411390  [ 3760/ 8640]\n",
            "loss: 0.917739  [ 3840/ 8640]\n",
            "loss: 0.976473  [ 3920/ 8640]\n",
            "loss: 0.766179  [ 4000/ 8640]\n",
            "loss: 0.400442  [ 4080/ 8640]\n",
            "loss: 0.810303  [ 4160/ 8640]\n",
            "loss: 0.689177  [ 4240/ 8640]\n",
            "loss: 0.703394  [ 4320/ 8640]\n",
            "loss: 0.576706  [ 4400/ 8640]\n",
            "loss: 0.849263  [ 4480/ 8640]\n",
            "loss: 0.910525  [ 4560/ 8640]\n",
            "loss: 1.103069  [ 4640/ 8640]\n",
            "loss: 0.663536  [ 4720/ 8640]\n",
            "loss: 0.851715  [ 4800/ 8640]\n",
            "loss: 1.037872  [ 4880/ 8640]\n",
            "loss: 0.863816  [ 4960/ 8640]\n",
            "loss: 0.689848  [ 5040/ 8640]\n",
            "loss: 0.518491  [ 5120/ 8640]\n",
            "loss: 0.387271  [ 5200/ 8640]\n",
            "loss: 0.957748  [ 5280/ 8640]\n",
            "loss: 0.635081  [ 5360/ 8640]\n",
            "loss: 0.762999  [ 5440/ 8640]\n",
            "loss: 0.651642  [ 5520/ 8640]\n",
            "loss: 0.447106  [ 5600/ 8640]\n",
            "loss: 0.507668  [ 5680/ 8640]\n",
            "loss: 0.860904  [ 5760/ 8640]\n",
            "loss: 0.808956  [ 5840/ 8640]\n",
            "loss: 0.831003  [ 5920/ 8640]\n",
            "loss: 0.557979  [ 6000/ 8640]\n",
            "loss: 0.354543  [ 6080/ 8640]\n",
            "loss: 0.580285  [ 6160/ 8640]\n",
            "loss: 0.685431  [ 6240/ 8640]\n",
            "loss: 0.754398  [ 6320/ 8640]\n",
            "loss: 0.891163  [ 6400/ 8640]\n",
            "loss: 0.580828  [ 6480/ 8640]\n",
            "loss: 0.947429  [ 6560/ 8640]\n",
            "loss: 0.639856  [ 6640/ 8640]\n",
            "loss: 0.535503  [ 6720/ 8640]\n",
            "loss: 0.279175  [ 6800/ 8640]\n",
            "loss: 0.548428  [ 6880/ 8640]\n",
            "loss: 1.044020  [ 6960/ 8640]\n",
            "loss: 0.707472  [ 7040/ 8640]\n",
            "loss: 0.407824  [ 7120/ 8640]\n",
            "loss: 0.565759  [ 7200/ 8640]\n",
            "loss: 0.679597  [ 7280/ 8640]\n",
            "loss: 0.900552  [ 7360/ 8640]\n",
            "loss: 0.269829  [ 7440/ 8640]\n",
            "loss: 0.768460  [ 7520/ 8640]\n",
            "loss: 0.862517  [ 7600/ 8640]\n",
            "loss: 1.001014  [ 7680/ 8640]\n",
            "loss: 0.529090  [ 7760/ 8640]\n",
            "loss: 0.649397  [ 7840/ 8640]\n",
            "loss: 0.837649  [ 7920/ 8640]\n",
            "loss: 0.656761  [ 8000/ 8640]\n",
            "loss: 0.611641  [ 8080/ 8640]\n",
            "loss: 0.910382  [ 8160/ 8640]\n",
            "loss: 0.648909  [ 8240/ 8640]\n",
            "loss: 0.889918  [ 8320/ 8640]\n",
            "loss: 0.869532  [ 8400/ 8640]\n",
            "loss: 0.844064  [ 8480/ 8640]\n",
            "loss: 0.675713  [ 8560/ 8640]\n",
            "Validation loss: 67.19\n",
            "Early stopping triggered\n",
            "Test Accuracy: 67.19%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_46448c1c-1bd0-4017-b1ac-76000280e363\", \"sample_text_add_b8_lr175e5_drop01_wd015.csv\", 8504)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "import random\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import CamembertTokenizer, CamembertModel\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def synonym_replacement(sentence, n):\n",
        "    words = sentence.split()\n",
        "    new_words = words.copy()\n",
        "    french_stopwords = set(nltk.corpus.stopwords.words('french'))\n",
        "    random_word_list = list(set([word for word in words if word not in french_stopwords]))\n",
        "    random.shuffle(random_word_list)\n",
        "    num_replaced = 0\n",
        "    for random_word in random_word_list:\n",
        "        synonyms = get_synonyms(random_word)\n",
        "        if len(synonyms) > 0:\n",
        "            synonym = random.choice(synonyms)\n",
        "            new_words = [synonym if word == random_word else word for word in new_words]\n",
        "            num_replaced += 1\n",
        "        if num_replaced >= n:  # Only replace up to n words\n",
        "            break\n",
        "    return ' '.join(new_words)\n",
        "\n",
        "def get_synonyms(word):\n",
        "    synonyms = set()\n",
        "    for syn in wordnet.synsets(word, lang='fra'):\n",
        "        for lemma in syn.lemmas(lang='fra'):\n",
        "            synonym = lemma.name().replace(\"_\", \" \").replace(\"-\", \" \").lower()\n",
        "            synonym = \"\".join([char for char in synonym if char.isalnum() or char.isspace()])\n",
        "            synonyms.add(synonym)\n",
        "    if word in synonyms:\n",
        "        synonyms.remove(word)\n",
        "    return list(synonyms)\n",
        "\n",
        "# Generate augmented sentences\n",
        "new_sentences = []\n",
        "new_difficulties = []\n",
        "for _, row in df_train.iterrows():\n",
        "    original_sentence = row['sentence']\n",
        "    difficulty = row['difficulty']\n",
        "    augmented_sentence = synonym_replacement(original_sentence, 2)\n",
        "    new_sentences.append(augmented_sentence)\n",
        "    new_difficulties.append(difficulty)\n",
        "\n",
        "# Create a new DataFrame for the augmented sentences\n",
        "df_augmented = pd.DataFrame({'sentence': new_sentences, 'difficulty': new_difficulties})\n",
        "\n",
        "# Concatenate the original and augmented DataFrames\n",
        "df_combined = pd.concat([df_train, df_augmented], ignore_index=True)\n",
        "\n",
        "# Load your data\n",
        "data = df_combined\n",
        "sentences = data['sentence'].tolist()\n",
        "difficulties = data['difficulty'].tolist()\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(difficulties)\n",
        "\n",
        "# Load CamemBERT tokenizer and model\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
        "camembert = CamembertModel.from_pretrained('camembert-base')\n",
        "\n",
        "# Tokenize sentences and convert to tensor\n",
        "def tokenize_and_encode(sentences):\n",
        "    return tokenizer(sentences, padding=True, truncation=True, max_length=600, return_tensors='pt')\n",
        "\n",
        "# Custom Dataset class\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.encodings = tokenize_and_encode(texts)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: self.encodings[key][idx] for key in self.encodings}, self.labels[idx]\n",
        "\n",
        "# Data preparation\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    sentences, encoded_labels, test_size=0.1, random_state=42, stratify=encoded_labels\n",
        ")\n",
        "\n",
        "train_dataset = TextDataset(X_train, y_train)\n",
        "test_dataset = TextDataset(X_test, y_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# Neural network model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Net, self).__init__()\n",
        "        self.camembert = camembert\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        self.fc = nn.Linear(self.camembert.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        outputs = self.camembert(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.fc(pooled_output)\n",
        "        return logits\n",
        "\n",
        "# Instantiate the model, loss, and optimizer\n",
        "model = Net(len(label_encoder.classes_)).to('cuda')\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1.75e-5, weight_decay=0.15)\n",
        "\n",
        "# Early stopping parameters\n",
        "early_stopping_patience = 1\n",
        "best_loss = float('inf')\n",
        "patience_counter = 0\n",
        "\n",
        "# Function to compute accuracy\n",
        "def compute_accuracy(dataloader, model):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            inputs, labels = batch\n",
        "            inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
        "            labels = labels.to('cuda')\n",
        "            outputs = model(**inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "# Training loop\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()  # Set model to training mode\n",
        "    for batch, (inputs, labels) in enumerate(dataloader):\n",
        "        inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
        "        labels = labels.to('cuda')\n",
        "        pred = model(**inputs)\n",
        "        loss = loss_fn(pred, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 10 == 0:\n",
        "            loss, current = loss.item(), batch * len(inputs['input_ids'])\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "# Execute training\n",
        "for epoch in range(10):  # Number of epochs\n",
        "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
        "    train_loop(train_loader, model, criterion, optimizer)\n",
        "    val_loss = compute_accuracy(test_loader, model)\n",
        "    print(f\"Validation loss: {val_loss:.2f}\")\n",
        "\n",
        "    # Check for early stopping\n",
        "    if val_loss < best_loss:\n",
        "        best_loss = val_loss\n",
        "        patience_counter = 0\n",
        "        # Save the model\n",
        "        torch.save(model.state_dict(), 'best_model.pth')\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= early_stopping_patience:\n",
        "            print(\"Early stopping triggered\")\n",
        "            break\n",
        "\n",
        "# Load the best model\n",
        "#model.load_state_dict(torch.load('best_model.pth'))\n",
        "\n",
        "# Test the model\n",
        "accuracy = compute_accuracy(test_loader, model)\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "# Further processing for generating predictions and submission remains the same...\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import CamembertTokenizer\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
        "\n",
        "# Tokenize and encode the test data\n",
        "def tokenize_and_encode(sentences):\n",
        "    return tokenizer(sentences, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
        "\n",
        "# Custom Dataset class for test data\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, texts):\n",
        "        self.encodings = tokenize_and_encode(texts)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings['input_ids'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: self.encodings[key][idx] for key in self.encodings}\n",
        "\n",
        "# Create the dataset and dataloader for df_test\n",
        "test_dataset = TestDataset(df_test['sentence'].tolist())\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# Define the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Generate predictions for df_test\n",
        "model.eval()  # Make sure the model is in evaluation mode\n",
        "all_predictions = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        inputs = {key: value.to(device) for key, value in batch.items()}\n",
        "        outputs = model(**inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "# Convert numeric predictions back to labels\n",
        "predicted_labels = label_encoder.inverse_transform(all_predictions)\n",
        "\n",
        "# Prepare and save the submission file\n",
        "submission_df = pd.DataFrame({\n",
        "    'id': df_test['id'],  # Ensure df_test includes an 'id' column\n",
        "    'difficulty': predicted_labels\n",
        "})\n",
        "\n",
        "submission_df.to_csv('sample_text_add_b8_lr175e5_drop01_wd015.csv', index=False)\n",
        "from google.colab import files\n",
        "files.download('sample_text_add_b8_lr175e5_drop01_wd015.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yQZEuUZJP5ic",
        "outputId": "a5f9cb44-7d35-4763-970c-9a24e51e0197"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 1.783658  [    0/ 8640]\n",
            "loss: 1.811606  [   80/ 8640]\n",
            "loss: 1.832079  [  160/ 8640]\n",
            "loss: 1.768653  [  240/ 8640]\n",
            "loss: 1.772610  [  320/ 8640]\n",
            "loss: 1.742198  [  400/ 8640]\n",
            "loss: 1.806882  [  480/ 8640]\n",
            "loss: 1.769136  [  560/ 8640]\n",
            "loss: 1.681716  [  640/ 8640]\n",
            "loss: 1.629272  [  720/ 8640]\n",
            "loss: 1.565492  [  800/ 8640]\n",
            "loss: 1.584505  [  880/ 8640]\n",
            "loss: 1.603585  [  960/ 8640]\n",
            "loss: 1.581653  [ 1040/ 8640]\n",
            "loss: 1.687155  [ 1120/ 8640]\n",
            "loss: 1.478335  [ 1200/ 8640]\n",
            "loss: 1.298736  [ 1280/ 8640]\n",
            "loss: 1.552001  [ 1360/ 8640]\n",
            "loss: 1.426776  [ 1440/ 8640]\n",
            "loss: 1.493022  [ 1520/ 8640]\n",
            "loss: 1.502383  [ 1600/ 8640]\n",
            "loss: 1.196475  [ 1680/ 8640]\n",
            "loss: 1.353438  [ 1760/ 8640]\n",
            "loss: 1.283953  [ 1840/ 8640]\n",
            "loss: 1.300572  [ 1920/ 8640]\n",
            "loss: 1.387003  [ 2000/ 8640]\n",
            "loss: 1.231985  [ 2080/ 8640]\n",
            "loss: 1.535987  [ 2160/ 8640]\n",
            "loss: 1.410243  [ 2240/ 8640]\n",
            "loss: 1.279744  [ 2320/ 8640]\n",
            "loss: 1.042958  [ 2400/ 8640]\n",
            "loss: 1.167870  [ 2480/ 8640]\n",
            "loss: 1.544197  [ 2560/ 8640]\n",
            "loss: 1.487032  [ 2640/ 8640]\n",
            "loss: 1.005092  [ 2720/ 8640]\n",
            "loss: 1.433792  [ 2800/ 8640]\n",
            "loss: 1.396941  [ 2880/ 8640]\n",
            "loss: 1.072242  [ 2960/ 8640]\n",
            "loss: 1.090913  [ 3040/ 8640]\n",
            "loss: 1.148909  [ 3120/ 8640]\n",
            "loss: 1.130468  [ 3200/ 8640]\n",
            "loss: 0.935670  [ 3280/ 8640]\n",
            "loss: 1.014745  [ 3360/ 8640]\n",
            "loss: 1.316754  [ 3440/ 8640]\n",
            "loss: 0.900638  [ 3520/ 8640]\n",
            "loss: 1.489418  [ 3600/ 8640]\n",
            "loss: 1.242659  [ 3680/ 8640]\n",
            "loss: 1.000127  [ 3760/ 8640]\n",
            "loss: 1.075735  [ 3840/ 8640]\n",
            "loss: 0.921741  [ 3920/ 8640]\n",
            "loss: 0.956633  [ 4000/ 8640]\n",
            "loss: 0.991166  [ 4080/ 8640]\n",
            "loss: 1.028981  [ 4160/ 8640]\n",
            "loss: 1.061979  [ 4240/ 8640]\n",
            "loss: 1.282414  [ 4320/ 8640]\n",
            "loss: 1.144975  [ 4400/ 8640]\n",
            "loss: 1.364672  [ 4480/ 8640]\n",
            "loss: 0.943827  [ 4560/ 8640]\n",
            "loss: 1.326556  [ 4640/ 8640]\n",
            "loss: 1.088231  [ 4720/ 8640]\n",
            "loss: 1.560401  [ 4800/ 8640]\n",
            "loss: 1.207590  [ 4880/ 8640]\n",
            "loss: 1.324779  [ 4960/ 8640]\n",
            "loss: 1.012434  [ 5040/ 8640]\n",
            "loss: 0.799872  [ 5120/ 8640]\n",
            "loss: 1.049495  [ 5200/ 8640]\n",
            "loss: 0.938314  [ 5280/ 8640]\n",
            "loss: 1.094166  [ 5360/ 8640]\n",
            "loss: 1.100852  [ 5440/ 8640]\n",
            "loss: 1.006301  [ 5520/ 8640]\n",
            "loss: 0.920278  [ 5600/ 8640]\n",
            "loss: 1.136686  [ 5680/ 8640]\n",
            "loss: 0.759468  [ 5760/ 8640]\n",
            "loss: 0.912285  [ 5840/ 8640]\n",
            "loss: 1.276607  [ 5920/ 8640]\n",
            "loss: 0.876141  [ 6000/ 8640]\n",
            "loss: 1.094294  [ 6080/ 8640]\n",
            "loss: 1.014452  [ 6160/ 8640]\n",
            "loss: 1.110920  [ 6240/ 8640]\n",
            "loss: 1.456343  [ 6320/ 8640]\n",
            "loss: 1.415023  [ 6400/ 8640]\n",
            "loss: 1.047166  [ 6480/ 8640]\n",
            "loss: 1.251692  [ 6560/ 8640]\n",
            "loss: 1.022008  [ 6640/ 8640]\n",
            "loss: 1.249843  [ 6720/ 8640]\n",
            "loss: 1.098784  [ 6800/ 8640]\n",
            "loss: 1.323460  [ 6880/ 8640]\n",
            "loss: 0.931649  [ 6960/ 8640]\n",
            "loss: 0.885004  [ 7040/ 8640]\n",
            "loss: 0.899721  [ 7120/ 8640]\n",
            "loss: 1.048525  [ 7200/ 8640]\n",
            "loss: 0.929225  [ 7280/ 8640]\n",
            "loss: 0.879761  [ 7360/ 8640]\n",
            "loss: 0.866762  [ 7440/ 8640]\n",
            "loss: 0.976092  [ 7520/ 8640]\n",
            "loss: 1.024279  [ 7600/ 8640]\n",
            "loss: 0.773784  [ 7680/ 8640]\n",
            "loss: 0.968794  [ 7760/ 8640]\n",
            "loss: 2.094090  [ 7840/ 8640]\n",
            "loss: 1.123870  [ 7920/ 8640]\n",
            "loss: 0.965608  [ 8000/ 8640]\n",
            "loss: 1.199325  [ 8080/ 8640]\n",
            "loss: 0.849204  [ 8160/ 8640]\n",
            "loss: 1.035617  [ 8240/ 8640]\n",
            "loss: 0.859921  [ 8320/ 8640]\n",
            "loss: 1.078125  [ 8400/ 8640]\n",
            "loss: 1.238623  [ 8480/ 8640]\n",
            "loss: 0.854825  [ 8560/ 8640]\n",
            "Training done\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 1.203502  [    0/ 8640]\n",
            "loss: 0.723889  [   80/ 8640]\n",
            "loss: 1.111950  [  160/ 8640]\n",
            "loss: 1.266748  [  240/ 8640]\n",
            "loss: 1.187992  [  320/ 8640]\n",
            "loss: 0.694907  [  400/ 8640]\n",
            "loss: 1.052183  [  480/ 8640]\n",
            "loss: 0.821289  [  560/ 8640]\n",
            "loss: 0.692175  [  640/ 8640]\n",
            "loss: 0.891220  [  720/ 8640]\n",
            "loss: 0.913106  [  800/ 8640]\n",
            "loss: 0.603884  [  880/ 8640]\n",
            "loss: 0.813989  [  960/ 8640]\n",
            "loss: 0.620272  [ 1040/ 8640]\n",
            "loss: 1.208875  [ 1120/ 8640]\n",
            "loss: 0.771755  [ 1200/ 8640]\n",
            "loss: 1.131337  [ 1280/ 8640]\n",
            "loss: 0.563281  [ 1360/ 8640]\n",
            "loss: 0.831931  [ 1440/ 8640]\n",
            "loss: 1.026900  [ 1520/ 8640]\n",
            "loss: 0.678336  [ 1600/ 8640]\n",
            "loss: 1.023771  [ 1680/ 8640]\n",
            "loss: 0.701948  [ 1760/ 8640]\n",
            "loss: 0.777076  [ 1840/ 8640]\n",
            "loss: 1.087997  [ 1920/ 8640]\n",
            "loss: 0.548354  [ 2000/ 8640]\n",
            "loss: 1.157872  [ 2080/ 8640]\n",
            "loss: 0.904938  [ 2160/ 8640]\n",
            "loss: 0.417490  [ 2240/ 8640]\n",
            "loss: 0.470354  [ 2320/ 8640]\n",
            "loss: 1.089248  [ 2400/ 8640]\n",
            "loss: 0.606496  [ 2480/ 8640]\n",
            "loss: 1.386523  [ 2560/ 8640]\n",
            "loss: 0.777622  [ 2640/ 8640]\n",
            "loss: 0.602600  [ 2720/ 8640]\n",
            "loss: 0.827702  [ 2800/ 8640]\n",
            "loss: 0.538812  [ 2880/ 8640]\n",
            "loss: 0.800797  [ 2960/ 8640]\n",
            "loss: 0.989256  [ 3040/ 8640]\n",
            "loss: 0.648061  [ 3120/ 8640]\n",
            "loss: 1.047241  [ 3200/ 8640]\n",
            "loss: 0.509374  [ 3280/ 8640]\n",
            "loss: 0.451590  [ 3360/ 8640]\n",
            "loss: 0.770701  [ 3440/ 8640]\n",
            "loss: 1.024833  [ 3520/ 8640]\n",
            "loss: 1.173062  [ 3600/ 8640]\n",
            "loss: 0.687997  [ 3680/ 8640]\n",
            "loss: 1.101685  [ 3760/ 8640]\n",
            "loss: 0.745687  [ 3840/ 8640]\n",
            "loss: 0.943603  [ 3920/ 8640]\n",
            "loss: 0.754739  [ 4000/ 8640]\n",
            "loss: 1.203944  [ 4080/ 8640]\n",
            "loss: 0.921348  [ 4160/ 8640]\n",
            "loss: 0.602493  [ 4240/ 8640]\n",
            "loss: 0.597604  [ 4320/ 8640]\n",
            "loss: 0.851988  [ 4400/ 8640]\n",
            "loss: 0.704961  [ 4480/ 8640]\n",
            "loss: 0.694054  [ 4560/ 8640]\n",
            "loss: 1.001220  [ 4640/ 8640]\n",
            "loss: 0.635709  [ 4720/ 8640]\n",
            "loss: 0.752259  [ 4800/ 8640]\n",
            "loss: 0.891309  [ 4880/ 8640]\n",
            "loss: 0.889002  [ 4960/ 8640]\n",
            "loss: 0.960853  [ 5040/ 8640]\n",
            "loss: 0.524622  [ 5120/ 8640]\n",
            "loss: 1.122966  [ 5200/ 8640]\n",
            "loss: 0.798397  [ 5280/ 8640]\n",
            "loss: 0.900406  [ 5360/ 8640]\n",
            "loss: 0.873131  [ 5440/ 8640]\n",
            "loss: 1.120759  [ 5520/ 8640]\n",
            "loss: 0.808948  [ 5600/ 8640]\n",
            "loss: 0.728529  [ 5680/ 8640]\n",
            "loss: 0.857421  [ 5760/ 8640]\n",
            "loss: 0.468687  [ 5840/ 8640]\n",
            "loss: 0.744738  [ 5920/ 8640]\n",
            "loss: 0.470894  [ 6000/ 8640]\n",
            "loss: 0.422485  [ 6080/ 8640]\n",
            "loss: 1.476175  [ 6160/ 8640]\n",
            "loss: 0.491172  [ 6240/ 8640]\n",
            "loss: 0.694655  [ 6320/ 8640]\n",
            "loss: 0.540625  [ 6400/ 8640]\n",
            "loss: 0.585382  [ 6480/ 8640]\n",
            "loss: 0.478347  [ 6560/ 8640]\n",
            "loss: 0.419916  [ 6640/ 8640]\n",
            "loss: 0.411958  [ 6720/ 8640]\n",
            "loss: 0.569627  [ 6800/ 8640]\n",
            "loss: 0.448149  [ 6880/ 8640]\n",
            "loss: 0.445237  [ 6960/ 8640]\n",
            "loss: 0.443217  [ 7040/ 8640]\n",
            "loss: 1.413047  [ 7120/ 8640]\n",
            "loss: 0.744491  [ 7200/ 8640]\n",
            "loss: 1.009935  [ 7280/ 8640]\n",
            "loss: 0.982409  [ 7360/ 8640]\n",
            "loss: 0.556170  [ 7440/ 8640]\n",
            "loss: 0.383409  [ 7520/ 8640]\n",
            "loss: 1.145802  [ 7600/ 8640]\n",
            "loss: 0.465544  [ 7680/ 8640]\n",
            "loss: 0.762796  [ 7760/ 8640]\n",
            "loss: 0.648620  [ 7840/ 8640]\n",
            "loss: 0.828928  [ 7920/ 8640]\n",
            "loss: 0.474415  [ 8000/ 8640]\n",
            "loss: 0.785614  [ 8080/ 8640]\n",
            "loss: 0.624629  [ 8160/ 8640]\n",
            "loss: 0.874543  [ 8240/ 8640]\n",
            "loss: 0.391934  [ 8320/ 8640]\n",
            "loss: 0.821000  [ 8400/ 8640]\n",
            "loss: 0.496037  [ 8480/ 8640]\n",
            "loss: 0.720599  [ 8560/ 8640]\n",
            "Training done\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.496056  [    0/ 8640]\n",
            "loss: 0.901951  [   80/ 8640]\n",
            "loss: 0.349714  [  160/ 8640]\n",
            "loss: 0.605058  [  240/ 8640]\n",
            "loss: 0.499673  [  320/ 8640]\n",
            "loss: 0.508959  [  400/ 8640]\n",
            "loss: 0.258843  [  480/ 8640]\n",
            "loss: 0.324723  [  560/ 8640]\n",
            "loss: 0.444665  [  640/ 8640]\n",
            "loss: 0.338583  [  720/ 8640]\n",
            "loss: 0.294327  [  800/ 8640]\n",
            "loss: 0.429991  [  880/ 8640]\n",
            "loss: 0.461362  [  960/ 8640]\n",
            "loss: 0.349799  [ 1040/ 8640]\n",
            "loss: 0.701492  [ 1120/ 8640]\n",
            "loss: 0.466519  [ 1200/ 8640]\n",
            "loss: 0.293402  [ 1280/ 8640]\n",
            "loss: 0.360125  [ 1360/ 8640]\n",
            "loss: 0.600976  [ 1440/ 8640]\n",
            "loss: 0.658485  [ 1520/ 8640]\n",
            "loss: 0.205811  [ 1600/ 8640]\n",
            "loss: 0.370849  [ 1680/ 8640]\n",
            "loss: 0.431613  [ 1760/ 8640]\n",
            "loss: 0.591794  [ 1840/ 8640]\n",
            "loss: 0.405411  [ 1920/ 8640]\n",
            "loss: 0.274892  [ 2000/ 8640]\n",
            "loss: 0.343446  [ 2080/ 8640]\n",
            "loss: 0.646638  [ 2160/ 8640]\n",
            "loss: 0.281805  [ 2240/ 8640]\n",
            "loss: 0.454896  [ 2320/ 8640]\n",
            "loss: 1.279235  [ 2400/ 8640]\n",
            "loss: 0.198178  [ 2480/ 8640]\n",
            "loss: 0.565362  [ 2560/ 8640]\n",
            "loss: 1.150301  [ 2640/ 8640]\n",
            "loss: 0.416670  [ 2720/ 8640]\n",
            "loss: 0.484063  [ 2800/ 8640]\n",
            "loss: 0.517093  [ 2880/ 8640]\n",
            "loss: 0.795087  [ 2960/ 8640]\n",
            "loss: 0.201057  [ 3040/ 8640]\n",
            "loss: 0.343409  [ 3120/ 8640]\n",
            "loss: 0.335351  [ 3200/ 8640]\n",
            "loss: 0.264218  [ 3280/ 8640]\n",
            "loss: 0.329356  [ 3360/ 8640]\n",
            "loss: 0.992239  [ 3440/ 8640]\n",
            "loss: 0.248163  [ 3520/ 8640]\n",
            "loss: 0.338595  [ 3600/ 8640]\n",
            "loss: 0.255002  [ 3680/ 8640]\n",
            "loss: 1.234493  [ 3760/ 8640]\n",
            "loss: 0.462322  [ 3840/ 8640]\n",
            "loss: 0.505397  [ 3920/ 8640]\n",
            "loss: 0.329794  [ 4000/ 8640]\n",
            "loss: 1.197254  [ 4080/ 8640]\n",
            "loss: 0.877339  [ 4160/ 8640]\n",
            "loss: 0.300352  [ 4240/ 8640]\n",
            "loss: 0.506256  [ 4320/ 8640]\n",
            "loss: 0.752915  [ 4400/ 8640]\n",
            "loss: 0.344448  [ 4480/ 8640]\n",
            "loss: 0.622965  [ 4560/ 8640]\n",
            "loss: 0.254945  [ 4640/ 8640]\n",
            "loss: 0.204139  [ 4720/ 8640]\n",
            "loss: 0.317066  [ 4800/ 8640]\n",
            "loss: 0.264381  [ 4880/ 8640]\n",
            "loss: 0.665914  [ 4960/ 8640]\n",
            "loss: 0.157027  [ 5040/ 8640]\n",
            "loss: 0.195979  [ 5120/ 8640]\n",
            "loss: 0.239013  [ 5200/ 8640]\n",
            "loss: 0.196392  [ 5280/ 8640]\n",
            "loss: 0.720842  [ 5360/ 8640]\n",
            "loss: 0.673634  [ 5440/ 8640]\n",
            "loss: 0.419124  [ 5520/ 8640]\n",
            "loss: 0.561874  [ 5600/ 8640]\n",
            "loss: 0.653976  [ 5680/ 8640]\n",
            "loss: 0.313606  [ 5760/ 8640]\n",
            "loss: 0.475422  [ 5840/ 8640]\n",
            "loss: 0.420419  [ 5920/ 8640]\n",
            "loss: 0.304217  [ 6000/ 8640]\n",
            "loss: 0.199840  [ 6080/ 8640]\n",
            "loss: 0.220863  [ 6160/ 8640]\n",
            "loss: 0.236400  [ 6240/ 8640]\n",
            "loss: 0.547054  [ 6320/ 8640]\n",
            "loss: 1.132775  [ 6400/ 8640]\n",
            "loss: 0.152377  [ 6480/ 8640]\n",
            "loss: 0.325943  [ 6560/ 8640]\n",
            "loss: 0.789661  [ 6640/ 8640]\n",
            "loss: 0.155231  [ 6720/ 8640]\n",
            "loss: 0.092536  [ 6800/ 8640]\n",
            "loss: 0.645189  [ 6880/ 8640]\n",
            "loss: 0.229596  [ 6960/ 8640]\n",
            "loss: 0.761368  [ 7040/ 8640]\n",
            "loss: 0.132302  [ 7120/ 8640]\n",
            "loss: 0.424489  [ 7200/ 8640]\n",
            "loss: 0.130793  [ 7280/ 8640]\n",
            "loss: 0.824395  [ 7360/ 8640]\n",
            "loss: 0.644317  [ 7440/ 8640]\n",
            "loss: 0.323088  [ 7520/ 8640]\n",
            "loss: 0.712623  [ 7600/ 8640]\n",
            "loss: 0.448785  [ 7680/ 8640]\n",
            "loss: 0.244322  [ 7760/ 8640]\n",
            "loss: 0.321895  [ 7840/ 8640]\n",
            "loss: 0.213536  [ 7920/ 8640]\n",
            "loss: 0.185367  [ 8000/ 8640]\n",
            "loss: 0.297350  [ 8080/ 8640]\n",
            "loss: 0.270600  [ 8160/ 8640]\n",
            "loss: 0.568859  [ 8240/ 8640]\n",
            "loss: 0.479668  [ 8320/ 8640]\n",
            "loss: 0.322344  [ 8400/ 8640]\n",
            "loss: 0.228594  [ 8480/ 8640]\n",
            "loss: 0.648182  [ 8560/ 8640]\n",
            "Training done\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.366891  [    0/ 8640]\n",
            "loss: 0.478407  [   80/ 8640]\n",
            "loss: 0.172015  [  160/ 8640]\n",
            "loss: 0.181861  [  240/ 8640]\n",
            "loss: 0.247624  [  320/ 8640]\n",
            "loss: 0.459612  [  400/ 8640]\n",
            "loss: 0.138022  [  480/ 8640]\n",
            "loss: 0.088141  [  560/ 8640]\n",
            "loss: 0.235752  [  640/ 8640]\n",
            "loss: 0.191320  [  720/ 8640]\n",
            "loss: 0.414438  [  800/ 8640]\n",
            "loss: 0.401479  [  880/ 8640]\n",
            "loss: 0.092494  [  960/ 8640]\n",
            "loss: 0.299732  [ 1040/ 8640]\n",
            "loss: 0.264612  [ 1120/ 8640]\n",
            "loss: 0.150411  [ 1200/ 8640]\n",
            "loss: 0.275990  [ 1280/ 8640]\n",
            "loss: 0.468531  [ 1360/ 8640]\n",
            "loss: 0.609199  [ 1440/ 8640]\n",
            "loss: 0.194678  [ 1520/ 8640]\n",
            "loss: 0.214001  [ 1600/ 8640]\n",
            "loss: 0.112414  [ 1680/ 8640]\n",
            "loss: 0.580424  [ 1760/ 8640]\n",
            "loss: 0.123082  [ 1840/ 8640]\n",
            "loss: 0.367541  [ 1920/ 8640]\n",
            "loss: 0.103749  [ 2000/ 8640]\n",
            "loss: 0.119705  [ 2080/ 8640]\n",
            "loss: 0.152436  [ 2160/ 8640]\n",
            "loss: 0.061064  [ 2240/ 8640]\n",
            "loss: 0.652601  [ 2320/ 8640]\n",
            "loss: 0.430992  [ 2400/ 8640]\n",
            "loss: 0.199552  [ 2480/ 8640]\n",
            "loss: 0.204713  [ 2560/ 8640]\n",
            "loss: 0.295673  [ 2640/ 8640]\n",
            "loss: 0.205831  [ 2720/ 8640]\n",
            "loss: 0.489526  [ 2800/ 8640]\n",
            "loss: 0.053023  [ 2880/ 8640]\n",
            "loss: 0.113762  [ 2960/ 8640]\n",
            "loss: 0.103796  [ 3040/ 8640]\n",
            "loss: 0.063892  [ 3120/ 8640]\n",
            "loss: 0.125860  [ 3200/ 8640]\n",
            "loss: 0.312557  [ 3280/ 8640]\n",
            "loss: 0.381774  [ 3360/ 8640]\n",
            "loss: 0.090628  [ 3440/ 8640]\n",
            "loss: 0.869789  [ 3520/ 8640]\n",
            "loss: 1.129455  [ 3600/ 8640]\n",
            "loss: 0.370723  [ 3680/ 8640]\n",
            "loss: 0.131327  [ 3760/ 8640]\n",
            "loss: 0.418159  [ 3840/ 8640]\n",
            "loss: 0.049616  [ 3920/ 8640]\n",
            "loss: 0.311134  [ 4000/ 8640]\n",
            "loss: 0.218396  [ 4080/ 8640]\n",
            "loss: 0.924520  [ 4160/ 8640]\n",
            "loss: 0.082776  [ 4240/ 8640]\n",
            "loss: 0.086385  [ 4320/ 8640]\n",
            "loss: 0.173594  [ 4400/ 8640]\n",
            "loss: 0.158581  [ 4480/ 8640]\n",
            "loss: 0.350871  [ 4560/ 8640]\n",
            "loss: 0.059113  [ 4640/ 8640]\n",
            "loss: 0.153782  [ 4720/ 8640]\n",
            "loss: 0.075306  [ 4800/ 8640]\n",
            "loss: 0.084117  [ 4880/ 8640]\n",
            "loss: 0.210361  [ 4960/ 8640]\n",
            "loss: 0.062141  [ 5040/ 8640]\n",
            "loss: 0.081762  [ 5120/ 8640]\n",
            "loss: 0.576181  [ 5200/ 8640]\n",
            "loss: 0.079028  [ 5280/ 8640]\n",
            "loss: 0.494561  [ 5360/ 8640]\n",
            "loss: 0.880171  [ 5440/ 8640]\n",
            "loss: 0.035770  [ 5520/ 8640]\n",
            "loss: 0.223800  [ 5600/ 8640]\n",
            "loss: 0.703397  [ 5680/ 8640]\n",
            "loss: 0.071904  [ 5760/ 8640]\n",
            "loss: 0.049171  [ 5840/ 8640]\n",
            "loss: 0.384454  [ 5920/ 8640]\n",
            "loss: 0.568488  [ 6000/ 8640]\n",
            "loss: 0.529039  [ 6080/ 8640]\n",
            "loss: 0.094355  [ 6160/ 8640]\n",
            "loss: 0.032598  [ 6240/ 8640]\n",
            "loss: 0.412400  [ 6320/ 8640]\n",
            "loss: 0.111360  [ 6400/ 8640]\n",
            "loss: 0.056960  [ 6480/ 8640]\n",
            "loss: 0.422648  [ 6560/ 8640]\n",
            "loss: 0.064703  [ 6640/ 8640]\n",
            "loss: 0.145292  [ 6720/ 8640]\n",
            "loss: 0.422422  [ 6800/ 8640]\n",
            "loss: 0.471763  [ 6880/ 8640]\n",
            "loss: 0.206992  [ 6960/ 8640]\n",
            "loss: 0.071668  [ 7040/ 8640]\n",
            "loss: 0.049064  [ 7120/ 8640]\n",
            "loss: 0.056412  [ 7200/ 8640]\n",
            "loss: 0.550518  [ 7280/ 8640]\n",
            "loss: 0.114523  [ 7360/ 8640]\n",
            "loss: 0.086239  [ 7440/ 8640]\n",
            "loss: 0.153840  [ 7520/ 8640]\n",
            "loss: 0.455406  [ 7600/ 8640]\n",
            "loss: 0.103426  [ 7680/ 8640]\n",
            "loss: 0.047360  [ 7760/ 8640]\n",
            "loss: 0.053165  [ 7840/ 8640]\n",
            "loss: 0.508146  [ 7920/ 8640]\n",
            "loss: 0.087527  [ 8000/ 8640]\n",
            "loss: 0.058127  [ 8080/ 8640]\n",
            "loss: 0.308052  [ 8160/ 8640]\n",
            "loss: 0.395242  [ 8240/ 8640]\n",
            "loss: 0.398364  [ 8320/ 8640]\n",
            "loss: 0.054313  [ 8400/ 8640]\n",
            "loss: 0.113989  [ 8480/ 8640]\n",
            "loss: 0.760165  [ 8560/ 8640]\n",
            "Training done\n",
            "Test Accuracy: 82.19%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_9aefdb3c-d351-42ab-a68e-faa5d33b426f\", \"sample_text_add_b8_lr175e5_drop01_new.csv\", 8504)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "import random\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import CamembertTokenizer, CamembertModel\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def synonym_replacement(sentence, n):\n",
        "    words = sentence.split()\n",
        "    new_words = words.copy()\n",
        "    french_stopwords = set(nltk.corpus.stopwords.words('french'))\n",
        "    random_word_list = list(set([word for word in words if word not in french_stopwords]))\n",
        "    random.shuffle(random_word_list)\n",
        "    num_replaced = 0\n",
        "    for random_word in random_word_list:\n",
        "        synonyms = get_synonyms(random_word)\n",
        "        if len(synonyms) > 0:\n",
        "            synonym = random.choice(synonyms)\n",
        "            new_words = [synonym if word == random_word else word for word in new_words]\n",
        "            num_replaced += 1\n",
        "        if num_replaced >= n:  # Only replace up to n words\n",
        "            break\n",
        "    return ' '.join(new_words)\n",
        "\n",
        "def get_synonyms(word):\n",
        "    synonyms = set()\n",
        "    for syn in wordnet.synsets(word, lang='fra'):\n",
        "        for lemma in syn.lemmas(lang='fra'):\n",
        "            synonym = lemma.name().replace(\"_\", \" \").replace(\"-\", \" \").lower()\n",
        "            synonym = \"\".join([char for char in synonym if char.isalnum() or char.isspace()])\n",
        "            synonyms.add(synonym)\n",
        "    if word in synonyms:\n",
        "        synonyms.remove(word)\n",
        "    return list(synonyms)\n",
        "\n",
        "# Generate augmented sentences\n",
        "new_sentences = []\n",
        "new_difficulties = []\n",
        "for _, row in df_train.iterrows():\n",
        "    original_sentence = row['sentence']\n",
        "    difficulty = row['difficulty']\n",
        "    augmented_sentence = synonym_replacement(original_sentence, 2)\n",
        "    new_sentences.append(augmented_sentence)\n",
        "    new_difficulties.append(difficulty)\n",
        "\n",
        "# Create a new DataFrame for the augmented sentences\n",
        "df_augmented = pd.DataFrame({'sentence': new_sentences, 'difficulty': new_difficulties})\n",
        "\n",
        "# Concatenate the original and augmented DataFrames\n",
        "df_combined = pd.concat([df_train, df_augmented], ignore_index=True)\n",
        "\n",
        "# Load your data\n",
        "data = df_combined\n",
        "sentences = data['sentence'].tolist()\n",
        "difficulties = data['difficulty'].tolist()\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(difficulties)\n",
        "\n",
        "# Load CamemBERT tokenizer and model\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
        "camembert = CamembertModel.from_pretrained('camembert-base')\n",
        "\n",
        "# Tokenize sentences and convert to tensor\n",
        "def tokenize_and_encode(sentences):\n",
        "    return tokenizer(sentences, padding=True, truncation=True, max_length=600, return_tensors='pt')\n",
        "\n",
        "# Custom Dataset class\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.encodings = tokenize_and_encode(texts)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: self.encodings[key][idx] for key in self.encodings}, self.labels[idx]\n",
        "\n",
        "# Data preparation\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    sentences, encoded_labels, test_size=0.1, random_state=42, stratify=encoded_labels\n",
        ")\n",
        "\n",
        "train_dataset = TextDataset(X_train, y_train)\n",
        "test_dataset = TextDataset(X_test, y_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# Neural network model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Net, self).__init__()\n",
        "        self.camembert = camembert\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        self.fc = nn.Linear(self.camembert.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        outputs = self.camembert(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.fc(pooled_output)\n",
        "        return logits\n",
        "\n",
        "# Instantiate the model, loss, and optimizer\n",
        "model = Net(len(label_encoder.classes_)).to('cuda')\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1.749e-5)\n",
        "\n",
        "# Function to compute accuracy\n",
        "def compute_accuracy(dataloader, model):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            inputs, labels = batch\n",
        "            inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
        "            labels = labels.to('cuda')\n",
        "            outputs = model(**inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "# Training loop\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()  # Set model to training mode\n",
        "    for batch, (inputs, labels) in enumerate(dataloader):\n",
        "        inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
        "        labels = labels.to('cuda')\n",
        "        pred = model(**inputs)\n",
        "        loss = loss_fn(pred, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 10 == 0:\n",
        "            loss, current = loss.item(), batch * len(inputs['input_ids'])\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "# Execute training\n",
        "for epoch in range(4):  # Number of epochs\n",
        "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
        "    train_loop(train_loader, model, criterion, optimizer)\n",
        "    print(\"Training done\")\n",
        "\n",
        "# Test the model\n",
        "accuracy = compute_accuracy(test_loader, model)\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import CamembertTokenizer\n",
        "\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
        "\n",
        "# Tokenize and encode the test data\n",
        "def tokenize_and_encode(sentences):\n",
        "    return tokenizer(sentences, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
        "\n",
        "# Custom Dataset class for test data\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, texts):\n",
        "        self.encodings = tokenize_and_encode(texts)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings['input_ids'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: self.encodings[key][idx] for key in self.encodings}\n",
        "\n",
        "# Create the dataset and dataloader for df_test\n",
        "test_dataset = TestDataset(df_test['sentence'].tolist())\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# Define the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Generate predictions for df_test\n",
        "model.eval()  # Make sure the model is in evaluation mode\n",
        "all_predictions = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        inputs = {key: value.to(device) for key, value in batch.items()}\n",
        "        outputs = model(**inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "# Convert numeric predictions back to labels\n",
        "predicted_labels = label_encoder.inverse_transform(all_predictions)\n",
        "\n",
        "# Prepare and save the submission file\n",
        "submission_df = pd.DataFrame({\n",
        "    'id': df_test['id'],  # Ensure df_test includes an 'id' column\n",
        "    'difficulty': predicted_labels\n",
        "})\n",
        "\n",
        "submission_df.to_csv('sample_text_add_b8_lr175e5_drop01_new.csv', index=False)\n",
        "from google.colab import files\n",
        "files.download('sample_text_add_b8_lr175e5_drop01_new.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Trying embeddings\n",
        "\n",
        "First, I tried a few models with the back translation technique. However, it required a lot computational power and didn't process."
      ],
      "metadata": {
        "id": "Sk_GIN7My4f0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
        "\n",
        "# Load the dataset\n",
        "df = df_test\n",
        "\n",
        "# Load the mBART model and tokenizer\n",
        "model_name = 'facebook/mbart-large-50-many-to-many-mmt'\n",
        "tokenizer = MBart50TokenizerFast.from_pretrained(model_name)\n",
        "model = MBartForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "# Set the language codes\n",
        "tokenizer.src_lang = \"fr_XX\"\n",
        "target_lang = \"en_XX\"\n",
        "\n",
        "def translate_to_russian(sentence, tokenizer, model):\n",
        "    # Tokenize and prepare the text for translation\n",
        "    inputs = tokenizer(sentence, return_tensors='pt')\n",
        "\n",
        "    # Generate translation\n",
        "    translated_tokens = model.generate(**inputs, forced_bos_token_id=tokenizer.lang_code_to_id[target_lang])\n",
        "\n",
        "    # Decode the translation\n",
        "    translated_sentence = tokenizer.decode(translated_tokens[0], skip_special_tokens=True)\n",
        "    return translated_sentence\n",
        "\n",
        "# Apply translation to the dataset\n",
        "df['translated_sentence'] = df['sentence'].apply(lambda x: translate_to_russian(x, tokenizer, model))\n",
        "\n",
        "# Save the new dataset\n",
        "\n",
        "print(\"Translation completed and saved to 'translated_data.csv'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "2rCuxqksZE91",
        "outputId": "d7ecf9f1-768d-4a73-df40-1769307700f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-694b0d8e0d3f>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Apply translation to the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'translated_sentence'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtranslate_to_russian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Save the new dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4628\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4629\u001b[0m         \"\"\"\n\u001b[0;32m-> 4630\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4632\u001b[0m     def _reduce(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m         \u001b[0;31m# self.f is Callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1025\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1077\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-694b0d8e0d3f>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Apply translation to the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'translated_sentence'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtranslate_to_russian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Save the new dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-694b0d8e0d3f>\u001b[0m in \u001b[0;36mtranslate_to_russian\u001b[0;34m(sentence, tokenizer, model)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Generate translation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mtranslated_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforced_bos_token_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlang_code_to_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_lang\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# Decode the translation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1653\u001b[0m             )\n\u001b[1;32m   1654\u001b[0m             \u001b[0;31m# 13. run beam search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1655\u001b[0;31m             result = self._beam_search(\n\u001b[0m\u001b[1;32m   1656\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, output_logits, return_dict_in_generate, synced_gpus, sequential, **model_kwargs)\u001b[0m\n\u001b[1;32m   3169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3170\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Unchanged original behavior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3171\u001b[0;31m                 outputs = self(\n\u001b[0m\u001b[1;32m   3172\u001b[0m                     \u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3173\u001b[0m                     \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/mbart/modeling_mbart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1574\u001b[0m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1575\u001b[0m         )\n\u001b[0;32m-> 1576\u001b[0;31m         \u001b[0mlm_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_logits_bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1578\u001b[0m         \u001b[0mmasked_lm_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from translate import Translator\n",
        "\n",
        "# Load the dataset\n",
        "df = df_test\n",
        "\n",
        "\n",
        "# Initialize the translator\n",
        "translator = Translator(to_lang=\"en\", from_lang=\"fr\")\n",
        "\n",
        "# Define a function to translate sentences\n",
        "def translate_sentence(sentence):\n",
        "    try:\n",
        "        translation = translator.translate(sentence)\n",
        "        return translation\n",
        "    except Exception as e:\n",
        "        print(f\"Error translating sentence '{sentence}': {e}\")\n",
        "        return None\n",
        "\n",
        "# Apply the translation function to the dataset\n",
        "df['translated_sentence'] = df['sentence'].apply(translate_sentence)\n",
        "\n",
        "# Save the new dataset with translations\n",
        "\n",
        "\n",
        "print(\"Translation completed and saved to 'translated_dataset.csv'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "IqDgp7e4MY_q",
        "outputId": "2dc7ec11-b4ea-47f0-b177-c769ac491c6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-b39888a807e3>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Apply the translation function to the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'translated_sentence'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslate_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Save the new dataset with translations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4628\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4629\u001b[0m         \"\"\"\n\u001b[0;32m-> 4630\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4632\u001b[0m     def _reduce(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m         \u001b[0;31m# self.f is Callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1025\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1077\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-b39888a807e3>\u001b[0m in \u001b[0;36mtranslate_sentence\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtranslate_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mtranslation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtranslation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/translate/translate.py\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mtext_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRANSLATION_API_MAX_LENGHT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace_whitespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprovider\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_translation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_wraped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext_wraped\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/translate/translate.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mtext_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRANSLATION_API_MAX_LENGHT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace_whitespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprovider\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_translation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_wraped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext_wraped\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/translate/providers/mymemory_translated.py\u001b[0m in \u001b[0;36mget_translation\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_translation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mtranslation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'responseData'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'translatedText'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/translate/providers/mymemory_translated.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'de'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memail\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \"\"\"\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"get\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0;31m# Redirect resolving generator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m             \u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve_redirects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0;31m# Redirect resolving generator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m             \u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve_redirects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mresolve_redirects\u001b[0;34m(self, resp, req, stream, timeout, verify, cert, proxies, yield_requests, **adapter_kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m                 resp = self.send(\n\u001b[0m\u001b[1;32m    267\u001b[0m                     \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                     \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    487\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    792\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;31m# Receive the response from the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1303\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "# Load the dataset\n",
        "df = df_test\n",
        "\n",
        "# Load the T5 model and tokenizer\n",
        "model_name = 'google/t5-small-ssm-nq'\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "def translate_to_russian(sentence, tokenizer, model):\n",
        "    # Prepare the text for translation\n",
        "    inputs = tokenizer.encode(f'translate French to Russian: {sentence}', return_tensors='pt')\n",
        "\n",
        "    # Generate translation\n",
        "    outputs = model.generate(inputs)\n",
        "\n",
        "    # Decode the translation\n",
        "    translated_sentence = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return translated_sentence\n",
        "\n",
        "# Apply the translation function to the dataset\n",
        "df['translated_sentence'] = df['sentence'].apply(lambda x: translate_to_russian(x, tokenizer, model))\n",
        "\n",
        "# Save the new dataset\n",
        "\n",
        "\n",
        "print(\"Translation completed and saved to 'translated_data.csv'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDxWzLpJF8Ar",
        "outputId": "2244dd1b-ff22-4942-d1bf-2dc03d1b6fbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1141: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translation completed and saved to 'translated_data.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rfEqQE6pN4im",
        "outputId": "6a915cdb-cb16-4a96-e4a0-5d086b7e39c7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 1.786511  [    0/ 8640]\n",
            "loss: 1.807472  [   80/ 8640]\n",
            "loss: 1.779651  [  160/ 8640]\n",
            "loss: 1.716003  [  240/ 8640]\n",
            "loss: 1.640763  [  320/ 8640]\n",
            "loss: 1.626217  [  400/ 8640]\n",
            "loss: 1.540816  [  480/ 8640]\n",
            "loss: 1.529840  [  560/ 8640]\n",
            "loss: 1.423571  [  640/ 8640]\n",
            "loss: 1.516129  [  720/ 8640]\n",
            "loss: 1.412546  [  800/ 8640]\n",
            "loss: 1.061795  [  880/ 8640]\n",
            "loss: 1.108844  [  960/ 8640]\n",
            "loss: 1.408844  [ 1040/ 8640]\n",
            "loss: 1.263089  [ 1120/ 8640]\n",
            "loss: 1.420491  [ 1200/ 8640]\n",
            "loss: 1.187398  [ 1280/ 8640]\n",
            "loss: 1.523376  [ 1360/ 8640]\n",
            "loss: 1.099955  [ 1440/ 8640]\n",
            "loss: 1.233220  [ 1520/ 8640]\n",
            "loss: 1.408776  [ 1600/ 8640]\n",
            "loss: 1.225007  [ 1680/ 8640]\n",
            "loss: 1.140383  [ 1760/ 8640]\n",
            "loss: 0.929376  [ 1840/ 8640]\n",
            "loss: 1.126644  [ 1920/ 8640]\n",
            "loss: 1.146497  [ 2000/ 8640]\n",
            "loss: 1.371192  [ 2080/ 8640]\n",
            "loss: 1.110719  [ 2160/ 8640]\n",
            "loss: 1.326157  [ 2240/ 8640]\n",
            "loss: 0.855516  [ 2320/ 8640]\n",
            "loss: 1.411407  [ 2400/ 8640]\n",
            "loss: 0.919865  [ 2480/ 8640]\n",
            "loss: 0.723934  [ 2560/ 8640]\n",
            "loss: 1.139720  [ 2640/ 8640]\n",
            "loss: 1.907530  [ 2720/ 8640]\n",
            "loss: 1.141031  [ 2800/ 8640]\n",
            "loss: 1.275679  [ 2880/ 8640]\n",
            "loss: 0.776967  [ 2960/ 8640]\n",
            "loss: 1.404006  [ 3040/ 8640]\n",
            "loss: 1.058344  [ 3120/ 8640]\n",
            "loss: 0.979485  [ 3200/ 8640]\n",
            "loss: 1.111107  [ 3280/ 8640]\n",
            "loss: 1.109999  [ 3360/ 8640]\n",
            "loss: 0.762109  [ 3440/ 8640]\n",
            "loss: 1.264644  [ 3520/ 8640]\n",
            "loss: 0.843185  [ 3600/ 8640]\n",
            "loss: 1.047271  [ 3680/ 8640]\n",
            "loss: 1.369970  [ 3760/ 8640]\n",
            "loss: 1.475778  [ 3840/ 8640]\n",
            "loss: 0.984643  [ 3920/ 8640]\n",
            "loss: 1.549231  [ 4000/ 8640]\n",
            "loss: 1.225747  [ 4080/ 8640]\n",
            "loss: 0.580885  [ 4160/ 8640]\n",
            "loss: 0.903683  [ 4240/ 8640]\n",
            "loss: 0.880306  [ 4320/ 8640]\n",
            "loss: 0.900485  [ 4400/ 8640]\n",
            "loss: 1.182476  [ 4480/ 8640]\n",
            "loss: 1.627206  [ 4560/ 8640]\n",
            "loss: 1.192983  [ 4640/ 8640]\n",
            "loss: 0.963091  [ 4720/ 8640]\n",
            "loss: 0.882645  [ 4800/ 8640]\n",
            "loss: 1.025069  [ 4880/ 8640]\n",
            "loss: 0.917632  [ 4960/ 8640]\n",
            "loss: 0.825964  [ 5040/ 8640]\n",
            "loss: 1.055928  [ 5120/ 8640]\n",
            "loss: 0.537900  [ 5200/ 8640]\n",
            "loss: 1.760728  [ 5280/ 8640]\n",
            "loss: 1.179043  [ 5360/ 8640]\n",
            "loss: 1.074112  [ 5440/ 8640]\n",
            "loss: 1.008929  [ 5520/ 8640]\n",
            "loss: 0.713095  [ 5600/ 8640]\n",
            "loss: 1.018960  [ 5680/ 8640]\n",
            "loss: 0.954295  [ 5760/ 8640]\n",
            "loss: 1.058079  [ 5840/ 8640]\n",
            "loss: 0.581156  [ 5920/ 8640]\n",
            "loss: 0.846867  [ 6000/ 8640]\n",
            "loss: 1.168359  [ 6080/ 8640]\n",
            "loss: 0.694623  [ 6160/ 8640]\n",
            "loss: 0.785453  [ 6240/ 8640]\n",
            "loss: 0.666781  [ 6320/ 8640]\n",
            "loss: 1.175784  [ 6400/ 8640]\n",
            "loss: 0.967450  [ 6480/ 8640]\n",
            "loss: 0.629008  [ 6560/ 8640]\n",
            "loss: 0.916452  [ 6640/ 8640]\n",
            "loss: 0.925016  [ 6720/ 8640]\n",
            "loss: 0.866001  [ 6800/ 8640]\n",
            "loss: 1.396786  [ 6880/ 8640]\n",
            "loss: 0.902153  [ 6960/ 8640]\n",
            "loss: 0.958079  [ 7040/ 8640]\n",
            "loss: 1.002658  [ 7120/ 8640]\n",
            "loss: 0.905545  [ 7200/ 8640]\n",
            "loss: 0.869022  [ 7280/ 8640]\n",
            "loss: 1.016953  [ 7360/ 8640]\n",
            "loss: 0.920279  [ 7440/ 8640]\n",
            "loss: 1.211515  [ 7520/ 8640]\n",
            "loss: 0.840582  [ 7600/ 8640]\n",
            "loss: 0.714317  [ 7680/ 8640]\n",
            "loss: 1.069928  [ 7760/ 8640]\n",
            "loss: 1.042220  [ 7840/ 8640]\n",
            "loss: 0.760448  [ 7920/ 8640]\n",
            "loss: 1.175268  [ 8000/ 8640]\n",
            "loss: 0.953394  [ 8080/ 8640]\n",
            "loss: 0.683287  [ 8160/ 8640]\n",
            "loss: 1.195937  [ 8240/ 8640]\n",
            "loss: 0.707147  [ 8320/ 8640]\n",
            "loss: 0.978594  [ 8400/ 8640]\n",
            "loss: 0.597650  [ 8480/ 8640]\n",
            "loss: 0.797570  [ 8560/ 8640]\n",
            "Training done\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.970900  [    0/ 8640]\n",
            "loss: 0.828791  [   80/ 8640]\n",
            "loss: 1.126519  [  160/ 8640]\n",
            "loss: 0.717524  [  240/ 8640]\n",
            "loss: 0.938661  [  320/ 8640]\n",
            "loss: 0.657557  [  400/ 8640]\n",
            "loss: 0.440344  [  480/ 8640]\n",
            "loss: 0.734889  [  560/ 8640]\n",
            "loss: 0.606549  [  640/ 8640]\n",
            "loss: 0.821933  [  720/ 8640]\n",
            "loss: 0.675002  [  800/ 8640]\n",
            "loss: 0.599215  [  880/ 8640]\n",
            "loss: 0.555716  [  960/ 8640]\n",
            "loss: 0.859857  [ 1040/ 8640]\n",
            "loss: 0.901477  [ 1120/ 8640]\n",
            "loss: 0.691562  [ 1200/ 8640]\n",
            "loss: 0.336824  [ 1280/ 8640]\n",
            "loss: 0.555208  [ 1360/ 8640]\n",
            "loss: 0.555962  [ 1440/ 8640]\n",
            "loss: 0.745853  [ 1520/ 8640]\n",
            "loss: 1.036783  [ 1600/ 8640]\n",
            "loss: 1.001288  [ 1680/ 8640]\n",
            "loss: 1.194033  [ 1760/ 8640]\n",
            "loss: 0.687179  [ 1840/ 8640]\n",
            "loss: 1.427806  [ 1920/ 8640]\n",
            "loss: 0.546145  [ 2000/ 8640]\n",
            "loss: 0.911413  [ 2080/ 8640]\n",
            "loss: 0.679904  [ 2160/ 8640]\n",
            "loss: 0.711367  [ 2240/ 8640]\n",
            "loss: 1.163569  [ 2320/ 8640]\n",
            "loss: 0.412410  [ 2400/ 8640]\n",
            "loss: 0.555447  [ 2480/ 8640]\n",
            "loss: 0.961172  [ 2560/ 8640]\n",
            "loss: 0.632952  [ 2640/ 8640]\n",
            "loss: 0.847360  [ 2720/ 8640]\n",
            "loss: 0.765320  [ 2800/ 8640]\n",
            "loss: 0.568037  [ 2880/ 8640]\n",
            "loss: 0.413981  [ 2960/ 8640]\n",
            "loss: 0.612268  [ 3040/ 8640]\n",
            "loss: 0.476893  [ 3120/ 8640]\n",
            "loss: 0.803805  [ 3200/ 8640]\n",
            "loss: 0.411745  [ 3280/ 8640]\n",
            "loss: 1.092808  [ 3360/ 8640]\n",
            "loss: 0.714344  [ 3440/ 8640]\n",
            "loss: 0.407293  [ 3520/ 8640]\n",
            "loss: 0.389184  [ 3600/ 8640]\n",
            "loss: 0.418242  [ 3680/ 8640]\n",
            "loss: 0.732119  [ 3760/ 8640]\n",
            "loss: 0.347008  [ 3840/ 8640]\n",
            "loss: 0.402425  [ 3920/ 8640]\n",
            "loss: 0.361927  [ 4000/ 8640]\n",
            "loss: 0.415288  [ 4080/ 8640]\n",
            "loss: 0.393949  [ 4160/ 8640]\n",
            "loss: 1.090253  [ 4240/ 8640]\n",
            "loss: 1.188920  [ 4320/ 8640]\n",
            "loss: 0.597310  [ 4400/ 8640]\n",
            "loss: 0.565910  [ 4480/ 8640]\n",
            "loss: 1.089562  [ 4560/ 8640]\n",
            "loss: 0.448508  [ 4640/ 8640]\n",
            "loss: 0.808765  [ 4720/ 8640]\n",
            "loss: 0.625431  [ 4800/ 8640]\n",
            "loss: 0.905725  [ 4880/ 8640]\n",
            "loss: 0.666624  [ 4960/ 8640]\n",
            "loss: 0.654501  [ 5040/ 8640]\n",
            "loss: 0.822942  [ 5120/ 8640]\n",
            "loss: 0.798556  [ 5200/ 8640]\n",
            "loss: 1.039107  [ 5280/ 8640]\n",
            "loss: 1.110666  [ 5360/ 8640]\n",
            "loss: 1.166663  [ 5440/ 8640]\n",
            "loss: 1.125599  [ 5520/ 8640]\n",
            "loss: 0.520611  [ 5600/ 8640]\n",
            "loss: 0.350463  [ 5680/ 8640]\n",
            "loss: 0.323477  [ 5760/ 8640]\n",
            "loss: 0.474489  [ 5840/ 8640]\n",
            "loss: 0.498276  [ 5920/ 8640]\n",
            "loss: 1.293965  [ 6000/ 8640]\n",
            "loss: 0.281838  [ 6080/ 8640]\n",
            "loss: 1.017352  [ 6160/ 8640]\n",
            "loss: 0.754297  [ 6240/ 8640]\n",
            "loss: 1.235405  [ 6320/ 8640]\n",
            "loss: 0.397884  [ 6400/ 8640]\n",
            "loss: 0.999297  [ 6480/ 8640]\n",
            "loss: 0.540939  [ 6560/ 8640]\n",
            "loss: 0.659570  [ 6640/ 8640]\n",
            "loss: 0.285188  [ 6720/ 8640]\n",
            "loss: 0.471861  [ 6800/ 8640]\n",
            "loss: 1.279847  [ 6880/ 8640]\n",
            "loss: 0.284542  [ 6960/ 8640]\n",
            "loss: 0.297241  [ 7040/ 8640]\n",
            "loss: 0.314072  [ 7120/ 8640]\n",
            "loss: 0.591112  [ 7200/ 8640]\n",
            "loss: 0.688553  [ 7280/ 8640]\n",
            "loss: 0.478093  [ 7360/ 8640]\n",
            "loss: 0.627616  [ 7440/ 8640]\n",
            "loss: 1.108315  [ 7520/ 8640]\n",
            "loss: 0.225951  [ 7600/ 8640]\n",
            "loss: 0.505911  [ 7680/ 8640]\n",
            "loss: 0.439996  [ 7760/ 8640]\n",
            "loss: 1.125683  [ 7840/ 8640]\n",
            "loss: 0.560969  [ 7920/ 8640]\n",
            "loss: 0.468750  [ 8000/ 8640]\n",
            "loss: 0.651945  [ 8080/ 8640]\n",
            "loss: 0.275952  [ 8160/ 8640]\n",
            "loss: 0.496792  [ 8240/ 8640]\n",
            "loss: 1.549569  [ 8320/ 8640]\n",
            "loss: 0.917226  [ 8400/ 8640]\n",
            "loss: 0.289794  [ 8480/ 8640]\n",
            "loss: 0.138313  [ 8560/ 8640]\n",
            "Training done\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.231297  [    0/ 8640]\n",
            "loss: 0.273388  [   80/ 8640]\n",
            "loss: 0.115439  [  160/ 8640]\n",
            "loss: 0.184545  [  240/ 8640]\n",
            "loss: 0.270234  [  320/ 8640]\n",
            "loss: 0.218987  [  400/ 8640]\n",
            "loss: 0.173979  [  480/ 8640]\n",
            "loss: 0.084914  [  560/ 8640]\n",
            "loss: 0.331421  [  640/ 8640]\n",
            "loss: 0.247075  [  720/ 8640]\n",
            "loss: 0.341151  [  800/ 8640]\n",
            "loss: 0.305779  [  880/ 8640]\n",
            "loss: 0.131140  [  960/ 8640]\n",
            "loss: 0.147050  [ 1040/ 8640]\n",
            "loss: 0.192841  [ 1120/ 8640]\n",
            "loss: 0.278535  [ 1200/ 8640]\n",
            "loss: 0.482919  [ 1280/ 8640]\n",
            "loss: 0.125037  [ 1360/ 8640]\n",
            "loss: 0.087999  [ 1440/ 8640]\n",
            "loss: 0.332683  [ 1520/ 8640]\n",
            "loss: 0.151214  [ 1600/ 8640]\n",
            "loss: 0.080746  [ 1680/ 8640]\n",
            "loss: 0.511265  [ 1760/ 8640]\n",
            "loss: 0.304172  [ 1840/ 8640]\n",
            "loss: 0.244016  [ 1920/ 8640]\n",
            "loss: 0.379949  [ 2000/ 8640]\n",
            "loss: 0.162540  [ 2080/ 8640]\n",
            "loss: 0.720159  [ 2160/ 8640]\n",
            "loss: 0.377961  [ 2240/ 8640]\n",
            "loss: 0.194733  [ 2320/ 8640]\n",
            "loss: 0.519805  [ 2400/ 8640]\n",
            "loss: 0.954136  [ 2480/ 8640]\n",
            "loss: 0.195357  [ 2560/ 8640]\n",
            "loss: 0.148353  [ 2640/ 8640]\n",
            "loss: 0.358286  [ 2720/ 8640]\n",
            "loss: 0.675518  [ 2800/ 8640]\n",
            "loss: 0.209654  [ 2880/ 8640]\n",
            "loss: 0.548826  [ 2960/ 8640]\n",
            "loss: 0.721512  [ 3040/ 8640]\n",
            "loss: 0.241052  [ 3120/ 8640]\n",
            "loss: 0.246227  [ 3200/ 8640]\n",
            "loss: 0.037150  [ 3280/ 8640]\n",
            "loss: 0.206692  [ 3360/ 8640]\n",
            "loss: 0.086606  [ 3440/ 8640]\n",
            "loss: 0.164593  [ 3520/ 8640]\n",
            "loss: 0.671025  [ 3600/ 8640]\n",
            "loss: 0.596511  [ 3680/ 8640]\n",
            "loss: 0.108969  [ 3760/ 8640]\n",
            "loss: 0.160891  [ 3840/ 8640]\n",
            "loss: 0.364343  [ 3920/ 8640]\n",
            "loss: 0.521895  [ 4000/ 8640]\n",
            "loss: 0.127802  [ 4080/ 8640]\n",
            "loss: 0.440797  [ 4160/ 8640]\n",
            "loss: 0.147564  [ 4240/ 8640]\n",
            "loss: 0.271619  [ 4320/ 8640]\n",
            "loss: 0.546520  [ 4400/ 8640]\n",
            "loss: 0.452211  [ 4480/ 8640]\n",
            "loss: 0.223308  [ 4560/ 8640]\n",
            "loss: 0.206662  [ 4640/ 8640]\n",
            "loss: 0.683235  [ 4720/ 8640]\n",
            "loss: 0.557254  [ 4800/ 8640]\n",
            "loss: 0.289053  [ 4880/ 8640]\n",
            "loss: 1.040456  [ 4960/ 8640]\n",
            "loss: 0.081300  [ 5040/ 8640]\n",
            "loss: 0.090082  [ 5120/ 8640]\n",
            "loss: 0.309950  [ 5200/ 8640]\n",
            "loss: 0.679889  [ 5280/ 8640]\n",
            "loss: 0.227372  [ 5360/ 8640]\n",
            "loss: 0.355766  [ 5440/ 8640]\n",
            "loss: 0.438260  [ 5520/ 8640]\n",
            "loss: 0.790186  [ 5600/ 8640]\n",
            "loss: 0.091909  [ 5680/ 8640]\n",
            "loss: 0.358797  [ 5760/ 8640]\n",
            "loss: 0.236021  [ 5840/ 8640]\n",
            "loss: 0.145105  [ 5920/ 8640]\n",
            "loss: 0.073308  [ 6000/ 8640]\n",
            "loss: 0.603000  [ 6080/ 8640]\n",
            "loss: 0.571365  [ 6160/ 8640]\n",
            "loss: 0.387043  [ 6240/ 8640]\n",
            "loss: 0.090527  [ 6320/ 8640]\n",
            "loss: 0.523659  [ 6400/ 8640]\n",
            "loss: 0.366352  [ 6480/ 8640]\n",
            "loss: 0.520524  [ 6560/ 8640]\n",
            "loss: 0.606464  [ 6640/ 8640]\n",
            "loss: 0.268766  [ 6720/ 8640]\n",
            "loss: 0.721730  [ 6800/ 8640]\n",
            "loss: 0.098071  [ 6880/ 8640]\n",
            "loss: 0.165765  [ 6960/ 8640]\n",
            "loss: 0.851526  [ 7040/ 8640]\n",
            "loss: 0.065981  [ 7120/ 8640]\n",
            "loss: 0.124477  [ 7200/ 8640]\n",
            "loss: 0.086186  [ 7280/ 8640]\n",
            "loss: 0.743398  [ 7360/ 8640]\n",
            "loss: 0.127848  [ 7440/ 8640]\n",
            "loss: 0.182543  [ 7520/ 8640]\n",
            "loss: 0.152487  [ 7600/ 8640]\n",
            "loss: 0.235045  [ 7680/ 8640]\n",
            "loss: 0.164052  [ 7760/ 8640]\n",
            "loss: 0.261562  [ 7840/ 8640]\n",
            "loss: 0.215135  [ 7920/ 8640]\n",
            "loss: 0.031208  [ 8000/ 8640]\n",
            "loss: 0.351603  [ 8080/ 8640]\n",
            "loss: 0.368903  [ 8160/ 8640]\n",
            "loss: 0.581905  [ 8240/ 8640]\n",
            "loss: 0.172850  [ 8320/ 8640]\n",
            "loss: 0.222788  [ 8400/ 8640]\n",
            "loss: 0.142368  [ 8480/ 8640]\n",
            "loss: 0.147690  [ 8560/ 8640]\n",
            "Training done\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.708075  [    0/ 8640]\n",
            "loss: 0.269202  [   80/ 8640]\n",
            "loss: 0.041097  [  160/ 8640]\n",
            "loss: 0.059243  [  240/ 8640]\n",
            "loss: 0.147639  [  320/ 8640]\n",
            "loss: 0.301247  [  400/ 8640]\n",
            "loss: 0.171522  [  480/ 8640]\n",
            "loss: 0.160653  [  560/ 8640]\n",
            "loss: 0.234460  [  640/ 8640]\n",
            "loss: 0.046326  [  720/ 8640]\n",
            "loss: 0.048848  [  800/ 8640]\n",
            "loss: 0.085973  [  880/ 8640]\n",
            "loss: 0.350978  [  960/ 8640]\n",
            "loss: 0.086904  [ 1040/ 8640]\n",
            "loss: 0.043731  [ 1120/ 8640]\n",
            "loss: 0.043620  [ 1200/ 8640]\n",
            "loss: 0.464903  [ 1280/ 8640]\n",
            "loss: 0.494894  [ 1360/ 8640]\n",
            "loss: 0.681591  [ 1440/ 8640]\n",
            "loss: 0.044420  [ 1520/ 8640]\n",
            "loss: 0.071987  [ 1600/ 8640]\n",
            "loss: 0.159399  [ 1680/ 8640]\n",
            "loss: 0.192164  [ 1760/ 8640]\n",
            "loss: 0.187580  [ 1840/ 8640]\n",
            "loss: 0.032873  [ 1920/ 8640]\n",
            "loss: 0.025388  [ 2000/ 8640]\n",
            "loss: 0.045284  [ 2080/ 8640]\n",
            "loss: 0.027277  [ 2160/ 8640]\n",
            "loss: 0.038642  [ 2240/ 8640]\n",
            "loss: 0.636380  [ 2320/ 8640]\n",
            "loss: 0.016666  [ 2400/ 8640]\n",
            "loss: 0.017230  [ 2480/ 8640]\n",
            "loss: 0.016000  [ 2560/ 8640]\n",
            "loss: 0.268766  [ 2640/ 8640]\n",
            "loss: 0.275702  [ 2720/ 8640]\n",
            "loss: 0.156551  [ 2800/ 8640]\n",
            "loss: 0.069284  [ 2880/ 8640]\n",
            "loss: 0.051674  [ 2960/ 8640]\n",
            "loss: 0.035067  [ 3040/ 8640]\n",
            "loss: 0.027162  [ 3120/ 8640]\n",
            "loss: 0.056155  [ 3200/ 8640]\n",
            "loss: 0.019775  [ 3280/ 8640]\n",
            "loss: 0.142067  [ 3360/ 8640]\n",
            "loss: 0.683327  [ 3440/ 8640]\n",
            "loss: 0.026652  [ 3520/ 8640]\n",
            "loss: 0.500263  [ 3600/ 8640]\n",
            "loss: 0.058822  [ 3680/ 8640]\n",
            "loss: 0.097303  [ 3760/ 8640]\n",
            "loss: 0.049158  [ 3840/ 8640]\n",
            "loss: 0.043601  [ 3920/ 8640]\n",
            "loss: 0.040887  [ 4000/ 8640]\n",
            "loss: 0.025019  [ 4080/ 8640]\n",
            "loss: 0.678575  [ 4160/ 8640]\n",
            "loss: 0.317867  [ 4240/ 8640]\n",
            "loss: 0.170167  [ 4320/ 8640]\n",
            "loss: 0.022344  [ 4400/ 8640]\n",
            "loss: 0.362160  [ 4480/ 8640]\n",
            "loss: 0.050234  [ 4560/ 8640]\n",
            "loss: 0.038891  [ 4640/ 8640]\n",
            "loss: 0.653390  [ 4720/ 8640]\n",
            "loss: 0.079131  [ 4800/ 8640]\n",
            "loss: 0.374857  [ 4880/ 8640]\n",
            "loss: 0.064044  [ 4960/ 8640]\n",
            "loss: 0.063009  [ 5040/ 8640]\n",
            "loss: 0.127855  [ 5120/ 8640]\n",
            "loss: 0.230124  [ 5200/ 8640]\n",
            "loss: 0.439492  [ 5280/ 8640]\n",
            "loss: 0.103018  [ 5360/ 8640]\n",
            "loss: 0.063170  [ 5440/ 8640]\n",
            "loss: 0.063185  [ 5520/ 8640]\n",
            "loss: 0.375515  [ 5600/ 8640]\n",
            "loss: 0.180286  [ 5680/ 8640]\n",
            "loss: 0.312797  [ 5760/ 8640]\n",
            "loss: 0.473118  [ 5840/ 8640]\n",
            "loss: 0.074612  [ 5920/ 8640]\n",
            "loss: 0.057759  [ 6000/ 8640]\n",
            "loss: 0.653816  [ 6080/ 8640]\n",
            "loss: 0.198844  [ 6160/ 8640]\n",
            "loss: 0.051028  [ 6240/ 8640]\n",
            "loss: 0.017272  [ 6320/ 8640]\n",
            "loss: 0.032177  [ 6400/ 8640]\n",
            "loss: 0.013498  [ 6480/ 8640]\n",
            "loss: 0.426970  [ 6560/ 8640]\n",
            "loss: 0.134368  [ 6640/ 8640]\n",
            "loss: 0.368979  [ 6720/ 8640]\n",
            "loss: 0.069028  [ 6800/ 8640]\n",
            "loss: 0.086497  [ 6880/ 8640]\n",
            "loss: 0.170374  [ 6960/ 8640]\n",
            "loss: 0.097758  [ 7040/ 8640]\n",
            "loss: 0.075871  [ 7120/ 8640]\n",
            "loss: 0.418505  [ 7200/ 8640]\n",
            "loss: 0.362962  [ 7280/ 8640]\n",
            "loss: 0.340850  [ 7360/ 8640]\n",
            "loss: 0.022372  [ 7440/ 8640]\n",
            "loss: 0.032053  [ 7520/ 8640]\n",
            "loss: 0.049734  [ 7600/ 8640]\n",
            "loss: 0.169555  [ 7680/ 8640]\n",
            "loss: 0.015255  [ 7760/ 8640]\n",
            "loss: 0.230016  [ 7840/ 8640]\n",
            "loss: 0.473475  [ 7920/ 8640]\n",
            "loss: 0.048221  [ 8000/ 8640]\n",
            "loss: 0.014909  [ 8080/ 8640]\n",
            "loss: 0.027541  [ 8160/ 8640]\n",
            "loss: 0.031777  [ 8240/ 8640]\n",
            "loss: 0.174546  [ 8320/ 8640]\n",
            "loss: 0.025795  [ 8400/ 8640]\n",
            "loss: 1.153903  [ 8480/ 8640]\n",
            "loss: 0.222745  [ 8560/ 8640]\n",
            "Training done\n",
            "Test Accuracy: 86.46%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_05f611bd-f73f-4f35-bb91-cc437a649b7e\", \"sample_text_add_b8_lr4e5_e4.csv\", 8504)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load your data\n",
        "data = df_combined\n",
        "sentences = data['sentence'].tolist()\n",
        "difficulties = data['difficulty'].tolist()\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(difficulties)\n",
        "\n",
        "# Load CamemBERT tokenizer and model\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
        "camembert = CamembertModel.from_pretrained('camembert-base')\n",
        "\n",
        "# Tokenize sentences and convert to tensor\n",
        "def tokenize_and_encode(sentences):\n",
        "    return tokenizer(sentences, padding=True, truncation=True, max_length=600, return_tensors='pt')\n",
        "\n",
        "# Custom Dataset class\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.encodings = tokenize_and_encode(texts)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: self.encodings[key][idx] for key in self.encodings}, self.labels[idx]\n",
        "\n",
        "# Data preparation\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    sentences, encoded_labels, test_size=0.1, random_state=42, stratify=encoded_labels\n",
        ")\n",
        "\n",
        "train_dataset = TextDataset(X_train, y_train)\n",
        "test_dataset = TextDataset(X_test, y_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# Neural network model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Net, self).__init__()\n",
        "        self.camembert = camembert\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.fc = nn.Linear(self.camembert.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        outputs = self.camembert(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.fc(pooled_output)\n",
        "        return logits\n",
        "\n",
        "# Instantiate the model, loss, and optimizer\n",
        "model = Net(len(label_encoder.classes_)).to('cuda')\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=4e-5)\n",
        "\n",
        "# Function to compute accuracy\n",
        "def compute_accuracy(dataloader, model):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            inputs, labels = batch\n",
        "            inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
        "            labels = labels.to('cuda')\n",
        "            outputs = model(**inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "# Training loop\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()  # Set model to training mode\n",
        "    for batch, (inputs, labels) in enumerate(dataloader):\n",
        "        inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
        "        labels = labels.to('cuda')\n",
        "        pred = model(**inputs)\n",
        "        loss = loss_fn(pred, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 10 == 0:\n",
        "            loss, current = loss.item(), batch * len(inputs['input_ids'])\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "# Execute training\n",
        "for epoch in range(4):  # Number of epochs\n",
        "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
        "    train_loop(train_loader, model, criterion, optimizer)\n",
        "    print(\"Training done\")\n",
        "\n",
        "# Test the model\n",
        "accuracy = compute_accuracy(test_loader, model)\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import CamembertTokenizer\n",
        "\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
        "\n",
        "# Tokenize and encode the test data\n",
        "def tokenize_and_encode(sentences):\n",
        "    return tokenizer(sentences, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
        "\n",
        "# Custom Dataset class for test data\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, texts):\n",
        "        self.encodings = tokenize_and_encode(texts)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings['input_ids'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: self.encodings[key][idx] for key in self.encodings}\n",
        "\n",
        "# Create the dataset and dataloader for df_test\n",
        "test_dataset = TestDataset(df_test['sentence'].tolist())\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# Define the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Generate predictions for df_test\n",
        "model.eval()  # Make sure the model is in evaluation mode\n",
        "all_predictions = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        inputs = {key: value.to(device) for key, value in batch.items()}\n",
        "        outputs = model(**inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "# Convert numeric predictions back to labels\n",
        "predicted_labels = label_encoder.inverse_transform(all_predictions)\n",
        "\n",
        "# Prepare and save the submission file\n",
        "submission_df = pd.DataFrame({\n",
        "    'id': df_test['id'],  # Ensure df_test includes an 'id' column\n",
        "    'difficulty': predicted_labels\n",
        "})\n",
        "\n",
        "submission_df.to_csv('sample_text_add_b8_lr4e5_e4.csv', index=False)\n",
        "from google.colab import files\n",
        "files.download('sample_text_add_b8_lr4e5_e4.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AtqR5bR2Fs9g",
        "outputId": "b7ac5755-3124-4960-8264-74ccc958cba0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 1.795988  [    0/ 8160]\n",
            "loss: 1.797478  [   80/ 8160]\n",
            "loss: 1.825825  [  160/ 8160]\n",
            "loss: 1.733957  [  240/ 8160]\n",
            "loss: 1.706884  [  320/ 8160]\n",
            "loss: 1.711145  [  400/ 8160]\n",
            "loss: 1.521396  [  480/ 8160]\n",
            "loss: 1.512682  [  560/ 8160]\n",
            "loss: 1.569028  [  640/ 8160]\n",
            "loss: 1.401170  [  720/ 8160]\n",
            "loss: 1.640328  [  800/ 8160]\n",
            "loss: 1.427413  [  880/ 8160]\n",
            "loss: 1.470399  [  960/ 8160]\n",
            "loss: 1.075428  [ 1040/ 8160]\n",
            "loss: 1.341420  [ 1120/ 8160]\n",
            "loss: 1.229537  [ 1200/ 8160]\n",
            "loss: 1.260453  [ 1280/ 8160]\n",
            "loss: 1.320525  [ 1360/ 8160]\n",
            "loss: 1.474462  [ 1440/ 8160]\n",
            "loss: 1.414066  [ 1520/ 8160]\n",
            "loss: 1.358855  [ 1600/ 8160]\n",
            "loss: 1.362416  [ 1680/ 8160]\n",
            "loss: 1.224808  [ 1760/ 8160]\n",
            "loss: 1.472096  [ 1840/ 8160]\n",
            "loss: 1.150709  [ 1920/ 8160]\n",
            "loss: 1.102430  [ 2000/ 8160]\n",
            "loss: 1.616877  [ 2080/ 8160]\n",
            "loss: 1.266897  [ 2160/ 8160]\n",
            "loss: 1.565632  [ 2240/ 8160]\n",
            "loss: 1.278989  [ 2320/ 8160]\n",
            "loss: 1.623816  [ 2400/ 8160]\n",
            "loss: 1.308924  [ 2480/ 8160]\n",
            "loss: 1.113584  [ 2560/ 8160]\n",
            "loss: 1.154083  [ 2640/ 8160]\n",
            "loss: 1.044272  [ 2720/ 8160]\n",
            "loss: 0.924072  [ 2800/ 8160]\n",
            "loss: 1.126482  [ 2880/ 8160]\n",
            "loss: 1.091001  [ 2960/ 8160]\n",
            "loss: 1.461967  [ 3040/ 8160]\n",
            "loss: 1.134611  [ 3120/ 8160]\n",
            "loss: 1.403615  [ 3200/ 8160]\n",
            "loss: 1.238088  [ 3280/ 8160]\n",
            "loss: 0.880348  [ 3360/ 8160]\n",
            "loss: 1.199517  [ 3440/ 8160]\n",
            "loss: 0.960622  [ 3520/ 8160]\n",
            "loss: 1.360843  [ 3600/ 8160]\n",
            "loss: 1.059475  [ 3680/ 8160]\n",
            "loss: 1.229773  [ 3760/ 8160]\n",
            "loss: 1.229249  [ 3840/ 8160]\n",
            "loss: 1.475848  [ 3920/ 8160]\n",
            "loss: 1.140935  [ 4000/ 8160]\n",
            "loss: 0.924200  [ 4080/ 8160]\n",
            "loss: 1.186186  [ 4160/ 8160]\n",
            "loss: 0.904311  [ 4240/ 8160]\n",
            "loss: 1.219672  [ 4320/ 8160]\n",
            "loss: 1.008881  [ 4400/ 8160]\n",
            "loss: 0.996322  [ 4480/ 8160]\n",
            "loss: 0.981498  [ 4560/ 8160]\n",
            "loss: 1.100943  [ 4640/ 8160]\n",
            "loss: 1.135534  [ 4720/ 8160]\n",
            "loss: 1.129692  [ 4800/ 8160]\n",
            "loss: 0.925485  [ 4880/ 8160]\n",
            "loss: 1.107897  [ 4960/ 8160]\n",
            "loss: 0.896300  [ 5040/ 8160]\n",
            "loss: 0.940978  [ 5120/ 8160]\n",
            "loss: 0.684497  [ 5200/ 8160]\n",
            "loss: 0.954590  [ 5280/ 8160]\n",
            "loss: 1.171832  [ 5360/ 8160]\n",
            "loss: 1.148352  [ 5440/ 8160]\n",
            "loss: 0.825307  [ 5520/ 8160]\n",
            "loss: 0.918037  [ 5600/ 8160]\n",
            "loss: 1.042695  [ 5680/ 8160]\n",
            "loss: 1.770092  [ 5760/ 8160]\n",
            "loss: 0.814595  [ 5840/ 8160]\n",
            "loss: 1.146970  [ 5920/ 8160]\n",
            "loss: 1.304194  [ 6000/ 8160]\n",
            "loss: 0.767054  [ 6080/ 8160]\n",
            "loss: 0.951685  [ 6160/ 8160]\n",
            "loss: 1.026136  [ 6240/ 8160]\n",
            "loss: 1.074962  [ 6320/ 8160]\n",
            "loss: 1.013106  [ 6400/ 8160]\n",
            "loss: 1.163446  [ 6480/ 8160]\n",
            "loss: 0.620088  [ 6560/ 8160]\n",
            "loss: 1.198275  [ 6640/ 8160]\n",
            "loss: 0.673804  [ 6720/ 8160]\n",
            "loss: 0.691251  [ 6800/ 8160]\n",
            "loss: 1.599039  [ 6880/ 8160]\n",
            "loss: 0.945330  [ 6960/ 8160]\n",
            "loss: 1.231476  [ 7040/ 8160]\n",
            "loss: 0.939026  [ 7120/ 8160]\n",
            "loss: 0.900743  [ 7200/ 8160]\n",
            "loss: 1.085356  [ 7280/ 8160]\n",
            "loss: 0.918766  [ 7360/ 8160]\n",
            "loss: 1.143852  [ 7440/ 8160]\n",
            "loss: 0.381538  [ 7520/ 8160]\n",
            "loss: 0.810469  [ 7600/ 8160]\n",
            "loss: 0.726244  [ 7680/ 8160]\n",
            "loss: 0.932275  [ 7760/ 8160]\n",
            "loss: 0.802160  [ 7840/ 8160]\n",
            "loss: 1.128024  [ 7920/ 8160]\n",
            "loss: 1.055465  [ 8000/ 8160]\n",
            "loss: 1.268877  [ 8080/ 8160]\n",
            "Training done\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.788720  [    0/ 8160]\n",
            "loss: 1.613786  [   80/ 8160]\n",
            "loss: 0.728726  [  160/ 8160]\n",
            "loss: 0.919088  [  240/ 8160]\n",
            "loss: 0.852245  [  320/ 8160]\n",
            "loss: 1.328943  [  400/ 8160]\n",
            "loss: 0.494158  [  480/ 8160]\n",
            "loss: 0.705341  [  560/ 8160]\n",
            "loss: 1.112836  [  640/ 8160]\n",
            "loss: 0.911938  [  720/ 8160]\n",
            "loss: 0.966229  [  800/ 8160]\n",
            "loss: 0.940040  [  880/ 8160]\n",
            "loss: 0.458372  [  960/ 8160]\n",
            "loss: 0.614215  [ 1040/ 8160]\n",
            "loss: 1.177914  [ 1120/ 8160]\n",
            "loss: 1.296462  [ 1200/ 8160]\n",
            "loss: 0.951891  [ 1280/ 8160]\n",
            "loss: 0.436637  [ 1360/ 8160]\n",
            "loss: 0.956732  [ 1440/ 8160]\n",
            "loss: 0.478928  [ 1520/ 8160]\n",
            "loss: 0.612085  [ 1600/ 8160]\n",
            "loss: 0.530971  [ 1680/ 8160]\n",
            "loss: 0.750893  [ 1760/ 8160]\n",
            "loss: 0.732771  [ 1840/ 8160]\n",
            "loss: 1.018522  [ 1920/ 8160]\n",
            "loss: 1.105524  [ 2000/ 8160]\n",
            "loss: 0.933193  [ 2080/ 8160]\n",
            "loss: 0.966483  [ 2160/ 8160]\n",
            "loss: 0.954333  [ 2240/ 8160]\n",
            "loss: 0.763629  [ 2320/ 8160]\n",
            "loss: 0.762035  [ 2400/ 8160]\n",
            "loss: 0.754533  [ 2480/ 8160]\n",
            "loss: 0.960510  [ 2560/ 8160]\n",
            "loss: 0.336067  [ 2640/ 8160]\n",
            "loss: 0.890280  [ 2720/ 8160]\n",
            "loss: 1.145859  [ 2800/ 8160]\n",
            "loss: 0.590212  [ 2880/ 8160]\n",
            "loss: 1.038665  [ 2960/ 8160]\n",
            "loss: 0.432281  [ 3040/ 8160]\n",
            "loss: 0.762880  [ 3120/ 8160]\n",
            "loss: 0.709563  [ 3200/ 8160]\n",
            "loss: 0.581324  [ 3280/ 8160]\n",
            "loss: 0.547467  [ 3360/ 8160]\n",
            "loss: 0.690035  [ 3440/ 8160]\n",
            "loss: 1.172565  [ 3520/ 8160]\n",
            "loss: 0.992600  [ 3600/ 8160]\n",
            "loss: 0.905784  [ 3680/ 8160]\n",
            "loss: 1.404188  [ 3760/ 8160]\n",
            "loss: 0.344927  [ 3840/ 8160]\n",
            "loss: 0.623020  [ 3920/ 8160]\n",
            "loss: 0.728376  [ 4000/ 8160]\n",
            "loss: 0.799885  [ 4080/ 8160]\n",
            "loss: 0.576923  [ 4160/ 8160]\n",
            "loss: 1.042070  [ 4240/ 8160]\n",
            "loss: 0.978526  [ 4320/ 8160]\n",
            "loss: 0.748208  [ 4400/ 8160]\n",
            "loss: 0.440625  [ 4480/ 8160]\n",
            "loss: 0.597404  [ 4560/ 8160]\n",
            "loss: 1.073003  [ 4640/ 8160]\n",
            "loss: 0.557829  [ 4720/ 8160]\n",
            "loss: 0.595741  [ 4800/ 8160]\n",
            "loss: 0.757270  [ 4880/ 8160]\n",
            "loss: 0.349326  [ 4960/ 8160]\n",
            "loss: 0.732484  [ 5040/ 8160]\n",
            "loss: 1.128115  [ 5120/ 8160]\n",
            "loss: 0.478643  [ 5200/ 8160]\n",
            "loss: 0.890157  [ 5280/ 8160]\n",
            "loss: 0.653012  [ 5360/ 8160]\n",
            "loss: 2.163393  [ 5440/ 8160]\n",
            "loss: 0.497316  [ 5520/ 8160]\n",
            "loss: 0.663568  [ 5600/ 8160]\n",
            "loss: 0.851451  [ 5680/ 8160]\n",
            "loss: 0.971770  [ 5760/ 8160]\n",
            "loss: 0.622090  [ 5840/ 8160]\n",
            "loss: 0.238646  [ 5920/ 8160]\n",
            "loss: 0.965154  [ 6000/ 8160]\n",
            "loss: 0.670279  [ 6080/ 8160]\n",
            "loss: 0.616698  [ 6160/ 8160]\n",
            "loss: 0.507304  [ 6240/ 8160]\n",
            "loss: 1.168029  [ 6320/ 8160]\n",
            "loss: 0.503090  [ 6400/ 8160]\n",
            "loss: 1.223015  [ 6480/ 8160]\n",
            "loss: 0.518778  [ 6560/ 8160]\n",
            "loss: 0.457924  [ 6640/ 8160]\n",
            "loss: 0.344706  [ 6720/ 8160]\n",
            "loss: 0.461535  [ 6800/ 8160]\n",
            "loss: 0.901737  [ 6880/ 8160]\n",
            "loss: 1.164454  [ 6960/ 8160]\n",
            "loss: 1.775495  [ 7040/ 8160]\n",
            "loss: 0.401229  [ 7120/ 8160]\n",
            "loss: 0.471527  [ 7200/ 8160]\n",
            "loss: 0.655680  [ 7280/ 8160]\n",
            "loss: 0.667322  [ 7360/ 8160]\n",
            "loss: 0.744667  [ 7440/ 8160]\n",
            "loss: 0.364575  [ 7520/ 8160]\n",
            "loss: 0.319323  [ 7600/ 8160]\n",
            "loss: 0.554049  [ 7680/ 8160]\n",
            "loss: 0.791364  [ 7760/ 8160]\n",
            "loss: 0.379194  [ 7840/ 8160]\n",
            "loss: 0.807240  [ 7920/ 8160]\n",
            "loss: 0.639277  [ 8000/ 8160]\n",
            "loss: 0.524433  [ 8080/ 8160]\n",
            "Training done\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.908335  [    0/ 8160]\n",
            "loss: 0.198851  [   80/ 8160]\n",
            "loss: 0.489869  [  160/ 8160]\n",
            "loss: 0.735031  [  240/ 8160]\n",
            "loss: 0.276766  [  320/ 8160]\n",
            "loss: 0.306499  [  400/ 8160]\n",
            "loss: 0.768658  [  480/ 8160]\n",
            "loss: 0.627786  [  560/ 8160]\n",
            "loss: 0.466398  [  640/ 8160]\n",
            "loss: 0.316478  [  720/ 8160]\n",
            "loss: 0.904693  [  800/ 8160]\n",
            "loss: 0.500632  [  880/ 8160]\n",
            "loss: 0.606131  [  960/ 8160]\n",
            "loss: 0.628339  [ 1040/ 8160]\n",
            "loss: 0.505169  [ 1120/ 8160]\n",
            "loss: 0.112574  [ 1200/ 8160]\n",
            "loss: 0.279755  [ 1280/ 8160]\n",
            "loss: 0.210473  [ 1360/ 8160]\n",
            "loss: 0.206428  [ 1440/ 8160]\n",
            "loss: 0.575311  [ 1520/ 8160]\n",
            "loss: 0.136278  [ 1600/ 8160]\n",
            "loss: 0.282620  [ 1680/ 8160]\n",
            "loss: 0.348373  [ 1760/ 8160]\n",
            "loss: 0.191266  [ 1840/ 8160]\n",
            "loss: 0.329197  [ 1920/ 8160]\n",
            "loss: 0.086256  [ 2000/ 8160]\n",
            "loss: 0.307653  [ 2080/ 8160]\n",
            "loss: 0.571622  [ 2160/ 8160]\n",
            "loss: 0.830479  [ 2240/ 8160]\n",
            "loss: 0.835899  [ 2320/ 8160]\n",
            "loss: 1.236484  [ 2400/ 8160]\n",
            "loss: 0.390324  [ 2480/ 8160]\n",
            "loss: 0.473175  [ 2560/ 8160]\n",
            "loss: 0.384321  [ 2640/ 8160]\n",
            "loss: 0.324955  [ 2720/ 8160]\n",
            "loss: 0.345115  [ 2800/ 8160]\n",
            "loss: 0.227526  [ 2880/ 8160]\n",
            "loss: 0.216372  [ 2960/ 8160]\n",
            "loss: 0.624365  [ 3040/ 8160]\n",
            "loss: 0.252564  [ 3120/ 8160]\n",
            "loss: 0.153860  [ 3200/ 8160]\n",
            "loss: 0.370931  [ 3280/ 8160]\n",
            "loss: 0.226500  [ 3360/ 8160]\n",
            "loss: 0.240552  [ 3440/ 8160]\n",
            "loss: 0.062595  [ 3520/ 8160]\n",
            "loss: 0.556230  [ 3600/ 8160]\n",
            "loss: 0.390004  [ 3680/ 8160]\n",
            "loss: 0.345406  [ 3760/ 8160]\n",
            "loss: 0.434274  [ 3840/ 8160]\n",
            "loss: 0.197434  [ 3920/ 8160]\n",
            "loss: 0.767655  [ 4000/ 8160]\n",
            "loss: 0.212444  [ 4080/ 8160]\n",
            "loss: 1.023244  [ 4160/ 8160]\n",
            "loss: 0.414594  [ 4240/ 8160]\n",
            "loss: 0.378111  [ 4320/ 8160]\n",
            "loss: 0.414206  [ 4400/ 8160]\n",
            "loss: 0.247495  [ 4480/ 8160]\n",
            "loss: 1.055488  [ 4560/ 8160]\n",
            "loss: 0.072296  [ 4640/ 8160]\n",
            "loss: 0.284853  [ 4720/ 8160]\n",
            "loss: 0.347936  [ 4800/ 8160]\n",
            "loss: 0.515210  [ 4880/ 8160]\n",
            "loss: 0.172258  [ 4960/ 8160]\n",
            "loss: 0.320387  [ 5040/ 8160]\n",
            "loss: 0.265909  [ 5120/ 8160]\n",
            "loss: 0.211865  [ 5200/ 8160]\n",
            "loss: 0.615927  [ 5280/ 8160]\n",
            "loss: 0.323117  [ 5360/ 8160]\n",
            "loss: 0.486202  [ 5440/ 8160]\n",
            "loss: 0.316167  [ 5520/ 8160]\n",
            "loss: 0.099552  [ 5600/ 8160]\n",
            "loss: 0.143373  [ 5680/ 8160]\n",
            "loss: 0.567828  [ 5760/ 8160]\n",
            "loss: 0.174752  [ 5840/ 8160]\n",
            "loss: 0.490466  [ 5920/ 8160]\n",
            "loss: 0.663357  [ 6000/ 8160]\n",
            "loss: 0.075256  [ 6080/ 8160]\n",
            "loss: 0.293273  [ 6160/ 8160]\n",
            "loss: 0.362970  [ 6240/ 8160]\n",
            "loss: 0.187103  [ 6320/ 8160]\n",
            "loss: 0.116946  [ 6400/ 8160]\n",
            "loss: 0.579699  [ 6480/ 8160]\n",
            "loss: 0.343374  [ 6560/ 8160]\n",
            "loss: 0.226963  [ 6640/ 8160]\n",
            "loss: 0.371237  [ 6720/ 8160]\n",
            "loss: 0.321092  [ 6800/ 8160]\n",
            "loss: 0.866853  [ 6880/ 8160]\n",
            "loss: 0.192796  [ 6960/ 8160]\n",
            "loss: 0.101035  [ 7040/ 8160]\n",
            "loss: 0.554067  [ 7120/ 8160]\n",
            "loss: 0.133877  [ 7200/ 8160]\n",
            "loss: 0.213941  [ 7280/ 8160]\n",
            "loss: 0.063090  [ 7360/ 8160]\n",
            "loss: 0.897314  [ 7440/ 8160]\n",
            "loss: 0.321664  [ 7520/ 8160]\n",
            "loss: 1.023541  [ 7600/ 8160]\n",
            "loss: 0.120848  [ 7680/ 8160]\n",
            "loss: 0.435462  [ 7760/ 8160]\n",
            "loss: 0.408042  [ 7840/ 8160]\n",
            "loss: 0.121251  [ 7920/ 8160]\n",
            "loss: 0.184245  [ 8000/ 8160]\n",
            "loss: 0.209008  [ 8080/ 8160]\n",
            "Training done\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.129324  [    0/ 8160]\n",
            "loss: 0.120068  [   80/ 8160]\n",
            "loss: 0.328564  [  160/ 8160]\n",
            "loss: 0.074824  [  240/ 8160]\n",
            "loss: 0.134292  [  320/ 8160]\n",
            "loss: 0.069928  [  400/ 8160]\n",
            "loss: 0.042260  [  480/ 8160]\n",
            "loss: 0.397268  [  560/ 8160]\n",
            "loss: 0.240616  [  640/ 8160]\n",
            "loss: 0.311708  [  720/ 8160]\n",
            "loss: 0.039291  [  800/ 8160]\n",
            "loss: 0.091144  [  880/ 8160]\n",
            "loss: 0.084429  [  960/ 8160]\n",
            "loss: 0.110007  [ 1040/ 8160]\n",
            "loss: 0.040232  [ 1120/ 8160]\n",
            "loss: 0.455973  [ 1200/ 8160]\n",
            "loss: 0.529097  [ 1280/ 8160]\n",
            "loss: 0.115786  [ 1360/ 8160]\n",
            "loss: 0.073411  [ 1440/ 8160]\n",
            "loss: 0.164926  [ 1520/ 8160]\n",
            "loss: 0.032780  [ 1600/ 8160]\n",
            "loss: 0.029532  [ 1680/ 8160]\n",
            "loss: 0.082196  [ 1760/ 8160]\n",
            "loss: 0.126821  [ 1840/ 8160]\n",
            "loss: 0.245413  [ 1920/ 8160]\n",
            "loss: 0.040752  [ 2000/ 8160]\n",
            "loss: 0.297922  [ 2080/ 8160]\n",
            "loss: 0.946467  [ 2160/ 8160]\n",
            "loss: 0.288109  [ 2240/ 8160]\n",
            "loss: 0.201820  [ 2320/ 8160]\n",
            "loss: 0.847448  [ 2400/ 8160]\n",
            "loss: 0.024359  [ 2480/ 8160]\n",
            "loss: 0.198278  [ 2560/ 8160]\n",
            "loss: 0.477024  [ 2640/ 8160]\n",
            "loss: 0.083298  [ 2720/ 8160]\n",
            "loss: 0.027330  [ 2800/ 8160]\n",
            "loss: 0.142851  [ 2880/ 8160]\n",
            "loss: 0.026433  [ 2960/ 8160]\n",
            "loss: 0.212583  [ 3040/ 8160]\n",
            "loss: 0.427594  [ 3120/ 8160]\n",
            "loss: 0.145291  [ 3200/ 8160]\n",
            "loss: 0.197257  [ 3280/ 8160]\n",
            "loss: 0.069122  [ 3360/ 8160]\n",
            "loss: 0.034337  [ 3440/ 8160]\n",
            "loss: 0.076616  [ 3520/ 8160]\n",
            "loss: 0.079348  [ 3600/ 8160]\n",
            "loss: 0.094093  [ 3680/ 8160]\n",
            "loss: 0.933840  [ 3760/ 8160]\n",
            "loss: 0.053398  [ 3840/ 8160]\n",
            "loss: 0.037862  [ 3920/ 8160]\n",
            "loss: 0.124027  [ 4000/ 8160]\n",
            "loss: 0.057523  [ 4080/ 8160]\n",
            "loss: 0.198320  [ 4160/ 8160]\n",
            "loss: 0.329123  [ 4240/ 8160]\n",
            "loss: 0.148827  [ 4320/ 8160]\n",
            "loss: 0.526136  [ 4400/ 8160]\n",
            "loss: 0.050738  [ 4480/ 8160]\n",
            "loss: 0.996527  [ 4560/ 8160]\n",
            "loss: 0.197973  [ 4640/ 8160]\n",
            "loss: 0.536745  [ 4720/ 8160]\n",
            "loss: 0.074885  [ 4800/ 8160]\n",
            "loss: 0.050086  [ 4880/ 8160]\n",
            "loss: 0.039531  [ 4960/ 8160]\n",
            "loss: 0.107245  [ 5040/ 8160]\n",
            "loss: 0.055243  [ 5120/ 8160]\n",
            "loss: 0.016960  [ 5200/ 8160]\n",
            "loss: 0.064951  [ 5280/ 8160]\n",
            "loss: 0.070925  [ 5360/ 8160]\n",
            "loss: 0.328884  [ 5440/ 8160]\n",
            "loss: 0.075051  [ 5520/ 8160]\n",
            "loss: 0.035395  [ 5600/ 8160]\n",
            "loss: 0.069603  [ 5680/ 8160]\n",
            "loss: 0.148411  [ 5760/ 8160]\n",
            "loss: 0.056170  [ 5840/ 8160]\n",
            "loss: 0.742102  [ 5920/ 8160]\n",
            "loss: 0.052220  [ 6000/ 8160]\n",
            "loss: 0.085550  [ 6080/ 8160]\n",
            "loss: 0.396842  [ 6160/ 8160]\n",
            "loss: 0.086521  [ 6240/ 8160]\n",
            "loss: 0.035475  [ 6320/ 8160]\n",
            "loss: 0.031054  [ 6400/ 8160]\n",
            "loss: 0.053290  [ 6480/ 8160]\n",
            "loss: 0.078639  [ 6560/ 8160]\n",
            "loss: 0.055501  [ 6640/ 8160]\n",
            "loss: 0.122379  [ 6720/ 8160]\n",
            "loss: 0.042679  [ 6800/ 8160]\n",
            "loss: 0.039736  [ 6880/ 8160]\n",
            "loss: 0.066287  [ 6960/ 8160]\n",
            "loss: 0.046236  [ 7040/ 8160]\n",
            "loss: 0.020521  [ 7120/ 8160]\n",
            "loss: 0.231050  [ 7200/ 8160]\n",
            "loss: 0.112647  [ 7280/ 8160]\n",
            "loss: 0.058671  [ 7360/ 8160]\n",
            "loss: 0.124747  [ 7440/ 8160]\n",
            "loss: 0.019101  [ 7520/ 8160]\n",
            "loss: 0.038719  [ 7600/ 8160]\n",
            "loss: 0.971105  [ 7680/ 8160]\n",
            "loss: 0.014644  [ 7760/ 8160]\n",
            "loss: 1.204555  [ 7840/ 8160]\n",
            "loss: 0.076744  [ 7920/ 8160]\n",
            "loss: 0.332877  [ 8000/ 8160]\n",
            "loss: 0.436739  [ 8080/ 8160]\n",
            "Training done\n",
            "Test Accuracy: 82.08%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_8633f767-5203-4214-a27b-8e2b59263698\", \"sample_text_add_b8_lr3e5_e4_t015.csv\", 8504)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load your data\n",
        "data = df_combined\n",
        "sentences = data['sentence'].tolist()\n",
        "difficulties = data['difficulty'].tolist()\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(difficulties)\n",
        "\n",
        "# Load CamemBERT tokenizer and model\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
        "camembert = CamembertModel.from_pretrained('camembert-base')\n",
        "\n",
        "# Tokenize sentences and convert to tensor\n",
        "def tokenize_and_encode(sentences):\n",
        "    return tokenizer(sentences, padding=True, truncation=True, max_length=600, return_tensors='pt')\n",
        "\n",
        "# Custom Dataset class\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.encodings = tokenize_and_encode(texts)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: self.encodings[key][idx] for key in self.encodings}, self.labels[idx]\n",
        "\n",
        "# Data preparation\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    sentences, encoded_labels, test_size=0.15, random_state=42, stratify=encoded_labels\n",
        ")\n",
        "\n",
        "train_dataset = TextDataset(X_train, y_train)\n",
        "test_dataset = TextDataset(X_test, y_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# Neural network model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Net, self).__init__()\n",
        "        self.camembert = camembert\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.fc = nn.Linear(self.camembert.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        outputs = self.camembert(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.fc(pooled_output)\n",
        "        return logits\n",
        "\n",
        "# Instantiate the model, loss, and optimizer\n",
        "model = Net(len(label_encoder.classes_)).to('cuda')\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-5)\n",
        "\n",
        "# Function to compute accuracy\n",
        "def compute_accuracy(dataloader, model):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            inputs, labels = batch\n",
        "            inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
        "            labels = labels.to('cuda')\n",
        "            outputs = model(**inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "# Training loop\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()  # Set model to training mode\n",
        "    for batch, (inputs, labels) in enumerate(dataloader):\n",
        "        inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
        "        labels = labels.to('cuda')\n",
        "        pred = model(**inputs)\n",
        "        loss = loss_fn(pred, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 10 == 0:\n",
        "            loss, current = loss.item(), batch * len(inputs['input_ids'])\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "# Execute training\n",
        "for epoch in range(4):  # Number of epochs\n",
        "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
        "    train_loop(train_loader, model, criterion, optimizer)\n",
        "    print(\"Training done\")\n",
        "\n",
        "# Test the model\n",
        "accuracy = compute_accuracy(test_loader, model)\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import CamembertTokenizer\n",
        "\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
        "\n",
        "# Tokenize and encode the test data\n",
        "def tokenize_and_encode(sentences):\n",
        "    return tokenizer(sentences, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
        "\n",
        "# Custom Dataset class for test data\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, texts):\n",
        "        self.encodings = tokenize_and_encode(texts)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings['input_ids'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: self.encodings[key][idx] for key in self.encodings}\n",
        "\n",
        "# Create the dataset and dataloader for df_test\n",
        "test_dataset = TestDataset(df_test['sentence'].tolist())\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# Define the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Generate predictions for df_test\n",
        "model.eval()  # Make sure the model is in evaluation mode\n",
        "all_predictions = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        inputs = {key: value.to(device) for key, value in batch.items()}\n",
        "        outputs = model(**inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "# Convert numeric predictions back to labels\n",
        "predicted_labels = label_encoder.inverse_transform(all_predictions)\n",
        "\n",
        "# Prepare and save the submission file\n",
        "submission_df = pd.DataFrame({\n",
        "    'id': df_test['id'],  # Ensure df_test includes an 'id' column\n",
        "    'difficulty': predicted_labels\n",
        "})\n",
        "\n",
        "submission_df.to_csv('sample_text_add_b8_lr3e5_e4_t015.csv', index=False)\n",
        "from google.colab import files\n",
        "files.download('sample_text_add_b8_lr3e5_e4_t015.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Psf5i2Z2CiHj"
      },
      "source": [
        "In addition, in future models I introduced the early stopping."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "IFSx9-b2am23",
        "outputId": "6f0f8b82-e03c-4929-85c2-f87f364dfd5a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3240' max='5400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3240/5400 17:05 < 11:24, 3.16 it/s, Epoch 3/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.148200</td>\n",
              "      <td>1.153521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.893800</td>\n",
              "      <td>1.005013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.794000</td>\n",
              "      <td>1.114019</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_82ffc3ff-1a2b-4ba3-8c87-4028c5136a13\", \"sample_full_2e5_b8_ws800_wd003_e5.csv\", 8504)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import CamembertTokenizer, CamembertForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming df_train and df_test are your training and testing dataframes already loaded\n",
        "training_data = df_combined\n",
        "test_data = df_test\n",
        "\n",
        "# Initialize tokenizer\n",
        "tokenizer = CamembertTokenizer.from_pretrained(\"camembert-base\")\n",
        "\n",
        "# Define the Dataset class\n",
        "class FrenchTextDataset(Dataset):\n",
        "    def __init__(self, texts, labels=None, max_length=512):\n",
        "        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=max_length)\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.labels is not None:\n",
        "            item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)\n",
        "\n",
        "# Encoding the labels\n",
        "label_dict = {label: i for i, label in enumerate(training_data['difficulty'].unique())}\n",
        "training_data['encoded_labels'] = training_data['difficulty'].map(label_dict)\n",
        "\n",
        "# Split training data to create a validation set\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    training_data['sentence'].tolist(),\n",
        "    training_data['encoded_labels'].tolist(),\n",
        "    test_size=0.1,  # Using 10% of data for validation\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Prepare datasets\n",
        "train_dataset = FrenchTextDataset(train_texts, train_labels)\n",
        "val_dataset = FrenchTextDataset(val_texts, val_labels)\n",
        "\n",
        "# Load pretrained CamemBERT model\n",
        "model = CamembertForSequenceClassification.from_pretrained(\"camembert-base\", num_labels=len(label_dict))\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',           # output directory\n",
        "    num_train_epochs=5,               # number of training epochs\n",
        "    per_device_train_batch_size=8,   # batch size for training\n",
        "    per_device_eval_batch_size=8,    # batch size for evaluation\n",
        "    warmup_steps=800,                 # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.03,                # strength of weight decay\n",
        "    learning_rate=2e-5,               # learning rate\n",
        "    logging_dir='./logs',             # directory for storing logs\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\",      # Evaluates at the end of each epoch\n",
        "    save_strategy=\"epoch\",            # Save the model at the end of each epoch\n",
        "    load_best_model_at_end=True,      # Load the best model at the end of training\n",
        "    metric_for_best_model='eval_loss',\n",
        "    greater_is_better=False\n",
        ")\n",
        "\n",
        "# Initialize Trainer with Early Stopping\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=1)]\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Prediction on test data for submission\n",
        "test_dataset = FrenchTextDataset(test_data['sentence'].tolist())\n",
        "test_outputs = trainer.predict(test_dataset)\n",
        "test_preds = np.argmax(test_outputs.predictions, axis=-1)\n",
        "\n",
        "# Convert numeric predictions back to labels\n",
        "inv_label_dict = {v: k for k, v in label_dict.items()}\n",
        "test_difficulties = [inv_label_dict[pred] for pred in test_preds]\n",
        "\n",
        "# Prepare the submission file\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_data['id'],\n",
        "    'difficulty': test_difficulties\n",
        "})\n",
        "\n",
        "submission_df.to_csv('sample_full_2e5_b8_ws800_wd003_e5.csv', index=False)\n",
        "from google.colab import files\n",
        "files.download('sample_full_2e5_b8_ws800_wd003_e5.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 866,
          "referenced_widgets": [
            "6d253ed25a1c4e8894690a41e389241d",
            "fbb571d0382a4960a91a935f8c1d6f0b",
            "4ee453271a944086b49215f301f54576",
            "f4c9769764c042f5b907c474fcae7bd7",
            "19b7f866090f4480a66fe2f8ef8ac98b"
          ]
        },
        "id": "2Xk7gg80am7G",
        "outputId": "fc47ae57-b40a-41ef-ff70-bc5efb528bdd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6d253ed25a1c4e8894690a41e389241d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fbb571d0382a4960a91a935f8c1d6f0b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/811k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ee453271a944086b49215f301f54576",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.40M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4c9769764c042f5b907c474fcae7bd7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/508 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "19b7f866090f4480a66fe2f8ef8ac98b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5400' max='8640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5400/8640 13:48 < 08:17, 6.52 it/s, Epoch 5/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.220500</td>\n",
              "      <td>1.197481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.002600</td>\n",
              "      <td>1.102893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.892800</td>\n",
              "      <td>1.048921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.649500</td>\n",
              "      <td>0.987065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.392900</td>\n",
              "      <td>1.094959</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "NameError",
          "evalue": "name 'submission_df' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-050b5169fa0a>\u001b[0m in \u001b[0;36m<cell line: 168>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    166\u001b[0m })\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m \u001b[0msubmission_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sample_full_15e4_b8_ws800_wd003.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sample_full_15e4_b8_ws800_wd003.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'submission_df' is not defined"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "import random\n",
        "import spacy\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import CamembertTokenizer, CamembertModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load Spacy French model\n",
        "nlp = spacy.load('fr_core_news_sm')\n",
        "\n",
        "# Lemmatization function\n",
        "def lemmatize_text(text):\n",
        "    doc = nlp(text)\n",
        "    return ' '.join([token.lemma_ for token in doc])\n",
        "\n",
        "# Synonym Replacement Function\n",
        "def synonym_replacement(sentence, n):\n",
        "    words = sentence.split()\n",
        "    new_words = words.copy()\n",
        "    french_stopwords = set(nltk.corpus.stopwords.words('french'))\n",
        "    random_word_list = list(set([word for word in words if word not in french_stopwords]))\n",
        "    random.shuffle(random_word_list)\n",
        "    num_replaced = 0\n",
        "    for random_word in random_word_list:\n",
        "        synonyms = get_synonyms(random_word)\n",
        "        if len(synonyms) > 0:\n",
        "            synonym = random.choice(synonyms)\n",
        "            new_words = [synonym if word == random_word else word for word in new_words]\n",
        "            num_replaced += 1\n",
        "        if num_replaced >= n:  # Only replace up to n words\n",
        "            break\n",
        "    return ' '.join(new_words)\n",
        "\n",
        "# Get synonyms using NLTK's WordNet\n",
        "def get_synonyms(word):\n",
        "    synonyms = set()\n",
        "    for syn in wordnet.synsets(word, lang='fra'):\n",
        "        for lemma in syn.lemmas(lang='fra'):\n",
        "            synonym = lemma.name().replace(\"_\", \" \").replace(\"-\", \" \").lower()\n",
        "            synonym = \"\".join([char for char in synonym if char.isalnum() or char.isspace()])\n",
        "            synonyms.add(synonym)\n",
        "    if word in synonyms:\n",
        "        synonyms.remove(word)\n",
        "    return list(synonyms)\n",
        "\n",
        "# Augment and Lemmatize Data\n",
        "new_sentences = []\n",
        "new_difficulties = []\n",
        "for _, row in df_train.iterrows():\n",
        "    original_sentence = row['sentence']\n",
        "    difficulty = row['difficulty']\n",
        "    # First, lemmatize\n",
        "    lemmatized_sentence = lemmatize_text(original_sentence)\n",
        "    # Then, augment via synonym replacement\n",
        "    augmented_sentence = synonym_replacement(lemmatized_sentence, 2)\n",
        "    new_sentences.append(augmented_sentence)\n",
        "    new_difficulties.append(difficulty)\n",
        "\n",
        "# Create a new DataFrame for the augmented sentences\n",
        "df_augmented = pd.DataFrame({'sentence': new_sentences, 'difficulty': new_difficulties})\n",
        "\n",
        "# Concatenate the original and augmented DataFrames\n",
        "df_combined = pd.concat([df_train, df_augmented], ignore_index=True)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import CamembertTokenizer, CamembertForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming df_train and df_test are your training and testing dataframes already loaded\n",
        "training_data = df_combined\n",
        "test_data = df_test\n",
        "\n",
        "# Initialize tokenizer\n",
        "tokenizer = CamembertTokenizer.from_pretrained(\"camembert-base\")\n",
        "\n",
        "# Define the Dataset class\n",
        "class FrenchTextDataset(Dataset):\n",
        "    def __init__(self, texts, labels=None, max_length=512):\n",
        "        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=max_length)\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.labels is not None:\n",
        "            item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)\n",
        "\n",
        "# Encoding the labels\n",
        "label_dict = {label: i for i, label in enumerate(training_data['difficulty'].unique())}\n",
        "training_data['encoded_labels'] = training_data['difficulty'].map(label_dict)\n",
        "\n",
        "# Split training data to create a validation set\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    training_data['sentence'].tolist(),\n",
        "    training_data['encoded_labels'].tolist(),\n",
        "    test_size=0.1,  # Using 10% of data for validation\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Prepare datasets\n",
        "train_dataset = FrenchTextDataset(train_texts, train_labels)\n",
        "val_dataset = FrenchTextDataset(val_texts, val_labels)\n",
        "\n",
        "# Load pretrained CamemBERT model\n",
        "model = CamembertForSequenceClassification.from_pretrained(\"camembert-base\", num_labels=len(label_dict))\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',           # output directory\n",
        "    num_train_epochs=8,               # number of training epochs\n",
        "    per_device_train_batch_size=8,   # batch size for training\n",
        "    per_device_eval_batch_size=8,    # batch size for evaluation\n",
        "    warmup_steps=800,                 # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.03,                # strength of weight decay\n",
        "    learning_rate=0.000015,               # learning rate\n",
        "    logging_dir='./logs',             # directory for storing logs\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\",      # Evaluates at the end of each epoch\n",
        "    save_strategy=\"epoch\",            # Save the model at the end of each epoch\n",
        "    load_best_model_at_end=True,      # Load the best model at the end of training\n",
        "    metric_for_best_model='eval_loss',\n",
        "    greater_is_better=False\n",
        ")\n",
        "\n",
        "# Initialize Trainer with Early Stopping\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=1)]\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Prediction on test data for submission\n",
        "test_dataset = FrenchTextDataset(test_data['sentence'].tolist())\n",
        "test_outputs = trainer.predict(test_dataset)\n",
        "test_preds = np.argmax(test_outputs.predictions, axis=-1)\n",
        "\n",
        "# Convert numeric predictions back to labels\n",
        "inv_label_dict = {v: k for k, v in label_dict.items()}\n",
        "test_difficulties = [inv_label_dict[pred] for pred in test_preds]\n",
        "\n",
        "# Prepare the submission file\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_data['id'],\n",
        "    'difficulty': test_difficulties\n",
        "})\n",
        "\n",
        "submission_df.to_csv('sample_full_15e4_b8_ws800_wd003.csv', index=False)\n",
        "from google.colab import files\n",
        "files.download('sample_full_15e4_b8_ws800_wd003.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "8THfQ8qVrzsk",
        "outputId": "10e1b207-29fb-4400-b5d0-2610e8b487cc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3780' max='4320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3780/4320 17:51 < 02:33, 3.53 it/s, Epoch 7/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.340700</td>\n",
              "      <td>1.330250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.068300</td>\n",
              "      <td>1.158415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.946000</td>\n",
              "      <td>1.115242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.742000</td>\n",
              "      <td>0.983687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.574100</td>\n",
              "      <td>0.938723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.390900</td>\n",
              "      <td>0.945055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.409600</td>\n",
              "      <td>0.943327</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_aa6729a2-ee2c-4460-8485-6c994e6cbd47\", \"sample_full_2e5_b16_ws800_wd003.csv\", 8504)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Assuming df_train and df_test are your training and testing dataframes already loaded\n",
        "training_data = df_combined\n",
        "test_data = df_test\n",
        "\n",
        "# Initialize tokenizer\n",
        "tokenizer = CamembertTokenizer.from_pretrained(\"camembert-base\")\n",
        "\n",
        "# Define the Dataset class\n",
        "class FrenchTextDataset(Dataset):\n",
        "    def __init__(self, texts, labels=None, max_length=512):\n",
        "        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=max_length)\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.labels is not None:\n",
        "            item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)\n",
        "\n",
        "# Encoding the labels\n",
        "label_dict = {label: i for i, label in enumerate(training_data['difficulty'].unique())}\n",
        "training_data['encoded_labels'] = training_data['difficulty'].map(label_dict)\n",
        "\n",
        "# Split training data to create a validation set\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    training_data['sentence'].tolist(),\n",
        "    training_data['encoded_labels'].tolist(),\n",
        "    test_size=0.1,  # Using 10% of data for validation\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Prepare datasets\n",
        "train_dataset = FrenchTextDataset(train_texts, train_labels)\n",
        "val_dataset = FrenchTextDataset(val_texts, val_labels)\n",
        "\n",
        "# Load pretrained CamemBERT model\n",
        "model = CamembertForSequenceClassification.from_pretrained(\"camembert-base\", num_labels=len(label_dict))\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',           # output directory\n",
        "    num_train_epochs=8,               # number of training epochs\n",
        "    per_device_train_batch_size=16,   # batch size for training\n",
        "    per_device_eval_batch_size=16,    # batch size for evaluation\n",
        "    warmup_steps=800,                 # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.03,                # strength of weight decay\n",
        "    learning_rate=0.00002,               # learning rate\n",
        "    logging_dir='./logs',             # directory for storing logs\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\",      # Evaluates at the end of each epoch\n",
        "    save_strategy=\"epoch\",            # Save the model at the end of each epoch\n",
        "    load_best_model_at_end=True,      # Load the best model at the end of training\n",
        "    metric_for_best_model='eval_loss',\n",
        "    greater_is_better=False\n",
        ")\n",
        "\n",
        "# Initialize Trainer with Early Stopping\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Prediction on test data for submission\n",
        "test_dataset = FrenchTextDataset(test_data['sentence'].tolist())\n",
        "test_outputs = trainer.predict(test_dataset)\n",
        "test_preds = np.argmax(test_outputs.predictions, axis=-1)\n",
        "\n",
        "# Convert numeric predictions back to labels\n",
        "inv_label_dict = {v: k for k, v in label_dict.items()}\n",
        "test_difficulties = [inv_label_dict[pred] for pred in test_preds]\n",
        "\n",
        "# Prepare the submission file\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_data['id'],\n",
        "    'difficulty': test_difficulties\n",
        "})\n",
        "\n",
        "submission.to_csv('sample_full_2e5_b16_ws800_wd003.csv', index=False)\n",
        "from google.colab import files\n",
        "files.download('sample_full_2e5_b16_ws800_wd003.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689,
          "referenced_widgets": [
            "894f118579224248b487140efd8f2bb4",
            "740a0f0618e345498bfd20e491f3e6cd",
            "5d2c0602638a44b6ad8f30788a095daa",
            "7b2d1c0bb1e243a1ac0053c3bf9f9a79",
            "d2a6a5faebc945dab8d90e4cef24d920",
            "c9a31171c73b452abd8abcbecf30f55e",
            "b1ede2668e744aeb94c8c57ce3a64bb3",
            "5f7b4b85edd341c4a55436795358f328",
            "6b1a08de92324d399461688098db2855",
            "43ab2c3b82624ac2b496ce87a335e9f9",
            "ff7b4f20988a41dfb540ef07b6b827ee",
            "04aca5f66c684f39b2742519560baa9e",
            "d0a2f4d256634c0696903e352e56e03c",
            "e00f07e0811248818d963346a3e7287b",
            "30d84510e0bb4d1a882dabc918790244",
            "745f71a5292740d2a179bb267a8f46d2",
            "c158850e950945afafa06ba89d96a098",
            "8fcd39fb7e2c4ad0ab38cc7cc53a7629",
            "af7f2c6e9cb04b788e524d1a8e0a6022",
            "7b11bc4dfdc645e38fb551e4e001a6ce",
            "8acf7afd6b6b474ca58d104e0d2ad138",
            "64d504ae9d8340a893bfc5e92c3245b6",
            "abec94fd8b59494fafb3c518afbdb1e5",
            "3161fb79e454458e8e04d495d39b0931",
            "fa4c45903e7a4b0fae62b4fa7feb06c3",
            "fccc75bb64b14e8492a1cfab2a372728",
            "e6adfea04dac40109af4005bdb8360b7",
            "ba2bf1ddb0704b4dabbc2c69718bc019",
            "95b348efac9d4302a940e453535838cd",
            "441821564d3c49f99e1faadb88c1bf86",
            "f89e4c68308943f29bde2770f9b92db9",
            "c0daf2c9ecca4e57b94a697f87acb1d0",
            "b71d47dfd19f4826909e46bf8f4b987a",
            "50cc0d88ff84476d96c5da46a90839ab",
            "333db846091a423c8ee45db90f383450",
            "f452c875be6e44e88701ad0a83050005",
            "123cfb18260948009985d261cfc83cc2",
            "67d7f3e8fb314b79a169ab2c80f2faf7",
            "55041bb27a6b463fa7ba5585fc9c18c6",
            "00dff373ee7f4ae9b73c0016ec233fc2",
            "3799f431f18143e68ec99ec35eb0c3ab",
            "658b80da5dd14af0a20b12b22fa9b8f1",
            "6368e7349e2c4e8d8709c6ff91b70b66",
            "86239162c28a4d1192f3560dda05dc72",
            "25b94efbf7eb4704a22b8b18db661738",
            "31cc8566ae7d4ff18ad882eb7428329e",
            "b2479957f07b4d0faa50805c69857115",
            "42fb3a0ef512430c8605c7bcc0c3878a",
            "8b8d286a58404563bc7250bcd2f24bbb",
            "16af1834d27e41a985cfdd0657d3e890",
            "444a13a1aed24d27a491d1242d78253e",
            "a1f739f2e26f46d6b9f38fbad9fd8dbd",
            "11919ce42d134a218b3b196efdaf7fa1",
            "822701c880be41e6a3bc4da402ca34b3",
            "a6916484459d49cfbe5d50b634e40cdf"
          ]
        },
        "id": "GWBzeTyTSRW5",
        "outputId": "1e4ede01-8eac-45a7-fe94-63b97de1d5b9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "894f118579224248b487140efd8f2bb4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "04aca5f66c684f39b2742519560baa9e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/811k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "abec94fd8b59494fafb3c518afbdb1e5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.40M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "50cc0d88ff84476d96c5da46a90839ab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/508 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "25b94efbf7eb4704a22b8b18db661738",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1620' max='1890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1620/1890 14:47 < 02:28, 1.82 it/s, Epoch 6/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.731900</td>\n",
              "      <td>1.718635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.338900</td>\n",
              "      <td>1.304006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.172000</td>\n",
              "      <td>1.187798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.021400</td>\n",
              "      <td>1.015917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.831900</td>\n",
              "      <td>1.013026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.697700</td>\n",
              "      <td>1.136656</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "NameError",
          "evalue": "name 'submission_df' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-be4e70bfa111>\u001b[0m in \u001b[0;36m<cell line: 94>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m })\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m \u001b[0msubmission_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sample_full_2e5_b16_ws1000_wd01.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sample_full_2e5_b16_ws1000_wd01.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'submission_df' is not defined"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import CamembertTokenizer, CamembertForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming df_train and df_test are your training and testing dataframes already loaded\n",
        "training_data = df_train\n",
        "test_data = df_test\n",
        "\n",
        "# Initialize tokenizer\n",
        "tokenizer = CamembertTokenizer.from_pretrained(\"camembert-base\")\n",
        "\n",
        "# Define the Dataset class\n",
        "class FrenchTextDataset(Dataset):\n",
        "    def __init__(self, texts, labels=None, max_length=512):\n",
        "        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=max_length)\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.labels is not None:\n",
        "            item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)\n",
        "\n",
        "# Encoding the labels\n",
        "label_dict = {label: i for i, label in enumerate(training_data['difficulty'].unique())}\n",
        "training_data['encoded_labels'] = training_data['difficulty'].map(label_dict)\n",
        "\n",
        "# Split training data to create a validation set\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    training_data['sentence'].tolist(),\n",
        "    training_data['encoded_labels'].tolist(),\n",
        "    test_size=0.1,  # Using 10% of data for validation\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Prepare datasets\n",
        "train_dataset = FrenchTextDataset(train_texts, train_labels)\n",
        "val_dataset = FrenchTextDataset(val_texts, val_labels)\n",
        "\n",
        "# Load pretrained CamemBERT model\n",
        "model = CamembertForSequenceClassification.from_pretrained(\"camembert-base\", num_labels=len(label_dict))\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',           # output directory\n",
        "    num_train_epochs=7,               # number of training epochs\n",
        "    per_device_train_batch_size=16,   # batch size for training\n",
        "    per_device_eval_batch_size=16,    # batch size for evaluation\n",
        "    warmup_steps=1000,                 # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.1,                # strength of weight decay\n",
        "    learning_rate=2e-5,               # learning rate\n",
        "    logging_dir='./logs',             # directory for storing logs\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\",      # Evaluates at the end of each epoch\n",
        "    save_strategy=\"epoch\",            # Save the model at the end of each epoch\n",
        "    load_best_model_at_end=True,      # Load the best model at the end of training\n",
        "    metric_for_best_model='eval_loss',\n",
        "    greater_is_better=False\n",
        ")\n",
        "\n",
        "# Initialize Trainer with Early Stopping\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=1)]\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Prediction on test data for submission\n",
        "test_dataset = FrenchTextDataset(test_data['sentence'].tolist())\n",
        "test_outputs = trainer.predict(test_dataset)\n",
        "test_preds = np.argmax(test_outputs.predictions, axis=-1)\n",
        "\n",
        "# Convert numeric predictions back to labels\n",
        "inv_label_dict = {v: k for k, v in label_dict.items()}\n",
        "test_difficulties = [inv_label_dict[pred] for pred in test_preds]\n",
        "\n",
        "# Prepare the submission file\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_data['id'],\n",
        "    'difficulty': test_difficulties\n",
        "})\n",
        "\n",
        "submission.to_csv('sample_full_2e5_b16_ws1000_wd01.csv', index=False)\n",
        "from google.colab import files\n",
        "files.download('sample_full_2e5_b16_ws1000_wd01.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "EKv4Vdd_WpPt",
        "outputId": "eb9669c7-fc33-4efb-973e-b889dd26f893"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_02d09b52-256d-40f8-bb3f-137ad14f2c4e\", \"sample_full_2e5_b16_ws1000_wd01.csv\", 8504)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "submission.to_csv('sample_full_2e5_b16_ws1000_wd01.csv', index=False)\n",
        "from google.colab import files\n",
        "files.download('sample_full_2e5_b16_ws1000_wd01.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "outputId": "b748c1cc-1c3d-4c99-9fb9-53eca8d21389",
        "id": "VvcnHBImz2dA"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-bd6bde5ebd72>\u001b[0m in \u001b[0;36m<cell line: 70>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mdifficulty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'difficulty'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0maugmented_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msynonym_replacement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mback_translated_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mback_translate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maugmented_sentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0mnew_sentences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mback_translated_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mnew_difficulties\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdifficulty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-bd6bde5ebd72>\u001b[0m in \u001b[0;36mback_translate\u001b[0;34m(texts)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mtranslated_to_en\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_fr_to_en\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer_fr_to_en\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;31m# Translate back from English to French\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mback_translated_to_fr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslated_to_en\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_en_to_fr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer_en_to_fr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mback_translated_to_fr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-bd6bde5ebd72>\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(texts, model, tokenizer)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mtranslated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1653\u001b[0m             )\n\u001b[1;32m   1654\u001b[0m             \u001b[0;31m# 13. run beam search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1655\u001b[0;31m             result = self._beam_search(\n\u001b[0m\u001b[1;32m   1656\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, output_logits, return_dict_in_generate, synced_gpus, sequential, **model_kwargs)\u001b[0m\n\u001b[1;32m   3169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3170\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Unchanged original behavior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3171\u001b[0;31m                 outputs = self(\n\u001b[0m\u001b[1;32m   3172\u001b[0m                     \u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3173\u001b[0m                     \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/marian/modeling_marian.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1415\u001b[0m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1416\u001b[0m         )\n\u001b[0;32m-> 1417\u001b[0;31m         \u001b[0mlm_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_logits_bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1419\u001b[0m         \u001b[0mmasked_lm_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "import random\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch import nn\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import CamembertTokenizer, CamembertModel, MarianMTModel, MarianTokenizer\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def synonym_replacement(sentence, n):\n",
        "    words = sentence.split()\n",
        "    new_words = words.copy()\n",
        "    french_stopwords = set(nltk.corpus.stopwords.words('french'))\n",
        "    random_word_list = list(set([word for word in words if word not in french_stopwords]))\n",
        "    random.shuffle(random_word_list)\n",
        "    num_replaced = 0\n",
        "    for random_word in random_word_list:\n",
        "        synonyms = get_synonyms(random_word)\n",
        "        if len(synonyms) > 0:\n",
        "            synonym = random.choice(synonyms)\n",
        "            new_words = [synonym if word == random_word else word for word in new_words]\n",
        "            num_replaced += 1\n",
        "        if num_replaced >= n:  # Only replace up to n words\n",
        "            break\n",
        "    return ' '.join(new_words)\n",
        "\n",
        "def get_synonyms(word):\n",
        "    synonyms = set()\n",
        "    for syn in wordnet.synsets(word, lang='fra'):\n",
        "        for lemma in syn.lemmas(lang='fra'):\n",
        "            synonym = lemma.name().replace(\"_\", \" \").replace(\"-\", \" \").lower()\n",
        "            synonym = \"\".join([char for char in synonym if char.isalnum() or char.isspace()])\n",
        "            synonyms.add(synonym)\n",
        "    if word in synonyms:\n",
        "        synonyms.remove(word)\n",
        "    return list(synonyms)\n",
        "\n",
        "# Load MarianMT models and tokenizers\n",
        "model_name_fr_to_en = 'Helsinki-NLP/opus-mt-fr-en'\n",
        "model_name_en_to_fr = 'Helsinki-NLP/opus-mt-en-fr'\n",
        "\n",
        "tokenizer_fr_to_en = MarianTokenizer.from_pretrained(model_name_fr_to_en)\n",
        "model_fr_to_en = MarianMTModel.from_pretrained(model_name_fr_to_en)\n",
        "\n",
        "tokenizer_en_to_fr = MarianTokenizer.from_pretrained(model_name_en_to_fr)\n",
        "model_en_to_fr = MarianMTModel.from_pretrained(model_name_en_to_fr)\n",
        "\n",
        "def translate(texts, model, tokenizer):\n",
        "    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    translated = model.generate(**inputs)\n",
        "    return tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
        "\n",
        "def back_translate(texts):\n",
        "    # Translate from French to English\n",
        "    translated_to_en = translate(texts, model_fr_to_en, tokenizer_fr_to_en)\n",
        "    # Translate back from English to French\n",
        "    back_translated_to_fr = translate(translated_to_en, model_en_to_fr, tokenizer_en_to_fr)\n",
        "    return back_translated_to_fr\n",
        "\n",
        "# Generate augmented sentences\n",
        "new_sentences = []\n",
        "new_difficulties = []\n",
        "for _, row in df_train.iterrows():\n",
        "    original_sentence = row['sentence']\n",
        "    difficulty = row['difficulty']\n",
        "    augmented_sentence = synonym_replacement(original_sentence, 2)\n",
        "    back_translated_sentence = back_translate([augmented_sentence])[0]\n",
        "    new_sentences.append(back_translated_sentence)\n",
        "    new_difficulties.append(difficulty)\n",
        "\n",
        "# Create a new DataFrame for the augmented sentences\n",
        "df_augmented = pd.DataFrame({'sentence': new_sentences, 'difficulty': new_difficulties})\n",
        "\n",
        "# Concatenate the original and augmented DataFrames\n",
        "df_combined = pd.concat([df_train, df_augmented], ignore_index=True)\n",
        "\n",
        "# Load your data\n",
        "data = df_combined\n",
        "sentences = data['sentence'].tolist()\n",
        "difficulties = data['difficulty'].tolist()\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(difficulties)\n",
        "\n",
        "# Load CamemBERT tokenizer and model\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
        "camembert = CamembertModel.from_pretrained('camembert-base')\n",
        "\n",
        "# Tokenize sentences and convert to tensor\n",
        "def tokenize_and_encode(sentences):\n",
        "    return tokenizer(sentences, padding=True, truncation=True, max_length=600, return_tensors='pt')\n",
        "\n",
        "# Custom Dataset class\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.encodings = tokenize_and_encode(texts)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: self.encodings[key][idx] for key in self.encodings}, self.labels[idx]\n",
        "\n",
        "# Data preparation\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    sentences, encoded_labels, test_size=0.1, random_state=42, stratify=encoded_labels\n",
        ")\n",
        "\n",
        "train_dataset = TextDataset(X_train, y_train)\n",
        "test_dataset = TextDataset(X_test, y_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# Neural network model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Net, self).__init__()\n",
        "        self.camembert = camembert\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        self.fc = nn.Linear(self.camembert.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        outputs = self.camembert(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.fc(pooled_output)\n",
        "        return logits\n",
        "\n",
        "# Instantiate the model, loss, and optimizer\n",
        "model = Net(len(label_encoder.classes_)).to('cuda')\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1.75e-5)\n",
        "\n",
        "# Function to compute accuracy\n",
        "def compute_accuracy(dataloader, model):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            inputs, labels = batch\n",
        "            inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
        "            labels = labels.to('cuda')\n",
        "            outputs = model(**inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "# Training loop\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()  # Set model to training mode\n",
        "    for batch, (inputs, labels) in enumerate(dataloader):\n",
        "        inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
        "        labels = labels.to('cuda')\n",
        "        pred = model(**inputs)\n",
        "        loss = loss_fn(pred, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 10 == 0:\n",
        "            loss, current = loss.item(), batch * len(inputs['input_ids'])\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "# Execute training\n",
        "for epoch in range(4):  # Number of epochs\n",
        "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
        "    train_loop(train_loader, model, criterion, optimizer)\n",
        "    print(\"Training done\")\n",
        "\n",
        "# Test the model\n",
        "accuracy = compute_accuracy(test_loader, model)\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "# Load your test data\n",
        "df_test = pd.read_csv('path/to/your/test_data.csv')  # Ensure you have the correct path to your test data\n",
        "\n",
        "# Custom Dataset class for test data\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, texts):\n",
        "        self.encodings = tokenize_and_encode(texts)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings['input_ids'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: self.encodings[key][idx] for key in self.encodings}\n",
        "\n",
        "# Create the dataset and dataloader for df_test\n",
        "test_dataset = TestDataset(df_test['sentence'].tolist())\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# Generate predictions for df_test\n",
        "model.eval()  # Make sure the model is in evaluation mode\n",
        "all_predictions = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        inputs = {key: value.to(device) for key, value in batch.items()}\n",
        "        outputs = model(**inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "# Convert numeric predictions back to labels\n",
        "predicted_labels = label_encoder.inverse_transform(all_predictions)\n",
        "\n",
        "# Prepare and save the submission file\n",
        "submission_df = pd.DataFrame({\n",
        "    'id': df_test['id'],  # Ensure df_test includes an 'id' column\n",
        "    'difficulty': predicted_labels\n",
        "})\n",
        "\n",
        "submission_df.to_csv('sample_text_add_b8_lr175e5_drop01.csv', index=False)\n",
        "from google.colab import files\n",
        "files.download('sample_text_add_b8_lr175e5_drop01.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FE0Q6Cgk0obq"
      },
      "source": [
        "### Streamlit attempts\n",
        "\n",
        "Here, I tried streamlit to get the app."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76d4fcd3-1f64-46cd-a110-a21c1ebe81cc",
        "id": "YjYCDoh40stM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import torch\n",
        "from transformers import CamembertTokenizer, CamembertModel\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the model architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Net, self).__init__()\n",
        "        self.camembert = CamembertModel.from_pretrained('camembert-base')\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        self.fc = nn.Linear(self.camembert.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        outputs = self.camembert(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.last_hidden_state[:, 0]\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.fc(pooled_output)\n",
        "        return logits\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
        "\n",
        "# Function to load the model from pre-trained weights\n",
        "def load_model():\n",
        "    model = Net(num_classes=3)  # Adjust num_classes as per your model\n",
        "    # Simulate loading pre-trained weights (these weights should be replaced with actual weights)\n",
        "    # Here I'm initializing random weights as placeholders\n",
        "    state_dict = model.state_dict()\n",
        "    for key in state_dict:\n",
        "        state_dict[key] = torch.randn(state_dict[key].shape)\n",
        "    model.load_state_dict(state_dict)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# Initialize the model\n",
        "model = load_model()\n",
        "\n",
        "# Prediction function\n",
        "def predict(sentence):\n",
        "    inputs = tokenizer(sentence, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "    return predicted.item()\n",
        "\n",
        "# Streamlit application\n",
        "st.title(\"French Sentence Difficulty Predictor\")\n",
        "\n",
        "input_sentence = st.text_area(\"Enter a French sentence:\", \"\")\n",
        "\n",
        "if st.button(\"Predict Difficulty\"):\n",
        "    if input_sentence:\n",
        "        difficulty = predict(input_sentence)\n",
        "        st.write(f\"The predicted difficulty level is: {difficulty}\")\n",
        "    else:\n",
        "        st.write(\"Please enter a sentence.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbe5c477-bde3-4279-a3d3-2055869cc42d",
        "id": "79tQDgqJ0wn2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<colabcode.code.ColabCode at 0x7f69870c53c0>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from colabcode import ColabCode\n",
        "\n",
        "ColabCode(port=8501, code=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "611f8699-9da7-442e-dd3b-ae976172ed12",
        "id": "Dfgo4-vt00qY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Install necessary packages\n",
        "#!pip install streamlit colabcode\n",
        "\n",
        "# Step 2: Write the Streamlit application code\n",
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import torch\n",
        "from transformers import CamembertTokenizer, CamembertModel\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the model architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Net, self).__init__()\n",
        "        self.camembert = CamembertModel.from_pretrained('camembert-base')\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        self.fc = nn.Linear(self.camembert.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        outputs = self.camembert(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.last_hidden_state[:, 0]\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.fc(pooled_output)\n",
        "        return logits\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
        "\n",
        "# Function to load the model from pre-trained weights\n",
        "def load_model():\n",
        "    model = Net(num_classes=3)  # Adjust num_classes as per your model\n",
        "    # Simulate loading pre-trained weights (these weights should be replaced with actual weights)\n",
        "    # Here I'm initializing random weights as placeholders\n",
        "    state_dict = model.state_dict()\n",
        "    for key in state_dict:\n",
        "        state_dict[key] = torch.randn(state_dict[key].shape)\n",
        "    model.load_state_dict(state_dict)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# Initialize the model\n",
        "model = load_model()\n",
        "\n",
        "# Prediction function\n",
        "def predict(sentence):\n",
        "    inputs = tokenizer(sentence, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "    return predicted.item()\n",
        "\n",
        "# Streamlit application\n",
        "st.title(\"French Sentence Difficulty Predictor\")\n",
        "\n",
        "input_sentence = st.text_area(\"Enter a French sentence:\", \"\")\n",
        "\n",
        "if st.button(\"Predict Difficulty\"):\n",
        "    if input_sentence:\n",
        "        difficulty = predict(input_sentence)\n",
        "        st.write(f\"The predicted difficulty level is: {difficulty}\")\n",
        "    else:\n",
        "        st.write(\"Please enter a sentence.\")\n",
        "\n",
        "# Step 3: Run the Streamlit application with ColabCode\n",
        "from colabcode import ColabCode\n",
        "\n",
        "ColabCode(port=8501, code=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42451e50-372b-482e-8377-d614d41a6343",
        "id": "zOdEjoVl05BA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.34.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (7.1.2)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.25.2)\n",
            "Requirement already satisfied: packaging<25,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.0)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.0.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.3.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.11.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: watchdog>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.0.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
            "\u001b[K\u001b[?25h/tools/node/bin/lt -> /tools/node/lib/node_modules/localtunnel/bin/lt.js\n",
            "+ localtunnel@2.0.2\n",
            "added 22 packages from 22 contributors in 1.94s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UsageError: Line magic function `%%writefile` not found.\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Install necessary packages\n",
        "!pip install streamlit\n",
        "!npm install -g localtunnel\n",
        "\n",
        "# Step 2: Write the Streamlit application code\n",
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import torch\n",
        "from transformers import CamembertTokenizer, CamembertModel\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the model architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Net, self).__init__()\n",
        "        self.camembert = CamembertModel.from_pretrained('camembert-base')\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        self.fc = nn.Linear(self.camembert.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        outputs = self.camembert(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.last_hidden_state[:, 0]\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.fc(pooled_output)\n",
        "        return logits\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
        "\n",
        "# Function to load the model from pre-trained weights\n",
        "def load_model():\n",
        "    model = Net(num_classes=3)  # Adjust num_classes as per your model\n",
        "    # Simulate loading pre-trained weights (these weights should be replaced with actual weights)\n",
        "    state_dict = model.state_dict()\n",
        "    for key in state_dict:\n",
        "        state_dict[key] = torch.randn(state_dict[key].shape)\n",
        "    model.load_state_dict(state_dict)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# Initialize the model\n",
        "model = load_model()\n",
        "\n",
        "# Prediction function\n",
        "def predict(sentence):\n",
        "    inputs = tokenizer(sentence, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "    return predicted.item()\n",
        "\n",
        "# Streamlit application\n",
        "st.title(\"French Sentence Difficulty Predictor\")\n",
        "\n",
        "input_sentence = st.text_area(\"Enter a French sentence:\", \"\")\n",
        "\n",
        "if st.button(\"Predict Difficulty\"):\n",
        "    if input_sentence:\n",
        "        difficulty = predict(input_sentence)\n",
        "        st.write(f\"The predicted difficulty level is: {difficulty}\")\n",
        "    else:\n",
        "        st.write(\"Please enter a sentence.\")\n",
        "\n",
        "# Step 3: Run the Streamlit application and expose it using Localtunnel\n",
        "import subprocess\n",
        "import threading\n",
        "\n",
        "# Function to run Streamlit app\n",
        "def run_streamlit():\n",
        "    subprocess.run([\"streamlit\", \"run\", \"app.py\"])\n",
        "\n",
        "# Function to run localtunnel\n",
        "def run_localtunnel():\n",
        "    subprocess.run([\"lt\", \"--port\", \"8501\"])\n",
        "\n",
        "# Start Streamlit in a new thread\n",
        "threading.Thread(target=run_streamlit).start()\n",
        "\n",
        "# Start localtunnel in the main thread\n",
        "run_localtunnel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "741f44b9-d30a-4205-fb90-670bcc7677e1",
        "id": "Yi6Oqq0n1BDI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import torch\n",
        "from transformers import CamembertTokenizer, CamembertModel\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the model architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Net, self).__init__()\n",
        "        self.camembert = CamembertModel.from_pretrained('camembert-base')\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        self.fc = nn.Linear(self.camembert.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        outputs = self.camembert(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.last_hidden_state[:, 0]\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.fc(pooled_output)\n",
        "        return logits\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
        "\n",
        "# Function to load the model from pre-trained weights\n",
        "def load_model():\n",
        "    model = Net(num_classes=3)  # Adjust num_classes as per your model\n",
        "    # Simulate loading pre-trained weights (these weights should be replaced with actual weights)\n",
        "    # Here I'm initializing random weights as placeholders\n",
        "    state_dict = model.state_dict()\n",
        "    for key in state_dict:\n",
        "        state_dict[key] = torch.randn(state_dict[key].shape)\n",
        "    model.load_state_dict(state_dict)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# Initialize the model\n",
        "model = load_model()\n",
        "\n",
        "# Prediction function\n",
        "def predict(sentence):\n",
        "    inputs = tokenizer(sentence, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "    return predicted.item()\n",
        "\n",
        "# Streamlit application\n",
        "st.title(\"French Sentence Difficulty Predictor\")\n",
        "\n",
        "input_sentence = st.text_area(\"Enter a French sentence:\", \"\")\n",
        "\n",
        "if st.button(\"Predict Difficulty\"):\n",
        "    if input_sentence:\n",
        "        difficulty = predict(input_sentence)\n",
        "        st.write(f\"The predicted difficulty level is: {difficulty}\")\n",
        "    else:\n",
        "        st.write(\"Please enter a sentence.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "outputId": "e1a79d8d-1a32-4508-92a3-6bec14e45b38",
        "id": "D3m2FCeu1F0T"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:pyngrok.process.ngrok:t=2024-05-21T21:08:56+0000 lvl=eror msg=\"failed to reconnect session\" obj=tunnels.session err=\"authentication failed: Your account is limited to 1 simultaneous ngrok agent sessions.\\nYou can run multiple tunnels on a single agent session using a configuration file.\\nTo learn more, see https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config/\\nYou can view your current agent sessions in the dashboard:\\nhttps://dashboard.ngrok.com/tunnels/agents\\r\\n\\r\\nERR_NGROK_108\\r\\n\"\n",
            "ERROR:pyngrok.process.ngrok:t=2024-05-21T21:08:56+0000 lvl=eror msg=\"session closing\" obj=tunnels.session err=\"authentication failed: Your account is limited to 1 simultaneous ngrok agent sessions.\\nYou can run multiple tunnels on a single agent session using a configuration file.\\nTo learn more, see https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config/\\nYou can view your current agent sessions in the dashboard:\\nhttps://dashboard.ngrok.com/tunnels/agents\\r\\n\\r\\nERR_NGROK_108\\r\\n\"\n"
          ]
        },
        {
          "ename": "PyngrokNgrokError",
          "evalue": "The ngrok process errored on start: authentication failed: Your account is limited to 1 simultaneous ngrok agent sessions.\\nYou can run multiple tunnels on a single agent session using a configuration file.\\nTo learn more, see https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config/\\nYou can view your current agent sessions in the dashboard:\\nhttps://dashboard.ngrok.com/tunnels/agents\\r\\n\\r\\nERR_NGROK_108\\r\\n.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPyngrokNgrokError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-eb2784c228cd>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Create a new tunnel to the Streamlit app\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mpublic_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mngrok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'8501'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Streamlit app is running at: {public_url}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(addr, proto, name, pyngrok_config, **options)\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"auth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mapi_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ngrok_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Creating tunnel with options: {options}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mget_ngrok_process\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0minstall_ngrok\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyngrok/process.py\u001b[0m in \u001b[0;36mget_process\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_current_processes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngrok_path\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_start_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyngrok/process.py\u001b[0m in \u001b[0;36m_start_process\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mngrok_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartup_error\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m             raise PyngrokNgrokError(f\"The ngrok process errored on start: {ngrok_process.startup_error}.\",\n\u001b[0m\u001b[1;32m    399\u001b[0m                                     \u001b[0mngrok_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m                                     ngrok_process.startup_error)\n",
            "\u001b[0;31mPyngrokNgrokError\u001b[0m: The ngrok process errored on start: authentication failed: Your account is limited to 1 simultaneous ngrok agent sessions.\\nYou can run multiple tunnels on a single agent session using a configuration file.\\nTo learn more, see https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config/\\nYou can view your current agent sessions in the dashboard:\\nhttps://dashboard.ngrok.com/tunnels/agents\\r\\n\\r\\nERR_NGROK_108\\r\\n."
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Terminate open tunnels if any\n",
        "ngrok.kill()\n",
        "\n",
        "# Create a new tunnel to the Streamlit app\n",
        "public_url = ngrok.connect(port='8501')\n",
        "print(f\"Streamlit app is running at: {public_url}\")\n",
        "\n",
        "# Run the Streamlit app\n",
        "!streamlit run app.py --server.port 8501"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "641a7871-aa25-421d-afb9-9d724af11f36",
        "id": "0PilMUez1VLk"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Code Server can be accessed on: NgrokTunnel: \"https://f5d5-34-125-46-126.ngrok-free.app\" -> \"http://localhost:8501\"\n",
            "[2024-05-21T22:37:35.567Z] info  code-server 3.10.2 387b12ef4ca404ffd39d84834e1f0776e9e3c005\n",
            "[2024-05-21T22:37:35.568Z] info  Using user-data-dir ~/.local/share/code-server\n",
            "[2024-05-21T22:37:35.580Z] info  Using config file ~/.config/code-server/config.yaml\n",
            "[2024-05-21T22:37:35.580Z] info  HTTP server listening on http://127.0.0.1:8501 \n",
            "[2024-05-21T22:37:35.580Z] info    - Authentication is disabled \n",
            "[2024-05-21T22:37:35.580Z] info    - Not serving HTTPS \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2024-05-21T22:43:08+0000 lvl=warn msg=\"Stopping forwarder\" name=http-8501-6a9979d9-8b44-4826-addd-afe72e8ed8a4 acceptErr=\"failed to accept connection: Listener closed\"\n"
          ]
        }
      ],
      "source": [
        "from colabcode import ColabCode\n",
        "\n",
        "ColabCode(port=8501)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f04fe50-6c5d-4c0f-8f3f-7665891af3e4",
        "id": "IB7GHIuQ1b90"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "import streamlit as st\n",
        "import torch\n",
        "from transformers import CamembertTokenizer, CamembertModel\n",
        "import torch.nn as nn\n",
        "\n",
        "# Load the tokenizer with special tokens\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
        "special_tokens_dict = {'additional_special_tokens': ['<special1>', '<special2>', '<special3>']}\n",
        "num_added_tokens = tokenizer.add_special_tokens(special_tokens_dict)\n",
        "\n",
        "# Ensure the model is aware of the additional special tokens\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Net, self).__init__()\n",
        "        self.camembert = CamembertModel.from_pretrained('camembert-base')\n",
        "        self.camembert.resize_token_embeddings(len(tokenizer))  # Resize for added tokens\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        self.fc = nn.Linear(self.camembert.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        outputs = self.camembert(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.last_hidden_state[:, 0]  # Use the [CLS] token output\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.fc(pooled_output)\n",
        "        return logits\n",
        "\n",
        "# Load the trained model (assuming it's saved as 'trained_model.pth')\n",
        "model = Net(num_classes=6)  # Adjust num_classes according to your problem\n",
        "\n",
        "# Load the state dictionary\n",
        "state_dict = torch.load('trained_model.pth', map_location=torch.device('cpu'))\n",
        "\n",
        "# Remove embedding layer weights to avoid size mismatch\n",
        "state_dict = {k: v for k, v in state_dict.items() if 'embeddings.word_embeddings.weight' not in k}\n",
        "\n",
        "# Load the state dictionary into the model\n",
        "model.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "# Initialize embeddings for the new tokens\n",
        "with torch.no_grad():\n",
        "    model.camembert.embeddings.word_embeddings.weight[-num_added_tokens:] = torch.nn.init.normal_(\n",
        "        model.camembert.embeddings.word_embeddings.weight[-num_added_tokens:], mean=0.0, std=0.02\n",
        "    )\n",
        "\n",
        "# Optionally, fine-tune the model (especially the embeddings) here if needed\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# Define the function to make predictions\n",
        "def predict_difficulty(sentence):\n",
        "    tokens = tokenizer(sentence, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
        "    input_ids = tokens['input_ids']\n",
        "    attention_mask = tokens['attention_mask']\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "    return predicted.item()\n",
        "\n",
        "# Streamlit UI\n",
        "st.title(\"French Text Difficulty Predictor\")\n",
        "\n",
        "st.write(\"Enter a French sentence to get its predicted difficulty level.\")\n",
        "\n",
        "# Input text box\n",
        "user_input = st.text_area(\"Enter a French sentence here:\")\n",
        "\n",
        "# Predict button\n",
        "if st.button(\"Predict Difficulty\"):\n",
        "    if user_input.strip() != \"\":\n",
        "        difficulty = predict_difficulty(user_input)\n",
        "        st.write(f\"The predicted difficulty level is: {difficulty}\")\n",
        "    else:\n",
        "        st.write(\"Please enter a sentence to get a prediction.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gvP3IG-Tz0-M"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "sCiUF3R_Xgrv"
      ],
      "gpuType": "L4",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0088be2426ce4cd1a2b9f71a0a0b0db0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00b42491f4874a9c8ecc7a0731ff71f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f89ba3c6e424402bb86432af3336a344",
            "max": 49,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ce028bf6abf4c3c931a6b5e5d495c21",
            "value": 49
          }
        },
        "00dff373ee7f4ae9b73c0016ec233fc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "028481c4bda74a7280205b85607cef0b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02b3f3ec396b4d9fb83e7f7ab71a152e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "039d9d0079474cb899b534691772e6a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03df6020b9fb4cfb8a9436b7dd2b7274": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33af99d83f994fdda5f1a1241a26c190",
            "placeholder": "​",
            "style": "IPY_MODEL_ce796738f25343e78d409a021715d663",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "0479589e2aba47ef929237d770561c2f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "047f5fd326c6414f96534d2c97b62f49": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff751d73142a474f9492d39405fade5a",
            "max": 293,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_69dd0ab2f5d74b9680a959f1b0337a00",
            "value": 293
          }
        },
        "04aca5f66c684f39b2742519560baa9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d0a2f4d256634c0696903e352e56e03c",
              "IPY_MODEL_e00f07e0811248818d963346a3e7287b",
              "IPY_MODEL_30d84510e0bb4d1a882dabc918790244"
            ],
            "layout": "IPY_MODEL_745f71a5292740d2a179bb267a8f46d2"
          }
        },
        "04e003b0f12e49098a395b4260e9ec0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6071e861d2874599bbb1b5fd846f2de9",
            "placeholder": "​",
            "style": "IPY_MODEL_f771564397d14268ada62260c8fdb988",
            "value": " 301M/301M [00:00&lt;00:00, 369MB/s]"
          }
        },
        "050800caa8014720af48cdb1de2671ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "057dbe930e0a4cee8a0f045a95a38792": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06c3b38b34b74557965a5d3375af6988": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1ad3750865249b2b8cff9207f9f31eb",
            "max": 995526,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f2170cf01f0d4dbf8b629ed7077b3ddc",
            "value": 995526
          }
        },
        "0741703d2f9b47499c10dcb799d72018": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a28f43e991248a6b0be274a8f20c7fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff4a1cefcd5d4ea69bcde8b043022b6f",
              "IPY_MODEL_dbb5e146d066417f9381965e22c6e00d",
              "IPY_MODEL_43bf11b0de1d4e8aab6198f5225a7fa4"
            ],
            "layout": "IPY_MODEL_ed7eb56c48354fd181d675ee17dc9f93"
          }
        },
        "0b1fc2176c5a484399eab063c0bd8ce6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ecbd800a7fb4f2b877e844a4adfba51",
            "max": 1339166,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_da2cbcf72a104d8e856df39892c1c5ee",
            "value": 1339166
          }
        },
        "0c100b1cb0434c59a01559933bdca8a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c26626bbb524c39afc8b079298af14d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_525f64f9f111410382068a541695fc6e",
            "max": 810912,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_673af21beafb488c8b5e9352ab6e87de",
            "value": 810912
          }
        },
        "0d89b2e47c01462ca86e6981425db5a6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d997177551741f184ce944fcf635cb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee1a1f2d666f463584615388d62b5b90",
              "IPY_MODEL_49d84830dfe140c59b997545490c8135",
              "IPY_MODEL_17b389aa5b7a4d0ab308f270d4325968"
            ],
            "layout": "IPY_MODEL_733e7d4ca03e42c59a7fe6241c3cc811"
          }
        },
        "0e31839ec3434ec0a01fabf1f8b736d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0efa9e0210044ff89d86b7067c7948c0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fd90e7057fa4ee19ad655a51c1c5a04": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0fe1a474db1e418daf1aa30382f2a0c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "110a1dfd0b34463b843f2f54c6bacc38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1130c12930d14c66b030f9ff0638cea6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c7de9c797d94fd7a8059d272a36a19f",
              "IPY_MODEL_4a3e7f230a9d43d7a1c41bf02e657955",
              "IPY_MODEL_f8b324d5d073416788a43d426fbb303a"
            ],
            "layout": "IPY_MODEL_2266f232cb1f4be7872c1d0584c04114"
          }
        },
        "117d626f10c543c6b3bfe1af9f056d0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11919ce42d134a218b3b196efdaf7fa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "11b563ebd7e943eda2b7e27a8ad5fdff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3b4b36e27524eb1b0718ad3244db173",
            "placeholder": "​",
            "style": "IPY_MODEL_ad15f2602a254a29949ad322e92efeb5",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "123cfb18260948009985d261cfc83cc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6368e7349e2c4e8d8709c6ff91b70b66",
            "placeholder": "​",
            "style": "IPY_MODEL_86239162c28a4d1192f3560dda05dc72",
            "value": " 508/508 [00:00&lt;00:00, 30.1kB/s]"
          }
        },
        "12c6f2f9686447b298976e84e42889e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13f3530bada04e50a50644afc933748b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1dee23b3f9eb4f4ba878f518320f4fee",
            "placeholder": "​",
            "style": "IPY_MODEL_73efcbc4b2894ee980eca7d5f24e7713",
            "value": " 1.40M/1.40M [00:00&lt;00:00, 7.05MB/s]"
          }
        },
        "14a3dc73bf114e58afc4b2c4c3628e5c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14c875b5b2de45e0af89707288046a7b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14d2eb31a64347a3a90bf7169bcda0d7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14d3ae72e40840188233db05b65630c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_519fe5b6e8444644bcfdbf4166e4edb3",
              "IPY_MODEL_7082c620549a4fc68033f31693396ac5",
              "IPY_MODEL_49896401ae9348c6ab7135a0d5b952bf"
            ],
            "layout": "IPY_MODEL_e7ae1a52cc97461797ed17465774837f"
          }
        },
        "152df182e7554fb28d517fe4a18554cd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "154748aa7f9d45c5aafdd6758fa31c47": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15694bd160124faa9eb30a0aeb02814b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15fe3e21451f48d9b55c810e53f492bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3bf28038bca43f0bda96355362a2497",
            "placeholder": "​",
            "style": "IPY_MODEL_55901e6a3f064b199d7026c8c40fca1f",
            "value": "vocab.txt: 100%"
          }
        },
        "16ac0aaf191a4ad5a24479afd8d37e31": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16af1834d27e41a985cfdd0657d3e890": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16d07f9b06b84ae0a0fb7acb1aeaab29": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16e7f1bbb20449bc8677d3bffacc4f70": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_03df6020b9fb4cfb8a9436b7dd2b7274",
              "IPY_MODEL_7c152e069bba4e0eb1de42faab91d848",
              "IPY_MODEL_d82b07ee90694fdeaacb483f4b534c47"
            ],
            "layout": "IPY_MODEL_bbd2c4291bc2438e93e4f17a8cfcb37d"
          }
        },
        "1787a7547d60489c9b9a31bfdda86d42": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17b389aa5b7a4d0ab308f270d4325968": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cbb26bf22b04717b1cab9bacea6a431",
            "placeholder": "​",
            "style": "IPY_MODEL_23c9ce071f7d49bfb177176be045f071",
            "value": " 996k/996k [00:00&lt;00:00, 7.51MB/s]"
          }
        },
        "18069acb3863421b8ba614b4f1fcebd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c934d421b0c4174b752c0b07f8f5905",
            "max": 802397,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_535e8a26e58e4b599a01014f6875be21",
            "value": 802397
          }
        },
        "18cb6d3a1d274f2e98ce466cc29f66b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5aa05a77f8f4e978eb3b2964f4ff9a1",
            "placeholder": "​",
            "style": "IPY_MODEL_5a2fa119b8d24e04a10d2194e3f1623d",
            "value": " 996k/996k [00:00&lt;00:00, 11.1MB/s]"
          }
        },
        "18d7b41b5fec41d185aeaebb0db970a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19ca3426bf69495f8d67e19fdbd5b17e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b93d98d00b34563b14ecadc3826f375": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1bae5abd6768461184549f532662d159": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b462f2effb9b429bb9365e86c35da020",
            "placeholder": "​",
            "style": "IPY_MODEL_9f55ed964e924124bacf1707d6f4ea10",
            "value": " 293/293 [00:00&lt;00:00, 27.8kB/s]"
          }
        },
        "1dee23b3f9eb4f4ba878f518320f4fee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f4bc8f9fc7e468e8d47d9dd54eb9c4c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fa9b3101d7f4f31a1dae7fe0fd23c42": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20308d0c810d4ca088cd3a2ca81e62e4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20c51a5214b54517bf2daad06c4c969d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21809437c894423db07fc234828352f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "218514e1177a43b78fd77d7c0336bc3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21ce2b1bab4542979184c77d9a016900": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2203950bfbb24db698311e4e1834cfe7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2249e3b13960470e93ae2a6defe61921": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2266f232cb1f4be7872c1d0584c04114": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23154509673847f4888e6342615ea9ec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2366427b387d4cf6973a0683a235ef46": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "23c9ce071f7d49bfb177176be045f071": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23f14973b04a48a19d26ac12bd621e97": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "240034f8394d4a46975a9a352f4cad4a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2465f1f8b12e41139d23abb12dbf4b7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d420e46be3c4899a70fa2313c05bbd2",
            "placeholder": "​",
            "style": "IPY_MODEL_050800caa8014720af48cdb1de2671ec",
            "value": " 25.0/25.0 [00:00&lt;00:00, 1.54kB/s]"
          }
        },
        "246f403d7227470dab948e25aeb52d76": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2499e308249a4d99bea3a08dc0ed3a29": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24c0f46a606b4782ba7b02ec6ef4f362": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd266b4f83154b6d872dde6ea7509e5e",
            "max": 42,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8c141d6676734e0db79b529daef2ce0a",
            "value": 42
          }
        },
        "2521d9c52112458f98c0ecfc72515c07": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2569e46aee614620bda857a6f8c9238d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25b94efbf7eb4704a22b8b18db661738": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_31cc8566ae7d4ff18ad882eb7428329e",
              "IPY_MODEL_b2479957f07b4d0faa50805c69857115",
              "IPY_MODEL_42fb3a0ef512430c8605c7bcc0c3878a"
            ],
            "layout": "IPY_MODEL_8b8d286a58404563bc7250bcd2f24bbb"
          }
        },
        "25dd612ccbe64b07ab8b7330f73b791b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed801dc178e0420498e5a715866063b2",
            "placeholder": "​",
            "style": "IPY_MODEL_715c0adcfc4549c8aa065038575b8634",
            "value": "tokenizer.json: 100%"
          }
        },
        "2608a62f05b5468b931f92146acf78b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27aa70f4dc8644d8b9ed174714775034": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa6e9998b0e14b26b49df2205b678e62",
            "placeholder": "​",
            "style": "IPY_MODEL_71363cfce17249688c2877847f25dcc6",
            "value": "tokenizer.json: 100%"
          }
        },
        "27d059e1b3b5417092017c57b201afad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a45b7227a9464f518c5072beadf83ba8",
            "max": 1961828,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f95aaf44f1294c24a849f16fcacfb598",
            "value": 1961828
          }
        },
        "2872e30171c84ed0b84cd7ab1291eb86": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29475d1918994a93a1d7469475281f19": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29d5f76c80f34da8b76d2154e477a42c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d986eb5036e458aaa9f4e49a4992031",
            "placeholder": "​",
            "style": "IPY_MODEL_8f8595c3cc654402bf82202b19482010",
            "value": " 49.0/49.0 [00:00&lt;00:00, 4.19kB/s]"
          }
        },
        "29f2a5738dc24d54aa34b067c7efb21e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f77add20ab84acd81fbf7d24d1f128e",
            "max": 293,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3a28c86be0d848f98e254305d14c5314",
            "value": 293
          }
        },
        "2a0e6ad5d3064cb0a8dda8ac70da75b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2a87f4fb419646b5a4df6df533b83d98": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b92ae8d24ca414e8936c1513b2dd0a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8d2a14f795c40c9a6884f7d49536d6f",
            "placeholder": "​",
            "style": "IPY_MODEL_12c6f2f9686447b298976e84e42889e3",
            "value": " 1.42k/1.42k [00:00&lt;00:00, 77.1kB/s]"
          }
        },
        "2bcbd5c7edec4d4ea2802449bcf8d10a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe15371c1ae8470cbe8e460201caba4a",
            "placeholder": "​",
            "style": "IPY_MODEL_57700dc2c7bd4dd18c686cbb7f4777b0",
            "value": "target.spm: 100%"
          }
        },
        "2bf90794afd6486882e36d8d3153afd9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c4f90a5b4c6431989d94e668b313706": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4052d33a69cb47e18c8d60d57332c4a9",
            "placeholder": "​",
            "style": "IPY_MODEL_e37e996517794c8092bd48622c3abb5d",
            "value": "vocab.txt: 100%"
          }
        },
        "2c50e03eacc8464f99df9d541956a128": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2cb4531602fc4f09b4c2097f1e2de0e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2cea345d24bf45e6b20e68a43dacd97a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6b7cd0cf19842cdb7f97d6ab790f87b",
            "max": 802397,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aebc5e8f1dbd450bae21d9fb6b61b008",
            "value": 802397
          }
        },
        "2d63d281516c4e81a1c24d652451eca9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e6ab4e304b64f24b63f3ad1f32ddd87": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2edfafd89835485482b9997c0a8ab664": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f4bd19638694fe09a070bd9c94baab6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30130fbe60844b5d8af3d4f5b236bb2b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3091dda380e141eb84e05577da6b4f45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "309a5e254dce4d4f8e050bcef9dc34cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30d84510e0bb4d1a882dabc918790244": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8acf7afd6b6b474ca58d104e0d2ad138",
            "placeholder": "​",
            "style": "IPY_MODEL_64d504ae9d8340a893bfc5e92c3245b6",
            "value": " 811k/811k [00:00&lt;00:00, 4.16MB/s]"
          }
        },
        "3161fb79e454458e8e04d495d39b0931": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba2bf1ddb0704b4dabbc2c69718bc019",
            "placeholder": "​",
            "style": "IPY_MODEL_95b348efac9d4302a940e453535838cd",
            "value": "tokenizer.json: 100%"
          }
        },
        "31cc8566ae7d4ff18ad882eb7428329e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16af1834d27e41a985cfdd0657d3e890",
            "placeholder": "​",
            "style": "IPY_MODEL_444a13a1aed24d27a491d1242d78253e",
            "value": "model.safetensors: 100%"
          }
        },
        "327cc60a92cd494fb7c5518c70ff6dce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "333db846091a423c8ee45db90f383450": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55041bb27a6b463fa7ba5585fc9c18c6",
            "placeholder": "​",
            "style": "IPY_MODEL_00dff373ee7f4ae9b73c0016ec233fc2",
            "value": "config.json: 100%"
          }
        },
        "3376e11e43df4d08bb96331f09afa7d7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33af99d83f994fdda5f1a1241a26c190": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33c9234ae412435cb350679e044f5c89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8216f129dc7047bca0313f481a566756",
            "placeholder": "​",
            "style": "IPY_MODEL_2cb4531602fc4f09b4c2097f1e2de0e2",
            "value": "tokenizer.json: 100%"
          }
        },
        "34a7060692d3465a9ce48b0c9cf5da25": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_057dbe930e0a4cee8a0f045a95a38792",
            "placeholder": "​",
            "style": "IPY_MODEL_3091dda380e141eb84e05577da6b4f45",
            "value": "config.json: 100%"
          }
        },
        "351e2d7494d54e648d1e317eb621deae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "355cdea776c14bfab32cfd15a2df2f55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30130fbe60844b5d8af3d4f5b236bb2b",
            "placeholder": "​",
            "style": "IPY_MODEL_aa4a80ec971546cf9e1359f5c865f3ec",
            "value": " 1.40M/1.40M [00:00&lt;00:00, 5.76MB/s]"
          }
        },
        "370253c6b9f543d29c3f2a3a58236701": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "376c4f5326684376bd3b818e0e4ec229": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3799f431f18143e68ec99ec35eb0c3ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37ed2172611940d086bcc085733c5886": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_869322f910994dfeb7bfa9a40f2a8643",
              "IPY_MODEL_a36834daea9e41608dc85778132f9bfe",
              "IPY_MODEL_a17d73c0392c4e07b2d3fff7ca773c0b"
            ],
            "layout": "IPY_MODEL_2499e308249a4d99bea3a08dc0ed3a29"
          }
        },
        "37f63104ecc543fc9431364fd4f1909d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38c036ce3e864f56a4e4c4082edd56f4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38d6dcb350d441e89fde65659be5af80": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "39d58cd0398b481e8dcb6f1363694f2e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a28c86be0d848f98e254305d14c5314": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3a9ca0401ec249aa825409f8fb44137c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57095b1ee01542358895ab9b1bd29499",
            "max": 1395301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0fd90e7057fa4ee19ad655a51c1c5a04",
            "value": 1395301
          }
        },
        "3aac719891f84df384e10741d6c74761": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ab36bfbda27453cbbde4c3458efc38f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b59a07648d34de1bfa22778d456fc70": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a41717fd78f54b9e95944d964f525cf0",
              "IPY_MODEL_0c26626bbb524c39afc8b079298af14d",
              "IPY_MODEL_97b75e666f384c39ac197271bdc505b3"
            ],
            "layout": "IPY_MODEL_d833d52f441a41768b9af91734900719"
          }
        },
        "3b90e766e3de4de681af63d313102329": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e90526d4b9e749f68a30363580a2f3c5",
            "placeholder": "​",
            "style": "IPY_MODEL_117d626f10c543c6b3bfe1af9f056d0b",
            "value": " 1.96M/1.96M [00:00&lt;00:00, 6.82MB/s]"
          }
        },
        "3d3211a97a744e4b9db5eadabb378d21": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d5da44d9f024f7a897b3116b630e0e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d7ee66c65f1496ab8e786545375c296": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e21ca738a5e42a295c58bd8f5febf83": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e9d8ffb1f674bd6a4f78154c498a6e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ecbd800a7fb4f2b877e844a4adfba51": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f3688f0308b441c810734bba50383aa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f59e6c6861b4cdf98c0793fbe074c87": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d91964e9b594ddcbb92182bfb7fbd34",
            "max": 1416,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bb69938a62454f2d84cfcc2bdd101ef3",
            "value": 1416
          }
        },
        "3f5f5aca0a34471f88e4b729015a78b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8d0e6919cf24b54b27831c0a494dbe2",
            "placeholder": "​",
            "style": "IPY_MODEL_bcb0d278d0db428e953766f078fa60c9",
            "value": "model.safetensors: 100%"
          }
        },
        "4052d33a69cb47e18c8d60d57332c4a9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "424abf6ce1e64c59a2116a2d20dd550e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be7832305adc466a9a02d09819f2e250",
              "IPY_MODEL_6b1d4be047954999b55514b680a2fbda",
              "IPY_MODEL_2465f1f8b12e41139d23abb12dbf4b7d"
            ],
            "layout": "IPY_MODEL_ac1e94d8a5fb485dbbfc754596ee8986"
          }
        },
        "428bb56d6e0043bf84001674096e7a74": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42fb3a0ef512430c8605c7bcc0c3878a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_822701c880be41e6a3bc4da402ca34b3",
            "placeholder": "​",
            "style": "IPY_MODEL_a6916484459d49cfbe5d50b634e40cdf",
            "value": " 445M/445M [00:02&lt;00:00, 221MB/s]"
          }
        },
        "43ab2c3b82624ac2b496ce87a335e9f9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43bf11b0de1d4e8aab6198f5225a7fa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7481059fbbfc41e591703849f61d2333",
            "placeholder": "​",
            "style": "IPY_MODEL_4dbb9eade36348e9af8882d207d83bc6",
            "value": " 508/508 [00:00&lt;00:00, 47.3kB/s]"
          }
        },
        "441821564d3c49f99e1faadb88c1bf86": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "442d1021dbcf43d3a034eb2630033781": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93f2b91d76084556b0da56866ceba7d0",
            "placeholder": "​",
            "style": "IPY_MODEL_77e5ee20cb8948c78cfd3b65c6395f9b",
            "value": "source.spm: 100%"
          }
        },
        "444a13a1aed24d27a491d1242d78253e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "450ba73092c7406ab649703a1a79d7bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db73637221c8473cbced109994759c92",
            "max": 1961828,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cb6fc0d1e65a4099ac0bd38edbeda90f",
            "value": 1961828
          }
        },
        "45bd53997eec46799b01790396581881": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b0b44e138e524b77b6dc379d3c1c2494",
              "IPY_MODEL_18069acb3863421b8ba614b4f1fcebd1",
              "IPY_MODEL_e8343a0f28974f19a1f6032ad63574d3"
            ],
            "layout": "IPY_MODEL_29475d1918994a93a1d7469475281f19"
          }
        },
        "47f319f363b64f0d90d3bf1e348be474": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23154509673847f4888e6342615ea9ec",
            "max": 714290682,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5fa30489cc254748962ede4d3024e37b",
            "value": 714290682
          }
        },
        "47f716f8c9e24eecbd6baceb2963ffd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cffdd21282ef495da58c634d5ff05aa1",
              "IPY_MODEL_6551cf9d7ab4444a88ebd6b615bfd373",
              "IPY_MODEL_ce119c52402444b6bf3fe138704d3814"
            ],
            "layout": "IPY_MODEL_37f63104ecc543fc9431364fd4f1909d"
          }
        },
        "49056a1aed1249719285c61683189b2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_68750d3063634f4b82efabf29a564d8e",
              "IPY_MODEL_e1b42517261f4584aff2e2be818b7cf8",
              "IPY_MODEL_ee1f2384bd2b4059a5d5df7feaeede87"
            ],
            "layout": "IPY_MODEL_828da0e1d5c340c5b6e34aba7c0bd1e9"
          }
        },
        "49896401ae9348c6ab7135a0d5b952bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0479589e2aba47ef929237d770561c2f",
            "placeholder": "​",
            "style": "IPY_MODEL_19ca3426bf69495f8d67e19fdbd5b17e",
            "value": " 625/625 [00:00&lt;00:00, 40.2kB/s]"
          }
        },
        "49cb86fd7de14fbebb80df731983954f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49d84830dfe140c59b997545490c8135": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff9b14aa8c354f43855cda0f33fe25cf",
            "max": 995526,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aa036fb1cb9c4c3a8a6ff99444509de6",
            "value": 995526
          }
        },
        "49d9dfa8f98340dea6b73c7e4ae77b4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a3e7f230a9d43d7a1c41bf02e657955": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76165cb68ebd42ea90d6c7d76e8b4bcf",
            "max": 714290682,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f13020bc47314a23ae7ae571d5bb3e75",
            "value": 714290682
          }
        },
        "4a68543a6e5b4287b958f7f00a4faade": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5767cd3738d54b8c8219b0bb67baa0f2",
            "max": 300827685,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7b68962035b2411891b6bdff1bc0aa4e",
            "value": 300827685
          }
        },
        "4ad9feb9ce8443f79948cf934304c17e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4beff63d28b940edae9e88f7a290f2dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4c4e12c6d0ba4103aba64f7f96aea2d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_33c9234ae412435cb350679e044f5c89",
              "IPY_MODEL_3a9ca0401ec249aa825409f8fb44137c",
              "IPY_MODEL_355cdea776c14bfab32cfd15a2df2f55"
            ],
            "layout": "IPY_MODEL_9bc783ec821d4830ad340d0fadb70f61"
          }
        },
        "4cc9f3ec455a4467b512e5510d274e9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d218f659c5c44f8adb585545c345a82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4dbb9eade36348e9af8882d207d83bc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4eef5874d04b4e259b77d11972ac1c97": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e190e6fec4f54cb8a569fad79691b31f",
              "IPY_MODEL_2cea345d24bf45e6b20e68a43dacd97a",
              "IPY_MODEL_960919cf9bb74641b28051fc356617ee"
            ],
            "layout": "IPY_MODEL_65354227bdd34a73ac09d86e91628bc9"
          }
        },
        "4f843ee40d7b43e0afd215fde18d76a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50b72575a341423296027982812af8c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50c55f07006048588ad9473625a3b43d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "50cc0d88ff84476d96c5da46a90839ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_333db846091a423c8ee45db90f383450",
              "IPY_MODEL_f452c875be6e44e88701ad0a83050005",
              "IPY_MODEL_123cfb18260948009985d261cfc83cc2"
            ],
            "layout": "IPY_MODEL_67d7f3e8fb314b79a169ab2c80f2faf7"
          }
        },
        "519fe5b6e8444644bcfdbf4166e4edb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e787f0154dfb40cd84ed2a3c442a4afb",
            "placeholder": "​",
            "style": "IPY_MODEL_dbb7704e3df142d19a0eb254062ee895",
            "value": "config.json: 100%"
          }
        },
        "51a3901b53a2400f8f20486de44a0674": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51d6f1ea3d0b441c9f3de2ef43a35e69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "525f64f9f111410382068a541695fc6e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52b478d3a29b4af69ccb21b6a8c1fb75": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f5f5aca0a34471f88e4b729015a78b1",
              "IPY_MODEL_47f319f363b64f0d90d3bf1e348be474",
              "IPY_MODEL_93b4c007f19b4d6996e38333fccb9a4e"
            ],
            "layout": "IPY_MODEL_79e3f40d1fc64e408c897f06bc24d303"
          }
        },
        "535e8a26e58e4b599a01014f6875be21": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "54986b4cf12e427db5774d6367ac468b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54d6bff4f2c04110bb3079cfc3f50b69": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55041bb27a6b463fa7ba5585fc9c18c6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55901e6a3f064b199d7026c8c40fca1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "564d52f9e7f84d0bb01047d1b6122f0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "56fcea3c78ee427daf57f10bfe879a64": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_028481c4bda74a7280205b85607cef0b",
            "max": 995526,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_564d52f9e7f84d0bb01047d1b6122f0a",
            "value": 995526
          }
        },
        "57095b1ee01542358895ab9b1bd29499": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5721cdbe865d44dc8c0c81c83230d70f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5767cd3738d54b8c8219b0bb67baa0f2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57700dc2c7bd4dd18c686cbb7f4777b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "578bb5a6f30e40b89baa2bb0de4b09a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_849ce637a0f64025a1339ef9d0b48466",
            "placeholder": "​",
            "style": "IPY_MODEL_72e5f7fae28048f0ab030fdc55f35544",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "58a6dee75512466f959e1c63d5dde5d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5a2fa119b8d24e04a10d2194e3f1623d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a9fbf48949b4c7a81ac431e36bd0536": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_578bb5a6f30e40b89baa2bb0de4b09a2",
              "IPY_MODEL_00b42491f4874a9c8ecc7a0731ff71f6",
              "IPY_MODEL_29d5f76c80f34da8b76d2154e477a42c"
            ],
            "layout": "IPY_MODEL_b892fdc138ff4ec5a0e93a910772db60"
          }
        },
        "5cbb26bf22b04717b1cab9bacea6a431": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ce537839ff74df1abc99aa05ccdf5a1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cf21325905243b6b12b9926965c4954": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6621f0fba8ed4fada476021607f61d4e",
            "max": 1339166,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fa8603735825495683c9864e9b2b386a",
            "value": 1339166
          }
        },
        "5d2c0602638a44b6ad8f30788a095daa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f7b4b85edd341c4a55436795358f328",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6b1a08de92324d399461688098db2855",
            "value": 25
          }
        },
        "5f7b4b85edd341c4a55436795358f328": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fa30489cc254748962ede4d3024e37b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ff17650b7374eeb8c7f70ec1e68cea4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "602f28ba1fd34221a661e44f0aca6c72": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9bc6c3f266ac449dba4951e12fa24860",
            "placeholder": "​",
            "style": "IPY_MODEL_6d2ce9499fe64d4998ae36279967e820",
            "value": "generation_config.json: 100%"
          }
        },
        "6071e861d2874599bbb1b5fd846f2de9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61365492dcb34eba86a47724baf81fca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "615b32bc3a9b4a88bad394596866bd87": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "633afddd380a401088af5580a2068aa0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6368e7349e2c4e8d8709c6ff91b70b66": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "636f68e313284fd1aca6dc1fcdf0f2b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49cb86fd7de14fbebb80df731983954f",
            "placeholder": "​",
            "style": "IPY_MODEL_f6e93cda2ab04dd3a2e730d540407bb7",
            "value": "config.json: 100%"
          }
        },
        "639d22a637754f558ff0701d0921ccb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2203950bfbb24db698311e4e1834cfe7",
            "placeholder": "​",
            "style": "IPY_MODEL_aa1f0ee78ad24b72990e75a3563ff081",
            "value": " 1.34M/1.34M [00:00&lt;00:00, 11.3MB/s]"
          }
        },
        "63e4ba002dcd49eab7bdec55894b9966": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "649255caee1c4cfa91d2658cb1c843d7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64d504ae9d8340a893bfc5e92c3245b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64eca053fbad4119ac97e8ab09711b4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_376c4f5326684376bd3b818e0e4ec229",
            "placeholder": "​",
            "style": "IPY_MODEL_fffadb74a2974676ad614a7a26dd11af",
            "value": "config.json: 100%"
          }
        },
        "65354227bdd34a73ac09d86e91628bc9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6551cf9d7ab4444a88ebd6b615bfd373": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7279fd8f57f242c4913f9a6865eefe63",
            "max": 445008750,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51d6f1ea3d0b441c9f3de2ef43a35e69",
            "value": 445008750
          }
        },
        "658b80da5dd14af0a20b12b22fa9b8f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6621f0fba8ed4fada476021607f61d4e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "673af21beafb488c8b5e9352ab6e87de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "67d7f3e8fb314b79a169ab2c80f2faf7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68750d3063634f4b82efabf29a564d8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ce537839ff74df1abc99aa05ccdf5a1",
            "placeholder": "​",
            "style": "IPY_MODEL_e256643bd7ac497bb72cdcfeaede545d",
            "value": "model.safetensors: 100%"
          }
        },
        "69621f20d31d4e91a647b8027519cd57": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69dd0ab2f5d74b9680a959f1b0337a00": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6a15d394c8b44d308b372260d0ddba6c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b1a08de92324d399461688098db2855": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6b1d4be047954999b55514b680a2fbda": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ad9feb9ce8443f79948cf934304c17e",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_38d6dcb350d441e89fde65659be5af80",
            "value": 25
          }
        },
        "6c0ffd1bf2ee4427b84165e16f4589b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_11b563ebd7e943eda2b7e27a8ad5fdff",
              "IPY_MODEL_7603024b2d7d48768e2c12a18030813c",
              "IPY_MODEL_844fbcd3090d44b8b3902c445de92e51"
            ],
            "layout": "IPY_MODEL_0088be2426ce4cd1a2b9f71a0a0b0db0"
          }
        },
        "6c4f20d4b4d44690b34fea75bfe79b92": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c71b891e62e4beb99ac75683b1277d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c4f20d4b4d44690b34fea75bfe79b92",
            "placeholder": "​",
            "style": "IPY_MODEL_8841989b4b45491b909f8dec565b326f",
            "value": "config.json: 100%"
          }
        },
        "6c7de9c797d94fd7a8059d272a36a19f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c42c474b89d24ccbb3cc3080135fe171",
            "placeholder": "​",
            "style": "IPY_MODEL_3d5da44d9f024f7a897b3116b630e0e5",
            "value": "model.safetensors: 100%"
          }
        },
        "6d2ce9499fe64d4998ae36279967e820": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e0f7d8592dd4e858b2a48e55eb11152": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e250655f9cb41bd91a93a781dab3a79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18d7b41b5fec41d185aeaebb0db970a2",
            "max": 300827685,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_21809437c894423db07fc234828352f8",
            "value": 300827685
          }
        },
        "6ea5ac60df5c4f74b42cddf86780dc5e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f1e3fecc7754a289affb11874e84f84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20308d0c810d4ca088cd3a2ca81e62e4",
            "placeholder": "​",
            "style": "IPY_MODEL_2249e3b13960470e93ae2a6defe61921",
            "value": " 996k/996k [00:00&lt;00:00, 5.82MB/s]"
          }
        },
        "7082c620549a4fc68033f31693396ac5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0665233909c4eaa8269e68337ace1d8",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b5dd3b86a0324936a657cd2614e43cbc",
            "value": 625
          }
        },
        "70eb7399947943b4a98c68832abd5974": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "71363cfce17249688c2877847f25dcc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "715c0adcfc4549c8aa065038575b8634": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71a3313a543e4e449184f16a367e1191": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d63d281516c4e81a1c24d652451eca9",
            "placeholder": "​",
            "style": "IPY_MODEL_4cc9f3ec455a4467b512e5510d274e9b",
            "value": " 625/625 [00:00&lt;00:00, 60.0kB/s]"
          }
        },
        "7279fd8f57f242c4913f9a6865eefe63": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7281536743ae46868819e1ce5607f172": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72e5f7fae28048f0ab030fdc55f35544": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "733e7d4ca03e42c59a7fe6241c3cc811": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73918b48058743aa9fb6dc0ce84599ef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73a425f8b2374ad3904cb0d299bf554d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c1ea6112c5064b568ea64981f78aa72b",
              "IPY_MODEL_27d059e1b3b5417092017c57b201afad",
              "IPY_MODEL_792b9fadded045ed9f59bb30bef7e56a"
            ],
            "layout": "IPY_MODEL_61365492dcb34eba86a47724baf81fca"
          }
        },
        "73bac6f7c34748749c765e32f8c1ca33": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "73efcbc4b2894ee980eca7d5f24e7713": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "740a0f0618e345498bfd20e491f3e6cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9a31171c73b452abd8abcbecf30f55e",
            "placeholder": "​",
            "style": "IPY_MODEL_b1ede2668e744aeb94c8c57ce3a64bb3",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "745f71a5292740d2a179bb267a8f46d2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7481059fbbfc41e591703849f61d2333": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7603024b2d7d48768e2c12a18030813c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7710ac86579e4f4789b651c930a51e5d",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4beff63d28b940edae9e88f7a290f2dc",
            "value": 25
          }
        },
        "76165cb68ebd42ea90d6c7d76e8b4bcf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7710ac86579e4f4789b651c930a51e5d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77e5ee20cb8948c78cfd3b65c6395f9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "792b9fadded045ed9f59bb30bef7e56a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39d58cd0398b481e8dcb6f1363694f2e",
            "placeholder": "​",
            "style": "IPY_MODEL_615b32bc3a9b4a88bad394596866bd87",
            "value": " 1.96M/1.96M [00:00&lt;00:00, 26.8MB/s]"
          }
        },
        "793e8ee59ae6492599d45eba1a2b3b25": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "79e3f40d1fc64e408c897f06bc24d303": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b11bc4dfdc645e38fb551e4e001a6ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b2d1c0bb1e243a1ac0053c3bf9f9a79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43ab2c3b82624ac2b496ce87a335e9f9",
            "placeholder": "​",
            "style": "IPY_MODEL_ff7b4f20988a41dfb540ef07b6b827ee",
            "value": " 25.0/25.0 [00:00&lt;00:00, 1.89kB/s]"
          }
        },
        "7b35f2114aa340188599c49212356532": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b68962035b2411891b6bdff1bc0aa4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7c152e069bba4e0eb1de42faab91d848": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a23552e5ea7841529d1f39a5ea6c17ee",
            "max": 49,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_793e8ee59ae6492599d45eba1a2b3b25",
            "value": 49
          }
        },
        "7c934d421b0c4174b752c0b07f8f5905": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ce028bf6abf4c3c931a6b5e5d495c21": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7d91964e9b594ddcbb92182bfb7fbd34": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d986eb5036e458aaa9f4e49a4992031": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f778c47be514a6e933fd81495993fae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bdbd74c403fc41e6aa868b18616ea561",
              "IPY_MODEL_6e250655f9cb41bd91a93a781dab3a79",
              "IPY_MODEL_04e003b0f12e49098a395b4260e9ec0a"
            ],
            "layout": "IPY_MODEL_9c728bfad6514ce5ad1fbd157b88703b"
          }
        },
        "800ef3027cbb451a9fb11e2673ace0aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14c875b5b2de45e0af89707288046a7b",
            "placeholder": "​",
            "style": "IPY_MODEL_110a1dfd0b34463b843f2f54c6bacc38",
            "value": " 508/508 [00:00&lt;00:00, 41.2kB/s]"
          }
        },
        "81b2d289ee0349dfb7ff05c8b571db95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ab36bfbda27453cbbde4c3458efc38f",
            "max": 508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3e9d8ffb1f674bd6a4f78154c498a6e7",
            "value": 508
          }
        },
        "81fb36edca0440ca975a20c5f40d25fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_602f28ba1fd34221a661e44f0aca6c72",
              "IPY_MODEL_047f5fd326c6414f96534d2c97b62f49",
              "IPY_MODEL_c991cd32e3dc457481510ef439e423f9"
            ],
            "layout": "IPY_MODEL_2bf90794afd6486882e36d8d3153afd9"
          }
        },
        "8204179b49f640a69c38bcfd71b4f118": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_27aa70f4dc8644d8b9ed174714775034",
              "IPY_MODEL_dfebd435f93a4525a1303dbcf45ab479",
              "IPY_MODEL_13f3530bada04e50a50644afc933748b"
            ],
            "layout": "IPY_MODEL_d4e6b7e32fa847b8827ad176b78c7385"
          }
        },
        "8216f129dc7047bca0313f481a566756": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "822701c880be41e6a3bc4da402ca34b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "828da0e1d5c340c5b6e34aba7c0bd1e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "838ea3137ea743aba873e07bb0e33705": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_25dd612ccbe64b07ab8b7330f73b791b",
              "IPY_MODEL_f2333f78fef54d3c9805ca1f963a9e3c",
              "IPY_MODEL_a4a544b5e9214bb6990e7f40a5050ad1"
            ],
            "layout": "IPY_MODEL_ea5c65d03f5f4aec9d697aa05c74a609"
          }
        },
        "844fbcd3090d44b8b3902c445de92e51": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a87f4fb419646b5a4df6df533b83d98",
            "placeholder": "​",
            "style": "IPY_MODEL_370253c6b9f543d29c3f2a3a58236701",
            "value": " 25.0/25.0 [00:00&lt;00:00, 1.91kB/s]"
          }
        },
        "849ce637a0f64025a1339ef9d0b48466": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86239162c28a4d1192f3560dda05dc72": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "869322f910994dfeb7bfa9a40f2a8643": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa2036691ef14b1d92ffba863d4917f1",
            "placeholder": "​",
            "style": "IPY_MODEL_16d07f9b06b84ae0a0fb7acb1aeaab29",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "87ea1f911a3649e3b3e86a0f06512447": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d12838d898aa4d489433da4ff14c628f",
            "placeholder": "​",
            "style": "IPY_MODEL_e47fabb291b249cd986eec928e8adbb2",
            "value": "generation_config.json: 100%"
          }
        },
        "8841989b4b45491b909f8dec565b326f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8863cbd44cc74ac1b82cb9f2f21305cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "894f118579224248b487140efd8f2bb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_740a0f0618e345498bfd20e491f3e6cd",
              "IPY_MODEL_5d2c0602638a44b6ad8f30788a095daa",
              "IPY_MODEL_7b2d1c0bb1e243a1ac0053c3bf9f9a79"
            ],
            "layout": "IPY_MODEL_d2a6a5faebc945dab8d90e4cef24d920"
          }
        },
        "89d9aa8acd7c4aedbdbd4b9e14c8777f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a3588d837dc4464aa63d322404b3c7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e99ac145af504eff8d93aff9cf069804",
              "IPY_MODEL_4a68543a6e5b4287b958f7f00a4faade",
              "IPY_MODEL_d6c059eb91c243659aa7792ae6a891d3"
            ],
            "layout": "IPY_MODEL_0741703d2f9b47499c10dcb799d72018"
          }
        },
        "8acf7afd6b6b474ca58d104e0d2ad138": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b8d286a58404563bc7250bcd2f24bbb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c141d6676734e0db79b529daef2ce0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8cc41d5ee8664be7adfc6b73364d9267": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8eedf2034fe74614a70cf7b41966f998": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a15d394c8b44d308b372260d0ddba6c",
            "placeholder": "​",
            "style": "IPY_MODEL_0e31839ec3434ec0a01fabf1f8b736d8",
            "value": "vocab.json: 100%"
          }
        },
        "8f77add20ab84acd81fbf7d24d1f128e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f8595c3cc654402bf82202b19482010": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8fcd39fb7e2c4ad0ab38cc7cc53a7629": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "904d8a2592d148ec882d02982a47798e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91cb7aa53be044d4a7e4d4c5fa8bb718": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8eedf2034fe74614a70cf7b41966f998",
              "IPY_MODEL_5cf21325905243b6b12b9926965c4954",
              "IPY_MODEL_b71b066eef32495abe841df9a887d5f5"
            ],
            "layout": "IPY_MODEL_649255caee1c4cfa91d2658cb1c843d7"
          }
        },
        "9271015749c941fb83cb95f1a84c1948": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_442d1021dbcf43d3a034eb2630033781",
              "IPY_MODEL_ab76fd5397034320bec56b5dbe07ab66",
              "IPY_MODEL_b7edc3ca5a544a9db4c180bc1cbe2238"
            ],
            "layout": "IPY_MODEL_a81398fa32b642569a62ec41ad082d76"
          }
        },
        "93b4c007f19b4d6996e38333fccb9a4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3aac719891f84df384e10741d6c74761",
            "placeholder": "​",
            "style": "IPY_MODEL_2c50e03eacc8464f99df9d541956a128",
            "value": " 714M/714M [00:02&lt;00:00, 264MB/s]"
          }
        },
        "93f2b91d76084556b0da56866ceba7d0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94e6df7f5e38417ebc0849ce8b264740": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95b348efac9d4302a940e453535838cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "960919cf9bb74641b28051fc356617ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_633afddd380a401088af5580a2068aa0",
            "placeholder": "​",
            "style": "IPY_MODEL_218514e1177a43b78fd77d7c0336bc3e",
            "value": " 802k/802k [00:00&lt;00:00, 12.4MB/s]"
          }
        },
        "97b75e666f384c39ac197271bdc505b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc4ce59a74204a68b10aab0bbc430420",
            "placeholder": "​",
            "style": "IPY_MODEL_7b35f2114aa340188599c49212356532",
            "value": " 811k/811k [00:00&lt;00:00, 27.4MB/s]"
          }
        },
        "9b65f4101c804dc2976447e49673815e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bc6c3f266ac449dba4951e12fa24860": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bc783ec821d4830ad340d0fadb70f61": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c6ec5d73f0344039e7aed059a23c4ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c728bfad6514ce5ad1fbd157b88703b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d420e46be3c4899a70fa2313c05bbd2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f55ed964e924124bacf1707d6f4ea10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a17d73c0392c4e07b2d3fff7ca773c0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b299692b07c645cb8f5d1aa0f341b0a5",
            "placeholder": "​",
            "style": "IPY_MODEL_f18d53f2b04549d7ac4ed3faf4dd10bf",
            "value": " 42.0/42.0 [00:00&lt;00:00, 3.67kB/s]"
          }
        },
        "a1f739f2e26f46d6b9f38fbad9fd8dbd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a23552e5ea7841529d1f39a5ea6c17ee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a275227406194bf0b472ee05a2b5fb7f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a344e0188fc84435a1ee41eb322a0f78": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a36834daea9e41608dc85778132f9bfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fe1a474db1e418daf1aa30382f2a0c5",
            "max": 42,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e3193ebeec5842539d4af3f8335241ee",
            "value": 42
          }
        },
        "a3ce64d8a56e43a78358452e7da8c3fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a41717fd78f54b9e95944d964f525cf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d3211a97a744e4b9db5eadabb378d21",
            "placeholder": "​",
            "style": "IPY_MODEL_327cc60a92cd494fb7c5518c70ff6dce",
            "value": "sentencepiece.bpe.model: 100%"
          }
        },
        "a45b7227a9464f518c5072beadf83ba8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4a544b5e9214bb6990e7f40a5050ad1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f3688f0308b441c810734bba50383aa",
            "placeholder": "​",
            "style": "IPY_MODEL_154748aa7f9d45c5aafdd6758fa31c47",
            "value": " 1.96M/1.96M [00:00&lt;00:00, 5.90MB/s]"
          }
        },
        "a63997fc448e44968c7193a90b086c3c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a666ddc5b55c4475a04102b693d81e29": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0d0ea71bc2d4cec95fa17d84912174e",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ed2e478e462b46dfb343195bb675bf72",
            "value": 625
          }
        },
        "a6916484459d49cfbe5d50b634e40cdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a81398fa32b642569a62ec41ad082d76": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8371995491645cc9b4a70495ba2fec4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8aeb7e9805c47a79b9e160c505b804b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c2c3af897eb4407a81f0be34616fb76f",
              "IPY_MODEL_aaa1153086dc46b9b4bd9cc8eefb9a01",
              "IPY_MODEL_f0551774a16441b79e5fead5f07c2677"
            ],
            "layout": "IPY_MODEL_1fa9b3101d7f4f31a1dae7fe0fd23c42"
          }
        },
        "a90693ce3adf414ba5a4850a59708db0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a994f6bbfd7f4d1589cef3933ac6fbf9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa036fb1cb9c4c3a8a6ff99444509de6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aa1f0ee78ad24b72990e75a3563ff081": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa4a80ec971546cf9e1359f5c865f3ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa6e9998b0e14b26b49df2205b678e62": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aaa1153086dc46b9b4bd9cc8eefb9a01": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16ac0aaf191a4ad5a24479afd8d37e31",
            "max": 810912,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4d218f659c5c44f8adb585545c345a82",
            "value": 810912
          }
        },
        "aac7c9859dbe405b8caa9b3842ee6ab4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_351e2d7494d54e648d1e317eb621deae",
            "placeholder": "​",
            "style": "IPY_MODEL_e0442cf2921f4a588c140d5ae4d1ab99",
            "value": "config.json: 100%"
          }
        },
        "ab1d5a31230449bda7e527c6e6458bed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab76fd5397034320bec56b5dbe07ab66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69621f20d31d4e91a647b8027519cd57",
            "max": 778395,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_50c55f07006048588ad9473625a3b43d",
            "value": 778395
          }
        },
        "abc29061ec0d4e3d86067f54883113a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2c4f90a5b4c6431989d94e668b313706",
              "IPY_MODEL_56fcea3c78ee427daf57f10bfe879a64",
              "IPY_MODEL_6f1e3fecc7754a289affb11874e84f84"
            ],
            "layout": "IPY_MODEL_b031c7275bc64c8fa22aa0a1ac8c9421"
          }
        },
        "abec94fd8b59494fafb3c518afbdb1e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3161fb79e454458e8e04d495d39b0931",
              "IPY_MODEL_fa4c45903e7a4b0fae62b4fa7feb06c3",
              "IPY_MODEL_fccc75bb64b14e8492a1cfab2a372728"
            ],
            "layout": "IPY_MODEL_e6adfea04dac40109af4005bdb8360b7"
          }
        },
        "ac1ab4a39a0b47c488109cccaa4028c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ac1e94d8a5fb485dbbfc754596ee8986": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac730df0bcb14d5aacb7801b05a0b7c9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac730faf81e843b6bb66909f505cb567": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad15f2602a254a29949ad322e92efeb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "add9dcb5a4b34c0c960cc22032881dfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae3f511422f54645aeb6e07b77b395c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87ea1f911a3649e3b3e86a0f06512447",
              "IPY_MODEL_29f2a5738dc24d54aa34b067c7efb21e",
              "IPY_MODEL_1bae5abd6768461184549f532662d159"
            ],
            "layout": "IPY_MODEL_f63374756893458d84c3e3176e030bf5"
          }
        },
        "ae5792751cfd494d8247f8e294011c9a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aebc5e8f1dbd450bae21d9fb6b61b008": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af7f2c6e9cb04b788e524d1a8e0a6022": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b031c7275bc64c8fa22aa0a1ac8c9421": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0b44e138e524b77b6dc379d3c1c2494": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8ac6b820be442568d35ebc0d7f39432",
            "placeholder": "​",
            "style": "IPY_MODEL_0c100b1cb0434c59a01559933bdca8a3",
            "value": "target.spm: 100%"
          }
        },
        "b10c15429c3f427c9f8b047b4e366ac8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c71b891e62e4beb99ac75683b1277d2",
              "IPY_MODEL_3f59e6c6861b4cdf98c0793fbe074c87",
              "IPY_MODEL_2b92ae8d24ca414e8936c1513b2dd0a1"
            ],
            "layout": "IPY_MODEL_02b3f3ec396b4d9fb83e7f7ab71a152e"
          }
        },
        "b1ede2668e744aeb94c8c57ce3a64bb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2479957f07b4d0faa50805c69857115": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1f739f2e26f46d6b9f38fbad9fd8dbd",
            "max": 445008750,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_11919ce42d134a218b3b196efdaf7fa1",
            "value": 445008750
          }
        },
        "b299692b07c645cb8f5d1aa0f341b0a5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b32f918873454449bb1c5f2dd754512f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d120a4af777640b9b4791f13262b7e20",
            "placeholder": "​",
            "style": "IPY_MODEL_2edfafd89835485482b9997c0a8ab664",
            "value": " 42.0/42.0 [00:00&lt;00:00, 3.83kB/s]"
          }
        },
        "b353b163ea324e29ac11b05e7a35d997": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3bf28038bca43f0bda96355362a2497": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b462f2effb9b429bb9365e86c35da020": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4f87c27fc6343d18b71adc829c1ae4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1787a7547d60489c9b9a31bfdda86d42",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ac1ab4a39a0b47c488109cccaa4028c5",
            "value": 625
          }
        },
        "b5dd3b86a0324936a657cd2614e43cbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b69ba8fc455d45b49934405030b6d4f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8371995491645cc9b4a70495ba2fec4",
            "max": 49,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_58a6dee75512466f959e1c63d5dde5d9",
            "value": 49
          }
        },
        "b6b7cd0cf19842cdb7f97d6ab790f87b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b71b066eef32495abe841df9a887d5f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e478945824b1482abd980721967c2444",
            "placeholder": "​",
            "style": "IPY_MODEL_49d9dfa8f98340dea6b73c7e4ae77b4f",
            "value": " 1.34M/1.34M [00:00&lt;00:00, 7.59MB/s]"
          }
        },
        "b71d47dfd19f4826909e46bf8f4b987a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7edc3ca5a544a9db4c180bc1cbe2238": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f4bc8f9fc7e468e8d47d9dd54eb9c4c",
            "placeholder": "​",
            "style": "IPY_MODEL_3e21ca738a5e42a295c58bd8f5febf83",
            "value": " 778k/778k [00:00&lt;00:00, 6.53MB/s]"
          }
        },
        "b892fdc138ff4ec5a0e93a910772db60": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8d0e6919cf24b54b27831c0a494dbe2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba2bf1ddb0704b4dabbc2c69718bc019": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb69938a62454f2d84cfcc2bdd101ef3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bbd2c4291bc2438e93e4f17a8cfcb37d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcb0d278d0db428e953766f078fa60c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd1c33d4719d4caf9070c59b6f1cea45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bdbd74c403fc41e6aa868b18616ea561": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b65f4101c804dc2976447e49673815e",
            "placeholder": "​",
            "style": "IPY_MODEL_8cc41d5ee8664be7adfc6b73364d9267",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "be7832305adc466a9a02d09819f2e250": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e30da31ab6eb4560ba7a674ad3e8aa25",
            "placeholder": "​",
            "style": "IPY_MODEL_5721cdbe865d44dc8c0c81c83230d70f",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "bea349bb1ce640c0b9520c4947400d88": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a63997fc448e44968c7193a90b086c3c",
            "max": 778395,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_70eb7399947943b4a98c68832abd5974",
            "value": 778395
          }
        },
        "bfc4fe88a5e74775ad858d13cafd8acb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ea5ac60df5c4f74b42cddf86780dc5e",
            "placeholder": "​",
            "style": "IPY_MODEL_2608a62f05b5468b931f92146acf78b3",
            "value": "vocab.json: 100%"
          }
        },
        "c0665233909c4eaa8269e68337ace1d8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0777279eac94647bbc7e83b83d2b53a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0daf2c9ecca4e57b94a697f87acb1d0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c158850e950945afafa06ba89d96a098": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1ea6112c5064b568ea64981f78aa72b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d56af21f3dc54dde8ca208249591c196",
            "placeholder": "​",
            "style": "IPY_MODEL_e9e93c8339f84085be06c6bbe7d9e28f",
            "value": "tokenizer.json: 100%"
          }
        },
        "c2041fe52c854dd581b1cb83ad478382": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2c3af897eb4407a81f0be34616fb76f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2872e30171c84ed0b84cd7ab1291eb86",
            "placeholder": "​",
            "style": "IPY_MODEL_b353b163ea324e29ac11b05e7a35d997",
            "value": "sentencepiece.bpe.model: 100%"
          }
        },
        "c3b4b36e27524eb1b0718ad3244db173": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c42c474b89d24ccbb3cc3080135fe171": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c489c2aaa0b14f709e5af68e103abb47": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_15fe3e21451f48d9b55c810e53f492bd",
              "IPY_MODEL_06c3b38b34b74557965a5d3375af6988",
              "IPY_MODEL_18cb6d3a1d274f2e98ce466cc29f66b9"
            ],
            "layout": "IPY_MODEL_2f4bd19638694fe09a070bd9c94baab6"
          }
        },
        "c5447064cf004b8691b51d72dfe4387e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2bcbd5c7edec4d4ea2802449bcf8d10a",
              "IPY_MODEL_bea349bb1ce640c0b9520c4947400d88",
              "IPY_MODEL_ce77b7d5debe4e779ff1f4c25829c3fa"
            ],
            "layout": "IPY_MODEL_f994cfba62f34088b9a04e4104e4e713"
          }
        },
        "c6fb23b24ef34f479b8207756e7c2fc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cfe20b1f39dd467eaedbf46fa47de826",
              "IPY_MODEL_b69ba8fc455d45b49934405030b6d4f6",
              "IPY_MODEL_edf58e56404c46c1ad786738d3203705"
            ],
            "layout": "IPY_MODEL_428bb56d6e0043bf84001674096e7a74"
          }
        },
        "c7100dcf5f744f65afb159533579e953": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c8ac6b820be442568d35ebc0d7f39432": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c991cd32e3dc457481510ef439e423f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac730df0bcb14d5aacb7801b05a0b7c9",
            "placeholder": "​",
            "style": "IPY_MODEL_039d9d0079474cb899b534691772e6a6",
            "value": " 293/293 [00:00&lt;00:00, 26.3kB/s]"
          }
        },
        "c9a31171c73b452abd8abcbecf30f55e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9ddddfb44614a66ade3e9daf4860126": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca7a5c1ff379425fba78ad7049a2a5bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_636f68e313284fd1aca6dc1fcdf0f2b8",
              "IPY_MODEL_81b2d289ee0349dfb7ff05c8b571db95",
              "IPY_MODEL_800ef3027cbb451a9fb11e2673ace0aa"
            ],
            "layout": "IPY_MODEL_54d6bff4f2c04110bb3079cfc3f50b69"
          }
        },
        "cb6fc0d1e65a4099ac0bd38edbeda90f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ce119c52402444b6bf3fe138704d3814": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cefee8f9f3d04237be793c61ebd0ea44",
            "placeholder": "​",
            "style": "IPY_MODEL_f0fbb2b1156f44c7b49cb183e91fff7b",
            "value": " 445M/445M [00:01&lt;00:00, 409MB/s]"
          }
        },
        "ce77b7d5debe4e779ff1f4c25829c3fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21ce2b1bab4542979184c77d9a016900",
            "placeholder": "​",
            "style": "IPY_MODEL_ab1d5a31230449bda7e527c6e6458bed",
            "value": " 778k/778k [00:00&lt;00:00, 19.7MB/s]"
          }
        },
        "ce796738f25343e78d409a021715d663": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cefee8f9f3d04237be793c61ebd0ea44": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf24c9a510354af5a2cac21e1697432b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bfc4fe88a5e74775ad858d13cafd8acb",
              "IPY_MODEL_0b1fc2176c5a484399eab063c0bd8ce6",
              "IPY_MODEL_639d22a637754f558ff0701d0921ccb4"
            ],
            "layout": "IPY_MODEL_2569e46aee614620bda857a6f8c9238d"
          }
        },
        "cf576f998f25435dbe5eb8b2cd92acf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aac7c9859dbe405b8caa9b3842ee6ab4",
              "IPY_MODEL_d04974052992476eb09ad74e4a2c692f",
              "IPY_MODEL_f5b2e3b82a4342e0884cb84ecc4a41e5"
            ],
            "layout": "IPY_MODEL_c2041fe52c854dd581b1cb83ad478382"
          }
        },
        "cfe20b1f39dd467eaedbf46fa47de826": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c6ec5d73f0344039e7aed059a23c4ad",
            "placeholder": "​",
            "style": "IPY_MODEL_2521d9c52112458f98c0ecfc72515c07",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "cffdd21282ef495da58c634d5ff05aa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14a3dc73bf114e58afc4b2c4c3628e5c",
            "placeholder": "​",
            "style": "IPY_MODEL_3d7ee66c65f1496ab8e786545375c296",
            "value": "model.safetensors: 100%"
          }
        },
        "d01c0222af9e4c62adafd7a8318626f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d04974052992476eb09ad74e4a2c692f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f843ee40d7b43e0afd215fde18d76a0",
            "max": 1416,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_89d9aa8acd7c4aedbdbd4b9e14c8777f",
            "value": 1416
          }
        },
        "d0a2f4d256634c0696903e352e56e03c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c158850e950945afafa06ba89d96a098",
            "placeholder": "​",
            "style": "IPY_MODEL_8fcd39fb7e2c4ad0ab38cc7cc53a7629",
            "value": "sentencepiece.bpe.model: 100%"
          }
        },
        "d120a4af777640b9b4791f13262b7e20": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d12838d898aa4d489433da4ff14c628f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d22992858d2145da90a4a2650476100e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e6ab4e304b64f24b63f3ad1f32ddd87",
            "placeholder": "​",
            "style": "IPY_MODEL_bd1c33d4719d4caf9070c59b6f1cea45",
            "value": "tokenizer.json: 100%"
          }
        },
        "d2a6a5faebc945dab8d90e4cef24d920": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4402f0782f34a02a89ff41f16fa78d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f938a61a322d4609ad25202c67e1c9e5",
              "IPY_MODEL_24c0f46a606b4782ba7b02ec6ef4f362",
              "IPY_MODEL_b32f918873454449bb1c5f2dd754512f"
            ],
            "layout": "IPY_MODEL_ae5792751cfd494d8247f8e294011c9a"
          }
        },
        "d4e6b7e32fa847b8827ad176b78c7385": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d56af21f3dc54dde8ca208249591c196": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5aa05a77f8f4e978eb3b2964f4ff9a1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6c059eb91c243659aa7792ae6a891d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94e6df7f5e38417ebc0849ce8b264740",
            "placeholder": "​",
            "style": "IPY_MODEL_c0777279eac94647bbc7e83b83d2b53a",
            "value": " 301M/301M [00:02&lt;00:00, 140MB/s]"
          }
        },
        "d6d7cffc7909465fad4767f0b6a71b05": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_34a7060692d3465a9ce48b0c9cf5da25",
              "IPY_MODEL_b4f87c27fc6343d18b71adc829c1ae4b",
              "IPY_MODEL_ed03f3f878894478abd01dc396e6188b"
            ],
            "layout": "IPY_MODEL_14d2eb31a64347a3a90bf7169bcda0d7"
          }
        },
        "d82b07ee90694fdeaacb483f4b534c47": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a994f6bbfd7f4d1589cef3933ac6fbf9",
            "placeholder": "​",
            "style": "IPY_MODEL_5ff17650b7374eeb8c7f70ec1e68cea4",
            "value": " 49.0/49.0 [00:00&lt;00:00, 4.39kB/s]"
          }
        },
        "d833d52f441a41768b9af91734900719": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da2cbcf72a104d8e856df39892c1c5ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db73637221c8473cbced109994759c92": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbb5e146d066417f9381965e22c6e00d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20c51a5214b54517bf2daad06c4c969d",
            "max": 508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2a0e6ad5d3064cb0a8dda8ac70da75b9",
            "value": 508
          }
        },
        "dbb7704e3df142d19a0eb254062ee895": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dfebd435f93a4525a1303dbcf45ab479": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7281536743ae46868819e1ce5607f172",
            "max": 1395301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2366427b387d4cf6973a0683a235ef46",
            "value": 1395301
          }
        },
        "e00f07e0811248818d963346a3e7287b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af7f2c6e9cb04b788e524d1a8e0a6022",
            "max": 810912,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7b11bc4dfdc645e38fb551e4e001a6ce",
            "value": 810912
          }
        },
        "e0442cf2921f4a588c140d5ae4d1ab99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0d0ea71bc2d4cec95fa17d84912174e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e190e6fec4f54cb8a569fad79691b31f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0efa9e0210044ff89d86b7067c7948c0",
            "placeholder": "​",
            "style": "IPY_MODEL_add9dcb5a4b34c0c960cc22032881dfb",
            "value": "source.spm: 100%"
          }
        },
        "e1ad3750865249b2b8cff9207f9f31eb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1b42517261f4584aff2e2be818b7cf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8863cbd44cc74ac1b82cb9f2f21305cb",
            "max": 445008750,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c7100dcf5f744f65afb159533579e953",
            "value": 445008750
          }
        },
        "e256643bd7ac497bb72cdcfeaede545d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e30da31ab6eb4560ba7a674ad3e8aa25": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3193ebeec5842539d4af3f8335241ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e37e996517794c8092bd48622c3abb5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e478945824b1482abd980721967c2444": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e47fabb291b249cd986eec928e8adbb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6adfea04dac40109af4005bdb8360b7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e787f0154dfb40cd84ed2a3c442a4afb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7ae1a52cc97461797ed17465774837f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8343a0f28974f19a1f6032ad63574d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_240034f8394d4a46975a9a352f4cad4a",
            "placeholder": "​",
            "style": "IPY_MODEL_15694bd160124faa9eb30a0aeb02814b",
            "value": " 802k/802k [00:00&lt;00:00, 37.3MB/s]"
          }
        },
        "e90526d4b9e749f68a30363580a2f3c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e99ac145af504eff8d93aff9cf069804": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51a3901b53a2400f8f20486de44a0674",
            "placeholder": "​",
            "style": "IPY_MODEL_d01c0222af9e4c62adafd7a8318626f7",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "e9e93c8339f84085be06c6bbe7d9e28f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea5c65d03f5f4aec9d697aa05c74a609": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed03f3f878894478abd01dc396e6188b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3376e11e43df4d08bb96331f09afa7d7",
            "placeholder": "​",
            "style": "IPY_MODEL_a3ce64d8a56e43a78358452e7da8c3fe",
            "value": " 625/625 [00:00&lt;00:00, 42.1kB/s]"
          }
        },
        "ed2e478e462b46dfb343195bb675bf72": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed7eb56c48354fd181d675ee17dc9f93": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed801dc178e0420498e5a715866063b2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edf58e56404c46c1ad786738d3203705": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38c036ce3e864f56a4e4c4082edd56f4",
            "placeholder": "​",
            "style": "IPY_MODEL_246f403d7227470dab948e25aeb52d76",
            "value": " 49.0/49.0 [00:00&lt;00:00, 3.60kB/s]"
          }
        },
        "ee1a1f2d666f463584615388d62b5b90": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a275227406194bf0b472ee05a2b5fb7f",
            "placeholder": "​",
            "style": "IPY_MODEL_904d8a2592d148ec882d02982a47798e",
            "value": "vocab.txt: 100%"
          }
        },
        "ee1f2384bd2b4059a5d5df7feaeede87": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac730faf81e843b6bb66909f505cb567",
            "placeholder": "​",
            "style": "IPY_MODEL_50b72575a341423296027982812af8c1",
            "value": " 445M/445M [00:01&lt;00:00, 244MB/s]"
          }
        },
        "f0551774a16441b79e5fead5f07c2677": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a344e0188fc84435a1ee41eb322a0f78",
            "placeholder": "​",
            "style": "IPY_MODEL_f472d1be6bdb46ddbf8adc2b44686919",
            "value": " 811k/811k [00:00&lt;00:00, 4.14MB/s]"
          }
        },
        "f0fbb2b1156f44c7b49cb183e91fff7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f13020bc47314a23ae7ae571d5bb3e75": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f18d53f2b04549d7ac4ed3faf4dd10bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2170cf01f0d4dbf8b629ed7077b3ddc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f2333f78fef54d3c9805ca1f963a9e3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9ddddfb44614a66ade3e9daf4860126",
            "max": 1961828,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_73bac6f7c34748749c765e32f8c1ca33",
            "value": 1961828
          }
        },
        "f29d4e9c22144860bfc51775a8331ea7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d22992858d2145da90a4a2650476100e",
              "IPY_MODEL_450ba73092c7406ab649703a1a79d7bd",
              "IPY_MODEL_3b90e766e3de4de681af63d313102329"
            ],
            "layout": "IPY_MODEL_a90693ce3adf414ba5a4850a59708db0"
          }
        },
        "f452c875be6e44e88701ad0a83050005": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3799f431f18143e68ec99ec35eb0c3ab",
            "max": 508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_658b80da5dd14af0a20b12b22fa9b8f1",
            "value": 508
          }
        },
        "f472d1be6bdb46ddbf8adc2b44686919": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5b2e3b82a4342e0884cb84ecc4a41e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73918b48058743aa9fb6dc0ce84599ef",
            "placeholder": "​",
            "style": "IPY_MODEL_309a5e254dce4d4f8e050bcef9dc34cb",
            "value": " 1.42k/1.42k [00:00&lt;00:00, 110kB/s]"
          }
        },
        "f63374756893458d84c3e3176e030bf5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6e93cda2ab04dd3a2e730d540407bb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f771564397d14268ada62260c8fdb988": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f89ba3c6e424402bb86432af3336a344": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f89e4c68308943f29bde2770f9b92db9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f8b324d5d073416788a43d426fbb303a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d89b2e47c01462ca86e6981425db5a6",
            "placeholder": "​",
            "style": "IPY_MODEL_54986b4cf12e427db5774d6367ac468b",
            "value": " 714M/714M [00:02&lt;00:00, 291MB/s]"
          }
        },
        "f8d2a14f795c40c9a6884f7d49536d6f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f938a61a322d4609ad25202c67e1c9e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23f14973b04a48a19d26ac12bd621e97",
            "placeholder": "​",
            "style": "IPY_MODEL_6e0f7d8592dd4e858b2a48e55eb11152",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "f95aaf44f1294c24a849f16fcacfb598": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f994cfba62f34088b9a04e4104e4e713": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9df237cc8ee41b0af6a1673dfd1c3cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_64eca053fbad4119ac97e8ab09711b4e",
              "IPY_MODEL_a666ddc5b55c4475a04102b693d81e29",
              "IPY_MODEL_71a3313a543e4e449184f16a367e1191"
            ],
            "layout": "IPY_MODEL_63e4ba002dcd49eab7bdec55894b9966"
          }
        },
        "fa2036691ef14b1d92ffba863d4917f1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa4c45903e7a4b0fae62b4fa7feb06c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_441821564d3c49f99e1faadb88c1bf86",
            "max": 1395301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f89e4c68308943f29bde2770f9b92db9",
            "value": 1395301
          }
        },
        "fa8603735825495683c9864e9b2b386a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc4ce59a74204a68b10aab0bbc430420": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fccc75bb64b14e8492a1cfab2a372728": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0daf2c9ecca4e57b94a697f87acb1d0",
            "placeholder": "​",
            "style": "IPY_MODEL_b71d47dfd19f4826909e46bf8f4b987a",
            "value": " 1.40M/1.40M [00:00&lt;00:00, 6.07MB/s]"
          }
        },
        "fd266b4f83154b6d872dde6ea7509e5e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe15371c1ae8470cbe8e460201caba4a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff4a1cefcd5d4ea69bcde8b043022b6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_152df182e7554fb28d517fe4a18554cd",
            "placeholder": "​",
            "style": "IPY_MODEL_1b93d98d00b34563b14ecadc3826f375",
            "value": "config.json: 100%"
          }
        },
        "ff751d73142a474f9492d39405fade5a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff7b4f20988a41dfb540ef07b6b827ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff9b14aa8c354f43855cda0f33fe25cf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fffadb74a2974676ad614a7a26dd11af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}